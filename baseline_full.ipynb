{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce75570c-9d4b-480f-908b-334af2001b03",
   "metadata": {},
   "source": [
    "## 准备图片数据集——全量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a0f867-e6e2-42e2-b8ee-1d134c716c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nxy/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/torchvision/transforms/transforms.py:330: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n",
      "begin to transform valid split\n",
      "29806it [01:17, 385.89it/s]\n",
      "finished transforming 29806 images for valid split, the output is saved at /data/nxy/Multimodal_Retrieval/valid\n",
      "begin to transform test split\n",
      "30399it [01:33, 325.81it/s]\n",
      "finished transforming 30399 images for test split, the output is saved at /data/nxy/Multimodal_Retrieval/test\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "!python3 src/preprocess/transform_images_to_npy.py --data_dir ./data/Multimodal_Retrieval --image_resolution 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a13a51-c933-480b-983e-440136ad6599",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ccc0d6-3ed4-454b-a003-5c2d4bffb698",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from src/training/model_configs/ViT-B-16.json\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 | Params:\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   aggregate: True\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   batch_size: 32\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   bert_weight_path: ./weights/pytorch_model.bin\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   beta1: 0.9\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   beta2: 0.98\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   checkpoint_path: ./logs/lr=1e-05_wd=0.001_agg=True_model=ViT-B-16_batchsize=32_date=2022-11-09-13-10-12/checkpoints\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   clip_weight_path: ./weights/ViT-B-16.state_dict.pt\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   copy_codebase: False\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   debug: False\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   dist_backend: nccl\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   dist_url: tcp://127.0.0.1:6100\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   distributed: False\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   dp: False\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   epochs: 10\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   eps: 1e-06\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   gpu: 0\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   log_level: 20\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   log_path: ./logs/lr=1e-05_wd=0.001_agg=True_model=ViT-B-16_batchsize=32_date=2022-11-09-13-10-12/out.log\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   logs: ./logs/\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   lr: 1e-05\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   model: ViT-B-16\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   multigpu: None\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   name: lr=1e-05_wd=0.001_agg=True_model=ViT-B-16_batchsize=32_date=2022-11-09-13-10-12\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   ngpus_per_node: 1\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   precision: amp\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   rank: 0\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   resume: None\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   save_frequency: 2\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   save_most_recent: False\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   skip_aggregate: False\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   skip_scheduler: False\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   train_data: ./data/Multimodal_Retrieval/MR_train_queries.jsonl\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   train_img: /data/nxy/Multimodal_Retrieval/train/\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   use_bn_sync: False\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   val_data: ./data/Multimodal_Retrieval/MR_valid_queries.jsonl\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   val_img: /data/nxy/Multimodal_Retrieval/valid/\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   warmup: 500\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   wd: 0.001\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 |   world_size: 1\n",
      "2022-11-09,13:10:12 | INFO | Rank 0 | Use GPU: 0 for training\n",
      "2022-11-09,13:10:19 | INFO | Rank 0 | Start epoch 0\n",
      "2022-11-09,13:10:23 | INFO | Rank 0 | Train Epoch: 0 [0/250314 (0%)]\tLoss: 5.715866\tData (t) 0.265\tBatch (t) 3.821\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:23 | INFO | Rank 0 | Train Epoch: 0 [32/250314 (0%)]\tLoss: 4.963783\tData (t) 0.230\tBatch (t) 0.403\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:24 | INFO | Rank 0 | Train Epoch: 0 [64/250314 (0%)]\tLoss: 6.101807\tData (t) 0.185\tBatch (t) 0.348\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:24 | INFO | Rank 0 | Train Epoch: 0 [96/250314 (0%)]\tLoss: 6.075851\tData (t) 0.278\tBatch (t) 0.441\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:25 | INFO | Rank 0 | Train Epoch: 0 [128/250314 (0%)]\tLoss: 5.063957\tData (t) 0.280\tBatch (t) 0.495\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:25 | INFO | Rank 0 | Train Epoch: 0 [160/250314 (0%)]\tLoss: 5.260567\tData (t) 0.315\tBatch (t) 0.529\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:25 | INFO | Rank 0 | Train Epoch: 0 [192/250314 (0%)]\tLoss: 5.922144\tData (t) 0.261\tBatch (t) 0.425\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:26 | INFO | Rank 0 | Train Epoch: 0 [224/250314 (0%)]\tLoss: 5.986801\tData (t) 0.247\tBatch (t) 0.453\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:26 | INFO | Rank 0 | Train Epoch: 0 [256/250314 (0%)]\tLoss: 5.350601\tData (t) 0.244\tBatch (t) 0.451\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:27 | INFO | Rank 0 | Train Epoch: 0 [288/250314 (0%)]\tLoss: 5.663986\tData (t) 0.288\tBatch (t) 0.494\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:27 | INFO | Rank 0 | Train Epoch: 0 [320/250314 (0%)]\tLoss: 5.344536\tData (t) 0.292\tBatch (t) 0.499\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:28 | INFO | Rank 0 | Train Epoch: 0 [352/250314 (0%)]\tLoss: 5.374054\tData (t) 0.255\tBatch (t) 0.462\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:28 | INFO | Rank 0 | Train Epoch: 0 [384/250314 (0%)]\tLoss: 5.604370\tData (t) 0.297\tBatch (t) 0.505\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:29 | INFO | Rank 0 | Train Epoch: 0 [416/250314 (0%)]\tLoss: 6.433521\tData (t) 0.262\tBatch (t) 0.469\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:29 | INFO | Rank 0 | Train Epoch: 0 [448/250314 (0%)]\tLoss: 5.937069\tData (t) 0.325\tBatch (t) 0.531\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:30 | INFO | Rank 0 | Train Epoch: 0 [480/250314 (0%)]\tLoss: 5.904579\tData (t) 0.353\tBatch (t) 0.560\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:30 | INFO | Rank 0 | Train Epoch: 0 [512/250314 (0%)]\tLoss: 4.938004\tData (t) 0.323\tBatch (t) 0.531\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:31 | INFO | Rank 0 | Train Epoch: 0 [544/250314 (0%)]\tLoss: 5.855368\tData (t) 0.272\tBatch (t) 0.480\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:31 | INFO | Rank 0 | Train Epoch: 0 [576/250314 (0%)]\tLoss: 5.722633\tData (t) 0.339\tBatch (t) 0.546\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:32 | INFO | Rank 0 | Train Epoch: 0 [608/250314 (0%)]\tLoss: 5.497196\tData (t) 0.231\tBatch (t) 0.437\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:32 | INFO | Rank 0 | Train Epoch: 0 [640/250314 (0%)]\tLoss: 5.549789\tData (t) 0.213\tBatch (t) 0.420\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:33 | INFO | Rank 0 | Train Epoch: 0 [672/250314 (0%)]\tLoss: 5.177605\tData (t) 0.322\tBatch (t) 0.528\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:33 | INFO | Rank 0 | Train Epoch: 0 [704/250314 (0%)]\tLoss: 4.850563\tData (t) 0.220\tBatch (t) 0.427\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:34 | INFO | Rank 0 | Train Epoch: 0 [736/250314 (0%)]\tLoss: 5.447815\tData (t) 0.321\tBatch (t) 0.528\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:34 | INFO | Rank 0 | Train Epoch: 0 [768/250314 (0%)]\tLoss: 5.693390\tData (t) 0.172\tBatch (t) 0.379\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-09,13:10:35 | INFO | Rank 0 | Train Epoch: 0 [800/250314 (0%)]\tLoss: 5.483917\tData (t) 0.306\tBatch (t) 0.514\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:35 | INFO | Rank 0 | Train Epoch: 0 [832/250314 (0%)]\tLoss: 5.153603\tData (t) 0.241\tBatch (t) 0.448\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:36 | INFO | Rank 0 | Train Epoch: 0 [864/250314 (0%)]\tLoss: 6.131702\tData (t) 0.223\tBatch (t) 0.429\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:36 | INFO | Rank 0 | Train Epoch: 0 [896/250314 (0%)]\tLoss: 5.610611\tData (t) 0.212\tBatch (t) 0.419\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:36 | INFO | Rank 0 | Train Epoch: 0 [928/250314 (0%)]\tLoss: 5.986023\tData (t) 0.258\tBatch (t) 0.466\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:37 | INFO | Rank 0 | Train Epoch: 0 [960/250314 (0%)]\tLoss: 4.894676\tData (t) 0.248\tBatch (t) 0.455\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:37 | INFO | Rank 0 | Train Epoch: 0 [992/250314 (0%)]\tLoss: 4.879562\tData (t) 0.205\tBatch (t) 0.412\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:38 | INFO | Rank 0 | Train Epoch: 0 [1024/250314 (0%)]\tLoss: 5.148872\tData (t) 0.255\tBatch (t) 0.462\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:38 | INFO | Rank 0 | Train Epoch: 0 [1056/250314 (0%)]\tLoss: 4.800812\tData (t) 0.270\tBatch (t) 0.476\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:39 | INFO | Rank 0 | Train Epoch: 0 [1088/250314 (0%)]\tLoss: 6.083702\tData (t) 0.301\tBatch (t) 0.508\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:39 | INFO | Rank 0 | Train Epoch: 0 [1120/250314 (0%)]\tLoss: 4.890472\tData (t) 0.323\tBatch (t) 0.530\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:40 | INFO | Rank 0 | Train Epoch: 0 [1152/250314 (0%)]\tLoss: 5.150444\tData (t) 0.250\tBatch (t) 0.457\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:40 | INFO | Rank 0 | Train Epoch: 0 [1184/250314 (0%)]\tLoss: 4.939156\tData (t) 0.210\tBatch (t) 0.417\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:41 | INFO | Rank 0 | Train Epoch: 0 [1216/250314 (0%)]\tLoss: 4.900566\tData (t) 0.367\tBatch (t) 0.574\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:41 | INFO | Rank 0 | Train Epoch: 0 [1248/250314 (0%)]\tLoss: 5.931957\tData (t) 0.326\tBatch (t) 0.533\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:42 | INFO | Rank 0 | Train Epoch: 0 [1280/250314 (1%)]\tLoss: 4.589294\tData (t) 0.258\tBatch (t) 0.466\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:42 | INFO | Rank 0 | Train Epoch: 0 [1312/250314 (1%)]\tLoss: 5.255508\tData (t) 0.273\tBatch (t) 0.480\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:43 | INFO | Rank 0 | Train Epoch: 0 [1344/250314 (1%)]\tLoss: 5.164818\tData (t) 0.222\tBatch (t) 0.429\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:43 | INFO | Rank 0 | Train Epoch: 0 [1376/250314 (1%)]\tLoss: 5.106750\tData (t) 0.218\tBatch (t) 0.425\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:44 | INFO | Rank 0 | Train Epoch: 0 [1408/250314 (1%)]\tLoss: 5.364868\tData (t) 0.258\tBatch (t) 0.465\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:44 | INFO | Rank 0 | Train Epoch: 0 [1440/250314 (1%)]\tLoss: 5.163040\tData (t) 0.272\tBatch (t) 0.479\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:45 | INFO | Rank 0 | Train Epoch: 0 [1472/250314 (1%)]\tLoss: 5.493935\tData (t) 0.239\tBatch (t) 0.446\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:45 | INFO | Rank 0 | Train Epoch: 0 [1504/250314 (1%)]\tLoss: 5.025391\tData (t) 0.373\tBatch (t) 0.581\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:46 | INFO | Rank 0 | Train Epoch: 0 [1536/250314 (1%)]\tLoss: 4.696381\tData (t) 0.242\tBatch (t) 0.450\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:46 | INFO | Rank 0 | Train Epoch: 0 [1568/250314 (1%)]\tLoss: 4.897476\tData (t) 0.274\tBatch (t) 0.481\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:47 | INFO | Rank 0 | Train Epoch: 0 [1600/250314 (1%)]\tLoss: 4.863152\tData (t) 0.284\tBatch (t) 0.492\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:47 | INFO | Rank 0 | Train Epoch: 0 [1632/250314 (1%)]\tLoss: 4.786301\tData (t) 0.255\tBatch (t) 0.463\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:47 | INFO | Rank 0 | Train Epoch: 0 [1664/250314 (1%)]\tLoss: 5.053364\tData (t) 0.286\tBatch (t) 0.493\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:48 | INFO | Rank 0 | Train Epoch: 0 [1696/250314 (1%)]\tLoss: 4.492119\tData (t) 0.292\tBatch (t) 0.501\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:48 | INFO | Rank 0 | Train Epoch: 0 [1728/250314 (1%)]\tLoss: 4.536903\tData (t) 0.262\tBatch (t) 0.470\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:49 | INFO | Rank 0 | Train Epoch: 0 [1760/250314 (1%)]\tLoss: 5.168991\tData (t) 0.250\tBatch (t) 0.458\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:49 | INFO | Rank 0 | Train Epoch: 0 [1792/250314 (1%)]\tLoss: 4.575390\tData (t) 0.299\tBatch (t) 0.507\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:50 | INFO | Rank 0 | Train Epoch: 0 [1824/250314 (1%)]\tLoss: 4.995277\tData (t) 0.273\tBatch (t) 0.481\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:50 | INFO | Rank 0 | Train Epoch: 0 [1856/250314 (1%)]\tLoss: 4.533226\tData (t) 0.242\tBatch (t) 0.449\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:51 | INFO | Rank 0 | Train Epoch: 0 [1888/250314 (1%)]\tLoss: 4.727829\tData (t) 0.255\tBatch (t) 0.463\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:51 | INFO | Rank 0 | Train Epoch: 0 [1920/250314 (1%)]\tLoss: 4.604782\tData (t) 0.233\tBatch (t) 0.441\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:52 | INFO | Rank 0 | Train Epoch: 0 [1952/250314 (1%)]\tLoss: 4.345245\tData (t) 0.243\tBatch (t) 0.450\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:52 | INFO | Rank 0 | Train Epoch: 0 [1984/250314 (1%)]\tLoss: 4.238174\tData (t) 0.236\tBatch (t) 0.444\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:53 | INFO | Rank 0 | Train Epoch: 0 [2016/250314 (1%)]\tLoss: 4.788177\tData (t) 0.286\tBatch (t) 0.494\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:53 | INFO | Rank 0 | Train Epoch: 0 [2048/250314 (1%)]\tLoss: 4.500149\tData (t) 0.237\tBatch (t) 0.446\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:54 | INFO | Rank 0 | Train Epoch: 0 [2080/250314 (1%)]\tLoss: 4.653641\tData (t) 0.254\tBatch (t) 0.462\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:54 | INFO | Rank 0 | Train Epoch: 0 [2112/250314 (1%)]\tLoss: 4.368645\tData (t) 0.218\tBatch (t) 0.426\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:54 | INFO | Rank 0 | Train Epoch: 0 [2144/250314 (1%)]\tLoss: 4.349640\tData (t) 0.255\tBatch (t) 0.463\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:55 | INFO | Rank 0 | Train Epoch: 0 [2176/250314 (1%)]\tLoss: 4.401031\tData (t) 0.263\tBatch (t) 0.471\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:55 | INFO | Rank 0 | Train Epoch: 0 [2208/250314 (1%)]\tLoss: 4.748543\tData (t) 0.285\tBatch (t) 0.493\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:56 | INFO | Rank 0 | Train Epoch: 0 [2240/250314 (1%)]\tLoss: 4.122112\tData (t) 0.275\tBatch (t) 0.483\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:56 | INFO | Rank 0 | Train Epoch: 0 [2272/250314 (1%)]\tLoss: 4.508450\tData (t) 0.313\tBatch (t) 0.521\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:57 | INFO | Rank 0 | Train Epoch: 0 [2304/250314 (1%)]\tLoss: 4.895950\tData (t) 0.355\tBatch (t) 0.563\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:57 | INFO | Rank 0 | Train Epoch: 0 [2336/250314 (1%)]\tLoss: 4.415131\tData (t) 0.267\tBatch (t) 0.475\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-09,13:10:58 | INFO | Rank 0 | Train Epoch: 0 [2368/250314 (1%)]\tLoss: 4.252922\tData (t) 0.266\tBatch (t) 0.475\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:10:58 | INFO | Rank 0 | Train Epoch: 0 [2400/250314 (1%)]\tLoss: 4.530225\tData (t) 0.254\tBatch (t) 0.462\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:10:59 | INFO | Rank 0 | Train Epoch: 0 [2432/250314 (1%)]\tLoss: 4.133621\tData (t) 0.260\tBatch (t) 0.468\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:10:59 | INFO | Rank 0 | Train Epoch: 0 [2464/250314 (1%)]\tLoss: 3.909302\tData (t) 0.266\tBatch (t) 0.474\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:00 | INFO | Rank 0 | Train Epoch: 0 [2496/250314 (1%)]\tLoss: 4.234116\tData (t) 0.331\tBatch (t) 0.540\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:00 | INFO | Rank 0 | Train Epoch: 0 [2528/250314 (1%)]\tLoss: 3.909927\tData (t) 0.292\tBatch (t) 0.500\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:01 | INFO | Rank 0 | Train Epoch: 0 [2560/250314 (1%)]\tLoss: 4.102104\tData (t) 0.291\tBatch (t) 0.498\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:01 | INFO | Rank 0 | Train Epoch: 0 [2592/250314 (1%)]\tLoss: 4.048477\tData (t) 0.214\tBatch (t) 0.422\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:02 | INFO | Rank 0 | Train Epoch: 0 [2624/250314 (1%)]\tLoss: 4.382259\tData (t) 0.276\tBatch (t) 0.484\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:02 | INFO | Rank 0 | Train Epoch: 0 [2656/250314 (1%)]\tLoss: 4.153404\tData (t) 0.292\tBatch (t) 0.500\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:03 | INFO | Rank 0 | Train Epoch: 0 [2688/250314 (1%)]\tLoss: 4.073044\tData (t) 0.250\tBatch (t) 0.458\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:03 | INFO | Rank 0 | Train Epoch: 0 [2720/250314 (1%)]\tLoss: 3.855015\tData (t) 0.239\tBatch (t) 0.447\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:04 | INFO | Rank 0 | Train Epoch: 0 [2752/250314 (1%)]\tLoss: 3.908180\tData (t) 0.238\tBatch (t) 0.448\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:04 | INFO | Rank 0 | Train Epoch: 0 [2784/250314 (1%)]\tLoss: 4.119965\tData (t) 0.220\tBatch (t) 0.430\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:04 | INFO | Rank 0 | Train Epoch: 0 [2816/250314 (1%)]\tLoss: 4.376938\tData (t) 0.221\tBatch (t) 0.429\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:05 | INFO | Rank 0 | Train Epoch: 0 [2848/250314 (1%)]\tLoss: 4.119797\tData (t) 0.287\tBatch (t) 0.496\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:05 | INFO | Rank 0 | Train Epoch: 0 [2880/250314 (1%)]\tLoss: 3.993286\tData (t) 0.278\tBatch (t) 0.487\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:06 | INFO | Rank 0 | Train Epoch: 0 [2912/250314 (1%)]\tLoss: 3.938957\tData (t) 0.316\tBatch (t) 0.525\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:06 | INFO | Rank 0 | Train Epoch: 0 [2944/250314 (1%)]\tLoss: 4.029526\tData (t) 0.308\tBatch (t) 0.516\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:07 | INFO | Rank 0 | Train Epoch: 0 [2976/250314 (1%)]\tLoss: 3.591469\tData (t) 0.232\tBatch (t) 0.441\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:07 | INFO | Rank 0 | Train Epoch: 0 [3008/250314 (1%)]\tLoss: 3.974548\tData (t) 0.244\tBatch (t) 0.453\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:08 | INFO | Rank 0 | Train Epoch: 0 [3040/250314 (1%)]\tLoss: 4.093002\tData (t) 0.271\tBatch (t) 0.479\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:08 | INFO | Rank 0 | Train Epoch: 0 [3072/250314 (1%)]\tLoss: 3.768906\tData (t) 0.298\tBatch (t) 0.507\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:09 | INFO | Rank 0 | Train Epoch: 0 [3104/250314 (1%)]\tLoss: 4.123116\tData (t) 0.284\tBatch (t) 0.493\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:09 | INFO | Rank 0 | Train Epoch: 0 [3136/250314 (1%)]\tLoss: 4.420509\tData (t) 0.296\tBatch (t) 0.504\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:10 | INFO | Rank 0 | Train Epoch: 0 [3168/250314 (1%)]\tLoss: 3.810982\tData (t) 0.306\tBatch (t) 0.514\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:10 | INFO | Rank 0 | Train Epoch: 0 [3200/250314 (1%)]\tLoss: 3.870033\tData (t) 0.286\tBatch (t) 0.495\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:11 | INFO | Rank 0 | Train Epoch: 0 [3232/250314 (1%)]\tLoss: 4.108978\tData (t) 0.271\tBatch (t) 0.479\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:11 | INFO | Rank 0 | Train Epoch: 0 [3264/250314 (1%)]\tLoss: 3.606308\tData (t) 0.265\tBatch (t) 0.474\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:12 | INFO | Rank 0 | Train Epoch: 0 [3296/250314 (1%)]\tLoss: 3.606529\tData (t) 0.288\tBatch (t) 0.497\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:12 | INFO | Rank 0 | Train Epoch: 0 [3328/250314 (1%)]\tLoss: 3.645737\tData (t) 0.228\tBatch (t) 0.437\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:13 | INFO | Rank 0 | Train Epoch: 0 [3360/250314 (1%)]\tLoss: 3.800751\tData (t) 0.280\tBatch (t) 0.488\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:13 | INFO | Rank 0 | Train Epoch: 0 [3392/250314 (1%)]\tLoss: 3.703842\tData (t) 0.331\tBatch (t) 0.539\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:14 | INFO | Rank 0 | Train Epoch: 0 [3424/250314 (1%)]\tLoss: 3.683739\tData (t) 0.284\tBatch (t) 0.493\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:14 | INFO | Rank 0 | Train Epoch: 0 [3456/250314 (1%)]\tLoss: 3.777893\tData (t) 0.242\tBatch (t) 0.451\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:15 | INFO | Rank 0 | Train Epoch: 0 [3488/250314 (1%)]\tLoss: 3.717300\tData (t) 0.217\tBatch (t) 0.426\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:15 | INFO | Rank 0 | Train Epoch: 0 [3520/250314 (1%)]\tLoss: 3.708363\tData (t) 0.297\tBatch (t) 0.506\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:16 | INFO | Rank 0 | Train Epoch: 0 [3552/250314 (1%)]\tLoss: 3.651665\tData (t) 0.264\tBatch (t) 0.473\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:16 | INFO | Rank 0 | Train Epoch: 0 [3584/250314 (1%)]\tLoss: 3.513908\tData (t) 0.302\tBatch (t) 0.511\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:17 | INFO | Rank 0 | Train Epoch: 0 [3616/250314 (1%)]\tLoss: 4.044060\tData (t) 0.285\tBatch (t) 0.494\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:17 | INFO | Rank 0 | Train Epoch: 0 [3648/250314 (1%)]\tLoss: 3.562126\tData (t) 0.288\tBatch (t) 0.497\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:18 | INFO | Rank 0 | Train Epoch: 0 [3680/250314 (1%)]\tLoss: 3.608353\tData (t) 0.289\tBatch (t) 0.497\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:18 | INFO | Rank 0 | Train Epoch: 0 [3712/250314 (1%)]\tLoss: 3.392487\tData (t) 0.243\tBatch (t) 0.451\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:19 | INFO | Rank 0 | Train Epoch: 0 [3744/250314 (1%)]\tLoss: 3.652168\tData (t) 0.253\tBatch (t) 0.462\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:19 | INFO | Rank 0 | Train Epoch: 0 [3776/250314 (2%)]\tLoss: 3.439308\tData (t) 0.277\tBatch (t) 0.485\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:20 | INFO | Rank 0 | Train Epoch: 0 [3808/250314 (2%)]\tLoss: 3.566673\tData (t) 0.275\tBatch (t) 0.484\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:20 | INFO | Rank 0 | Train Epoch: 0 [3840/250314 (2%)]\tLoss: 3.557495\tData (t) 0.414\tBatch (t) 0.623\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:21 | INFO | Rank 0 | Train Epoch: 0 [3872/250314 (2%)]\tLoss: 3.624397\tData (t) 0.281\tBatch (t) 0.490\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:21 | INFO | Rank 0 | Train Epoch: 0 [3904/250314 (2%)]\tLoss: 3.502396\tData (t) 0.306\tBatch (t) 0.515\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:22 | INFO | Rank 0 | Train Epoch: 0 [3936/250314 (2%)]\tLoss: 3.648148\tData (t) 0.238\tBatch (t) 0.446\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-09,13:11:22 | INFO | Rank 0 | Train Epoch: 0 [3968/250314 (2%)]\tLoss: 3.657219\tData (t) 0.297\tBatch (t) 0.505\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:23 | INFO | Rank 0 | Train Epoch: 0 [4000/250314 (2%)]\tLoss: 3.657013\tData (t) 0.286\tBatch (t) 0.494\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:23 | INFO | Rank 0 | Train Epoch: 0 [4032/250314 (2%)]\tLoss: 3.254570\tData (t) 0.266\tBatch (t) 0.474\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:24 | INFO | Rank 0 | Train Epoch: 0 [4064/250314 (2%)]\tLoss: 3.445755\tData (t) 0.323\tBatch (t) 0.532\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:24 | INFO | Rank 0 | Train Epoch: 0 [4096/250314 (2%)]\tLoss: 3.712074\tData (t) 0.291\tBatch (t) 0.500\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:25 | INFO | Rank 0 | Train Epoch: 0 [4128/250314 (2%)]\tLoss: 3.347473\tData (t) 0.254\tBatch (t) 0.463\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:25 | INFO | Rank 0 | Train Epoch: 0 [4160/250314 (2%)]\tLoss: 3.681198\tData (t) 0.212\tBatch (t) 0.421\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:25 | INFO | Rank 0 | Train Epoch: 0 [4192/250314 (2%)]\tLoss: 3.247650\tData (t) 0.292\tBatch (t) 0.501\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:26 | INFO | Rank 0 | Train Epoch: 0 [4224/250314 (2%)]\tLoss: 3.159683\tData (t) 0.282\tBatch (t) 0.491\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:26 | INFO | Rank 0 | Train Epoch: 0 [4256/250314 (2%)]\tLoss: 3.639511\tData (t) 0.163\tBatch (t) 0.371\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:27 | INFO | Rank 0 | Train Epoch: 0 [4288/250314 (2%)]\tLoss: 3.380238\tData (t) 0.250\tBatch (t) 0.459\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:27 | INFO | Rank 0 | Train Epoch: 0 [4320/250314 (2%)]\tLoss: 3.397110\tData (t) 0.282\tBatch (t) 0.491\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:28 | INFO | Rank 0 | Train Epoch: 0 [4352/250314 (2%)]\tLoss: 3.176079\tData (t) 0.239\tBatch (t) 0.448\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:28 | INFO | Rank 0 | Train Epoch: 0 [4384/250314 (2%)]\tLoss: 3.264763\tData (t) 0.239\tBatch (t) 0.448\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:29 | INFO | Rank 0 | Train Epoch: 0 [4416/250314 (2%)]\tLoss: 3.526764\tData (t) 0.306\tBatch (t) 0.515\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:29 | INFO | Rank 0 | Train Epoch: 0 [4448/250314 (2%)]\tLoss: 3.492577\tData (t) 0.264\tBatch (t) 0.473\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:30 | INFO | Rank 0 | Train Epoch: 0 [4480/250314 (2%)]\tLoss: 3.313904\tData (t) 0.289\tBatch (t) 0.498\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:30 | INFO | Rank 0 | Train Epoch: 0 [4512/250314 (2%)]\tLoss: 3.430969\tData (t) 0.348\tBatch (t) 0.557\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:31 | INFO | Rank 0 | Train Epoch: 0 [4544/250314 (2%)]\tLoss: 3.419838\tData (t) 0.349\tBatch (t) 0.558\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:31 | INFO | Rank 0 | Train Epoch: 0 [4576/250314 (2%)]\tLoss: 3.380997\tData (t) 0.301\tBatch (t) 0.510\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:32 | INFO | Rank 0 | Train Epoch: 0 [4608/250314 (2%)]\tLoss: 3.346634\tData (t) 0.276\tBatch (t) 0.485\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:32 | INFO | Rank 0 | Train Epoch: 0 [4640/250314 (2%)]\tLoss: 3.221603\tData (t) 0.269\tBatch (t) 0.478\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:33 | INFO | Rank 0 | Train Epoch: 0 [4672/250314 (2%)]\tLoss: 3.239052\tData (t) 0.318\tBatch (t) 0.527\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:33 | INFO | Rank 0 | Train Epoch: 0 [4704/250314 (2%)]\tLoss: 2.903503\tData (t) 0.256\tBatch (t) 0.465\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:34 | INFO | Rank 0 | Train Epoch: 0 [4736/250314 (2%)]\tLoss: 3.347961\tData (t) 0.244\tBatch (t) 0.452\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:34 | INFO | Rank 0 | Train Epoch: 0 [4768/250314 (2%)]\tLoss: 3.294178\tData (t) 0.296\tBatch (t) 0.505\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:35 | INFO | Rank 0 | Train Epoch: 0 [4800/250314 (2%)]\tLoss: 3.371635\tData (t) 0.258\tBatch (t) 0.467\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:35 | INFO | Rank 0 | Train Epoch: 0 [4832/250314 (2%)]\tLoss: 2.925766\tData (t) 0.281\tBatch (t) 0.490\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:36 | INFO | Rank 0 | Train Epoch: 0 [4864/250314 (2%)]\tLoss: 3.257950\tData (t) 0.271\tBatch (t) 0.480\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:36 | INFO | Rank 0 | Train Epoch: 0 [4896/250314 (2%)]\tLoss: 2.980286\tData (t) 0.382\tBatch (t) 0.591\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:37 | INFO | Rank 0 | Train Epoch: 0 [4928/250314 (2%)]\tLoss: 3.247040\tData (t) 0.240\tBatch (t) 0.448\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:37 | INFO | Rank 0 | Train Epoch: 0 [4960/250314 (2%)]\tLoss: 2.982475\tData (t) 0.288\tBatch (t) 0.496\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:38 | INFO | Rank 0 | Train Epoch: 0 [4992/250314 (2%)]\tLoss: 3.062386\tData (t) 0.265\tBatch (t) 0.474\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:38 | INFO | Rank 0 | Train Epoch: 0 [5024/250314 (2%)]\tLoss: 3.495575\tData (t) 0.292\tBatch (t) 0.500\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:39 | INFO | Rank 0 | Train Epoch: 0 [5056/250314 (2%)]\tLoss: 3.242615\tData (t) 0.295\tBatch (t) 0.503\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:39 | INFO | Rank 0 | Train Epoch: 0 [5088/250314 (2%)]\tLoss: 3.330788\tData (t) 0.272\tBatch (t) 0.481\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:40 | INFO | Rank 0 | Train Epoch: 0 [5120/250314 (2%)]\tLoss: 3.162849\tData (t) 0.282\tBatch (t) 0.490\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:40 | INFO | Rank 0 | Train Epoch: 0 [5152/250314 (2%)]\tLoss: 2.909363\tData (t) 0.255\tBatch (t) 0.464\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:41 | INFO | Rank 0 | Train Epoch: 0 [5184/250314 (2%)]\tLoss: 3.053543\tData (t) 0.407\tBatch (t) 0.615\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:41 | INFO | Rank 0 | Train Epoch: 0 [5216/250314 (2%)]\tLoss: 3.375969\tData (t) 0.239\tBatch (t) 0.448\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:42 | INFO | Rank 0 | Train Epoch: 0 [5248/250314 (2%)]\tLoss: 3.010704\tData (t) 0.268\tBatch (t) 0.477\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:42 | INFO | Rank 0 | Train Epoch: 0 [5280/250314 (2%)]\tLoss: 2.833557\tData (t) 0.246\tBatch (t) 0.455\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:43 | INFO | Rank 0 | Train Epoch: 0 [5312/250314 (2%)]\tLoss: 2.883736\tData (t) 0.276\tBatch (t) 0.485\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:43 | INFO | Rank 0 | Train Epoch: 0 [5344/250314 (2%)]\tLoss: 2.994019\tData (t) 0.256\tBatch (t) 0.465\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:44 | INFO | Rank 0 | Train Epoch: 0 [5376/250314 (2%)]\tLoss: 3.079414\tData (t) 0.286\tBatch (t) 0.495\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:44 | INFO | Rank 0 | Train Epoch: 0 [5408/250314 (2%)]\tLoss: 2.898682\tData (t) 0.231\tBatch (t) 0.440\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:44 | INFO | Rank 0 | Train Epoch: 0 [5440/250314 (2%)]\tLoss: 3.021011\tData (t) 0.186\tBatch (t) 0.395\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:45 | INFO | Rank 0 | Train Epoch: 0 [5472/250314 (2%)]\tLoss: 2.946335\tData (t) 0.262\tBatch (t) 0.471\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:45 | INFO | Rank 0 | Train Epoch: 0 [5504/250314 (2%)]\tLoss: 2.938721\tData (t) 0.251\tBatch (t) 0.460\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:46 | INFO | Rank 0 | Train Epoch: 0 [5536/250314 (2%)]\tLoss: 3.057663\tData (t) 0.288\tBatch (t) 0.497\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:46 | INFO | Rank 0 | Train Epoch: 0 [5568/250314 (2%)]\tLoss: 3.095032\tData (t) 0.292\tBatch (t) 0.501\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-09,13:11:47 | INFO | Rank 0 | Train Epoch: 0 [5600/250314 (2%)]\tLoss: 3.036186\tData (t) 0.274\tBatch (t) 0.483\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:47 | INFO | Rank 0 | Train Epoch: 0 [5632/250314 (2%)]\tLoss: 3.029816\tData (t) 0.207\tBatch (t) 0.416\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:48 | INFO | Rank 0 | Train Epoch: 0 [5664/250314 (2%)]\tLoss: 2.862671\tData (t) 0.244\tBatch (t) 0.453\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:48 | INFO | Rank 0 | Train Epoch: 0 [5696/250314 (2%)]\tLoss: 2.831188\tData (t) 0.210\tBatch (t) 0.419\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:49 | INFO | Rank 0 | Train Epoch: 0 [5728/250314 (2%)]\tLoss: 2.951622\tData (t) 0.323\tBatch (t) 0.532\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:49 | INFO | Rank 0 | Train Epoch: 0 [5760/250314 (2%)]\tLoss: 3.233131\tData (t) 0.319\tBatch (t) 0.528\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:50 | INFO | Rank 0 | Train Epoch: 0 [5792/250314 (2%)]\tLoss: 3.035507\tData (t) 0.297\tBatch (t) 0.505\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:50 | INFO | Rank 0 | Train Epoch: 0 [5824/250314 (2%)]\tLoss: 2.706364\tData (t) 0.239\tBatch (t) 0.448\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:51 | INFO | Rank 0 | Train Epoch: 0 [5856/250314 (2%)]\tLoss: 3.106926\tData (t) 0.242\tBatch (t) 0.451\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:51 | INFO | Rank 0 | Train Epoch: 0 [5888/250314 (2%)]\tLoss: 2.942123\tData (t) 0.221\tBatch (t) 0.430\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:52 | INFO | Rank 0 | Train Epoch: 0 [5920/250314 (2%)]\tLoss: 3.048279\tData (t) 0.377\tBatch (t) 0.586\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:52 | INFO | Rank 0 | Train Epoch: 0 [5952/250314 (2%)]\tLoss: 2.773285\tData (t) 0.265\tBatch (t) 0.474\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:52 | INFO | Rank 0 | Train Epoch: 0 [5984/250314 (2%)]\tLoss: 2.828552\tData (t) 0.243\tBatch (t) 0.452\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:53 | INFO | Rank 0 | Train Epoch: 0 [6016/250314 (2%)]\tLoss: 2.818497\tData (t) 0.254\tBatch (t) 0.462\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:53 | INFO | Rank 0 | Train Epoch: 0 [6048/250314 (2%)]\tLoss: 2.790937\tData (t) 0.315\tBatch (t) 0.524\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:54 | INFO | Rank 0 | Train Epoch: 0 [6080/250314 (2%)]\tLoss: 2.822113\tData (t) 0.259\tBatch (t) 0.468\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:54 | INFO | Rank 0 | Train Epoch: 0 [6112/250314 (2%)]\tLoss: 3.167831\tData (t) 0.279\tBatch (t) 0.488\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:55 | INFO | Rank 0 | Train Epoch: 0 [6144/250314 (2%)]\tLoss: 2.962128\tData (t) 0.233\tBatch (t) 0.441\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:55 | INFO | Rank 0 | Train Epoch: 0 [6176/250314 (2%)]\tLoss: 2.626465\tData (t) 0.292\tBatch (t) 0.502\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:56 | INFO | Rank 0 | Train Epoch: 0 [6208/250314 (2%)]\tLoss: 2.782837\tData (t) 0.342\tBatch (t) 0.551\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:57 | INFO | Rank 0 | Train Epoch: 0 [6240/250314 (2%)]\tLoss: 2.858509\tData (t) 0.458\tBatch (t) 0.667\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:57 | INFO | Rank 0 | Train Epoch: 0 [6272/250314 (3%)]\tLoss: 3.047962\tData (t) 0.309\tBatch (t) 0.518\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:58 | INFO | Rank 0 | Train Epoch: 0 [6304/250314 (3%)]\tLoss: 2.698883\tData (t) 0.247\tBatch (t) 0.456\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:58 | INFO | Rank 0 | Train Epoch: 0 [6336/250314 (3%)]\tLoss: 2.511154\tData (t) 0.294\tBatch (t) 0.503\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:58 | INFO | Rank 0 | Train Epoch: 0 [6368/250314 (3%)]\tLoss: 2.389000\tData (t) 0.205\tBatch (t) 0.414\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:59 | INFO | Rank 0 | Train Epoch: 0 [6400/250314 (3%)]\tLoss: 2.471542\tData (t) 0.276\tBatch (t) 0.485\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:11:59 | INFO | Rank 0 | Train Epoch: 0 [6432/250314 (3%)]\tLoss: 2.512619\tData (t) 0.234\tBatch (t) 0.443\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:00 | INFO | Rank 0 | Train Epoch: 0 [6464/250314 (3%)]\tLoss: 2.656761\tData (t) 0.248\tBatch (t) 0.457\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:00 | INFO | Rank 0 | Train Epoch: 0 [6496/250314 (3%)]\tLoss: 3.051422\tData (t) 0.241\tBatch (t) 0.450\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:01 | INFO | Rank 0 | Train Epoch: 0 [6528/250314 (3%)]\tLoss: 2.750835\tData (t) 0.205\tBatch (t) 0.414\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:01 | INFO | Rank 0 | Train Epoch: 0 [6560/250314 (3%)]\tLoss: 2.823711\tData (t) 0.295\tBatch (t) 0.504\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:02 | INFO | Rank 0 | Train Epoch: 0 [6592/250314 (3%)]\tLoss: 2.529583\tData (t) 0.289\tBatch (t) 0.498\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:02 | INFO | Rank 0 | Train Epoch: 0 [6624/250314 (3%)]\tLoss: 2.826387\tData (t) 0.260\tBatch (t) 0.469\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:03 | INFO | Rank 0 | Train Epoch: 0 [6656/250314 (3%)]\tLoss: 2.490295\tData (t) 0.209\tBatch (t) 0.418\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:03 | INFO | Rank 0 | Train Epoch: 0 [6688/250314 (3%)]\tLoss: 2.822586\tData (t) 0.244\tBatch (t) 0.453\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:04 | INFO | Rank 0 | Train Epoch: 0 [6720/250314 (3%)]\tLoss: 2.432358\tData (t) 0.253\tBatch (t) 0.462\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:04 | INFO | Rank 0 | Train Epoch: 0 [6752/250314 (3%)]\tLoss: 2.655544\tData (t) 0.324\tBatch (t) 0.533\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:05 | INFO | Rank 0 | Train Epoch: 0 [6784/250314 (3%)]\tLoss: 2.295980\tData (t) 0.265\tBatch (t) 0.474\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:05 | INFO | Rank 0 | Train Epoch: 0 [6816/250314 (3%)]\tLoss: 2.547558\tData (t) 0.233\tBatch (t) 0.442\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:05 | INFO | Rank 0 | Train Epoch: 0 [6848/250314 (3%)]\tLoss: 2.799686\tData (t) 0.299\tBatch (t) 0.509\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:06 | INFO | Rank 0 | Train Epoch: 0 [6880/250314 (3%)]\tLoss: 2.468182\tData (t) 0.348\tBatch (t) 0.558\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:07 | INFO | Rank 0 | Train Epoch: 0 [6912/250314 (3%)]\tLoss: 2.561401\tData (t) 0.353\tBatch (t) 0.562\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:07 | INFO | Rank 0 | Train Epoch: 0 [6944/250314 (3%)]\tLoss: 2.726597\tData (t) 0.250\tBatch (t) 0.459\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:08 | INFO | Rank 0 | Train Epoch: 0 [6976/250314 (3%)]\tLoss: 2.694887\tData (t) 0.247\tBatch (t) 0.456\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:08 | INFO | Rank 0 | Train Epoch: 0 [7008/250314 (3%)]\tLoss: 2.489303\tData (t) 0.320\tBatch (t) 0.529\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:09 | INFO | Rank 0 | Train Epoch: 0 [7040/250314 (3%)]\tLoss: 2.603165\tData (t) 0.247\tBatch (t) 0.457\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:09 | INFO | Rank 0 | Train Epoch: 0 [7072/250314 (3%)]\tLoss: 2.657255\tData (t) 0.338\tBatch (t) 0.547\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:10 | INFO | Rank 0 | Train Epoch: 0 [7104/250314 (3%)]\tLoss: 2.662045\tData (t) 0.318\tBatch (t) 0.527\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:10 | INFO | Rank 0 | Train Epoch: 0 [7136/250314 (3%)]\tLoss: 2.251808\tData (t) 0.244\tBatch (t) 0.453\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-09,13:12:11 | INFO | Rank 0 | Train Epoch: 0 [7168/250314 (3%)]\tLoss: 2.522205\tData (t) 0.279\tBatch (t) 0.488\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:11 | INFO | Rank 0 | Train Epoch: 0 [7200/250314 (3%)]\tLoss: 2.478405\tData (t) 0.251\tBatch (t) 0.460\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:11 | INFO | Rank 0 | Train Epoch: 0 [7232/250314 (3%)]\tLoss: 2.787106\tData (t) 0.237\tBatch (t) 0.446\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:12 | INFO | Rank 0 | Train Epoch: 0 [7264/250314 (3%)]\tLoss: 2.336310\tData (t) 0.337\tBatch (t) 0.546\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:12 | INFO | Rank 0 | Train Epoch: 0 [7296/250314 (3%)]\tLoss: 2.289539\tData (t) 0.276\tBatch (t) 0.485\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:13 | INFO | Rank 0 | Train Epoch: 0 [7328/250314 (3%)]\tLoss: 2.241579\tData (t) 0.262\tBatch (t) 0.471\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:13 | INFO | Rank 0 | Train Epoch: 0 [7360/250314 (3%)]\tLoss: 2.683619\tData (t) 0.205\tBatch (t) 0.415\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:14 | INFO | Rank 0 | Train Epoch: 0 [7392/250314 (3%)]\tLoss: 2.279228\tData (t) 0.287\tBatch (t) 0.496\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:14 | INFO | Rank 0 | Train Epoch: 0 [7424/250314 (3%)]\tLoss: 2.693893\tData (t) 0.302\tBatch (t) 0.512\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:15 | INFO | Rank 0 | Train Epoch: 0 [7456/250314 (3%)]\tLoss: 2.709654\tData (t) 0.247\tBatch (t) 0.457\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:15 | INFO | Rank 0 | Train Epoch: 0 [7488/250314 (3%)]\tLoss: 2.352493\tData (t) 0.217\tBatch (t) 0.426\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:16 | INFO | Rank 0 | Train Epoch: 0 [7520/250314 (3%)]\tLoss: 2.615568\tData (t) 0.330\tBatch (t) 0.540\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:16 | INFO | Rank 0 | Train Epoch: 0 [7552/250314 (3%)]\tLoss: 2.227458\tData (t) 0.266\tBatch (t) 0.475\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:17 | INFO | Rank 0 | Train Epoch: 0 [7584/250314 (3%)]\tLoss: 2.293095\tData (t) 0.334\tBatch (t) 0.543\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:17 | INFO | Rank 0 | Train Epoch: 0 [7616/250314 (3%)]\tLoss: 2.372208\tData (t) 0.302\tBatch (t) 0.511\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:18 | INFO | Rank 0 | Train Epoch: 0 [7648/250314 (3%)]\tLoss: 2.088676\tData (t) 0.257\tBatch (t) 0.467\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:18 | INFO | Rank 0 | Train Epoch: 0 [7680/250314 (3%)]\tLoss: 2.273468\tData (t) 0.283\tBatch (t) 0.493\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:19 | INFO | Rank 0 | Train Epoch: 0 [7712/250314 (3%)]\tLoss: 3.136166\tData (t) 0.254\tBatch (t) 0.463\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:19 | INFO | Rank 0 | Train Epoch: 0 [7744/250314 (3%)]\tLoss: 2.361371\tData (t) 0.284\tBatch (t) 0.493\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:20 | INFO | Rank 0 | Train Epoch: 0 [7776/250314 (3%)]\tLoss: 2.468128\tData (t) 0.257\tBatch (t) 0.467\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:20 | INFO | Rank 0 | Train Epoch: 0 [7808/250314 (3%)]\tLoss: 2.064809\tData (t) 0.312\tBatch (t) 0.521\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:21 | INFO | Rank 0 | Train Epoch: 0 [7840/250314 (3%)]\tLoss: 2.588236\tData (t) 0.248\tBatch (t) 0.457\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:21 | INFO | Rank 0 | Train Epoch: 0 [7872/250314 (3%)]\tLoss: 2.118703\tData (t) 0.283\tBatch (t) 0.492\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:22 | INFO | Rank 0 | Train Epoch: 0 [7904/250314 (3%)]\tLoss: 2.533033\tData (t) 0.320\tBatch (t) 0.530\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:22 | INFO | Rank 0 | Train Epoch: 0 [7936/250314 (3%)]\tLoss: 2.589874\tData (t) 0.292\tBatch (t) 0.502\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:23 | INFO | Rank 0 | Train Epoch: 0 [7968/250314 (3%)]\tLoss: 2.175514\tData (t) 0.344\tBatch (t) 0.554\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:23 | INFO | Rank 0 | Train Epoch: 0 [8000/250314 (3%)]\tLoss: 2.306322\tData (t) 0.282\tBatch (t) 0.491\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:24 | INFO | Rank 0 | Train Epoch: 0 [8032/250314 (3%)]\tLoss: 2.075794\tData (t) 0.245\tBatch (t) 0.455\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:24 | INFO | Rank 0 | Train Epoch: 0 [8064/250314 (3%)]\tLoss: 2.346921\tData (t) 0.304\tBatch (t) 0.514\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:25 | INFO | Rank 0 | Train Epoch: 0 [8096/250314 (3%)]\tLoss: 2.378666\tData (t) 0.249\tBatch (t) 0.458\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:25 | INFO | Rank 0 | Train Epoch: 0 [8128/250314 (3%)]\tLoss: 2.508228\tData (t) 0.311\tBatch (t) 0.519\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:26 | INFO | Rank 0 | Train Epoch: 0 [8160/250314 (3%)]\tLoss: 1.953764\tData (t) 0.250\tBatch (t) 0.459\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:26 | INFO | Rank 0 | Train Epoch: 0 [8192/250314 (3%)]\tLoss: 2.211201\tData (t) 0.275\tBatch (t) 0.484\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:27 | INFO | Rank 0 | Train Epoch: 0 [8224/250314 (3%)]\tLoss: 2.095315\tData (t) 0.243\tBatch (t) 0.452\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:27 | INFO | Rank 0 | Train Epoch: 0 [8256/250314 (3%)]\tLoss: 2.397343\tData (t) 0.239\tBatch (t) 0.448\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:28 | INFO | Rank 0 | Train Epoch: 0 [8288/250314 (3%)]\tLoss: 2.556389\tData (t) 0.296\tBatch (t) 0.504\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:28 | INFO | Rank 0 | Train Epoch: 0 [8320/250314 (3%)]\tLoss: 2.160886\tData (t) 0.306\tBatch (t) 0.516\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:28 | INFO | Rank 0 | Train Epoch: 0 [8352/250314 (3%)]\tLoss: 2.555626\tData (t) 0.250\tBatch (t) 0.459\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:29 | INFO | Rank 0 | Train Epoch: 0 [8384/250314 (3%)]\tLoss: 2.330910\tData (t) 0.247\tBatch (t) 0.456\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:29 | INFO | Rank 0 | Train Epoch: 0 [8416/250314 (3%)]\tLoss: 2.350796\tData (t) 0.251\tBatch (t) 0.460\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:30 | INFO | Rank 0 | Train Epoch: 0 [8448/250314 (3%)]\tLoss: 2.213023\tData (t) 0.317\tBatch (t) 0.527\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:30 | INFO | Rank 0 | Train Epoch: 0 [8480/250314 (3%)]\tLoss: 2.438177\tData (t) 0.317\tBatch (t) 0.526\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:31 | INFO | Rank 0 | Train Epoch: 0 [8512/250314 (3%)]\tLoss: 2.242134\tData (t) 0.290\tBatch (t) 0.499\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:31 | INFO | Rank 0 | Train Epoch: 0 [8544/250314 (3%)]\tLoss: 2.439713\tData (t) 0.242\tBatch (t) 0.451\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:32 | INFO | Rank 0 | Train Epoch: 0 [8576/250314 (3%)]\tLoss: 1.888330\tData (t) 0.360\tBatch (t) 0.569\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:33 | INFO | Rank 0 | Train Epoch: 0 [8608/250314 (3%)]\tLoss: 1.966889\tData (t) 0.362\tBatch (t) 0.572\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:33 | INFO | Rank 0 | Train Epoch: 0 [8640/250314 (3%)]\tLoss: 2.480274\tData (t) 0.283\tBatch (t) 0.492\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:33 | INFO | Rank 0 | Train Epoch: 0 [8672/250314 (3%)]\tLoss: 2.093842\tData (t) 0.237\tBatch (t) 0.447\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:34 | INFO | Rank 0 | Train Epoch: 0 [8704/250314 (3%)]\tLoss: 2.030644\tData (t) 0.260\tBatch (t) 0.469\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:34 | INFO | Rank 0 | Train Epoch: 0 [8736/250314 (3%)]\tLoss: 2.200720\tData (t) 0.306\tBatch (t) 0.515\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-09,13:12:35 | INFO | Rank 0 | Train Epoch: 0 [8768/250314 (4%)]\tLoss: 2.044260\tData (t) 0.255\tBatch (t) 0.464\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:35 | INFO | Rank 0 | Train Epoch: 0 [8800/250314 (4%)]\tLoss: 2.207732\tData (t) 0.268\tBatch (t) 0.478\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:36 | INFO | Rank 0 | Train Epoch: 0 [8832/250314 (4%)]\tLoss: 1.998616\tData (t) 0.296\tBatch (t) 0.505\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:36 | INFO | Rank 0 | Train Epoch: 0 [8864/250314 (4%)]\tLoss: 2.039461\tData (t) 0.269\tBatch (t) 0.478\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:37 | INFO | Rank 0 | Train Epoch: 0 [8896/250314 (4%)]\tLoss: 1.981062\tData (t) 0.280\tBatch (t) 0.489\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:37 | INFO | Rank 0 | Train Epoch: 0 [8928/250314 (4%)]\tLoss: 1.945195\tData (t) 0.311\tBatch (t) 0.521\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:38 | INFO | Rank 0 | Train Epoch: 0 [8960/250314 (4%)]\tLoss: 2.202242\tData (t) 0.256\tBatch (t) 0.465\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:38 | INFO | Rank 0 | Train Epoch: 0 [8992/250314 (4%)]\tLoss: 2.021592\tData (t) 0.232\tBatch (t) 0.441\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:39 | INFO | Rank 0 | Train Epoch: 0 [9024/250314 (4%)]\tLoss: 2.223700\tData (t) 0.204\tBatch (t) 0.414\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:39 | INFO | Rank 0 | Train Epoch: 0 [9056/250314 (4%)]\tLoss: 1.990164\tData (t) 0.265\tBatch (t) 0.474\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:40 | INFO | Rank 0 | Train Epoch: 0 [9088/250314 (4%)]\tLoss: 1.915943\tData (t) 0.262\tBatch (t) 0.471\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:40 | INFO | Rank 0 | Train Epoch: 0 [9120/250314 (4%)]\tLoss: 2.110034\tData (t) 0.213\tBatch (t) 0.422\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:41 | INFO | Rank 0 | Train Epoch: 0 [9152/250314 (4%)]\tLoss: 1.848562\tData (t) 0.273\tBatch (t) 0.482\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:41 | INFO | Rank 0 | Train Epoch: 0 [9184/250314 (4%)]\tLoss: 1.549796\tData (t) 0.240\tBatch (t) 0.449\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:41 | INFO | Rank 0 | Train Epoch: 0 [9216/250314 (4%)]\tLoss: 2.304287\tData (t) 0.248\tBatch (t) 0.457\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:42 | INFO | Rank 0 | Train Epoch: 0 [9248/250314 (4%)]\tLoss: 2.218172\tData (t) 0.261\tBatch (t) 0.470\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:43 | INFO | Rank 0 | Train Epoch: 0 [9280/250314 (4%)]\tLoss: 1.997197\tData (t) 0.411\tBatch (t) 0.620\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:43 | INFO | Rank 0 | Train Epoch: 0 [9312/250314 (4%)]\tLoss: 2.183199\tData (t) 0.299\tBatch (t) 0.507\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:44 | INFO | Rank 0 | Train Epoch: 0 [9344/250314 (4%)]\tLoss: 2.222989\tData (t) 0.215\tBatch (t) 0.425\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:44 | INFO | Rank 0 | Train Epoch: 0 [9376/250314 (4%)]\tLoss: 1.812859\tData (t) 0.293\tBatch (t) 0.502\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:44 | INFO | Rank 0 | Train Epoch: 0 [9408/250314 (4%)]\tLoss: 1.914751\tData (t) 0.269\tBatch (t) 0.479\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:45 | INFO | Rank 0 | Train Epoch: 0 [9440/250314 (4%)]\tLoss: 2.113498\tData (t) 0.294\tBatch (t) 0.504\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:45 | INFO | Rank 0 | Train Epoch: 0 [9472/250314 (4%)]\tLoss: 2.144679\tData (t) 0.242\tBatch (t) 0.451\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:46 | INFO | Rank 0 | Train Epoch: 0 [9504/250314 (4%)]\tLoss: 2.338042\tData (t) 0.275\tBatch (t) 0.485\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:46 | INFO | Rank 0 | Train Epoch: 0 [9536/250314 (4%)]\tLoss: 2.218862\tData (t) 0.303\tBatch (t) 0.511\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:47 | INFO | Rank 0 | Train Epoch: 0 [9568/250314 (4%)]\tLoss: 1.649254\tData (t) 0.289\tBatch (t) 0.498\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:47 | INFO | Rank 0 | Train Epoch: 0 [9600/250314 (4%)]\tLoss: 1.521667\tData (t) 0.301\tBatch (t) 0.510\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:48 | INFO | Rank 0 | Train Epoch: 0 [9632/250314 (4%)]\tLoss: 1.982990\tData (t) 0.279\tBatch (t) 0.489\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:49 | INFO | Rank 0 | Train Epoch: 0 [9664/250314 (4%)]\tLoss: 2.169111\tData (t) 0.386\tBatch (t) 0.595\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:49 | INFO | Rank 0 | Train Epoch: 0 [9696/250314 (4%)]\tLoss: 1.852602\tData (t) 0.267\tBatch (t) 0.477\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:50 | INFO | Rank 0 | Train Epoch: 0 [9728/250314 (4%)]\tLoss: 1.843917\tData (t) 0.299\tBatch (t) 0.509\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:50 | INFO | Rank 0 | Train Epoch: 0 [9760/250314 (4%)]\tLoss: 1.735664\tData (t) 0.254\tBatch (t) 0.463\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:51 | INFO | Rank 0 | Train Epoch: 0 [9792/250314 (4%)]\tLoss: 2.103985\tData (t) 0.310\tBatch (t) 0.519\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:51 | INFO | Rank 0 | Train Epoch: 0 [9824/250314 (4%)]\tLoss: 2.125346\tData (t) 0.213\tBatch (t) 0.424\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:51 | INFO | Rank 0 | Train Epoch: 0 [9856/250314 (4%)]\tLoss: 1.850623\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:52 | INFO | Rank 0 | Train Epoch: 0 [9888/250314 (4%)]\tLoss: 1.904404\tData (t) 0.232\tBatch (t) 0.441\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:52 | INFO | Rank 0 | Train Epoch: 0 [9920/250314 (4%)]\tLoss: 2.060219\tData (t) 0.265\tBatch (t) 0.474\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:53 | INFO | Rank 0 | Train Epoch: 0 [9952/250314 (4%)]\tLoss: 1.939535\tData (t) 0.405\tBatch (t) 0.614\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:53 | INFO | Rank 0 | Train Epoch: 0 [9984/250314 (4%)]\tLoss: 2.092932\tData (t) 0.323\tBatch (t) 0.532\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:54 | INFO | Rank 0 | Train Epoch: 0 [10016/250314 (4%)]\tLoss: 1.742238\tData (t) 0.248\tBatch (t) 0.457\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:55 | INFO | Rank 0 | Train Epoch: 0 [10048/250314 (4%)]\tLoss: 1.845977\tData (t) 0.463\tBatch (t) 0.672\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:55 | INFO | Rank 0 | Train Epoch: 0 [10080/250314 (4%)]\tLoss: 1.972003\tData (t) 0.283\tBatch (t) 0.492\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:56 | INFO | Rank 0 | Train Epoch: 0 [10112/250314 (4%)]\tLoss: 2.089708\tData (t) 0.207\tBatch (t) 0.416\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:56 | INFO | Rank 0 | Train Epoch: 0 [10144/250314 (4%)]\tLoss: 2.068139\tData (t) 0.305\tBatch (t) 0.514\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:56 | INFO | Rank 0 | Train Epoch: 0 [10176/250314 (4%)]\tLoss: 2.046953\tData (t) 0.245\tBatch (t) 0.455\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:57 | INFO | Rank 0 | Train Epoch: 0 [10208/250314 (4%)]\tLoss: 2.064492\tData (t) 0.300\tBatch (t) 0.510\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:57 | INFO | Rank 0 | Train Epoch: 0 [10240/250314 (4%)]\tLoss: 2.000618\tData (t) 0.264\tBatch (t) 0.473\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:58 | INFO | Rank 0 | Train Epoch: 0 [10272/250314 (4%)]\tLoss: 1.708944\tData (t) 0.302\tBatch (t) 0.511\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:59 | INFO | Rank 0 | Train Epoch: 0 [10304/250314 (4%)]\tLoss: 1.860576\tData (t) 0.323\tBatch (t) 0.532\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:59 | INFO | Rank 0 | Train Epoch: 0 [10336/250314 (4%)]\tLoss: 1.503586\tData (t) 0.281\tBatch (t) 0.490\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-09,13:12:59 | INFO | Rank 0 | Train Epoch: 0 [10368/250314 (4%)]\tLoss: 1.847183\tData (t) 0.278\tBatch (t) 0.487\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:00 | INFO | Rank 0 | Train Epoch: 0 [10400/250314 (4%)]\tLoss: 1.851542\tData (t) 0.296\tBatch (t) 0.505\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:00 | INFO | Rank 0 | Train Epoch: 0 [10432/250314 (4%)]\tLoss: 1.444389\tData (t) 0.272\tBatch (t) 0.481\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:01 | INFO | Rank 0 | Train Epoch: 0 [10464/250314 (4%)]\tLoss: 2.177893\tData (t) 0.271\tBatch (t) 0.481\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:01 | INFO | Rank 0 | Train Epoch: 0 [10496/250314 (4%)]\tLoss: 1.831543\tData (t) 0.289\tBatch (t) 0.498\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:02 | INFO | Rank 0 | Train Epoch: 0 [10528/250314 (4%)]\tLoss: 1.859964\tData (t) 0.318\tBatch (t) 0.527\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:02 | INFO | Rank 0 | Train Epoch: 0 [10560/250314 (4%)]\tLoss: 2.219110\tData (t) 0.315\tBatch (t) 0.525\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:03 | INFO | Rank 0 | Train Epoch: 0 [10592/250314 (4%)]\tLoss: 1.898961\tData (t) 0.281\tBatch (t) 0.491\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:04 | INFO | Rank 0 | Train Epoch: 0 [10624/250314 (4%)]\tLoss: 1.986771\tData (t) 0.331\tBatch (t) 0.540\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:04 | INFO | Rank 0 | Train Epoch: 0 [10656/250314 (4%)]\tLoss: 1.779947\tData (t) 0.328\tBatch (t) 0.538\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:05 | INFO | Rank 0 | Train Epoch: 0 [10688/250314 (4%)]\tLoss: 2.043157\tData (t) 0.371\tBatch (t) 0.580\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:05 | INFO | Rank 0 | Train Epoch: 0 [10720/250314 (4%)]\tLoss: 1.684285\tData (t) 0.305\tBatch (t) 0.515\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:06 | INFO | Rank 0 | Train Epoch: 0 [10752/250314 (4%)]\tLoss: 2.360294\tData (t) 0.254\tBatch (t) 0.464\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:06 | INFO | Rank 0 | Train Epoch: 0 [10784/250314 (4%)]\tLoss: 1.346058\tData (t) 0.304\tBatch (t) 0.513\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:07 | INFO | Rank 0 | Train Epoch: 0 [10816/250314 (4%)]\tLoss: 2.011277\tData (t) 0.238\tBatch (t) 0.448\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:07 | INFO | Rank 0 | Train Epoch: 0 [10848/250314 (4%)]\tLoss: 1.876354\tData (t) 0.215\tBatch (t) 0.425\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:07 | INFO | Rank 0 | Train Epoch: 0 [10880/250314 (4%)]\tLoss: 1.366047\tData (t) 0.262\tBatch (t) 0.472\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:08 | INFO | Rank 0 | Train Epoch: 0 [10912/250314 (4%)]\tLoss: 1.747526\tData (t) 0.217\tBatch (t) 0.427\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:08 | INFO | Rank 0 | Train Epoch: 0 [10944/250314 (4%)]\tLoss: 2.266034\tData (t) 0.306\tBatch (t) 0.516\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:09 | INFO | Rank 0 | Train Epoch: 0 [10976/250314 (4%)]\tLoss: 1.627395\tData (t) 0.277\tBatch (t) 0.486\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:09 | INFO | Rank 0 | Train Epoch: 0 [11008/250314 (4%)]\tLoss: 1.512173\tData (t) 0.334\tBatch (t) 0.543\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:10 | INFO | Rank 0 | Train Epoch: 0 [11040/250314 (4%)]\tLoss: 1.651559\tData (t) 0.375\tBatch (t) 0.584\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:11 | INFO | Rank 0 | Train Epoch: 0 [11072/250314 (4%)]\tLoss: 1.953122\tData (t) 0.255\tBatch (t) 0.464\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:11 | INFO | Rank 0 | Train Epoch: 0 [11104/250314 (4%)]\tLoss: 1.595128\tData (t) 0.227\tBatch (t) 0.436\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:11 | INFO | Rank 0 | Train Epoch: 0 [11136/250314 (4%)]\tLoss: 1.989377\tData (t) 0.230\tBatch (t) 0.440\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:12 | INFO | Rank 0 | Train Epoch: 0 [11168/250314 (4%)]\tLoss: 1.900754\tData (t) 0.214\tBatch (t) 0.424\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:12 | INFO | Rank 0 | Train Epoch: 0 [11200/250314 (4%)]\tLoss: 1.627824\tData (t) 0.275\tBatch (t) 0.485\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:13 | INFO | Rank 0 | Train Epoch: 0 [11232/250314 (4%)]\tLoss: 1.362976\tData (t) 0.245\tBatch (t) 0.455\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:13 | INFO | Rank 0 | Train Epoch: 0 [11264/250314 (5%)]\tLoss: 1.642778\tData (t) 0.243\tBatch (t) 0.452\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:14 | INFO | Rank 0 | Train Epoch: 0 [11296/250314 (5%)]\tLoss: 1.507270\tData (t) 0.313\tBatch (t) 0.522\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:14 | INFO | Rank 0 | Train Epoch: 0 [11328/250314 (5%)]\tLoss: 1.925546\tData (t) 0.357\tBatch (t) 0.566\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:15 | INFO | Rank 0 | Train Epoch: 0 [11360/250314 (5%)]\tLoss: 2.105492\tData (t) 0.260\tBatch (t) 0.470\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:15 | INFO | Rank 0 | Train Epoch: 0 [11392/250314 (5%)]\tLoss: 1.702204\tData (t) 0.257\tBatch (t) 0.466\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:16 | INFO | Rank 0 | Train Epoch: 0 [11424/250314 (5%)]\tLoss: 1.832488\tData (t) 0.286\tBatch (t) 0.495\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:16 | INFO | Rank 0 | Train Epoch: 0 [11456/250314 (5%)]\tLoss: 1.253332\tData (t) 0.185\tBatch (t) 0.394\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:17 | INFO | Rank 0 | Train Epoch: 0 [11488/250314 (5%)]\tLoss: 1.751944\tData (t) 0.246\tBatch (t) 0.456\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:17 | INFO | Rank 0 | Train Epoch: 0 [11520/250314 (5%)]\tLoss: 1.877762\tData (t) 0.242\tBatch (t) 0.451\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:18 | INFO | Rank 0 | Train Epoch: 0 [11552/250314 (5%)]\tLoss: 1.306254\tData (t) 0.295\tBatch (t) 0.504\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:18 | INFO | Rank 0 | Train Epoch: 0 [11584/250314 (5%)]\tLoss: 1.668427\tData (t) 0.257\tBatch (t) 0.466\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-09,13:13:18 | INFO | Rank 0 | Train Epoch: 0 [11616/250314 (5%)]\tLoss: 1.733528\tData (t) 0.239\tBatch (t) 0.448\tLR: 0.000007\tlogit_scale 4.604\n",
      "2022-11-09,13:13:19 | INFO | Rank 0 | Train Epoch: 0 [11648/250314 (5%)]\tLoss: 1.559735\tData (t) 0.284\tBatch (t) 0.493\tLR: 0.000007\tlogit_scale 4.604\n",
      "2022-11-09,13:13:19 | INFO | Rank 0 | Train Epoch: 0 [11680/250314 (5%)]\tLoss: 1.649470\tData (t) 0.303\tBatch (t) 0.513\tLR: 0.000007\tlogit_scale 4.604\n",
      "2022-11-09,13:13:20 | INFO | Rank 0 | Train Epoch: 0 [11712/250314 (5%)]\tLoss: 1.761190\tData (t) 0.286\tBatch (t) 0.495\tLR: 0.000007\tlogit_scale 4.604\n",
      "2022-11-09,13:13:20 | INFO | Rank 0 | Train Epoch: 0 [11744/250314 (5%)]\tLoss: 1.645025\tData (t) 0.320\tBatch (t) 0.530\tLR: 0.000007\tlogit_scale 4.604\n",
      "2022-11-09,13:13:21 | INFO | Rank 0 | Train Epoch: 0 [11776/250314 (5%)]\tLoss: 1.680214\tData (t) 0.295\tBatch (t) 0.505\tLR: 0.000007\tlogit_scale 4.604\n",
      "2022-11-09,13:13:21 | INFO | Rank 0 | Train Epoch: 0 [11808/250314 (5%)]\tLoss: 1.656806\tData (t) 0.279\tBatch (t) 0.488\tLR: 0.000007\tlogit_scale 4.604\n",
      "2022-11-09,13:13:22 | INFO | Rank 0 | Train Epoch: 0 [11840/250314 (5%)]\tLoss: 1.670753\tData (t) 0.246\tBatch (t) 0.456\tLR: 0.000007\tlogit_scale 4.604\n",
      "2022-11-09,13:13:22 | INFO | Rank 0 | Train Epoch: 0 [11872/250314 (5%)]\tLoss: 2.175622\tData (t) 0.230\tBatch (t) 0.439\tLR: 0.000007\tlogit_scale 4.604\n",
      "2022-11-09,13:13:23 | INFO | Rank 0 | Train Epoch: 0 [11904/250314 (5%)]\tLoss: 1.636048\tData (t) 0.277\tBatch (t) 0.487\tLR: 0.000007\tlogit_scale 4.604\n",
      "2022-11-09,13:13:23 | INFO | Rank 0 | Train Epoch: 0 [11936/250314 (5%)]\tLoss: 2.286317\tData (t) 0.180\tBatch (t) 0.390\tLR: 0.000007\tlogit_scale 4.604\n",
      "2022-11-09,13:13:24 | INFO | Rank 0 | Train Epoch: 0 [11968/250314 (5%)]\tLoss: 1.629311\tData (t) 0.274\tBatch (t) 0.484\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:24 | INFO | Rank 0 | Train Epoch: 0 [12000/250314 (5%)]\tLoss: 1.932578\tData (t) 0.264\tBatch (t) 0.474\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:25 | INFO | Rank 0 | Train Epoch: 0 [12032/250314 (5%)]\tLoss: 1.710608\tData (t) 0.298\tBatch (t) 0.508\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:25 | INFO | Rank 0 | Train Epoch: 0 [12064/250314 (5%)]\tLoss: 1.814779\tData (t) 0.260\tBatch (t) 0.470\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:26 | INFO | Rank 0 | Train Epoch: 0 [12096/250314 (5%)]\tLoss: 1.412525\tData (t) 0.277\tBatch (t) 0.486\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:26 | INFO | Rank 0 | Train Epoch: 0 [12128/250314 (5%)]\tLoss: 1.819427\tData (t) 0.277\tBatch (t) 0.487\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:27 | INFO | Rank 0 | Train Epoch: 0 [12160/250314 (5%)]\tLoss: 1.473660\tData (t) 0.287\tBatch (t) 0.497\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:27 | INFO | Rank 0 | Train Epoch: 0 [12192/250314 (5%)]\tLoss: 1.607731\tData (t) 0.283\tBatch (t) 0.493\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:28 | INFO | Rank 0 | Train Epoch: 0 [12224/250314 (5%)]\tLoss: 1.930620\tData (t) 0.297\tBatch (t) 0.507\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:28 | INFO | Rank 0 | Train Epoch: 0 [12256/250314 (5%)]\tLoss: 1.395744\tData (t) 0.334\tBatch (t) 0.544\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:29 | INFO | Rank 0 | Train Epoch: 0 [12288/250314 (5%)]\tLoss: 1.463181\tData (t) 0.244\tBatch (t) 0.454\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:29 | INFO | Rank 0 | Train Epoch: 0 [12320/250314 (5%)]\tLoss: 1.506766\tData (t) 0.212\tBatch (t) 0.421\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:30 | INFO | Rank 0 | Train Epoch: 0 [12352/250314 (5%)]\tLoss: 1.869315\tData (t) 0.350\tBatch (t) 0.560\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:30 | INFO | Rank 0 | Train Epoch: 0 [12384/250314 (5%)]\tLoss: 1.623332\tData (t) 0.250\tBatch (t) 0.460\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:31 | INFO | Rank 0 | Train Epoch: 0 [12416/250314 (5%)]\tLoss: 1.399487\tData (t) 0.287\tBatch (t) 0.497\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:31 | INFO | Rank 0 | Train Epoch: 0 [12448/250314 (5%)]\tLoss: 1.721661\tData (t) 0.296\tBatch (t) 0.506\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:32 | INFO | Rank 0 | Train Epoch: 0 [12480/250314 (5%)]\tLoss: 1.715273\tData (t) 0.272\tBatch (t) 0.482\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:32 | INFO | Rank 0 | Train Epoch: 0 [12512/250314 (5%)]\tLoss: 1.457839\tData (t) 0.303\tBatch (t) 0.512\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:33 | INFO | Rank 0 | Train Epoch: 0 [12544/250314 (5%)]\tLoss: 1.830492\tData (t) 0.312\tBatch (t) 0.521\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:33 | INFO | Rank 0 | Train Epoch: 0 [12576/250314 (5%)]\tLoss: 1.468780\tData (t) 0.257\tBatch (t) 0.467\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:34 | INFO | Rank 0 | Train Epoch: 0 [12608/250314 (5%)]\tLoss: 1.619343\tData (t) 0.269\tBatch (t) 0.479\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:34 | INFO | Rank 0 | Train Epoch: 0 [12640/250314 (5%)]\tLoss: 1.394834\tData (t) 0.262\tBatch (t) 0.472\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:34 | INFO | Rank 0 | Train Epoch: 0 [12672/250314 (5%)]\tLoss: 2.254439\tData (t) 0.225\tBatch (t) 0.435\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:35 | INFO | Rank 0 | Train Epoch: 0 [12704/250314 (5%)]\tLoss: 1.678851\tData (t) 0.315\tBatch (t) 0.525\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:35 | INFO | Rank 0 | Train Epoch: 0 [12736/250314 (5%)]\tLoss: 2.037928\tData (t) 0.320\tBatch (t) 0.530\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:36 | INFO | Rank 0 | Train Epoch: 0 [12768/250314 (5%)]\tLoss: 1.866948\tData (t) 0.281\tBatch (t) 0.491\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:37 | INFO | Rank 0 | Train Epoch: 0 [12800/250314 (5%)]\tLoss: 1.708853\tData (t) 0.317\tBatch (t) 0.528\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:37 | INFO | Rank 0 | Train Epoch: 0 [12832/250314 (5%)]\tLoss: 1.568327\tData (t) 0.300\tBatch (t) 0.510\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:38 | INFO | Rank 0 | Train Epoch: 0 [12864/250314 (5%)]\tLoss: 1.728755\tData (t) 0.271\tBatch (t) 0.480\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:38 | INFO | Rank 0 | Train Epoch: 0 [12896/250314 (5%)]\tLoss: 1.618237\tData (t) 0.276\tBatch (t) 0.485\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:38 | INFO | Rank 0 | Train Epoch: 0 [12928/250314 (5%)]\tLoss: 1.632097\tData (t) 0.277\tBatch (t) 0.487\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:39 | INFO | Rank 0 | Train Epoch: 0 [12960/250314 (5%)]\tLoss: 1.695011\tData (t) 0.284\tBatch (t) 0.494\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:39 | INFO | Rank 0 | Train Epoch: 0 [12992/250314 (5%)]\tLoss: 1.814762\tData (t) 0.259\tBatch (t) 0.469\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:40 | INFO | Rank 0 | Train Epoch: 0 [13024/250314 (5%)]\tLoss: 1.266170\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:40 | INFO | Rank 0 | Train Epoch: 0 [13056/250314 (5%)]\tLoss: 2.032264\tData (t) 0.251\tBatch (t) 0.461\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:41 | INFO | Rank 0 | Train Epoch: 0 [13088/250314 (5%)]\tLoss: 1.767709\tData (t) 0.302\tBatch (t) 0.512\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:41 | INFO | Rank 0 | Train Epoch: 0 [13120/250314 (5%)]\tLoss: 1.690390\tData (t) 0.246\tBatch (t) 0.456\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:42 | INFO | Rank 0 | Train Epoch: 0 [13152/250314 (5%)]\tLoss: 1.470887\tData (t) 0.288\tBatch (t) 0.498\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:42 | INFO | Rank 0 | Train Epoch: 0 [13184/250314 (5%)]\tLoss: 1.596762\tData (t) 0.295\tBatch (t) 0.505\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:43 | INFO | Rank 0 | Train Epoch: 0 [13216/250314 (5%)]\tLoss: 1.692625\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:43 | INFO | Rank 0 | Train Epoch: 0 [13248/250314 (5%)]\tLoss: 1.167815\tData (t) 0.247\tBatch (t) 0.457\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:44 | INFO | Rank 0 | Train Epoch: 0 [13280/250314 (5%)]\tLoss: 1.536894\tData (t) 0.220\tBatch (t) 0.429\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:44 | INFO | Rank 0 | Train Epoch: 0 [13312/250314 (5%)]\tLoss: 1.550909\tData (t) 0.304\tBatch (t) 0.514\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:45 | INFO | Rank 0 | Train Epoch: 0 [13344/250314 (5%)]\tLoss: 1.704205\tData (t) 0.263\tBatch (t) 0.473\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:45 | INFO | Rank 0 | Train Epoch: 0 [13376/250314 (5%)]\tLoss: 1.725115\tData (t) 0.328\tBatch (t) 0.538\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:46 | INFO | Rank 0 | Train Epoch: 0 [13408/250314 (5%)]\tLoss: 1.825919\tData (t) 0.279\tBatch (t) 0.489\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:46 | INFO | Rank 0 | Train Epoch: 0 [13440/250314 (5%)]\tLoss: 1.526495\tData (t) 0.338\tBatch (t) 0.548\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:47 | INFO | Rank 0 | Train Epoch: 0 [13472/250314 (5%)]\tLoss: 1.547300\tData (t) 0.279\tBatch (t) 0.489\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:47 | INFO | Rank 0 | Train Epoch: 0 [13504/250314 (5%)]\tLoss: 1.583647\tData (t) 0.277\tBatch (t) 0.486\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:48 | INFO | Rank 0 | Train Epoch: 0 [13536/250314 (5%)]\tLoss: 1.527040\tData (t) 0.318\tBatch (t) 0.528\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:48 | INFO | Rank 0 | Train Epoch: 0 [13568/250314 (5%)]\tLoss: 1.725130\tData (t) 0.276\tBatch (t) 0.486\tLR: 0.000008\tlogit_scale 4.604\n",
      "2022-11-09,13:13:49 | INFO | Rank 0 | Train Epoch: 0 [13600/250314 (5%)]\tLoss: 1.595602\tData (t) 0.298\tBatch (t) 0.508\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:49 | INFO | Rank 0 | Train Epoch: 0 [13632/250314 (5%)]\tLoss: 1.808798\tData (t) 0.312\tBatch (t) 0.522\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:50 | INFO | Rank 0 | Train Epoch: 0 [13664/250314 (5%)]\tLoss: 2.009045\tData (t) 0.259\tBatch (t) 0.469\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:50 | INFO | Rank 0 | Train Epoch: 0 [13696/250314 (5%)]\tLoss: 1.466896\tData (t) 0.268\tBatch (t) 0.478\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:51 | INFO | Rank 0 | Train Epoch: 0 [13728/250314 (5%)]\tLoss: 1.419560\tData (t) 0.258\tBatch (t) 0.468\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:51 | INFO | Rank 0 | Train Epoch: 0 [13760/250314 (5%)]\tLoss: 1.650046\tData (t) 0.269\tBatch (t) 0.478\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:52 | INFO | Rank 0 | Train Epoch: 0 [13792/250314 (6%)]\tLoss: 1.597141\tData (t) 0.311\tBatch (t) 0.521\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:52 | INFO | Rank 0 | Train Epoch: 0 [13824/250314 (6%)]\tLoss: 1.747835\tData (t) 0.294\tBatch (t) 0.504\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:53 | INFO | Rank 0 | Train Epoch: 0 [13856/250314 (6%)]\tLoss: 1.615639\tData (t) 0.285\tBatch (t) 0.495\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:53 | INFO | Rank 0 | Train Epoch: 0 [13888/250314 (6%)]\tLoss: 1.569999\tData (t) 0.213\tBatch (t) 0.422\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:54 | INFO | Rank 0 | Train Epoch: 0 [13920/250314 (6%)]\tLoss: 1.595742\tData (t) 0.262\tBatch (t) 0.472\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:54 | INFO | Rank 0 | Train Epoch: 0 [13952/250314 (6%)]\tLoss: 2.114296\tData (t) 0.223\tBatch (t) 0.433\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:55 | INFO | Rank 0 | Train Epoch: 0 [13984/250314 (6%)]\tLoss: 1.288688\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:55 | INFO | Rank 0 | Train Epoch: 0 [14016/250314 (6%)]\tLoss: 1.479904\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:56 | INFO | Rank 0 | Train Epoch: 0 [14048/250314 (6%)]\tLoss: 1.367706\tData (t) 0.267\tBatch (t) 0.477\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:56 | INFO | Rank 0 | Train Epoch: 0 [14080/250314 (6%)]\tLoss: 1.839140\tData (t) 0.303\tBatch (t) 0.513\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:57 | INFO | Rank 0 | Train Epoch: 0 [14112/250314 (6%)]\tLoss: 2.050368\tData (t) 0.265\tBatch (t) 0.474\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:57 | INFO | Rank 0 | Train Epoch: 0 [14144/250314 (6%)]\tLoss: 1.333577\tData (t) 0.307\tBatch (t) 0.517\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:58 | INFO | Rank 0 | Train Epoch: 0 [14176/250314 (6%)]\tLoss: 1.578311\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:58 | INFO | Rank 0 | Train Epoch: 0 [14208/250314 (6%)]\tLoss: 1.869304\tData (t) 0.290\tBatch (t) 0.500\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:59 | INFO | Rank 0 | Train Epoch: 0 [14240/250314 (6%)]\tLoss: 1.381245\tData (t) 0.325\tBatch (t) 0.535\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:13:59 | INFO | Rank 0 | Train Epoch: 0 [14272/250314 (6%)]\tLoss: 1.396577\tData (t) 0.284\tBatch (t) 0.493\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:00 | INFO | Rank 0 | Train Epoch: 0 [14304/250314 (6%)]\tLoss: 1.592986\tData (t) 0.273\tBatch (t) 0.483\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:00 | INFO | Rank 0 | Train Epoch: 0 [14336/250314 (6%)]\tLoss: 1.412853\tData (t) 0.260\tBatch (t) 0.470\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:01 | INFO | Rank 0 | Train Epoch: 0 [14368/250314 (6%)]\tLoss: 1.417646\tData (t) 0.312\tBatch (t) 0.521\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:01 | INFO | Rank 0 | Train Epoch: 0 [14400/250314 (6%)]\tLoss: 1.435380\tData (t) 0.335\tBatch (t) 0.544\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:02 | INFO | Rank 0 | Train Epoch: 0 [14432/250314 (6%)]\tLoss: 1.461010\tData (t) 0.336\tBatch (t) 0.546\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:02 | INFO | Rank 0 | Train Epoch: 0 [14464/250314 (6%)]\tLoss: 1.887710\tData (t) 0.254\tBatch (t) 0.464\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:03 | INFO | Rank 0 | Train Epoch: 0 [14496/250314 (6%)]\tLoss: 1.824406\tData (t) 0.260\tBatch (t) 0.470\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:03 | INFO | Rank 0 | Train Epoch: 0 [14528/250314 (6%)]\tLoss: 1.374600\tData (t) 0.284\tBatch (t) 0.494\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:03 | INFO | Rank 0 | Train Epoch: 0 [14560/250314 (6%)]\tLoss: 1.553869\tData (t) 0.211\tBatch (t) 0.421\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:04 | INFO | Rank 0 | Train Epoch: 0 [14592/250314 (6%)]\tLoss: 1.368006\tData (t) 0.292\tBatch (t) 0.502\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:05 | INFO | Rank 0 | Train Epoch: 0 [14624/250314 (6%)]\tLoss: 1.496247\tData (t) 0.334\tBatch (t) 0.544\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:05 | INFO | Rank 0 | Train Epoch: 0 [14656/250314 (6%)]\tLoss: 1.668128\tData (t) 0.299\tBatch (t) 0.509\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:06 | INFO | Rank 0 | Train Epoch: 0 [14688/250314 (6%)]\tLoss: 1.222046\tData (t) 0.412\tBatch (t) 0.622\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:06 | INFO | Rank 0 | Train Epoch: 0 [14720/250314 (6%)]\tLoss: 1.416085\tData (t) 0.266\tBatch (t) 0.476\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:07 | INFO | Rank 0 | Train Epoch: 0 [14752/250314 (6%)]\tLoss: 1.710486\tData (t) 0.260\tBatch (t) 0.470\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:07 | INFO | Rank 0 | Train Epoch: 0 [14784/250314 (6%)]\tLoss: 1.632069\tData (t) 0.305\tBatch (t) 0.515\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:08 | INFO | Rank 0 | Train Epoch: 0 [14816/250314 (6%)]\tLoss: 1.548322\tData (t) 0.237\tBatch (t) 0.447\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:08 | INFO | Rank 0 | Train Epoch: 0 [14848/250314 (6%)]\tLoss: 1.299215\tData (t) 0.303\tBatch (t) 0.513\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:09 | INFO | Rank 0 | Train Epoch: 0 [14880/250314 (6%)]\tLoss: 1.262987\tData (t) 0.217\tBatch (t) 0.427\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:09 | INFO | Rank 0 | Train Epoch: 0 [14912/250314 (6%)]\tLoss: 1.236074\tData (t) 0.276\tBatch (t) 0.486\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:10 | INFO | Rank 0 | Train Epoch: 0 [14944/250314 (6%)]\tLoss: 1.043602\tData (t) 0.326\tBatch (t) 0.535\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:10 | INFO | Rank 0 | Train Epoch: 0 [14976/250314 (6%)]\tLoss: 1.692392\tData (t) 0.252\tBatch (t) 0.462\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:10 | INFO | Rank 0 | Train Epoch: 0 [15008/250314 (6%)]\tLoss: 1.560447\tData (t) 0.266\tBatch (t) 0.476\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:11 | INFO | Rank 0 | Train Epoch: 0 [15040/250314 (6%)]\tLoss: 1.799338\tData (t) 0.280\tBatch (t) 0.490\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:11 | INFO | Rank 0 | Train Epoch: 0 [15072/250314 (6%)]\tLoss: 1.829875\tData (t) 0.234\tBatch (t) 0.444\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:12 | INFO | Rank 0 | Train Epoch: 0 [15104/250314 (6%)]\tLoss: 1.516828\tData (t) 0.345\tBatch (t) 0.555\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:12 | INFO | Rank 0 | Train Epoch: 0 [15136/250314 (6%)]\tLoss: 1.293177\tData (t) 0.246\tBatch (t) 0.456\tLR: 0.000009\tlogit_scale 4.604\n",
      "2022-11-09,13:14:13 | INFO | Rank 0 | Train Epoch: 0 [15168/250314 (6%)]\tLoss: 1.169701\tData (t) 0.315\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:13 | INFO | Rank 0 | Train Epoch: 0 [15200/250314 (6%)]\tLoss: 1.517453\tData (t) 0.285\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:14 | INFO | Rank 0 | Train Epoch: 0 [15232/250314 (6%)]\tLoss: 1.254278\tData (t) 0.324\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:15 | INFO | Rank 0 | Train Epoch: 0 [15264/250314 (6%)]\tLoss: 1.098513\tData (t) 0.334\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:15 | INFO | Rank 0 | Train Epoch: 0 [15296/250314 (6%)]\tLoss: 1.386141\tData (t) 0.229\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:15 | INFO | Rank 0 | Train Epoch: 0 [15328/250314 (6%)]\tLoss: 1.414682\tData (t) 0.279\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:16 | INFO | Rank 0 | Train Epoch: 0 [15360/250314 (6%)]\tLoss: 1.359357\tData (t) 0.298\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:16 | INFO | Rank 0 | Train Epoch: 0 [15392/250314 (6%)]\tLoss: 1.218741\tData (t) 0.294\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:17 | INFO | Rank 0 | Train Epoch: 0 [15424/250314 (6%)]\tLoss: 1.749789\tData (t) 0.310\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:17 | INFO | Rank 0 | Train Epoch: 0 [15456/250314 (6%)]\tLoss: 1.865160\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:18 | INFO | Rank 0 | Train Epoch: 0 [15488/250314 (6%)]\tLoss: 1.701529\tData (t) 0.311\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:18 | INFO | Rank 0 | Train Epoch: 0 [15520/250314 (6%)]\tLoss: 1.344910\tData (t) 0.271\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:19 | INFO | Rank 0 | Train Epoch: 0 [15552/250314 (6%)]\tLoss: 1.176907\tData (t) 0.258\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:19 | INFO | Rank 0 | Train Epoch: 0 [15584/250314 (6%)]\tLoss: 1.925027\tData (t) 0.264\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:20 | INFO | Rank 0 | Train Epoch: 0 [15616/250314 (6%)]\tLoss: 1.489536\tData (t) 0.268\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:20 | INFO | Rank 0 | Train Epoch: 0 [15648/250314 (6%)]\tLoss: 1.465907\tData (t) 0.268\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:21 | INFO | Rank 0 | Train Epoch: 0 [15680/250314 (6%)]\tLoss: 1.172939\tData (t) 0.263\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:21 | INFO | Rank 0 | Train Epoch: 0 [15712/250314 (6%)]\tLoss: 1.948942\tData (t) 0.322\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:22 | INFO | Rank 0 | Train Epoch: 0 [15744/250314 (6%)]\tLoss: 1.656730\tData (t) 0.301\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:22 | INFO | Rank 0 | Train Epoch: 0 [15776/250314 (6%)]\tLoss: 1.514742\tData (t) 0.321\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:23 | INFO | Rank 0 | Train Epoch: 0 [15808/250314 (6%)]\tLoss: 1.269469\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:23 | INFO | Rank 0 | Train Epoch: 0 [15840/250314 (6%)]\tLoss: 1.231688\tData (t) 0.254\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:24 | INFO | Rank 0 | Train Epoch: 0 [15872/250314 (6%)]\tLoss: 1.367407\tData (t) 0.256\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:24 | INFO | Rank 0 | Train Epoch: 0 [15904/250314 (6%)]\tLoss: 1.745840\tData (t) 0.279\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:25 | INFO | Rank 0 | Train Epoch: 0 [15936/250314 (6%)]\tLoss: 1.363791\tData (t) 0.243\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:25 | INFO | Rank 0 | Train Epoch: 0 [15968/250314 (6%)]\tLoss: 1.789460\tData (t) 0.249\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:26 | INFO | Rank 0 | Train Epoch: 0 [16000/250314 (6%)]\tLoss: 1.370508\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:26 | INFO | Rank 0 | Train Epoch: 0 [16032/250314 (6%)]\tLoss: 1.892585\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:27 | INFO | Rank 0 | Train Epoch: 0 [16064/250314 (6%)]\tLoss: 2.081137\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:27 | INFO | Rank 0 | Train Epoch: 0 [16096/250314 (6%)]\tLoss: 1.754121\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:28 | INFO | Rank 0 | Train Epoch: 0 [16128/250314 (6%)]\tLoss: 1.593271\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:28 | INFO | Rank 0 | Train Epoch: 0 [16160/250314 (6%)]\tLoss: 1.026109\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:29 | INFO | Rank 0 | Train Epoch: 0 [16192/250314 (6%)]\tLoss: 1.640220\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:29 | INFO | Rank 0 | Train Epoch: 0 [16224/250314 (6%)]\tLoss: 1.540228\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:30 | INFO | Rank 0 | Train Epoch: 0 [16256/250314 (6%)]\tLoss: 1.404288\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:30 | INFO | Rank 0 | Train Epoch: 0 [16288/250314 (7%)]\tLoss: 1.566608\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:31 | INFO | Rank 0 | Train Epoch: 0 [16320/250314 (7%)]\tLoss: 1.470141\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:31 | INFO | Rank 0 | Train Epoch: 0 [16352/250314 (7%)]\tLoss: 1.469189\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:32 | INFO | Rank 0 | Train Epoch: 0 [16384/250314 (7%)]\tLoss: 1.472390\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:32 | INFO | Rank 0 | Train Epoch: 0 [16416/250314 (7%)]\tLoss: 1.931183\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:33 | INFO | Rank 0 | Train Epoch: 0 [16448/250314 (7%)]\tLoss: 1.060328\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:33 | INFO | Rank 0 | Train Epoch: 0 [16480/250314 (7%)]\tLoss: 1.152138\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:34 | INFO | Rank 0 | Train Epoch: 0 [16512/250314 (7%)]\tLoss: 1.226016\tData (t) 0.256\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:34 | INFO | Rank 0 | Train Epoch: 0 [16544/250314 (7%)]\tLoss: 1.429448\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:35 | INFO | Rank 0 | Train Epoch: 0 [16576/250314 (7%)]\tLoss: 1.354617\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:35 | INFO | Rank 0 | Train Epoch: 0 [16608/250314 (7%)]\tLoss: 1.204098\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:35 | INFO | Rank 0 | Train Epoch: 0 [16640/250314 (7%)]\tLoss: 1.305398\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:36 | INFO | Rank 0 | Train Epoch: 0 [16672/250314 (7%)]\tLoss: 1.134831\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:36 | INFO | Rank 0 | Train Epoch: 0 [16704/250314 (7%)]\tLoss: 1.631232\tData (t) 0.356\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:37 | INFO | Rank 0 | Train Epoch: 0 [16736/250314 (7%)]\tLoss: 1.367879\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:38 | INFO | Rank 0 | Train Epoch: 0 [16768/250314 (7%)]\tLoss: 1.376827\tData (t) 0.422\tBatch (t) 0.633\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:38 | INFO | Rank 0 | Train Epoch: 0 [16800/250314 (7%)]\tLoss: 1.246127\tData (t) 0.288\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:39 | INFO | Rank 0 | Train Epoch: 0 [16832/250314 (7%)]\tLoss: 1.230448\tData (t) 0.276\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:39 | INFO | Rank 0 | Train Epoch: 0 [16864/250314 (7%)]\tLoss: 1.477023\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:40 | INFO | Rank 0 | Train Epoch: 0 [16896/250314 (7%)]\tLoss: 1.226976\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:40 | INFO | Rank 0 | Train Epoch: 0 [16928/250314 (7%)]\tLoss: 1.796703\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:40 | INFO | Rank 0 | Train Epoch: 0 [16960/250314 (7%)]\tLoss: 1.552963\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:41 | INFO | Rank 0 | Train Epoch: 0 [16992/250314 (7%)]\tLoss: 1.189641\tData (t) 0.233\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:41 | INFO | Rank 0 | Train Epoch: 0 [17024/250314 (7%)]\tLoss: 1.507897\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:42 | INFO | Rank 0 | Train Epoch: 0 [17056/250314 (7%)]\tLoss: 1.517555\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:42 | INFO | Rank 0 | Train Epoch: 0 [17088/250314 (7%)]\tLoss: 1.395613\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:43 | INFO | Rank 0 | Train Epoch: 0 [17120/250314 (7%)]\tLoss: 1.270370\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:43 | INFO | Rank 0 | Train Epoch: 0 [17152/250314 (7%)]\tLoss: 1.580357\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:44 | INFO | Rank 0 | Train Epoch: 0 [17184/250314 (7%)]\tLoss: 1.152763\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:44 | INFO | Rank 0 | Train Epoch: 0 [17216/250314 (7%)]\tLoss: 1.139602\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:45 | INFO | Rank 0 | Train Epoch: 0 [17248/250314 (7%)]\tLoss: 1.668134\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:45 | INFO | Rank 0 | Train Epoch: 0 [17280/250314 (7%)]\tLoss: 1.272164\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:46 | INFO | Rank 0 | Train Epoch: 0 [17312/250314 (7%)]\tLoss: 1.168945\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:46 | INFO | Rank 0 | Train Epoch: 0 [17344/250314 (7%)]\tLoss: 1.639058\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:47 | INFO | Rank 0 | Train Epoch: 0 [17376/250314 (7%)]\tLoss: 1.331689\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:47 | INFO | Rank 0 | Train Epoch: 0 [17408/250314 (7%)]\tLoss: 1.726351\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:48 | INFO | Rank 0 | Train Epoch: 0 [17440/250314 (7%)]\tLoss: 1.988653\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:48 | INFO | Rank 0 | Train Epoch: 0 [17472/250314 (7%)]\tLoss: 1.461797\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:49 | INFO | Rank 0 | Train Epoch: 0 [17504/250314 (7%)]\tLoss: 1.127319\tData (t) 0.227\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:49 | INFO | Rank 0 | Train Epoch: 0 [17536/250314 (7%)]\tLoss: 0.994736\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:50 | INFO | Rank 0 | Train Epoch: 0 [17568/250314 (7%)]\tLoss: 1.300370\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:50 | INFO | Rank 0 | Train Epoch: 0 [17600/250314 (7%)]\tLoss: 1.563887\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:51 | INFO | Rank 0 | Train Epoch: 0 [17632/250314 (7%)]\tLoss: 1.609989\tData (t) 0.219\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:51 | INFO | Rank 0 | Train Epoch: 0 [17664/250314 (7%)]\tLoss: 1.796621\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:52 | INFO | Rank 0 | Train Epoch: 0 [17696/250314 (7%)]\tLoss: 1.599598\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:52 | INFO | Rank 0 | Train Epoch: 0 [17728/250314 (7%)]\tLoss: 1.875466\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:53 | INFO | Rank 0 | Train Epoch: 0 [17760/250314 (7%)]\tLoss: 1.497084\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:53 | INFO | Rank 0 | Train Epoch: 0 [17792/250314 (7%)]\tLoss: 1.424610\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.604\n",
      "2022-11-09,13:14:53 | INFO | Rank 0 | Train Epoch: 0 [17824/250314 (7%)]\tLoss: 1.301345\tData (t) 0.192\tBatch (t) 0.404\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:14:54 | INFO | Rank 0 | Train Epoch: 0 [17856/250314 (7%)]\tLoss: 1.374711\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:14:55 | INFO | Rank 0 | Train Epoch: 0 [17888/250314 (7%)]\tLoss: 1.435850\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:14:55 | INFO | Rank 0 | Train Epoch: 0 [17920/250314 (7%)]\tLoss: 1.120271\tData (t) 0.213\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:14:55 | INFO | Rank 0 | Train Epoch: 0 [17952/250314 (7%)]\tLoss: 1.085521\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:14:56 | INFO | Rank 0 | Train Epoch: 0 [17984/250314 (7%)]\tLoss: 0.844178\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:14:56 | INFO | Rank 0 | Train Epoch: 0 [18016/250314 (7%)]\tLoss: 1.158817\tData (t) 0.181\tBatch (t) 0.392\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:14:57 | INFO | Rank 0 | Train Epoch: 0 [18048/250314 (7%)]\tLoss: 1.300231\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:14:57 | INFO | Rank 0 | Train Epoch: 0 [18080/250314 (7%)]\tLoss: 1.347003\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:14:58 | INFO | Rank 0 | Train Epoch: 0 [18112/250314 (7%)]\tLoss: 1.571625\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:14:58 | INFO | Rank 0 | Train Epoch: 0 [18144/250314 (7%)]\tLoss: 0.974441\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:14:59 | INFO | Rank 0 | Train Epoch: 0 [18176/250314 (7%)]\tLoss: 1.381571\tData (t) 0.347\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:14:59 | INFO | Rank 0 | Train Epoch: 0 [18208/250314 (7%)]\tLoss: 1.396709\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:00 | INFO | Rank 0 | Train Epoch: 0 [18240/250314 (7%)]\tLoss: 1.223384\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:00 | INFO | Rank 0 | Train Epoch: 0 [18272/250314 (7%)]\tLoss: 1.675729\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:01 | INFO | Rank 0 | Train Epoch: 0 [18304/250314 (7%)]\tLoss: 1.233570\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:01 | INFO | Rank 0 | Train Epoch: 0 [18336/250314 (7%)]\tLoss: 1.883772\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:02 | INFO | Rank 0 | Train Epoch: 0 [18368/250314 (7%)]\tLoss: 1.551870\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:02 | INFO | Rank 0 | Train Epoch: 0 [18400/250314 (7%)]\tLoss: 1.364283\tData (t) 0.325\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:03 | INFO | Rank 0 | Train Epoch: 0 [18432/250314 (7%)]\tLoss: 1.595561\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:03 | INFO | Rank 0 | Train Epoch: 0 [18464/250314 (7%)]\tLoss: 1.681221\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:04 | INFO | Rank 0 | Train Epoch: 0 [18496/250314 (7%)]\tLoss: 1.520465\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:04 | INFO | Rank 0 | Train Epoch: 0 [18528/250314 (7%)]\tLoss: 1.373671\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:05 | INFO | Rank 0 | Train Epoch: 0 [18560/250314 (7%)]\tLoss: 1.380961\tData (t) 0.355\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:05 | INFO | Rank 0 | Train Epoch: 0 [18592/250314 (7%)]\tLoss: 1.356781\tData (t) 0.365\tBatch (t) 0.577\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:06 | INFO | Rank 0 | Train Epoch: 0 [18624/250314 (7%)]\tLoss: 1.930727\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:06 | INFO | Rank 0 | Train Epoch: 0 [18656/250314 (7%)]\tLoss: 1.373219\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:07 | INFO | Rank 0 | Train Epoch: 0 [18688/250314 (7%)]\tLoss: 1.178969\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:07 | INFO | Rank 0 | Train Epoch: 0 [18720/250314 (7%)]\tLoss: 1.238379\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:08 | INFO | Rank 0 | Train Epoch: 0 [18752/250314 (7%)]\tLoss: 1.193940\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:08 | INFO | Rank 0 | Train Epoch: 0 [18784/250314 (8%)]\tLoss: 1.390041\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:09 | INFO | Rank 0 | Train Epoch: 0 [18816/250314 (8%)]\tLoss: 1.347444\tData (t) 0.338\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:09 | INFO | Rank 0 | Train Epoch: 0 [18848/250314 (8%)]\tLoss: 1.588412\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:10 | INFO | Rank 0 | Train Epoch: 0 [18880/250314 (8%)]\tLoss: 1.581523\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:10 | INFO | Rank 0 | Train Epoch: 0 [18912/250314 (8%)]\tLoss: 1.572819\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:11 | INFO | Rank 0 | Train Epoch: 0 [18944/250314 (8%)]\tLoss: 1.297179\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:11 | INFO | Rank 0 | Train Epoch: 0 [18976/250314 (8%)]\tLoss: 1.427146\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:12 | INFO | Rank 0 | Train Epoch: 0 [19008/250314 (8%)]\tLoss: 1.188146\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:12 | INFO | Rank 0 | Train Epoch: 0 [19040/250314 (8%)]\tLoss: 1.249485\tData (t) 0.318\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:13 | INFO | Rank 0 | Train Epoch: 0 [19072/250314 (8%)]\tLoss: 1.524799\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:13 | INFO | Rank 0 | Train Epoch: 0 [19104/250314 (8%)]\tLoss: 1.235320\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:14 | INFO | Rank 0 | Train Epoch: 0 [19136/250314 (8%)]\tLoss: 1.271208\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:14 | INFO | Rank 0 | Train Epoch: 0 [19168/250314 (8%)]\tLoss: 1.463751\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:15 | INFO | Rank 0 | Train Epoch: 0 [19200/250314 (8%)]\tLoss: 1.244811\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:15 | INFO | Rank 0 | Train Epoch: 0 [19232/250314 (8%)]\tLoss: 2.045526\tData (t) 0.320\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:16 | INFO | Rank 0 | Train Epoch: 0 [19264/250314 (8%)]\tLoss: 1.039631\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:16 | INFO | Rank 0 | Train Epoch: 0 [19296/250314 (8%)]\tLoss: 1.130992\tData (t) 0.230\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:17 | INFO | Rank 0 | Train Epoch: 0 [19328/250314 (8%)]\tLoss: 1.449694\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:17 | INFO | Rank 0 | Train Epoch: 0 [19360/250314 (8%)]\tLoss: 1.248502\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:18 | INFO | Rank 0 | Train Epoch: 0 [19392/250314 (8%)]\tLoss: 1.119759\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:18 | INFO | Rank 0 | Train Epoch: 0 [19424/250314 (8%)]\tLoss: 1.211172\tData (t) 0.356\tBatch (t) 0.567\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:19 | INFO | Rank 0 | Train Epoch: 0 [19456/250314 (8%)]\tLoss: 1.135367\tData (t) 0.171\tBatch (t) 0.382\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:19 | INFO | Rank 0 | Train Epoch: 0 [19488/250314 (8%)]\tLoss: 1.535703\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:20 | INFO | Rank 0 | Train Epoch: 0 [19520/250314 (8%)]\tLoss: 1.088444\tData (t) 0.415\tBatch (t) 0.627\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:20 | INFO | Rank 0 | Train Epoch: 0 [19552/250314 (8%)]\tLoss: 0.991261\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:21 | INFO | Rank 0 | Train Epoch: 0 [19584/250314 (8%)]\tLoss: 1.465693\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:21 | INFO | Rank 0 | Train Epoch: 0 [19616/250314 (8%)]\tLoss: 1.403431\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:22 | INFO | Rank 0 | Train Epoch: 0 [19648/250314 (8%)]\tLoss: 1.207570\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:22 | INFO | Rank 0 | Train Epoch: 0 [19680/250314 (8%)]\tLoss: 1.745047\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:23 | INFO | Rank 0 | Train Epoch: 0 [19712/250314 (8%)]\tLoss: 1.299605\tData (t) 0.373\tBatch (t) 0.584\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:23 | INFO | Rank 0 | Train Epoch: 0 [19744/250314 (8%)]\tLoss: 1.301862\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:24 | INFO | Rank 0 | Train Epoch: 0 [19776/250314 (8%)]\tLoss: 1.585627\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:24 | INFO | Rank 0 | Train Epoch: 0 [19808/250314 (8%)]\tLoss: 1.326263\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:25 | INFO | Rank 0 | Train Epoch: 0 [19840/250314 (8%)]\tLoss: 1.289314\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:25 | INFO | Rank 0 | Train Epoch: 0 [19872/250314 (8%)]\tLoss: 1.100054\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:26 | INFO | Rank 0 | Train Epoch: 0 [19904/250314 (8%)]\tLoss: 1.178278\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:26 | INFO | Rank 0 | Train Epoch: 0 [19936/250314 (8%)]\tLoss: 1.487960\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:27 | INFO | Rank 0 | Train Epoch: 0 [19968/250314 (8%)]\tLoss: 0.693130\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:27 | INFO | Rank 0 | Train Epoch: 0 [20000/250314 (8%)]\tLoss: 1.754493\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:27 | INFO | Rank 0 | Train Epoch: 0 [20032/250314 (8%)]\tLoss: 1.320662\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:28 | INFO | Rank 0 | Train Epoch: 0 [20064/250314 (8%)]\tLoss: 1.251863\tData (t) 0.354\tBatch (t) 0.565\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:29 | INFO | Rank 0 | Train Epoch: 0 [20096/250314 (8%)]\tLoss: 0.886967\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:29 | INFO | Rank 0 | Train Epoch: 0 [20128/250314 (8%)]\tLoss: 1.738753\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:30 | INFO | Rank 0 | Train Epoch: 0 [20160/250314 (8%)]\tLoss: 1.450549\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:30 | INFO | Rank 0 | Train Epoch: 0 [20192/250314 (8%)]\tLoss: 1.186729\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:31 | INFO | Rank 0 | Train Epoch: 0 [20224/250314 (8%)]\tLoss: 1.396485\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:31 | INFO | Rank 0 | Train Epoch: 0 [20256/250314 (8%)]\tLoss: 1.559075\tData (t) 0.277\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:32 | INFO | Rank 0 | Train Epoch: 0 [20288/250314 (8%)]\tLoss: 1.232435\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:32 | INFO | Rank 0 | Train Epoch: 0 [20320/250314 (8%)]\tLoss: 1.469731\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:32 | INFO | Rank 0 | Train Epoch: 0 [20352/250314 (8%)]\tLoss: 1.221103\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:33 | INFO | Rank 0 | Train Epoch: 0 [20384/250314 (8%)]\tLoss: 0.927799\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:33 | INFO | Rank 0 | Train Epoch: 0 [20416/250314 (8%)]\tLoss: 1.197587\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:34 | INFO | Rank 0 | Train Epoch: 0 [20448/250314 (8%)]\tLoss: 1.170850\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:34 | INFO | Rank 0 | Train Epoch: 0 [20480/250314 (8%)]\tLoss: 1.518035\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:35 | INFO | Rank 0 | Train Epoch: 0 [20512/250314 (8%)]\tLoss: 1.359807\tData (t) 0.347\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:35 | INFO | Rank 0 | Train Epoch: 0 [20544/250314 (8%)]\tLoss: 1.316935\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:36 | INFO | Rank 0 | Train Epoch: 0 [20576/250314 (8%)]\tLoss: 1.489324\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:36 | INFO | Rank 0 | Train Epoch: 0 [20608/250314 (8%)]\tLoss: 1.167311\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:37 | INFO | Rank 0 | Train Epoch: 0 [20640/250314 (8%)]\tLoss: 1.098415\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:37 | INFO | Rank 0 | Train Epoch: 0 [20672/250314 (8%)]\tLoss: 1.655200\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:38 | INFO | Rank 0 | Train Epoch: 0 [20704/250314 (8%)]\tLoss: 1.327473\tData (t) 0.423\tBatch (t) 0.634\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:39 | INFO | Rank 0 | Train Epoch: 0 [20736/250314 (8%)]\tLoss: 1.221134\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:39 | INFO | Rank 0 | Train Epoch: 0 [20768/250314 (8%)]\tLoss: 1.198252\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:40 | INFO | Rank 0 | Train Epoch: 0 [20800/250314 (8%)]\tLoss: 1.291158\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:40 | INFO | Rank 0 | Train Epoch: 0 [20832/250314 (8%)]\tLoss: 1.943433\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:40 | INFO | Rank 0 | Train Epoch: 0 [20864/250314 (8%)]\tLoss: 1.083709\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:41 | INFO | Rank 0 | Train Epoch: 0 [20896/250314 (8%)]\tLoss: 0.981514\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:41 | INFO | Rank 0 | Train Epoch: 0 [20928/250314 (8%)]\tLoss: 0.855406\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:42 | INFO | Rank 0 | Train Epoch: 0 [20960/250314 (8%)]\tLoss: 1.299006\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:42 | INFO | Rank 0 | Train Epoch: 0 [20992/250314 (8%)]\tLoss: 1.132275\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:43 | INFO | Rank 0 | Train Epoch: 0 [21024/250314 (8%)]\tLoss: 1.614743\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:43 | INFO | Rank 0 | Train Epoch: 0 [21056/250314 (8%)]\tLoss: 0.909266\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:44 | INFO | Rank 0 | Train Epoch: 0 [21088/250314 (8%)]\tLoss: 1.195670\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:44 | INFO | Rank 0 | Train Epoch: 0 [21120/250314 (8%)]\tLoss: 1.138993\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:45 | INFO | Rank 0 | Train Epoch: 0 [21152/250314 (8%)]\tLoss: 1.229684\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:45 | INFO | Rank 0 | Train Epoch: 0 [21184/250314 (8%)]\tLoss: 1.494350\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:46 | INFO | Rank 0 | Train Epoch: 0 [21216/250314 (8%)]\tLoss: 1.382363\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:46 | INFO | Rank 0 | Train Epoch: 0 [21248/250314 (8%)]\tLoss: 1.113928\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:47 | INFO | Rank 0 | Train Epoch: 0 [21280/250314 (9%)]\tLoss: 0.949344\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:47 | INFO | Rank 0 | Train Epoch: 0 [21312/250314 (9%)]\tLoss: 1.026880\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:48 | INFO | Rank 0 | Train Epoch: 0 [21344/250314 (9%)]\tLoss: 1.281205\tData (t) 0.316\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:48 | INFO | Rank 0 | Train Epoch: 0 [21376/250314 (9%)]\tLoss: 1.136164\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:49 | INFO | Rank 0 | Train Epoch: 0 [21408/250314 (9%)]\tLoss: 1.713387\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:49 | INFO | Rank 0 | Train Epoch: 0 [21440/250314 (9%)]\tLoss: 1.302144\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:50 | INFO | Rank 0 | Train Epoch: 0 [21472/250314 (9%)]\tLoss: 1.568729\tData (t) 0.225\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:50 | INFO | Rank 0 | Train Epoch: 0 [21504/250314 (9%)]\tLoss: 1.093301\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:51 | INFO | Rank 0 | Train Epoch: 0 [21536/250314 (9%)]\tLoss: 0.992305\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:51 | INFO | Rank 0 | Train Epoch: 0 [21568/250314 (9%)]\tLoss: 1.508491\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:52 | INFO | Rank 0 | Train Epoch: 0 [21600/250314 (9%)]\tLoss: 1.695022\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:52 | INFO | Rank 0 | Train Epoch: 0 [21632/250314 (9%)]\tLoss: 1.333290\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:53 | INFO | Rank 0 | Train Epoch: 0 [21664/250314 (9%)]\tLoss: 1.435339\tData (t) 0.335\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:53 | INFO | Rank 0 | Train Epoch: 0 [21696/250314 (9%)]\tLoss: 1.193516\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:54 | INFO | Rank 0 | Train Epoch: 0 [21728/250314 (9%)]\tLoss: 1.360305\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:54 | INFO | Rank 0 | Train Epoch: 0 [21760/250314 (9%)]\tLoss: 1.452218\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:55 | INFO | Rank 0 | Train Epoch: 0 [21792/250314 (9%)]\tLoss: 1.079610\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:56 | INFO | Rank 0 | Train Epoch: 0 [21824/250314 (9%)]\tLoss: 1.291981\tData (t) 0.484\tBatch (t) 0.695\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:56 | INFO | Rank 0 | Train Epoch: 0 [21856/250314 (9%)]\tLoss: 1.211113\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:56 | INFO | Rank 0 | Train Epoch: 0 [21888/250314 (9%)]\tLoss: 1.457317\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:57 | INFO | Rank 0 | Train Epoch: 0 [21920/250314 (9%)]\tLoss: 1.252854\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:57 | INFO | Rank 0 | Train Epoch: 0 [21952/250314 (9%)]\tLoss: 1.675736\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:58 | INFO | Rank 0 | Train Epoch: 0 [21984/250314 (9%)]\tLoss: 1.167204\tData (t) 0.307\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:58 | INFO | Rank 0 | Train Epoch: 0 [22016/250314 (9%)]\tLoss: 1.211524\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:59 | INFO | Rank 0 | Train Epoch: 0 [22048/250314 (9%)]\tLoss: 1.461059\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:15:59 | INFO | Rank 0 | Train Epoch: 0 [22080/250314 (9%)]\tLoss: 1.325907\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:00 | INFO | Rank 0 | Train Epoch: 0 [22112/250314 (9%)]\tLoss: 0.593189\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:00 | INFO | Rank 0 | Train Epoch: 0 [22144/250314 (9%)]\tLoss: 1.379527\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:01 | INFO | Rank 0 | Train Epoch: 0 [22176/250314 (9%)]\tLoss: 0.817187\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:01 | INFO | Rank 0 | Train Epoch: 0 [22208/250314 (9%)]\tLoss: 1.667444\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:02 | INFO | Rank 0 | Train Epoch: 0 [22240/250314 (9%)]\tLoss: 0.906558\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:02 | INFO | Rank 0 | Train Epoch: 0 [22272/250314 (9%)]\tLoss: 1.850617\tData (t) 0.227\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:03 | INFO | Rank 0 | Train Epoch: 0 [22304/250314 (9%)]\tLoss: 1.234116\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:03 | INFO | Rank 0 | Train Epoch: 0 [22336/250314 (9%)]\tLoss: 1.043582\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:04 | INFO | Rank 0 | Train Epoch: 0 [22368/250314 (9%)]\tLoss: 0.865602\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:04 | INFO | Rank 0 | Train Epoch: 0 [22400/250314 (9%)]\tLoss: 1.239838\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:05 | INFO | Rank 0 | Train Epoch: 0 [22432/250314 (9%)]\tLoss: 1.156772\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:05 | INFO | Rank 0 | Train Epoch: 0 [22464/250314 (9%)]\tLoss: 1.249576\tData (t) 0.393\tBatch (t) 0.604\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:06 | INFO | Rank 0 | Train Epoch: 0 [22496/250314 (9%)]\tLoss: 1.097757\tData (t) 0.231\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:06 | INFO | Rank 0 | Train Epoch: 0 [22528/250314 (9%)]\tLoss: 1.468862\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:07 | INFO | Rank 0 | Train Epoch: 0 [22560/250314 (9%)]\tLoss: 1.491215\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:07 | INFO | Rank 0 | Train Epoch: 0 [22592/250314 (9%)]\tLoss: 0.967202\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:08 | INFO | Rank 0 | Train Epoch: 0 [22624/250314 (9%)]\tLoss: 1.323876\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:08 | INFO | Rank 0 | Train Epoch: 0 [22656/250314 (9%)]\tLoss: 1.087025\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:09 | INFO | Rank 0 | Train Epoch: 0 [22688/250314 (9%)]\tLoss: 1.383850\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:09 | INFO | Rank 0 | Train Epoch: 0 [22720/250314 (9%)]\tLoss: 1.442402\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:10 | INFO | Rank 0 | Train Epoch: 0 [22752/250314 (9%)]\tLoss: 1.609293\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:10 | INFO | Rank 0 | Train Epoch: 0 [22784/250314 (9%)]\tLoss: 1.543071\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:11 | INFO | Rank 0 | Train Epoch: 0 [22816/250314 (9%)]\tLoss: 1.575831\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:11 | INFO | Rank 0 | Train Epoch: 0 [22848/250314 (9%)]\tLoss: 1.198726\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:12 | INFO | Rank 0 | Train Epoch: 0 [22880/250314 (9%)]\tLoss: 1.656847\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:12 | INFO | Rank 0 | Train Epoch: 0 [22912/250314 (9%)]\tLoss: 1.751654\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:13 | INFO | Rank 0 | Train Epoch: 0 [22944/250314 (9%)]\tLoss: 1.159330\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:13 | INFO | Rank 0 | Train Epoch: 0 [22976/250314 (9%)]\tLoss: 1.242305\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:14 | INFO | Rank 0 | Train Epoch: 0 [23008/250314 (9%)]\tLoss: 1.123654\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:14 | INFO | Rank 0 | Train Epoch: 0 [23040/250314 (9%)]\tLoss: 1.263926\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:15 | INFO | Rank 0 | Train Epoch: 0 [23072/250314 (9%)]\tLoss: 0.848661\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:15 | INFO | Rank 0 | Train Epoch: 0 [23104/250314 (9%)]\tLoss: 1.099409\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:16 | INFO | Rank 0 | Train Epoch: 0 [23136/250314 (9%)]\tLoss: 1.073503\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:16 | INFO | Rank 0 | Train Epoch: 0 [23168/250314 (9%)]\tLoss: 0.997596\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:16 | INFO | Rank 0 | Train Epoch: 0 [23200/250314 (9%)]\tLoss: 1.557564\tData (t) 0.210\tBatch (t) 0.422\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:17 | INFO | Rank 0 | Train Epoch: 0 [23232/250314 (9%)]\tLoss: 1.262309\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:17 | INFO | Rank 0 | Train Epoch: 0 [23264/250314 (9%)]\tLoss: 1.873647\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:18 | INFO | Rank 0 | Train Epoch: 0 [23296/250314 (9%)]\tLoss: 1.448977\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:18 | INFO | Rank 0 | Train Epoch: 0 [23328/250314 (9%)]\tLoss: 1.832757\tData (t) 0.278\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:19 | INFO | Rank 0 | Train Epoch: 0 [23360/250314 (9%)]\tLoss: 1.583083\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:19 | INFO | Rank 0 | Train Epoch: 0 [23392/250314 (9%)]\tLoss: 1.509031\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:20 | INFO | Rank 0 | Train Epoch: 0 [23424/250314 (9%)]\tLoss: 0.954089\tData (t) 0.509\tBatch (t) 0.720\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:21 | INFO | Rank 0 | Train Epoch: 0 [23456/250314 (9%)]\tLoss: 1.315292\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:21 | INFO | Rank 0 | Train Epoch: 0 [23488/250314 (9%)]\tLoss: 1.287423\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:22 | INFO | Rank 0 | Train Epoch: 0 [23520/250314 (9%)]\tLoss: 1.529813\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:22 | INFO | Rank 0 | Train Epoch: 0 [23552/250314 (9%)]\tLoss: 1.342728\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:22 | INFO | Rank 0 | Train Epoch: 0 [23584/250314 (9%)]\tLoss: 1.146147\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:23 | INFO | Rank 0 | Train Epoch: 0 [23616/250314 (9%)]\tLoss: 1.369569\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:23 | INFO | Rank 0 | Train Epoch: 0 [23648/250314 (9%)]\tLoss: 1.575233\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:24 | INFO | Rank 0 | Train Epoch: 0 [23680/250314 (9%)]\tLoss: 1.590616\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:24 | INFO | Rank 0 | Train Epoch: 0 [23712/250314 (9%)]\tLoss: 1.424379\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:25 | INFO | Rank 0 | Train Epoch: 0 [23744/250314 (9%)]\tLoss: 1.479762\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:25 | INFO | Rank 0 | Train Epoch: 0 [23776/250314 (9%)]\tLoss: 1.508929\tData (t) 0.273\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:26 | INFO | Rank 0 | Train Epoch: 0 [23808/250314 (10%)]\tLoss: 1.047204\tData (t) 0.315\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:26 | INFO | Rank 0 | Train Epoch: 0 [23840/250314 (10%)]\tLoss: 1.278347\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:27 | INFO | Rank 0 | Train Epoch: 0 [23872/250314 (10%)]\tLoss: 1.354386\tData (t) 0.230\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:27 | INFO | Rank 0 | Train Epoch: 0 [23904/250314 (10%)]\tLoss: 1.378657\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:28 | INFO | Rank 0 | Train Epoch: 0 [23936/250314 (10%)]\tLoss: 1.533564\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:28 | INFO | Rank 0 | Train Epoch: 0 [23968/250314 (10%)]\tLoss: 1.054096\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:29 | INFO | Rank 0 | Train Epoch: 0 [24000/250314 (10%)]\tLoss: 1.085296\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:29 | INFO | Rank 0 | Train Epoch: 0 [24032/250314 (10%)]\tLoss: 1.655505\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:30 | INFO | Rank 0 | Train Epoch: 0 [24064/250314 (10%)]\tLoss: 1.418508\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:30 | INFO | Rank 0 | Train Epoch: 0 [24096/250314 (10%)]\tLoss: 1.341649\tData (t) 0.398\tBatch (t) 0.610\tLR: 0.000010\tlogit_scale 4.603\n",
      "2022-11-09,13:16:31 | INFO | Rank 0 | Train Epoch: 0 [24128/250314 (10%)]\tLoss: 1.692895\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:31 | INFO | Rank 0 | Train Epoch: 0 [24160/250314 (10%)]\tLoss: 1.513221\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:32 | INFO | Rank 0 | Train Epoch: 0 [24192/250314 (10%)]\tLoss: 1.133908\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:33 | INFO | Rank 0 | Train Epoch: 0 [24224/250314 (10%)]\tLoss: 1.400753\tData (t) 0.354\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:33 | INFO | Rank 0 | Train Epoch: 0 [24256/250314 (10%)]\tLoss: 1.412872\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:34 | INFO | Rank 0 | Train Epoch: 0 [24288/250314 (10%)]\tLoss: 1.678930\tData (t) 0.330\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:34 | INFO | Rank 0 | Train Epoch: 0 [24320/250314 (10%)]\tLoss: 1.105345\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:34 | INFO | Rank 0 | Train Epoch: 0 [24352/250314 (10%)]\tLoss: 1.671325\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:35 | INFO | Rank 0 | Train Epoch: 0 [24384/250314 (10%)]\tLoss: 1.546158\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:35 | INFO | Rank 0 | Train Epoch: 0 [24416/250314 (10%)]\tLoss: 1.178957\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:36 | INFO | Rank 0 | Train Epoch: 0 [24448/250314 (10%)]\tLoss: 1.458132\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:36 | INFO | Rank 0 | Train Epoch: 0 [24480/250314 (10%)]\tLoss: 1.351140\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:37 | INFO | Rank 0 | Train Epoch: 0 [24512/250314 (10%)]\tLoss: 1.482063\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:37 | INFO | Rank 0 | Train Epoch: 0 [24544/250314 (10%)]\tLoss: 1.546496\tData (t) 0.230\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:38 | INFO | Rank 0 | Train Epoch: 0 [24576/250314 (10%)]\tLoss: 1.194027\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:38 | INFO | Rank 0 | Train Epoch: 0 [24608/250314 (10%)]\tLoss: 1.033728\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:39 | INFO | Rank 0 | Train Epoch: 0 [24640/250314 (10%)]\tLoss: 1.192011\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:39 | INFO | Rank 0 | Train Epoch: 0 [24672/250314 (10%)]\tLoss: 1.017892\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:40 | INFO | Rank 0 | Train Epoch: 0 [24704/250314 (10%)]\tLoss: 0.946432\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:40 | INFO | Rank 0 | Train Epoch: 0 [24736/250314 (10%)]\tLoss: 1.239835\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:41 | INFO | Rank 0 | Train Epoch: 0 [24768/250314 (10%)]\tLoss: 1.217743\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:41 | INFO | Rank 0 | Train Epoch: 0 [24800/250314 (10%)]\tLoss: 1.511333\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:42 | INFO | Rank 0 | Train Epoch: 0 [24832/250314 (10%)]\tLoss: 1.476928\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:42 | INFO | Rank 0 | Train Epoch: 0 [24864/250314 (10%)]\tLoss: 1.001163\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:43 | INFO | Rank 0 | Train Epoch: 0 [24896/250314 (10%)]\tLoss: 1.176462\tData (t) 0.225\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:43 | INFO | Rank 0 | Train Epoch: 0 [24928/250314 (10%)]\tLoss: 1.255611\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:44 | INFO | Rank 0 | Train Epoch: 0 [24960/250314 (10%)]\tLoss: 1.221140\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:44 | INFO | Rank 0 | Train Epoch: 0 [24992/250314 (10%)]\tLoss: 1.133163\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:45 | INFO | Rank 0 | Train Epoch: 0 [25024/250314 (10%)]\tLoss: 1.540645\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:45 | INFO | Rank 0 | Train Epoch: 0 [25056/250314 (10%)]\tLoss: 1.237251\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:46 | INFO | Rank 0 | Train Epoch: 0 [25088/250314 (10%)]\tLoss: 1.140143\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:46 | INFO | Rank 0 | Train Epoch: 0 [25120/250314 (10%)]\tLoss: 1.256746\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:47 | INFO | Rank 0 | Train Epoch: 0 [25152/250314 (10%)]\tLoss: 0.961521\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:47 | INFO | Rank 0 | Train Epoch: 0 [25184/250314 (10%)]\tLoss: 1.194507\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:48 | INFO | Rank 0 | Train Epoch: 0 [25216/250314 (10%)]\tLoss: 1.227637\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:48 | INFO | Rank 0 | Train Epoch: 0 [25248/250314 (10%)]\tLoss: 1.697850\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:49 | INFO | Rank 0 | Train Epoch: 0 [25280/250314 (10%)]\tLoss: 1.218473\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:49 | INFO | Rank 0 | Train Epoch: 0 [25312/250314 (10%)]\tLoss: 1.469828\tData (t) 0.221\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:50 | INFO | Rank 0 | Train Epoch: 0 [25344/250314 (10%)]\tLoss: 1.192472\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:50 | INFO | Rank 0 | Train Epoch: 0 [25376/250314 (10%)]\tLoss: 1.502404\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:51 | INFO | Rank 0 | Train Epoch: 0 [25408/250314 (10%)]\tLoss: 1.057244\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:51 | INFO | Rank 0 | Train Epoch: 0 [25440/250314 (10%)]\tLoss: 1.014337\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:51 | INFO | Rank 0 | Train Epoch: 0 [25472/250314 (10%)]\tLoss: 1.101231\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:52 | INFO | Rank 0 | Train Epoch: 0 [25504/250314 (10%)]\tLoss: 1.287805\tData (t) 0.339\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:52 | INFO | Rank 0 | Train Epoch: 0 [25536/250314 (10%)]\tLoss: 1.301053\tData (t) 0.208\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:53 | INFO | Rank 0 | Train Epoch: 0 [25568/250314 (10%)]\tLoss: 1.019886\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:53 | INFO | Rank 0 | Train Epoch: 0 [25600/250314 (10%)]\tLoss: 1.338907\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:54 | INFO | Rank 0 | Train Epoch: 0 [25632/250314 (10%)]\tLoss: 1.132627\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:54 | INFO | Rank 0 | Train Epoch: 0 [25664/250314 (10%)]\tLoss: 1.440170\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:55 | INFO | Rank 0 | Train Epoch: 0 [25696/250314 (10%)]\tLoss: 1.501017\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:55 | INFO | Rank 0 | Train Epoch: 0 [25728/250314 (10%)]\tLoss: 1.150008\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:56 | INFO | Rank 0 | Train Epoch: 0 [25760/250314 (10%)]\tLoss: 1.144602\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:56 | INFO | Rank 0 | Train Epoch: 0 [25792/250314 (10%)]\tLoss: 1.022335\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:57 | INFO | Rank 0 | Train Epoch: 0 [25824/250314 (10%)]\tLoss: 1.051741\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:57 | INFO | Rank 0 | Train Epoch: 0 [25856/250314 (10%)]\tLoss: 1.110988\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:58 | INFO | Rank 0 | Train Epoch: 0 [25888/250314 (10%)]\tLoss: 1.122303\tData (t) 0.269\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:58 | INFO | Rank 0 | Train Epoch: 0 [25920/250314 (10%)]\tLoss: 0.781797\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:59 | INFO | Rank 0 | Train Epoch: 0 [25952/250314 (10%)]\tLoss: 1.118076\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:16:59 | INFO | Rank 0 | Train Epoch: 0 [25984/250314 (10%)]\tLoss: 1.019413\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:00 | INFO | Rank 0 | Train Epoch: 0 [26016/250314 (10%)]\tLoss: 1.333934\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:00 | INFO | Rank 0 | Train Epoch: 0 [26048/250314 (10%)]\tLoss: 1.928342\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:01 | INFO | Rank 0 | Train Epoch: 0 [26080/250314 (10%)]\tLoss: 1.287196\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:01 | INFO | Rank 0 | Train Epoch: 0 [26112/250314 (10%)]\tLoss: 1.161983\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:02 | INFO | Rank 0 | Train Epoch: 0 [26144/250314 (10%)]\tLoss: 2.092155\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:02 | INFO | Rank 0 | Train Epoch: 0 [26176/250314 (10%)]\tLoss: 1.155852\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:03 | INFO | Rank 0 | Train Epoch: 0 [26208/250314 (10%)]\tLoss: 1.430454\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:03 | INFO | Rank 0 | Train Epoch: 0 [26240/250314 (10%)]\tLoss: 1.014330\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:04 | INFO | Rank 0 | Train Epoch: 0 [26272/250314 (10%)]\tLoss: 1.308959\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:04 | INFO | Rank 0 | Train Epoch: 0 [26304/250314 (11%)]\tLoss: 1.039358\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:05 | INFO | Rank 0 | Train Epoch: 0 [26336/250314 (11%)]\tLoss: 1.319913\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:05 | INFO | Rank 0 | Train Epoch: 0 [26368/250314 (11%)]\tLoss: 0.932257\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:06 | INFO | Rank 0 | Train Epoch: 0 [26400/250314 (11%)]\tLoss: 1.019468\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:06 | INFO | Rank 0 | Train Epoch: 0 [26432/250314 (11%)]\tLoss: 1.494211\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:06 | INFO | Rank 0 | Train Epoch: 0 [26464/250314 (11%)]\tLoss: 1.538105\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:07 | INFO | Rank 0 | Train Epoch: 0 [26496/250314 (11%)]\tLoss: 1.460446\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:08 | INFO | Rank 0 | Train Epoch: 0 [26528/250314 (11%)]\tLoss: 1.314875\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:08 | INFO | Rank 0 | Train Epoch: 0 [26560/250314 (11%)]\tLoss: 1.207282\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:09 | INFO | Rank 0 | Train Epoch: 0 [26592/250314 (11%)]\tLoss: 0.979536\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:09 | INFO | Rank 0 | Train Epoch: 0 [26624/250314 (11%)]\tLoss: 0.952847\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:10 | INFO | Rank 0 | Train Epoch: 0 [26656/250314 (11%)]\tLoss: 1.223283\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:10 | INFO | Rank 0 | Train Epoch: 0 [26688/250314 (11%)]\tLoss: 1.270967\tData (t) 0.212\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:10 | INFO | Rank 0 | Train Epoch: 0 [26720/250314 (11%)]\tLoss: 1.113753\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:11 | INFO | Rank 0 | Train Epoch: 0 [26752/250314 (11%)]\tLoss: 1.258795\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:11 | INFO | Rank 0 | Train Epoch: 0 [26784/250314 (11%)]\tLoss: 1.435336\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:12 | INFO | Rank 0 | Train Epoch: 0 [26816/250314 (11%)]\tLoss: 1.557153\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:12 | INFO | Rank 0 | Train Epoch: 0 [26848/250314 (11%)]\tLoss: 1.118823\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:13 | INFO | Rank 0 | Train Epoch: 0 [26880/250314 (11%)]\tLoss: 1.920404\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:13 | INFO | Rank 0 | Train Epoch: 0 [26912/250314 (11%)]\tLoss: 1.230969\tData (t) 0.288\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:14 | INFO | Rank 0 | Train Epoch: 0 [26944/250314 (11%)]\tLoss: 1.562726\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:14 | INFO | Rank 0 | Train Epoch: 0 [26976/250314 (11%)]\tLoss: 1.391320\tData (t) 0.222\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:15 | INFO | Rank 0 | Train Epoch: 0 [27008/250314 (11%)]\tLoss: 1.149898\tData (t) 0.317\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:15 | INFO | Rank 0 | Train Epoch: 0 [27040/250314 (11%)]\tLoss: 1.906717\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:16 | INFO | Rank 0 | Train Epoch: 0 [27072/250314 (11%)]\tLoss: 0.999460\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:16 | INFO | Rank 0 | Train Epoch: 0 [27104/250314 (11%)]\tLoss: 1.112154\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:17 | INFO | Rank 0 | Train Epoch: 0 [27136/250314 (11%)]\tLoss: 1.089208\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:17 | INFO | Rank 0 | Train Epoch: 0 [27168/250314 (11%)]\tLoss: 1.133449\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:18 | INFO | Rank 0 | Train Epoch: 0 [27200/250314 (11%)]\tLoss: 1.074678\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:18 | INFO | Rank 0 | Train Epoch: 0 [27232/250314 (11%)]\tLoss: 1.139792\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:19 | INFO | Rank 0 | Train Epoch: 0 [27264/250314 (11%)]\tLoss: 1.453739\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:19 | INFO | Rank 0 | Train Epoch: 0 [27296/250314 (11%)]\tLoss: 0.832785\tData (t) 0.332\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:20 | INFO | Rank 0 | Train Epoch: 0 [27328/250314 (11%)]\tLoss: 1.227563\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:20 | INFO | Rank 0 | Train Epoch: 0 [27360/250314 (11%)]\tLoss: 1.071025\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:21 | INFO | Rank 0 | Train Epoch: 0 [27392/250314 (11%)]\tLoss: 0.876143\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:21 | INFO | Rank 0 | Train Epoch: 0 [27424/250314 (11%)]\tLoss: 1.417660\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:22 | INFO | Rank 0 | Train Epoch: 0 [27456/250314 (11%)]\tLoss: 1.094341\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:22 | INFO | Rank 0 | Train Epoch: 0 [27488/250314 (11%)]\tLoss: 1.152000\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:23 | INFO | Rank 0 | Train Epoch: 0 [27520/250314 (11%)]\tLoss: 1.040960\tData (t) 0.262\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:23 | INFO | Rank 0 | Train Epoch: 0 [27552/250314 (11%)]\tLoss: 0.976958\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:24 | INFO | Rank 0 | Train Epoch: 0 [27584/250314 (11%)]\tLoss: 1.461332\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:24 | INFO | Rank 0 | Train Epoch: 0 [27616/250314 (11%)]\tLoss: 1.031351\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:25 | INFO | Rank 0 | Train Epoch: 0 [27648/250314 (11%)]\tLoss: 1.347569\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:25 | INFO | Rank 0 | Train Epoch: 0 [27680/250314 (11%)]\tLoss: 1.375133\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:26 | INFO | Rank 0 | Train Epoch: 0 [27712/250314 (11%)]\tLoss: 1.326233\tData (t) 0.349\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:26 | INFO | Rank 0 | Train Epoch: 0 [27744/250314 (11%)]\tLoss: 1.013444\tData (t) 0.225\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:27 | INFO | Rank 0 | Train Epoch: 0 [27776/250314 (11%)]\tLoss: 2.040580\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:27 | INFO | Rank 0 | Train Epoch: 0 [27808/250314 (11%)]\tLoss: 1.123135\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:28 | INFO | Rank 0 | Train Epoch: 0 [27840/250314 (11%)]\tLoss: 0.901786\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:28 | INFO | Rank 0 | Train Epoch: 0 [27872/250314 (11%)]\tLoss: 1.047768\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:29 | INFO | Rank 0 | Train Epoch: 0 [27904/250314 (11%)]\tLoss: 1.146472\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:29 | INFO | Rank 0 | Train Epoch: 0 [27936/250314 (11%)]\tLoss: 1.185952\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:30 | INFO | Rank 0 | Train Epoch: 0 [27968/250314 (11%)]\tLoss: 1.339587\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:30 | INFO | Rank 0 | Train Epoch: 0 [28000/250314 (11%)]\tLoss: 1.548333\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:31 | INFO | Rank 0 | Train Epoch: 0 [28032/250314 (11%)]\tLoss: 1.374980\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:31 | INFO | Rank 0 | Train Epoch: 0 [28064/250314 (11%)]\tLoss: 1.577521\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:32 | INFO | Rank 0 | Train Epoch: 0 [28096/250314 (11%)]\tLoss: 1.434535\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:32 | INFO | Rank 0 | Train Epoch: 0 [28128/250314 (11%)]\tLoss: 0.592118\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:33 | INFO | Rank 0 | Train Epoch: 0 [28160/250314 (11%)]\tLoss: 1.328011\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:33 | INFO | Rank 0 | Train Epoch: 0 [28192/250314 (11%)]\tLoss: 1.098075\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:34 | INFO | Rank 0 | Train Epoch: 0 [28224/250314 (11%)]\tLoss: 1.108830\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:34 | INFO | Rank 0 | Train Epoch: 0 [28256/250314 (11%)]\tLoss: 1.151527\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:35 | INFO | Rank 0 | Train Epoch: 0 [28288/250314 (11%)]\tLoss: 1.463938\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:35 | INFO | Rank 0 | Train Epoch: 0 [28320/250314 (11%)]\tLoss: 1.383020\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:35 | INFO | Rank 0 | Train Epoch: 0 [28352/250314 (11%)]\tLoss: 1.363396\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:36 | INFO | Rank 0 | Train Epoch: 0 [28384/250314 (11%)]\tLoss: 1.401942\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:36 | INFO | Rank 0 | Train Epoch: 0 [28416/250314 (11%)]\tLoss: 1.170021\tData (t) 0.331\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:37 | INFO | Rank 0 | Train Epoch: 0 [28448/250314 (11%)]\tLoss: 1.361723\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:37 | INFO | Rank 0 | Train Epoch: 0 [28480/250314 (11%)]\tLoss: 1.152092\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:38 | INFO | Rank 0 | Train Epoch: 0 [28512/250314 (11%)]\tLoss: 1.426234\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:38 | INFO | Rank 0 | Train Epoch: 0 [28544/250314 (11%)]\tLoss: 0.738192\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:39 | INFO | Rank 0 | Train Epoch: 0 [28576/250314 (11%)]\tLoss: 1.126562\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:39 | INFO | Rank 0 | Train Epoch: 0 [28608/250314 (11%)]\tLoss: 0.997716\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:40 | INFO | Rank 0 | Train Epoch: 0 [28640/250314 (11%)]\tLoss: 1.392404\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:40 | INFO | Rank 0 | Train Epoch: 0 [28672/250314 (11%)]\tLoss: 1.687964\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:41 | INFO | Rank 0 | Train Epoch: 0 [28704/250314 (11%)]\tLoss: 1.282239\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:41 | INFO | Rank 0 | Train Epoch: 0 [28736/250314 (11%)]\tLoss: 1.460465\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:42 | INFO | Rank 0 | Train Epoch: 0 [28768/250314 (11%)]\tLoss: 1.182666\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:42 | INFO | Rank 0 | Train Epoch: 0 [28800/250314 (12%)]\tLoss: 1.274490\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:43 | INFO | Rank 0 | Train Epoch: 0 [28832/250314 (12%)]\tLoss: 1.181450\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:43 | INFO | Rank 0 | Train Epoch: 0 [28864/250314 (12%)]\tLoss: 1.499846\tData (t) 0.370\tBatch (t) 0.581\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:44 | INFO | Rank 0 | Train Epoch: 0 [28896/250314 (12%)]\tLoss: 1.192134\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:44 | INFO | Rank 0 | Train Epoch: 0 [28928/250314 (12%)]\tLoss: 1.071842\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:45 | INFO | Rank 0 | Train Epoch: 0 [28960/250314 (12%)]\tLoss: 1.233876\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:45 | INFO | Rank 0 | Train Epoch: 0 [28992/250314 (12%)]\tLoss: 1.171826\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:46 | INFO | Rank 0 | Train Epoch: 0 [29024/250314 (12%)]\tLoss: 1.607431\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:46 | INFO | Rank 0 | Train Epoch: 0 [29056/250314 (12%)]\tLoss: 1.064872\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:47 | INFO | Rank 0 | Train Epoch: 0 [29088/250314 (12%)]\tLoss: 1.118373\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:47 | INFO | Rank 0 | Train Epoch: 0 [29120/250314 (12%)]\tLoss: 1.315286\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:48 | INFO | Rank 0 | Train Epoch: 0 [29152/250314 (12%)]\tLoss: 0.921534\tData (t) 0.462\tBatch (t) 0.673\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:48 | INFO | Rank 0 | Train Epoch: 0 [29184/250314 (12%)]\tLoss: 1.536680\tData (t) 0.233\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:49 | INFO | Rank 0 | Train Epoch: 0 [29216/250314 (12%)]\tLoss: 1.066190\tData (t) 0.229\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:49 | INFO | Rank 0 | Train Epoch: 0 [29248/250314 (12%)]\tLoss: 0.888065\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:50 | INFO | Rank 0 | Train Epoch: 0 [29280/250314 (12%)]\tLoss: 0.973893\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:50 | INFO | Rank 0 | Train Epoch: 0 [29312/250314 (12%)]\tLoss: 1.365166\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:51 | INFO | Rank 0 | Train Epoch: 0 [29344/250314 (12%)]\tLoss: 0.850573\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:51 | INFO | Rank 0 | Train Epoch: 0 [29376/250314 (12%)]\tLoss: 1.322022\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:52 | INFO | Rank 0 | Train Epoch: 0 [29408/250314 (12%)]\tLoss: 1.075722\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:52 | INFO | Rank 0 | Train Epoch: 0 [29440/250314 (12%)]\tLoss: 1.253713\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:53 | INFO | Rank 0 | Train Epoch: 0 [29472/250314 (12%)]\tLoss: 1.096135\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:53 | INFO | Rank 0 | Train Epoch: 0 [29504/250314 (12%)]\tLoss: 1.522184\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:54 | INFO | Rank 0 | Train Epoch: 0 [29536/250314 (12%)]\tLoss: 0.868110\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:54 | INFO | Rank 0 | Train Epoch: 0 [29568/250314 (12%)]\tLoss: 1.143455\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:55 | INFO | Rank 0 | Train Epoch: 0 [29600/250314 (12%)]\tLoss: 0.919474\tData (t) 0.222\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:55 | INFO | Rank 0 | Train Epoch: 0 [29632/250314 (12%)]\tLoss: 1.112565\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:56 | INFO | Rank 0 | Train Epoch: 0 [29664/250314 (12%)]\tLoss: 1.075349\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:56 | INFO | Rank 0 | Train Epoch: 0 [29696/250314 (12%)]\tLoss: 0.654667\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:57 | INFO | Rank 0 | Train Epoch: 0 [29728/250314 (12%)]\tLoss: 1.294606\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:57 | INFO | Rank 0 | Train Epoch: 0 [29760/250314 (12%)]\tLoss: 1.195645\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:58 | INFO | Rank 0 | Train Epoch: 0 [29792/250314 (12%)]\tLoss: 1.364856\tData (t) 0.329\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:58 | INFO | Rank 0 | Train Epoch: 0 [29824/250314 (12%)]\tLoss: 1.127957\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:59 | INFO | Rank 0 | Train Epoch: 0 [29856/250314 (12%)]\tLoss: 1.494758\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:17:59 | INFO | Rank 0 | Train Epoch: 0 [29888/250314 (12%)]\tLoss: 1.055957\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:00 | INFO | Rank 0 | Train Epoch: 0 [29920/250314 (12%)]\tLoss: 1.433314\tData (t) 0.279\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:00 | INFO | Rank 0 | Train Epoch: 0 [29952/250314 (12%)]\tLoss: 1.237495\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:01 | INFO | Rank 0 | Train Epoch: 0 [29984/250314 (12%)]\tLoss: 1.194702\tData (t) 0.230\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:01 | INFO | Rank 0 | Train Epoch: 0 [30016/250314 (12%)]\tLoss: 0.961160\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:02 | INFO | Rank 0 | Train Epoch: 0 [30048/250314 (12%)]\tLoss: 0.999859\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:02 | INFO | Rank 0 | Train Epoch: 0 [30080/250314 (12%)]\tLoss: 0.987123\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:03 | INFO | Rank 0 | Train Epoch: 0 [30112/250314 (12%)]\tLoss: 0.765952\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:03 | INFO | Rank 0 | Train Epoch: 0 [30144/250314 (12%)]\tLoss: 0.931042\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:04 | INFO | Rank 0 | Train Epoch: 0 [30176/250314 (12%)]\tLoss: 1.235110\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:04 | INFO | Rank 0 | Train Epoch: 0 [30208/250314 (12%)]\tLoss: 1.380347\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:05 | INFO | Rank 0 | Train Epoch: 0 [30240/250314 (12%)]\tLoss: 1.673755\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:05 | INFO | Rank 0 | Train Epoch: 0 [30272/250314 (12%)]\tLoss: 1.327684\tData (t) 0.202\tBatch (t) 0.413\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:06 | INFO | Rank 0 | Train Epoch: 0 [30304/250314 (12%)]\tLoss: 1.222225\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:06 | INFO | Rank 0 | Train Epoch: 0 [30336/250314 (12%)]\tLoss: 1.337946\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:07 | INFO | Rank 0 | Train Epoch: 0 [30368/250314 (12%)]\tLoss: 1.572394\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:07 | INFO | Rank 0 | Train Epoch: 0 [30400/250314 (12%)]\tLoss: 0.930800\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:08 | INFO | Rank 0 | Train Epoch: 0 [30432/250314 (12%)]\tLoss: 0.882156\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:08 | INFO | Rank 0 | Train Epoch: 0 [30464/250314 (12%)]\tLoss: 1.412978\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:09 | INFO | Rank 0 | Train Epoch: 0 [30496/250314 (12%)]\tLoss: 1.080271\tData (t) 0.335\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:09 | INFO | Rank 0 | Train Epoch: 0 [30528/250314 (12%)]\tLoss: 1.616776\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:09 | INFO | Rank 0 | Train Epoch: 0 [30560/250314 (12%)]\tLoss: 0.934470\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:10 | INFO | Rank 0 | Train Epoch: 0 [30592/250314 (12%)]\tLoss: 1.327996\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:10 | INFO | Rank 0 | Train Epoch: 0 [30624/250314 (12%)]\tLoss: 1.095191\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:11 | INFO | Rank 0 | Train Epoch: 0 [30656/250314 (12%)]\tLoss: 1.626705\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:11 | INFO | Rank 0 | Train Epoch: 0 [30688/250314 (12%)]\tLoss: 1.364215\tData (t) 0.213\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:12 | INFO | Rank 0 | Train Epoch: 0 [30720/250314 (12%)]\tLoss: 1.080811\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:12 | INFO | Rank 0 | Train Epoch: 0 [30752/250314 (12%)]\tLoss: 1.025553\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:13 | INFO | Rank 0 | Train Epoch: 0 [30784/250314 (12%)]\tLoss: 1.344031\tData (t) 0.300\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:13 | INFO | Rank 0 | Train Epoch: 0 [30816/250314 (12%)]\tLoss: 1.343987\tData (t) 0.340\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:14 | INFO | Rank 0 | Train Epoch: 0 [30848/250314 (12%)]\tLoss: 1.251763\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:14 | INFO | Rank 0 | Train Epoch: 0 [30880/250314 (12%)]\tLoss: 1.030152\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:15 | INFO | Rank 0 | Train Epoch: 0 [30912/250314 (12%)]\tLoss: 1.401680\tData (t) 0.287\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:15 | INFO | Rank 0 | Train Epoch: 0 [30944/250314 (12%)]\tLoss: 1.235226\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:16 | INFO | Rank 0 | Train Epoch: 0 [30976/250314 (12%)]\tLoss: 1.133230\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:16 | INFO | Rank 0 | Train Epoch: 0 [31008/250314 (12%)]\tLoss: 1.296260\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:17 | INFO | Rank 0 | Train Epoch: 0 [31040/250314 (12%)]\tLoss: 0.704890\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:17 | INFO | Rank 0 | Train Epoch: 0 [31072/250314 (12%)]\tLoss: 1.515883\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:18 | INFO | Rank 0 | Train Epoch: 0 [31104/250314 (12%)]\tLoss: 1.335386\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:18 | INFO | Rank 0 | Train Epoch: 0 [31136/250314 (12%)]\tLoss: 0.560987\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:19 | INFO | Rank 0 | Train Epoch: 0 [31168/250314 (12%)]\tLoss: 1.602395\tData (t) 0.369\tBatch (t) 0.581\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:19 | INFO | Rank 0 | Train Epoch: 0 [31200/250314 (12%)]\tLoss: 1.128619\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:20 | INFO | Rank 0 | Train Epoch: 0 [31232/250314 (12%)]\tLoss: 1.837978\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:20 | INFO | Rank 0 | Train Epoch: 0 [31264/250314 (12%)]\tLoss: 1.226908\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:21 | INFO | Rank 0 | Train Epoch: 0 [31296/250314 (13%)]\tLoss: 0.904365\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:21 | INFO | Rank 0 | Train Epoch: 0 [31328/250314 (13%)]\tLoss: 1.193211\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:22 | INFO | Rank 0 | Train Epoch: 0 [31360/250314 (13%)]\tLoss: 1.040543\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.602\n",
      "2022-11-09,13:18:22 | INFO | Rank 0 | Train Epoch: 0 [31392/250314 (13%)]\tLoss: 0.960378\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:23 | INFO | Rank 0 | Train Epoch: 0 [31424/250314 (13%)]\tLoss: 1.149533\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:23 | INFO | Rank 0 | Train Epoch: 0 [31456/250314 (13%)]\tLoss: 1.290354\tData (t) 0.220\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:24 | INFO | Rank 0 | Train Epoch: 0 [31488/250314 (13%)]\tLoss: 0.924553\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:24 | INFO | Rank 0 | Train Epoch: 0 [31520/250314 (13%)]\tLoss: 0.652882\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:25 | INFO | Rank 0 | Train Epoch: 0 [31552/250314 (13%)]\tLoss: 1.380211\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:25 | INFO | Rank 0 | Train Epoch: 0 [31584/250314 (13%)]\tLoss: 0.905114\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:26 | INFO | Rank 0 | Train Epoch: 0 [31616/250314 (13%)]\tLoss: 1.192211\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:26 | INFO | Rank 0 | Train Epoch: 0 [31648/250314 (13%)]\tLoss: 1.451569\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:27 | INFO | Rank 0 | Train Epoch: 0 [31680/250314 (13%)]\tLoss: 1.026644\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:27 | INFO | Rank 0 | Train Epoch: 0 [31712/250314 (13%)]\tLoss: 1.240241\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:28 | INFO | Rank 0 | Train Epoch: 0 [31744/250314 (13%)]\tLoss: 1.079924\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:28 | INFO | Rank 0 | Train Epoch: 0 [31776/250314 (13%)]\tLoss: 0.772629\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:29 | INFO | Rank 0 | Train Epoch: 0 [31808/250314 (13%)]\tLoss: 1.114993\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:29 | INFO | Rank 0 | Train Epoch: 0 [31840/250314 (13%)]\tLoss: 1.221640\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:30 | INFO | Rank 0 | Train Epoch: 0 [31872/250314 (13%)]\tLoss: 1.383053\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:30 | INFO | Rank 0 | Train Epoch: 0 [31904/250314 (13%)]\tLoss: 0.917359\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:31 | INFO | Rank 0 | Train Epoch: 0 [31936/250314 (13%)]\tLoss: 1.182801\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:31 | INFO | Rank 0 | Train Epoch: 0 [31968/250314 (13%)]\tLoss: 1.006004\tData (t) 0.222\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:32 | INFO | Rank 0 | Train Epoch: 0 [32000/250314 (13%)]\tLoss: 0.841978\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:32 | INFO | Rank 0 | Train Epoch: 0 [32032/250314 (13%)]\tLoss: 1.029802\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:32 | INFO | Rank 0 | Train Epoch: 0 [32064/250314 (13%)]\tLoss: 1.096141\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:33 | INFO | Rank 0 | Train Epoch: 0 [32096/250314 (13%)]\tLoss: 0.976795\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:33 | INFO | Rank 0 | Train Epoch: 0 [32128/250314 (13%)]\tLoss: 1.064894\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:34 | INFO | Rank 0 | Train Epoch: 0 [32160/250314 (13%)]\tLoss: 1.183078\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:34 | INFO | Rank 0 | Train Epoch: 0 [32192/250314 (13%)]\tLoss: 1.016587\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:35 | INFO | Rank 0 | Train Epoch: 0 [32224/250314 (13%)]\tLoss: 1.074361\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:35 | INFO | Rank 0 | Train Epoch: 0 [32256/250314 (13%)]\tLoss: 0.832093\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:36 | INFO | Rank 0 | Train Epoch: 0 [32288/250314 (13%)]\tLoss: 2.104785\tData (t) 0.340\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:36 | INFO | Rank 0 | Train Epoch: 0 [32320/250314 (13%)]\tLoss: 1.359642\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:37 | INFO | Rank 0 | Train Epoch: 0 [32352/250314 (13%)]\tLoss: 0.969594\tData (t) 0.338\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:37 | INFO | Rank 0 | Train Epoch: 0 [32384/250314 (13%)]\tLoss: 1.323645\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:38 | INFO | Rank 0 | Train Epoch: 0 [32416/250314 (13%)]\tLoss: 0.968766\tData (t) 0.226\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:38 | INFO | Rank 0 | Train Epoch: 0 [32448/250314 (13%)]\tLoss: 1.200511\tData (t) 0.218\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:39 | INFO | Rank 0 | Train Epoch: 0 [32480/250314 (13%)]\tLoss: 1.086145\tData (t) 0.350\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:39 | INFO | Rank 0 | Train Epoch: 0 [32512/250314 (13%)]\tLoss: 1.077663\tData (t) 0.293\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:40 | INFO | Rank 0 | Train Epoch: 0 [32544/250314 (13%)]\tLoss: 0.823064\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:40 | INFO | Rank 0 | Train Epoch: 0 [32576/250314 (13%)]\tLoss: 1.418381\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:41 | INFO | Rank 0 | Train Epoch: 0 [32608/250314 (13%)]\tLoss: 1.045506\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:41 | INFO | Rank 0 | Train Epoch: 0 [32640/250314 (13%)]\tLoss: 1.254330\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:42 | INFO | Rank 0 | Train Epoch: 0 [32672/250314 (13%)]\tLoss: 0.696685\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:42 | INFO | Rank 0 | Train Epoch: 0 [32704/250314 (13%)]\tLoss: 1.023614\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:43 | INFO | Rank 0 | Train Epoch: 0 [32736/250314 (13%)]\tLoss: 1.044392\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:43 | INFO | Rank 0 | Train Epoch: 0 [32768/250314 (13%)]\tLoss: 1.380917\tData (t) 0.343\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:44 | INFO | Rank 0 | Train Epoch: 0 [32800/250314 (13%)]\tLoss: 1.209637\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:44 | INFO | Rank 0 | Train Epoch: 0 [32832/250314 (13%)]\tLoss: 0.980046\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:45 | INFO | Rank 0 | Train Epoch: 0 [32864/250314 (13%)]\tLoss: 1.099159\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:45 | INFO | Rank 0 | Train Epoch: 0 [32896/250314 (13%)]\tLoss: 1.328053\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:46 | INFO | Rank 0 | Train Epoch: 0 [32928/250314 (13%)]\tLoss: 1.115207\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:46 | INFO | Rank 0 | Train Epoch: 0 [32960/250314 (13%)]\tLoss: 1.922042\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:47 | INFO | Rank 0 | Train Epoch: 0 [32992/250314 (13%)]\tLoss: 1.026417\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:47 | INFO | Rank 0 | Train Epoch: 0 [33024/250314 (13%)]\tLoss: 1.618087\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:48 | INFO | Rank 0 | Train Epoch: 0 [33056/250314 (13%)]\tLoss: 1.044493\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:48 | INFO | Rank 0 | Train Epoch: 0 [33088/250314 (13%)]\tLoss: 1.274965\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:49 | INFO | Rank 0 | Train Epoch: 0 [33120/250314 (13%)]\tLoss: 1.069546\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:49 | INFO | Rank 0 | Train Epoch: 0 [33152/250314 (13%)]\tLoss: 1.474541\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:50 | INFO | Rank 0 | Train Epoch: 0 [33184/250314 (13%)]\tLoss: 1.145780\tData (t) 0.465\tBatch (t) 0.677\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:51 | INFO | Rank 0 | Train Epoch: 0 [33216/250314 (13%)]\tLoss: 0.995124\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:51 | INFO | Rank 0 | Train Epoch: 0 [33248/250314 (13%)]\tLoss: 1.078059\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:52 | INFO | Rank 0 | Train Epoch: 0 [33280/250314 (13%)]\tLoss: 0.682464\tData (t) 0.207\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:52 | INFO | Rank 0 | Train Epoch: 0 [33312/250314 (13%)]\tLoss: 1.169773\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:53 | INFO | Rank 0 | Train Epoch: 0 [33344/250314 (13%)]\tLoss: 1.106732\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:53 | INFO | Rank 0 | Train Epoch: 0 [33376/250314 (13%)]\tLoss: 1.334056\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:53 | INFO | Rank 0 | Train Epoch: 0 [33408/250314 (13%)]\tLoss: 0.993941\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:54 | INFO | Rank 0 | Train Epoch: 0 [33440/250314 (13%)]\tLoss: 0.584714\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:54 | INFO | Rank 0 | Train Epoch: 0 [33472/250314 (13%)]\tLoss: 0.844490\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:55 | INFO | Rank 0 | Train Epoch: 0 [33504/250314 (13%)]\tLoss: 1.171727\tData (t) 0.350\tBatch (t) 0.562\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:55 | INFO | Rank 0 | Train Epoch: 0 [33536/250314 (13%)]\tLoss: 1.152436\tData (t) 0.229\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:56 | INFO | Rank 0 | Train Epoch: 0 [33568/250314 (13%)]\tLoss: 1.358608\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:56 | INFO | Rank 0 | Train Epoch: 0 [33600/250314 (13%)]\tLoss: 1.392923\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:57 | INFO | Rank 0 | Train Epoch: 0 [33632/250314 (13%)]\tLoss: 0.949233\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:57 | INFO | Rank 0 | Train Epoch: 0 [33664/250314 (13%)]\tLoss: 1.006931\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:58 | INFO | Rank 0 | Train Epoch: 0 [33696/250314 (13%)]\tLoss: 0.760179\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:58 | INFO | Rank 0 | Train Epoch: 0 [33728/250314 (13%)]\tLoss: 1.403726\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:59 | INFO | Rank 0 | Train Epoch: 0 [33760/250314 (13%)]\tLoss: 1.030725\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:18:59 | INFO | Rank 0 | Train Epoch: 0 [33792/250314 (14%)]\tLoss: 1.253560\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:00 | INFO | Rank 0 | Train Epoch: 0 [33824/250314 (14%)]\tLoss: 0.773354\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:00 | INFO | Rank 0 | Train Epoch: 0 [33856/250314 (14%)]\tLoss: 1.330644\tData (t) 0.229\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:01 | INFO | Rank 0 | Train Epoch: 0 [33888/250314 (14%)]\tLoss: 0.855398\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:01 | INFO | Rank 0 | Train Epoch: 0 [33920/250314 (14%)]\tLoss: 0.745581\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:02 | INFO | Rank 0 | Train Epoch: 0 [33952/250314 (14%)]\tLoss: 1.064338\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:02 | INFO | Rank 0 | Train Epoch: 0 [33984/250314 (14%)]\tLoss: 0.895152\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:03 | INFO | Rank 0 | Train Epoch: 0 [34016/250314 (14%)]\tLoss: 1.200131\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:03 | INFO | Rank 0 | Train Epoch: 0 [34048/250314 (14%)]\tLoss: 1.378408\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:04 | INFO | Rank 0 | Train Epoch: 0 [34080/250314 (14%)]\tLoss: 1.235549\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:04 | INFO | Rank 0 | Train Epoch: 0 [34112/250314 (14%)]\tLoss: 1.057293\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:05 | INFO | Rank 0 | Train Epoch: 0 [34144/250314 (14%)]\tLoss: 1.011197\tData (t) 0.340\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:05 | INFO | Rank 0 | Train Epoch: 0 [34176/250314 (14%)]\tLoss: 0.830913\tData (t) 0.317\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:06 | INFO | Rank 0 | Train Epoch: 0 [34208/250314 (14%)]\tLoss: 1.436371\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:06 | INFO | Rank 0 | Train Epoch: 0 [34240/250314 (14%)]\tLoss: 1.286654\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:07 | INFO | Rank 0 | Train Epoch: 0 [34272/250314 (14%)]\tLoss: 1.387094\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:07 | INFO | Rank 0 | Train Epoch: 0 [34304/250314 (14%)]\tLoss: 1.138938\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:08 | INFO | Rank 0 | Train Epoch: 0 [34336/250314 (14%)]\tLoss: 1.106115\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:08 | INFO | Rank 0 | Train Epoch: 0 [34368/250314 (14%)]\tLoss: 1.045075\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:09 | INFO | Rank 0 | Train Epoch: 0 [34400/250314 (14%)]\tLoss: 1.147545\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:09 | INFO | Rank 0 | Train Epoch: 0 [34432/250314 (14%)]\tLoss: 1.220313\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:10 | INFO | Rank 0 | Train Epoch: 0 [34464/250314 (14%)]\tLoss: 0.938350\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:10 | INFO | Rank 0 | Train Epoch: 0 [34496/250314 (14%)]\tLoss: 1.429860\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:11 | INFO | Rank 0 | Train Epoch: 0 [34528/250314 (14%)]\tLoss: 0.836324\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:11 | INFO | Rank 0 | Train Epoch: 0 [34560/250314 (14%)]\tLoss: 0.808812\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:12 | INFO | Rank 0 | Train Epoch: 0 [34592/250314 (14%)]\tLoss: 1.224329\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:12 | INFO | Rank 0 | Train Epoch: 0 [34624/250314 (14%)]\tLoss: 1.229066\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:13 | INFO | Rank 0 | Train Epoch: 0 [34656/250314 (14%)]\tLoss: 1.224557\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:13 | INFO | Rank 0 | Train Epoch: 0 [34688/250314 (14%)]\tLoss: 0.951637\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:14 | INFO | Rank 0 | Train Epoch: 0 [34720/250314 (14%)]\tLoss: 0.988182\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:14 | INFO | Rank 0 | Train Epoch: 0 [34752/250314 (14%)]\tLoss: 1.075552\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:15 | INFO | Rank 0 | Train Epoch: 0 [34784/250314 (14%)]\tLoss: 1.552156\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:15 | INFO | Rank 0 | Train Epoch: 0 [34816/250314 (14%)]\tLoss: 1.409513\tData (t) 0.333\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:16 | INFO | Rank 0 | Train Epoch: 0 [34848/250314 (14%)]\tLoss: 1.200472\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:16 | INFO | Rank 0 | Train Epoch: 0 [34880/250314 (14%)]\tLoss: 0.998342\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:17 | INFO | Rank 0 | Train Epoch: 0 [34912/250314 (14%)]\tLoss: 1.312593\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:17 | INFO | Rank 0 | Train Epoch: 0 [34944/250314 (14%)]\tLoss: 1.050733\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:18 | INFO | Rank 0 | Train Epoch: 0 [34976/250314 (14%)]\tLoss: 1.193455\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:18 | INFO | Rank 0 | Train Epoch: 0 [35008/250314 (14%)]\tLoss: 0.748041\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:19 | INFO | Rank 0 | Train Epoch: 0 [35040/250314 (14%)]\tLoss: 1.229188\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:19 | INFO | Rank 0 | Train Epoch: 0 [35072/250314 (14%)]\tLoss: 1.074878\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:20 | INFO | Rank 0 | Train Epoch: 0 [35104/250314 (14%)]\tLoss: 1.037468\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:20 | INFO | Rank 0 | Train Epoch: 0 [35136/250314 (14%)]\tLoss: 1.142442\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:21 | INFO | Rank 0 | Train Epoch: 0 [35168/250314 (14%)]\tLoss: 0.825914\tData (t) 0.330\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:21 | INFO | Rank 0 | Train Epoch: 0 [35200/250314 (14%)]\tLoss: 0.859432\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:22 | INFO | Rank 0 | Train Epoch: 0 [35232/250314 (14%)]\tLoss: 1.183549\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:22 | INFO | Rank 0 | Train Epoch: 0 [35264/250314 (14%)]\tLoss: 1.636524\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:23 | INFO | Rank 0 | Train Epoch: 0 [35296/250314 (14%)]\tLoss: 1.197460\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:23 | INFO | Rank 0 | Train Epoch: 0 [35328/250314 (14%)]\tLoss: 0.817870\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:24 | INFO | Rank 0 | Train Epoch: 0 [35360/250314 (14%)]\tLoss: 1.087641\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:24 | INFO | Rank 0 | Train Epoch: 0 [35392/250314 (14%)]\tLoss: 0.994279\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:25 | INFO | Rank 0 | Train Epoch: 0 [35424/250314 (14%)]\tLoss: 1.283614\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:25 | INFO | Rank 0 | Train Epoch: 0 [35456/250314 (14%)]\tLoss: 1.044294\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:25 | INFO | Rank 0 | Train Epoch: 0 [35488/250314 (14%)]\tLoss: 1.160586\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:26 | INFO | Rank 0 | Train Epoch: 0 [35520/250314 (14%)]\tLoss: 1.332235\tData (t) 0.368\tBatch (t) 0.581\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:27 | INFO | Rank 0 | Train Epoch: 0 [35552/250314 (14%)]\tLoss: 1.236355\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:27 | INFO | Rank 0 | Train Epoch: 0 [35584/250314 (14%)]\tLoss: 1.239238\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:28 | INFO | Rank 0 | Train Epoch: 0 [35616/250314 (14%)]\tLoss: 1.108401\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:28 | INFO | Rank 0 | Train Epoch: 0 [35648/250314 (14%)]\tLoss: 1.135451\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:29 | INFO | Rank 0 | Train Epoch: 0 [35680/250314 (14%)]\tLoss: 0.970689\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:29 | INFO | Rank 0 | Train Epoch: 0 [35712/250314 (14%)]\tLoss: 1.250911\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:30 | INFO | Rank 0 | Train Epoch: 0 [35744/250314 (14%)]\tLoss: 1.156198\tData (t) 0.328\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:30 | INFO | Rank 0 | Train Epoch: 0 [35776/250314 (14%)]\tLoss: 0.944374\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:31 | INFO | Rank 0 | Train Epoch: 0 [35808/250314 (14%)]\tLoss: 1.004884\tData (t) 0.398\tBatch (t) 0.610\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:31 | INFO | Rank 0 | Train Epoch: 0 [35840/250314 (14%)]\tLoss: 1.177245\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:32 | INFO | Rank 0 | Train Epoch: 0 [35872/250314 (14%)]\tLoss: 0.977873\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:32 | INFO | Rank 0 | Train Epoch: 0 [35904/250314 (14%)]\tLoss: 0.963118\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:33 | INFO | Rank 0 | Train Epoch: 0 [35936/250314 (14%)]\tLoss: 0.912173\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:33 | INFO | Rank 0 | Train Epoch: 0 [35968/250314 (14%)]\tLoss: 1.181929\tData (t) 0.338\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:34 | INFO | Rank 0 | Train Epoch: 0 [36000/250314 (14%)]\tLoss: 1.115923\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:34 | INFO | Rank 0 | Train Epoch: 0 [36032/250314 (14%)]\tLoss: 1.046857\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:35 | INFO | Rank 0 | Train Epoch: 0 [36064/250314 (14%)]\tLoss: 0.794322\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:35 | INFO | Rank 0 | Train Epoch: 0 [36096/250314 (14%)]\tLoss: 1.100378\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:36 | INFO | Rank 0 | Train Epoch: 0 [36128/250314 (14%)]\tLoss: 0.795297\tData (t) 0.382\tBatch (t) 0.594\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:36 | INFO | Rank 0 | Train Epoch: 0 [36160/250314 (14%)]\tLoss: 1.020329\tData (t) 0.332\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:37 | INFO | Rank 0 | Train Epoch: 0 [36192/250314 (14%)]\tLoss: 0.708083\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:37 | INFO | Rank 0 | Train Epoch: 0 [36224/250314 (14%)]\tLoss: 1.312696\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:38 | INFO | Rank 0 | Train Epoch: 0 [36256/250314 (14%)]\tLoss: 0.773448\tData (t) 0.210\tBatch (t) 0.421\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:38 | INFO | Rank 0 | Train Epoch: 0 [36288/250314 (14%)]\tLoss: 0.811378\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:39 | INFO | Rank 0 | Train Epoch: 0 [36320/250314 (15%)]\tLoss: 1.502772\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:39 | INFO | Rank 0 | Train Epoch: 0 [36352/250314 (15%)]\tLoss: 1.074134\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:40 | INFO | Rank 0 | Train Epoch: 0 [36384/250314 (15%)]\tLoss: 1.330027\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:40 | INFO | Rank 0 | Train Epoch: 0 [36416/250314 (15%)]\tLoss: 0.629382\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:41 | INFO | Rank 0 | Train Epoch: 0 [36448/250314 (15%)]\tLoss: 0.896112\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:41 | INFO | Rank 0 | Train Epoch: 0 [36480/250314 (15%)]\tLoss: 0.665813\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:41 | INFO | Rank 0 | Train Epoch: 0 [36512/250314 (15%)]\tLoss: 0.903478\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:42 | INFO | Rank 0 | Train Epoch: 0 [36544/250314 (15%)]\tLoss: 1.419546\tData (t) 0.222\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:42 | INFO | Rank 0 | Train Epoch: 0 [36576/250314 (15%)]\tLoss: 1.051567\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:43 | INFO | Rank 0 | Train Epoch: 0 [36608/250314 (15%)]\tLoss: 1.233102\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:43 | INFO | Rank 0 | Train Epoch: 0 [36640/250314 (15%)]\tLoss: 0.985612\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:44 | INFO | Rank 0 | Train Epoch: 0 [36672/250314 (15%)]\tLoss: 1.243963\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:44 | INFO | Rank 0 | Train Epoch: 0 [36704/250314 (15%)]\tLoss: 1.507920\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:45 | INFO | Rank 0 | Train Epoch: 0 [36736/250314 (15%)]\tLoss: 0.715147\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:45 | INFO | Rank 0 | Train Epoch: 0 [36768/250314 (15%)]\tLoss: 1.094041\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:46 | INFO | Rank 0 | Train Epoch: 0 [36800/250314 (15%)]\tLoss: 1.203678\tData (t) 0.341\tBatch (t) 0.553\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:46 | INFO | Rank 0 | Train Epoch: 0 [36832/250314 (15%)]\tLoss: 1.197340\tData (t) 0.353\tBatch (t) 0.565\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:47 | INFO | Rank 0 | Train Epoch: 0 [36864/250314 (15%)]\tLoss: 0.924338\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:47 | INFO | Rank 0 | Train Epoch: 0 [36896/250314 (15%)]\tLoss: 0.919768\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:48 | INFO | Rank 0 | Train Epoch: 0 [36928/250314 (15%)]\tLoss: 1.098251\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:48 | INFO | Rank 0 | Train Epoch: 0 [36960/250314 (15%)]\tLoss: 0.792525\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:49 | INFO | Rank 0 | Train Epoch: 0 [36992/250314 (15%)]\tLoss: 1.040548\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:49 | INFO | Rank 0 | Train Epoch: 0 [37024/250314 (15%)]\tLoss: 1.094270\tData (t) 0.233\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:50 | INFO | Rank 0 | Train Epoch: 0 [37056/250314 (15%)]\tLoss: 1.374995\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:50 | INFO | Rank 0 | Train Epoch: 0 [37088/250314 (15%)]\tLoss: 1.130107\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:51 | INFO | Rank 0 | Train Epoch: 0 [37120/250314 (15%)]\tLoss: 1.373958\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:51 | INFO | Rank 0 | Train Epoch: 0 [37152/250314 (15%)]\tLoss: 1.426246\tData (t) 0.347\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:52 | INFO | Rank 0 | Train Epoch: 0 [37184/250314 (15%)]\tLoss: 0.733708\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:52 | INFO | Rank 0 | Train Epoch: 0 [37216/250314 (15%)]\tLoss: 1.103264\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:53 | INFO | Rank 0 | Train Epoch: 0 [37248/250314 (15%)]\tLoss: 0.954728\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:53 | INFO | Rank 0 | Train Epoch: 0 [37280/250314 (15%)]\tLoss: 1.153557\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:54 | INFO | Rank 0 | Train Epoch: 0 [37312/250314 (15%)]\tLoss: 1.205391\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:54 | INFO | Rank 0 | Train Epoch: 0 [37344/250314 (15%)]\tLoss: 1.124186\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:55 | INFO | Rank 0 | Train Epoch: 0 [37376/250314 (15%)]\tLoss: 1.050717\tData (t) 0.216\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:55 | INFO | Rank 0 | Train Epoch: 0 [37408/250314 (15%)]\tLoss: 1.155640\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:56 | INFO | Rank 0 | Train Epoch: 0 [37440/250314 (15%)]\tLoss: 1.260139\tData (t) 0.345\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:57 | INFO | Rank 0 | Train Epoch: 0 [37472/250314 (15%)]\tLoss: 1.046681\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:57 | INFO | Rank 0 | Train Epoch: 0 [37504/250314 (15%)]\tLoss: 0.947319\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:57 | INFO | Rank 0 | Train Epoch: 0 [37536/250314 (15%)]\tLoss: 1.090667\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:58 | INFO | Rank 0 | Train Epoch: 0 [37568/250314 (15%)]\tLoss: 1.335696\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:58 | INFO | Rank 0 | Train Epoch: 0 [37600/250314 (15%)]\tLoss: 1.293265\tData (t) 0.292\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:19:59 | INFO | Rank 0 | Train Epoch: 0 [37632/250314 (15%)]\tLoss: 1.106941\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:00 | INFO | Rank 0 | Train Epoch: 0 [37664/250314 (15%)]\tLoss: 0.823361\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:00 | INFO | Rank 0 | Train Epoch: 0 [37696/250314 (15%)]\tLoss: 1.214748\tData (t) 0.289\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:01 | INFO | Rank 0 | Train Epoch: 0 [37728/250314 (15%)]\tLoss: 0.899885\tData (t) 0.305\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:01 | INFO | Rank 0 | Train Epoch: 0 [37760/250314 (15%)]\tLoss: 0.840667\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:01 | INFO | Rank 0 | Train Epoch: 0 [37792/250314 (15%)]\tLoss: 1.280757\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:02 | INFO | Rank 0 | Train Epoch: 0 [37824/250314 (15%)]\tLoss: 0.791877\tData (t) 0.264\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:03 | INFO | Rank 0 | Train Epoch: 0 [37856/250314 (15%)]\tLoss: 1.287814\tData (t) 0.384\tBatch (t) 0.595\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:03 | INFO | Rank 0 | Train Epoch: 0 [37888/250314 (15%)]\tLoss: 0.760775\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:04 | INFO | Rank 0 | Train Epoch: 0 [37920/250314 (15%)]\tLoss: 1.423543\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:04 | INFO | Rank 0 | Train Epoch: 0 [37952/250314 (15%)]\tLoss: 1.341348\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:05 | INFO | Rank 0 | Train Epoch: 0 [37984/250314 (15%)]\tLoss: 1.084566\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:05 | INFO | Rank 0 | Train Epoch: 0 [38016/250314 (15%)]\tLoss: 1.123522\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:06 | INFO | Rank 0 | Train Epoch: 0 [38048/250314 (15%)]\tLoss: 1.369085\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:06 | INFO | Rank 0 | Train Epoch: 0 [38080/250314 (15%)]\tLoss: 1.340124\tData (t) 0.368\tBatch (t) 0.578\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:07 | INFO | Rank 0 | Train Epoch: 0 [38112/250314 (15%)]\tLoss: 1.000160\tData (t) 0.319\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:07 | INFO | Rank 0 | Train Epoch: 0 [38144/250314 (15%)]\tLoss: 1.115618\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:08 | INFO | Rank 0 | Train Epoch: 0 [38176/250314 (15%)]\tLoss: 1.222437\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:08 | INFO | Rank 0 | Train Epoch: 0 [38208/250314 (15%)]\tLoss: 0.609750\tData (t) 0.218\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:09 | INFO | Rank 0 | Train Epoch: 0 [38240/250314 (15%)]\tLoss: 1.562825\tData (t) 0.321\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:09 | INFO | Rank 0 | Train Epoch: 0 [38272/250314 (15%)]\tLoss: 1.155370\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:10 | INFO | Rank 0 | Train Epoch: 0 [38304/250314 (15%)]\tLoss: 1.201839\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:10 | INFO | Rank 0 | Train Epoch: 0 [38336/250314 (15%)]\tLoss: 0.948198\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:11 | INFO | Rank 0 | Train Epoch: 0 [38368/250314 (15%)]\tLoss: 0.795125\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:11 | INFO | Rank 0 | Train Epoch: 0 [38400/250314 (15%)]\tLoss: 0.798163\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:12 | INFO | Rank 0 | Train Epoch: 0 [38432/250314 (15%)]\tLoss: 1.355171\tData (t) 0.385\tBatch (t) 0.597\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:12 | INFO | Rank 0 | Train Epoch: 0 [38464/250314 (15%)]\tLoss: 0.995042\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:13 | INFO | Rank 0 | Train Epoch: 0 [38496/250314 (15%)]\tLoss: 0.657734\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:13 | INFO | Rank 0 | Train Epoch: 0 [38528/250314 (15%)]\tLoss: 0.925950\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:14 | INFO | Rank 0 | Train Epoch: 0 [38560/250314 (15%)]\tLoss: 1.233614\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:14 | INFO | Rank 0 | Train Epoch: 0 [38592/250314 (15%)]\tLoss: 1.563425\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:15 | INFO | Rank 0 | Train Epoch: 0 [38624/250314 (15%)]\tLoss: 0.761178\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:15 | INFO | Rank 0 | Train Epoch: 0 [38656/250314 (15%)]\tLoss: 1.259370\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:16 | INFO | Rank 0 | Train Epoch: 0 [38688/250314 (15%)]\tLoss: 1.119694\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:16 | INFO | Rank 0 | Train Epoch: 0 [38720/250314 (15%)]\tLoss: 0.805911\tData (t) 0.212\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:17 | INFO | Rank 0 | Train Epoch: 0 [38752/250314 (15%)]\tLoss: 1.171724\tData (t) 0.459\tBatch (t) 0.671\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:17 | INFO | Rank 0 | Train Epoch: 0 [38784/250314 (15%)]\tLoss: 0.979071\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:18 | INFO | Rank 0 | Train Epoch: 0 [38816/250314 (16%)]\tLoss: 0.871793\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:18 | INFO | Rank 0 | Train Epoch: 0 [38848/250314 (16%)]\tLoss: 0.999837\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:19 | INFO | Rank 0 | Train Epoch: 0 [38880/250314 (16%)]\tLoss: 0.736736\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:19 | INFO | Rank 0 | Train Epoch: 0 [38912/250314 (16%)]\tLoss: 1.578525\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:20 | INFO | Rank 0 | Train Epoch: 0 [38944/250314 (16%)]\tLoss: 0.932246\tData (t) 0.228\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:20 | INFO | Rank 0 | Train Epoch: 0 [38976/250314 (16%)]\tLoss: 1.154995\tData (t) 0.284\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:21 | INFO | Rank 0 | Train Epoch: 0 [39008/250314 (16%)]\tLoss: 1.399818\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:21 | INFO | Rank 0 | Train Epoch: 0 [39040/250314 (16%)]\tLoss: 1.403565\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:22 | INFO | Rank 0 | Train Epoch: 0 [39072/250314 (16%)]\tLoss: 0.933837\tData (t) 0.429\tBatch (t) 0.640\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:22 | INFO | Rank 0 | Train Epoch: 0 [39104/250314 (16%)]\tLoss: 1.309293\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:23 | INFO | Rank 0 | Train Epoch: 0 [39136/250314 (16%)]\tLoss: 1.250446\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:23 | INFO | Rank 0 | Train Epoch: 0 [39168/250314 (16%)]\tLoss: 0.989113\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:24 | INFO | Rank 0 | Train Epoch: 0 [39200/250314 (16%)]\tLoss: 1.372722\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:24 | INFO | Rank 0 | Train Epoch: 0 [39232/250314 (16%)]\tLoss: 1.109194\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:25 | INFO | Rank 0 | Train Epoch: 0 [39264/250314 (16%)]\tLoss: 1.006458\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:25 | INFO | Rank 0 | Train Epoch: 0 [39296/250314 (16%)]\tLoss: 1.243159\tData (t) 0.214\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:25 | INFO | Rank 0 | Train Epoch: 0 [39328/250314 (16%)]\tLoss: 0.971041\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:26 | INFO | Rank 0 | Train Epoch: 0 [39360/250314 (16%)]\tLoss: 1.063998\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:27 | INFO | Rank 0 | Train Epoch: 0 [39392/250314 (16%)]\tLoss: 0.992172\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:27 | INFO | Rank 0 | Train Epoch: 0 [39424/250314 (16%)]\tLoss: 1.148748\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.601\n",
      "2022-11-09,13:20:28 | INFO | Rank 0 | Train Epoch: 0 [39456/250314 (16%)]\tLoss: 1.192387\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:28 | INFO | Rank 0 | Train Epoch: 0 [39488/250314 (16%)]\tLoss: 1.040339\tData (t) 0.318\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:29 | INFO | Rank 0 | Train Epoch: 0 [39520/250314 (16%)]\tLoss: 1.002145\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:29 | INFO | Rank 0 | Train Epoch: 0 [39552/250314 (16%)]\tLoss: 1.061607\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:30 | INFO | Rank 0 | Train Epoch: 0 [39584/250314 (16%)]\tLoss: 1.209770\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:30 | INFO | Rank 0 | Train Epoch: 0 [39616/250314 (16%)]\tLoss: 0.799793\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:31 | INFO | Rank 0 | Train Epoch: 0 [39648/250314 (16%)]\tLoss: 0.788796\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:31 | INFO | Rank 0 | Train Epoch: 0 [39680/250314 (16%)]\tLoss: 1.150107\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:32 | INFO | Rank 0 | Train Epoch: 0 [39712/250314 (16%)]\tLoss: 1.161931\tData (t) 0.481\tBatch (t) 0.693\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:32 | INFO | Rank 0 | Train Epoch: 0 [39744/250314 (16%)]\tLoss: 1.262089\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:33 | INFO | Rank 0 | Train Epoch: 0 [39776/250314 (16%)]\tLoss: 0.985330\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:33 | INFO | Rank 0 | Train Epoch: 0 [39808/250314 (16%)]\tLoss: 1.052456\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:34 | INFO | Rank 0 | Train Epoch: 0 [39840/250314 (16%)]\tLoss: 0.679719\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:34 | INFO | Rank 0 | Train Epoch: 0 [39872/250314 (16%)]\tLoss: 1.434990\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:35 | INFO | Rank 0 | Train Epoch: 0 [39904/250314 (16%)]\tLoss: 0.758714\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:35 | INFO | Rank 0 | Train Epoch: 0 [39936/250314 (16%)]\tLoss: 1.229316\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:36 | INFO | Rank 0 | Train Epoch: 0 [39968/250314 (16%)]\tLoss: 1.233904\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:36 | INFO | Rank 0 | Train Epoch: 0 [40000/250314 (16%)]\tLoss: 0.728317\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:37 | INFO | Rank 0 | Train Epoch: 0 [40032/250314 (16%)]\tLoss: 1.320491\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:37 | INFO | Rank 0 | Train Epoch: 0 [40064/250314 (16%)]\tLoss: 0.516779\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:38 | INFO | Rank 0 | Train Epoch: 0 [40096/250314 (16%)]\tLoss: 0.604296\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:38 | INFO | Rank 0 | Train Epoch: 0 [40128/250314 (16%)]\tLoss: 0.963205\tData (t) 0.501\tBatch (t) 0.713\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:39 | INFO | Rank 0 | Train Epoch: 0 [40160/250314 (16%)]\tLoss: 0.820988\tData (t) 0.343\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:39 | INFO | Rank 0 | Train Epoch: 0 [40192/250314 (16%)]\tLoss: 0.894286\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:40 | INFO | Rank 0 | Train Epoch: 0 [40224/250314 (16%)]\tLoss: 1.121669\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:40 | INFO | Rank 0 | Train Epoch: 0 [40256/250314 (16%)]\tLoss: 1.021888\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:41 | INFO | Rank 0 | Train Epoch: 0 [40288/250314 (16%)]\tLoss: 0.726389\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:41 | INFO | Rank 0 | Train Epoch: 0 [40320/250314 (16%)]\tLoss: 1.102377\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:42 | INFO | Rank 0 | Train Epoch: 0 [40352/250314 (16%)]\tLoss: 1.183043\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:42 | INFO | Rank 0 | Train Epoch: 0 [40384/250314 (16%)]\tLoss: 0.764063\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:43 | INFO | Rank 0 | Train Epoch: 0 [40416/250314 (16%)]\tLoss: 0.992979\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:43 | INFO | Rank 0 | Train Epoch: 0 [40448/250314 (16%)]\tLoss: 1.061540\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:44 | INFO | Rank 0 | Train Epoch: 0 [40480/250314 (16%)]\tLoss: 1.817129\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:44 | INFO | Rank 0 | Train Epoch: 0 [40512/250314 (16%)]\tLoss: 0.827679\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:45 | INFO | Rank 0 | Train Epoch: 0 [40544/250314 (16%)]\tLoss: 0.811372\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:45 | INFO | Rank 0 | Train Epoch: 0 [40576/250314 (16%)]\tLoss: 1.022976\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:46 | INFO | Rank 0 | Train Epoch: 0 [40608/250314 (16%)]\tLoss: 0.774934\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:46 | INFO | Rank 0 | Train Epoch: 0 [40640/250314 (16%)]\tLoss: 0.750832\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:47 | INFO | Rank 0 | Train Epoch: 0 [40672/250314 (16%)]\tLoss: 0.733999\tData (t) 0.341\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:47 | INFO | Rank 0 | Train Epoch: 0 [40704/250314 (16%)]\tLoss: 0.990131\tData (t) 0.388\tBatch (t) 0.600\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:48 | INFO | Rank 0 | Train Epoch: 0 [40736/250314 (16%)]\tLoss: 1.402658\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:48 | INFO | Rank 0 | Train Epoch: 0 [40768/250314 (16%)]\tLoss: 0.878563\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:49 | INFO | Rank 0 | Train Epoch: 0 [40800/250314 (16%)]\tLoss: 0.959408\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:49 | INFO | Rank 0 | Train Epoch: 0 [40832/250314 (16%)]\tLoss: 1.378069\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:50 | INFO | Rank 0 | Train Epoch: 0 [40864/250314 (16%)]\tLoss: 0.932066\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:50 | INFO | Rank 0 | Train Epoch: 0 [40896/250314 (16%)]\tLoss: 1.159014\tData (t) 0.325\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:51 | INFO | Rank 0 | Train Epoch: 0 [40928/250314 (16%)]\tLoss: 0.832422\tData (t) 0.219\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:51 | INFO | Rank 0 | Train Epoch: 0 [40960/250314 (16%)]\tLoss: 0.656125\tData (t) 0.250\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:52 | INFO | Rank 0 | Train Epoch: 0 [40992/250314 (16%)]\tLoss: 0.766165\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:52 | INFO | Rank 0 | Train Epoch: 0 [41024/250314 (16%)]\tLoss: 0.865824\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:53 | INFO | Rank 0 | Train Epoch: 0 [41056/250314 (16%)]\tLoss: 0.821086\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:53 | INFO | Rank 0 | Train Epoch: 0 [41088/250314 (16%)]\tLoss: 1.122883\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:54 | INFO | Rank 0 | Train Epoch: 0 [41120/250314 (16%)]\tLoss: 1.235970\tData (t) 0.296\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:54 | INFO | Rank 0 | Train Epoch: 0 [41152/250314 (16%)]\tLoss: 0.840513\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:55 | INFO | Rank 0 | Train Epoch: 0 [41184/250314 (16%)]\tLoss: 1.139541\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:55 | INFO | Rank 0 | Train Epoch: 0 [41216/250314 (16%)]\tLoss: 1.125969\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:56 | INFO | Rank 0 | Train Epoch: 0 [41248/250314 (16%)]\tLoss: 1.468118\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:56 | INFO | Rank 0 | Train Epoch: 0 [41280/250314 (16%)]\tLoss: 1.213980\tData (t) 0.331\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:57 | INFO | Rank 0 | Train Epoch: 0 [41312/250314 (17%)]\tLoss: 1.441622\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:57 | INFO | Rank 0 | Train Epoch: 0 [41344/250314 (17%)]\tLoss: 0.795237\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:58 | INFO | Rank 0 | Train Epoch: 0 [41376/250314 (17%)]\tLoss: 1.266191\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:58 | INFO | Rank 0 | Train Epoch: 0 [41408/250314 (17%)]\tLoss: 1.110501\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:59 | INFO | Rank 0 | Train Epoch: 0 [41440/250314 (17%)]\tLoss: 1.644740\tData (t) 0.328\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:20:59 | INFO | Rank 0 | Train Epoch: 0 [41472/250314 (17%)]\tLoss: 0.682703\tData (t) 0.220\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:00 | INFO | Rank 0 | Train Epoch: 0 [41504/250314 (17%)]\tLoss: 1.232771\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:00 | INFO | Rank 0 | Train Epoch: 0 [41536/250314 (17%)]\tLoss: 0.926449\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:01 | INFO | Rank 0 | Train Epoch: 0 [41568/250314 (17%)]\tLoss: 0.751957\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:01 | INFO | Rank 0 | Train Epoch: 0 [41600/250314 (17%)]\tLoss: 0.811199\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:02 | INFO | Rank 0 | Train Epoch: 0 [41632/250314 (17%)]\tLoss: 1.556739\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:02 | INFO | Rank 0 | Train Epoch: 0 [41664/250314 (17%)]\tLoss: 1.516679\tData (t) 0.334\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:03 | INFO | Rank 0 | Train Epoch: 0 [41696/250314 (17%)]\tLoss: 1.192629\tData (t) 0.329\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:03 | INFO | Rank 0 | Train Epoch: 0 [41728/250314 (17%)]\tLoss: 0.979679\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:04 | INFO | Rank 0 | Train Epoch: 0 [41760/250314 (17%)]\tLoss: 1.176295\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:04 | INFO | Rank 0 | Train Epoch: 0 [41792/250314 (17%)]\tLoss: 0.855095\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:05 | INFO | Rank 0 | Train Epoch: 0 [41824/250314 (17%)]\tLoss: 1.464829\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:05 | INFO | Rank 0 | Train Epoch: 0 [41856/250314 (17%)]\tLoss: 0.769394\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:06 | INFO | Rank 0 | Train Epoch: 0 [41888/250314 (17%)]\tLoss: 0.983844\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:06 | INFO | Rank 0 | Train Epoch: 0 [41920/250314 (17%)]\tLoss: 0.932773\tData (t) 0.204\tBatch (t) 0.415\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:07 | INFO | Rank 0 | Train Epoch: 0 [41952/250314 (17%)]\tLoss: 0.756520\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:07 | INFO | Rank 0 | Train Epoch: 0 [41984/250314 (17%)]\tLoss: 0.757286\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:08 | INFO | Rank 0 | Train Epoch: 0 [42016/250314 (17%)]\tLoss: 0.776982\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:08 | INFO | Rank 0 | Train Epoch: 0 [42048/250314 (17%)]\tLoss: 0.883266\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:09 | INFO | Rank 0 | Train Epoch: 0 [42080/250314 (17%)]\tLoss: 1.062702\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:09 | INFO | Rank 0 | Train Epoch: 0 [42112/250314 (17%)]\tLoss: 1.219868\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:10 | INFO | Rank 0 | Train Epoch: 0 [42144/250314 (17%)]\tLoss: 0.646201\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:10 | INFO | Rank 0 | Train Epoch: 0 [42176/250314 (17%)]\tLoss: 1.292994\tData (t) 0.184\tBatch (t) 0.396\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:11 | INFO | Rank 0 | Train Epoch: 0 [42208/250314 (17%)]\tLoss: 0.856026\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:11 | INFO | Rank 0 | Train Epoch: 0 [42240/250314 (17%)]\tLoss: 1.093692\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:12 | INFO | Rank 0 | Train Epoch: 0 [42272/250314 (17%)]\tLoss: 0.674397\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:12 | INFO | Rank 0 | Train Epoch: 0 [42304/250314 (17%)]\tLoss: 0.913024\tData (t) 0.359\tBatch (t) 0.570\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:13 | INFO | Rank 0 | Train Epoch: 0 [42336/250314 (17%)]\tLoss: 1.335762\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:13 | INFO | Rank 0 | Train Epoch: 0 [42368/250314 (17%)]\tLoss: 0.729902\tData (t) 0.337\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:14 | INFO | Rank 0 | Train Epoch: 0 [42400/250314 (17%)]\tLoss: 0.817967\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:14 | INFO | Rank 0 | Train Epoch: 0 [42432/250314 (17%)]\tLoss: 0.802392\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:15 | INFO | Rank 0 | Train Epoch: 0 [42464/250314 (17%)]\tLoss: 0.955482\tData (t) 0.346\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:15 | INFO | Rank 0 | Train Epoch: 0 [42496/250314 (17%)]\tLoss: 1.223077\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:16 | INFO | Rank 0 | Train Epoch: 0 [42528/250314 (17%)]\tLoss: 1.044876\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:16 | INFO | Rank 0 | Train Epoch: 0 [42560/250314 (17%)]\tLoss: 1.073207\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:17 | INFO | Rank 0 | Train Epoch: 0 [42592/250314 (17%)]\tLoss: 1.119675\tData (t) 0.339\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:17 | INFO | Rank 0 | Train Epoch: 0 [42624/250314 (17%)]\tLoss: 1.095695\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:18 | INFO | Rank 0 | Train Epoch: 0 [42656/250314 (17%)]\tLoss: 1.098365\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:18 | INFO | Rank 0 | Train Epoch: 0 [42688/250314 (17%)]\tLoss: 1.780192\tData (t) 0.338\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:19 | INFO | Rank 0 | Train Epoch: 0 [42720/250314 (17%)]\tLoss: 0.955898\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:19 | INFO | Rank 0 | Train Epoch: 0 [42752/250314 (17%)]\tLoss: 1.061464\tData (t) 0.356\tBatch (t) 0.567\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:20 | INFO | Rank 0 | Train Epoch: 0 [42784/250314 (17%)]\tLoss: 0.733502\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:20 | INFO | Rank 0 | Train Epoch: 0 [42816/250314 (17%)]\tLoss: 1.160191\tData (t) 0.277\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:21 | INFO | Rank 0 | Train Epoch: 0 [42848/250314 (17%)]\tLoss: 0.458076\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:21 | INFO | Rank 0 | Train Epoch: 0 [42880/250314 (17%)]\tLoss: 1.083811\tData (t) 0.213\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:22 | INFO | Rank 0 | Train Epoch: 0 [42912/250314 (17%)]\tLoss: 1.090299\tData (t) 0.340\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:22 | INFO | Rank 0 | Train Epoch: 0 [42944/250314 (17%)]\tLoss: 1.395921\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:23 | INFO | Rank 0 | Train Epoch: 0 [42976/250314 (17%)]\tLoss: 1.129290\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:24 | INFO | Rank 0 | Train Epoch: 0 [43008/250314 (17%)]\tLoss: 0.693218\tData (t) 0.430\tBatch (t) 0.641\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:24 | INFO | Rank 0 | Train Epoch: 0 [43040/250314 (17%)]\tLoss: 0.978331\tData (t) 0.354\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:25 | INFO | Rank 0 | Train Epoch: 0 [43072/250314 (17%)]\tLoss: 0.770553\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:25 | INFO | Rank 0 | Train Epoch: 0 [43104/250314 (17%)]\tLoss: 1.242897\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:26 | INFO | Rank 0 | Train Epoch: 0 [43136/250314 (17%)]\tLoss: 0.705174\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:26 | INFO | Rank 0 | Train Epoch: 0 [43168/250314 (17%)]\tLoss: 0.729717\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:27 | INFO | Rank 0 | Train Epoch: 0 [43200/250314 (17%)]\tLoss: 1.325756\tData (t) 0.381\tBatch (t) 0.593\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:27 | INFO | Rank 0 | Train Epoch: 0 [43232/250314 (17%)]\tLoss: 0.959806\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:28 | INFO | Rank 0 | Train Epoch: 0 [43264/250314 (17%)]\tLoss: 1.162063\tData (t) 0.253\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:28 | INFO | Rank 0 | Train Epoch: 0 [43296/250314 (17%)]\tLoss: 0.544415\tData (t) 0.206\tBatch (t) 0.417\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:29 | INFO | Rank 0 | Train Epoch: 0 [43328/250314 (17%)]\tLoss: 0.946082\tData (t) 0.367\tBatch (t) 0.582\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:29 | INFO | Rank 0 | Train Epoch: 0 [43360/250314 (17%)]\tLoss: 1.004681\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:30 | INFO | Rank 0 | Train Epoch: 0 [43392/250314 (17%)]\tLoss: 0.645769\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:30 | INFO | Rank 0 | Train Epoch: 0 [43424/250314 (17%)]\tLoss: 0.890302\tData (t) 0.335\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:31 | INFO | Rank 0 | Train Epoch: 0 [43456/250314 (17%)]\tLoss: 1.087946\tData (t) 0.291\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:31 | INFO | Rank 0 | Train Epoch: 0 [43488/250314 (17%)]\tLoss: 1.073716\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:32 | INFO | Rank 0 | Train Epoch: 0 [43520/250314 (17%)]\tLoss: 0.917111\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:32 | INFO | Rank 0 | Train Epoch: 0 [43552/250314 (17%)]\tLoss: 0.828158\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:33 | INFO | Rank 0 | Train Epoch: 0 [43584/250314 (17%)]\tLoss: 0.856240\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:33 | INFO | Rank 0 | Train Epoch: 0 [43616/250314 (17%)]\tLoss: 0.831315\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:34 | INFO | Rank 0 | Train Epoch: 0 [43648/250314 (17%)]\tLoss: 0.845800\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:34 | INFO | Rank 0 | Train Epoch: 0 [43680/250314 (17%)]\tLoss: 1.043734\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:35 | INFO | Rank 0 | Train Epoch: 0 [43712/250314 (17%)]\tLoss: 0.974226\tData (t) 0.318\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:35 | INFO | Rank 0 | Train Epoch: 0 [43744/250314 (17%)]\tLoss: 1.042344\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:36 | INFO | Rank 0 | Train Epoch: 0 [43776/250314 (17%)]\tLoss: 0.926893\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:36 | INFO | Rank 0 | Train Epoch: 0 [43808/250314 (18%)]\tLoss: 1.451246\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:37 | INFO | Rank 0 | Train Epoch: 0 [43840/250314 (18%)]\tLoss: 1.248255\tData (t) 0.324\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:37 | INFO | Rank 0 | Train Epoch: 0 [43872/250314 (18%)]\tLoss: 0.888951\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:38 | INFO | Rank 0 | Train Epoch: 0 [43904/250314 (18%)]\tLoss: 1.163817\tData (t) 0.222\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:38 | INFO | Rank 0 | Train Epoch: 0 [43936/250314 (18%)]\tLoss: 0.932234\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:39 | INFO | Rank 0 | Train Epoch: 0 [43968/250314 (18%)]\tLoss: 0.650440\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:39 | INFO | Rank 0 | Train Epoch: 0 [44000/250314 (18%)]\tLoss: 0.753543\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:40 | INFO | Rank 0 | Train Epoch: 0 [44032/250314 (18%)]\tLoss: 0.765481\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:40 | INFO | Rank 0 | Train Epoch: 0 [44064/250314 (18%)]\tLoss: 0.824162\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:41 | INFO | Rank 0 | Train Epoch: 0 [44096/250314 (18%)]\tLoss: 1.348437\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:41 | INFO | Rank 0 | Train Epoch: 0 [44128/250314 (18%)]\tLoss: 1.082491\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:42 | INFO | Rank 0 | Train Epoch: 0 [44160/250314 (18%)]\tLoss: 0.664621\tData (t) 0.226\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:42 | INFO | Rank 0 | Train Epoch: 0 [44192/250314 (18%)]\tLoss: 1.513193\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:43 | INFO | Rank 0 | Train Epoch: 0 [44224/250314 (18%)]\tLoss: 1.151657\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:43 | INFO | Rank 0 | Train Epoch: 0 [44256/250314 (18%)]\tLoss: 0.862319\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:44 | INFO | Rank 0 | Train Epoch: 0 [44288/250314 (18%)]\tLoss: 0.884890\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:44 | INFO | Rank 0 | Train Epoch: 0 [44320/250314 (18%)]\tLoss: 0.709197\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:45 | INFO | Rank 0 | Train Epoch: 0 [44352/250314 (18%)]\tLoss: 0.692695\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:45 | INFO | Rank 0 | Train Epoch: 0 [44384/250314 (18%)]\tLoss: 1.367020\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:46 | INFO | Rank 0 | Train Epoch: 0 [44416/250314 (18%)]\tLoss: 1.240730\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:46 | INFO | Rank 0 | Train Epoch: 0 [44448/250314 (18%)]\tLoss: 0.654595\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:47 | INFO | Rank 0 | Train Epoch: 0 [44480/250314 (18%)]\tLoss: 1.077985\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:47 | INFO | Rank 0 | Train Epoch: 0 [44512/250314 (18%)]\tLoss: 0.910496\tData (t) 0.322\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:48 | INFO | Rank 0 | Train Epoch: 0 [44544/250314 (18%)]\tLoss: 1.023523\tData (t) 0.314\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:48 | INFO | Rank 0 | Train Epoch: 0 [44576/250314 (18%)]\tLoss: 1.119159\tData (t) 0.287\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:49 | INFO | Rank 0 | Train Epoch: 0 [44608/250314 (18%)]\tLoss: 0.890334\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:49 | INFO | Rank 0 | Train Epoch: 0 [44640/250314 (18%)]\tLoss: 0.845519\tData (t) 0.322\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:50 | INFO | Rank 0 | Train Epoch: 0 [44672/250314 (18%)]\tLoss: 0.965887\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:50 | INFO | Rank 0 | Train Epoch: 0 [44704/250314 (18%)]\tLoss: 0.871019\tData (t) 0.290\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:51 | INFO | Rank 0 | Train Epoch: 0 [44736/250314 (18%)]\tLoss: 0.973530\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:51 | INFO | Rank 0 | Train Epoch: 0 [44768/250314 (18%)]\tLoss: 0.907559\tData (t) 0.284\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:52 | INFO | Rank 0 | Train Epoch: 0 [44800/250314 (18%)]\tLoss: 0.810917\tData (t) 0.273\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:52 | INFO | Rank 0 | Train Epoch: 0 [44832/250314 (18%)]\tLoss: 1.063460\tData (t) 0.311\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:53 | INFO | Rank 0 | Train Epoch: 0 [44864/250314 (18%)]\tLoss: 1.012278\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:53 | INFO | Rank 0 | Train Epoch: 0 [44896/250314 (18%)]\tLoss: 0.888429\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:54 | INFO | Rank 0 | Train Epoch: 0 [44928/250314 (18%)]\tLoss: 0.807986\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:54 | INFO | Rank 0 | Train Epoch: 0 [44960/250314 (18%)]\tLoss: 0.972987\tData (t) 0.495\tBatch (t) 0.707\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:55 | INFO | Rank 0 | Train Epoch: 0 [44992/250314 (18%)]\tLoss: 0.933751\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:55 | INFO | Rank 0 | Train Epoch: 0 [45024/250314 (18%)]\tLoss: 1.283129\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:56 | INFO | Rank 0 | Train Epoch: 0 [45056/250314 (18%)]\tLoss: 0.809214\tData (t) 0.342\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:56 | INFO | Rank 0 | Train Epoch: 0 [45088/250314 (18%)]\tLoss: 1.493954\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:57 | INFO | Rank 0 | Train Epoch: 0 [45120/250314 (18%)]\tLoss: 0.868480\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:57 | INFO | Rank 0 | Train Epoch: 0 [45152/250314 (18%)]\tLoss: 0.900172\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:58 | INFO | Rank 0 | Train Epoch: 0 [45184/250314 (18%)]\tLoss: 0.917329\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:58 | INFO | Rank 0 | Train Epoch: 0 [45216/250314 (18%)]\tLoss: 1.035333\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:21:59 | INFO | Rank 0 | Train Epoch: 0 [45248/250314 (18%)]\tLoss: 1.369307\tData (t) 0.305\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:00 | INFO | Rank 0 | Train Epoch: 0 [45280/250314 (18%)]\tLoss: 0.999003\tData (t) 0.431\tBatch (t) 0.643\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:00 | INFO | Rank 0 | Train Epoch: 0 [45312/250314 (18%)]\tLoss: 1.195855\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:01 | INFO | Rank 0 | Train Epoch: 0 [45344/250314 (18%)]\tLoss: 1.109387\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:01 | INFO | Rank 0 | Train Epoch: 0 [45376/250314 (18%)]\tLoss: 0.938335\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:02 | INFO | Rank 0 | Train Epoch: 0 [45408/250314 (18%)]\tLoss: 0.910625\tData (t) 0.370\tBatch (t) 0.582\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:02 | INFO | Rank 0 | Train Epoch: 0 [45440/250314 (18%)]\tLoss: 1.236805\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:03 | INFO | Rank 0 | Train Epoch: 0 [45472/250314 (18%)]\tLoss: 1.497785\tData (t) 0.320\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:03 | INFO | Rank 0 | Train Epoch: 0 [45504/250314 (18%)]\tLoss: 1.032285\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:04 | INFO | Rank 0 | Train Epoch: 0 [45536/250314 (18%)]\tLoss: 0.877836\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:04 | INFO | Rank 0 | Train Epoch: 0 [45568/250314 (18%)]\tLoss: 0.942574\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:05 | INFO | Rank 0 | Train Epoch: 0 [45600/250314 (18%)]\tLoss: 1.068657\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:05 | INFO | Rank 0 | Train Epoch: 0 [45632/250314 (18%)]\tLoss: 1.134606\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:06 | INFO | Rank 0 | Train Epoch: 0 [45664/250314 (18%)]\tLoss: 0.706327\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:06 | INFO | Rank 0 | Train Epoch: 0 [45696/250314 (18%)]\tLoss: 1.127218\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:07 | INFO | Rank 0 | Train Epoch: 0 [45728/250314 (18%)]\tLoss: 0.864137\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:07 | INFO | Rank 0 | Train Epoch: 0 [45760/250314 (18%)]\tLoss: 0.903712\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:08 | INFO | Rank 0 | Train Epoch: 0 [45792/250314 (18%)]\tLoss: 1.164992\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:08 | INFO | Rank 0 | Train Epoch: 0 [45824/250314 (18%)]\tLoss: 1.027310\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:09 | INFO | Rank 0 | Train Epoch: 0 [45856/250314 (18%)]\tLoss: 1.011495\tData (t) 0.345\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:09 | INFO | Rank 0 | Train Epoch: 0 [45888/250314 (18%)]\tLoss: 1.132038\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:10 | INFO | Rank 0 | Train Epoch: 0 [45920/250314 (18%)]\tLoss: 0.952330\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:10 | INFO | Rank 0 | Train Epoch: 0 [45952/250314 (18%)]\tLoss: 0.544009\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:11 | INFO | Rank 0 | Train Epoch: 0 [45984/250314 (18%)]\tLoss: 1.210693\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:11 | INFO | Rank 0 | Train Epoch: 0 [46016/250314 (18%)]\tLoss: 1.451472\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:12 | INFO | Rank 0 | Train Epoch: 0 [46048/250314 (18%)]\tLoss: 0.713894\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:12 | INFO | Rank 0 | Train Epoch: 0 [46080/250314 (18%)]\tLoss: 1.438017\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:13 | INFO | Rank 0 | Train Epoch: 0 [46112/250314 (18%)]\tLoss: 1.202133\tData (t) 0.214\tBatch (t) 0.426\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:13 | INFO | Rank 0 | Train Epoch: 0 [46144/250314 (18%)]\tLoss: 1.163785\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:14 | INFO | Rank 0 | Train Epoch: 0 [46176/250314 (18%)]\tLoss: 0.916510\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:14 | INFO | Rank 0 | Train Epoch: 0 [46208/250314 (18%)]\tLoss: 1.037290\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:15 | INFO | Rank 0 | Train Epoch: 0 [46240/250314 (18%)]\tLoss: 0.677219\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:15 | INFO | Rank 0 | Train Epoch: 0 [46272/250314 (18%)]\tLoss: 1.358058\tData (t) 0.354\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:16 | INFO | Rank 0 | Train Epoch: 0 [46304/250314 (18%)]\tLoss: 0.985530\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:16 | INFO | Rank 0 | Train Epoch: 0 [46336/250314 (19%)]\tLoss: 0.613756\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:17 | INFO | Rank 0 | Train Epoch: 0 [46368/250314 (19%)]\tLoss: 1.269006\tData (t) 0.348\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:17 | INFO | Rank 0 | Train Epoch: 0 [46400/250314 (19%)]\tLoss: 0.878992\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:18 | INFO | Rank 0 | Train Epoch: 0 [46432/250314 (19%)]\tLoss: 1.322592\tData (t) 0.222\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:18 | INFO | Rank 0 | Train Epoch: 0 [46464/250314 (19%)]\tLoss: 1.236866\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:19 | INFO | Rank 0 | Train Epoch: 0 [46496/250314 (19%)]\tLoss: 1.225627\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:19 | INFO | Rank 0 | Train Epoch: 0 [46528/250314 (19%)]\tLoss: 0.908000\tData (t) 0.355\tBatch (t) 0.567\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:20 | INFO | Rank 0 | Train Epoch: 0 [46560/250314 (19%)]\tLoss: 1.062919\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:20 | INFO | Rank 0 | Train Epoch: 0 [46592/250314 (19%)]\tLoss: 1.268481\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:21 | INFO | Rank 0 | Train Epoch: 0 [46624/250314 (19%)]\tLoss: 1.169393\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:21 | INFO | Rank 0 | Train Epoch: 0 [46656/250314 (19%)]\tLoss: 1.091453\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:22 | INFO | Rank 0 | Train Epoch: 0 [46688/250314 (19%)]\tLoss: 0.892770\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:22 | INFO | Rank 0 | Train Epoch: 0 [46720/250314 (19%)]\tLoss: 1.077271\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:23 | INFO | Rank 0 | Train Epoch: 0 [46752/250314 (19%)]\tLoss: 1.024511\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:23 | INFO | Rank 0 | Train Epoch: 0 [46784/250314 (19%)]\tLoss: 0.978288\tData (t) 0.272\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:24 | INFO | Rank 0 | Train Epoch: 0 [46816/250314 (19%)]\tLoss: 1.271771\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:24 | INFO | Rank 0 | Train Epoch: 0 [46848/250314 (19%)]\tLoss: 0.919681\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:25 | INFO | Rank 0 | Train Epoch: 0 [46880/250314 (19%)]\tLoss: 1.003558\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:25 | INFO | Rank 0 | Train Epoch: 0 [46912/250314 (19%)]\tLoss: 0.913489\tData (t) 0.352\tBatch (t) 0.563\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:26 | INFO | Rank 0 | Train Epoch: 0 [46944/250314 (19%)]\tLoss: 0.781599\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:26 | INFO | Rank 0 | Train Epoch: 0 [46976/250314 (19%)]\tLoss: 0.930120\tData (t) 0.524\tBatch (t) 0.735\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:27 | INFO | Rank 0 | Train Epoch: 0 [47008/250314 (19%)]\tLoss: 0.777718\tData (t) 0.294\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:27 | INFO | Rank 0 | Train Epoch: 0 [47040/250314 (19%)]\tLoss: 1.241011\tData (t) 0.325\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:28 | INFO | Rank 0 | Train Epoch: 0 [47072/250314 (19%)]\tLoss: 1.075278\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:28 | INFO | Rank 0 | Train Epoch: 0 [47104/250314 (19%)]\tLoss: 0.724556\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:29 | INFO | Rank 0 | Train Epoch: 0 [47136/250314 (19%)]\tLoss: 1.018073\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:29 | INFO | Rank 0 | Train Epoch: 0 [47168/250314 (19%)]\tLoss: 0.936880\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:30 | INFO | Rank 0 | Train Epoch: 0 [47200/250314 (19%)]\tLoss: 0.977570\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:30 | INFO | Rank 0 | Train Epoch: 0 [47232/250314 (19%)]\tLoss: 0.612559\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:31 | INFO | Rank 0 | Train Epoch: 0 [47264/250314 (19%)]\tLoss: 1.403034\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:32 | INFO | Rank 0 | Train Epoch: 0 [47296/250314 (19%)]\tLoss: 1.484323\tData (t) 0.345\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:32 | INFO | Rank 0 | Train Epoch: 0 [47328/250314 (19%)]\tLoss: 0.745684\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:32 | INFO | Rank 0 | Train Epoch: 0 [47360/250314 (19%)]\tLoss: 0.754196\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:33 | INFO | Rank 0 | Train Epoch: 0 [47392/250314 (19%)]\tLoss: 0.762578\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:33 | INFO | Rank 0 | Train Epoch: 0 [47424/250314 (19%)]\tLoss: 0.744193\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:34 | INFO | Rank 0 | Train Epoch: 0 [47456/250314 (19%)]\tLoss: 1.225102\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:34 | INFO | Rank 0 | Train Epoch: 0 [47488/250314 (19%)]\tLoss: 1.544965\tData (t) 0.341\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:35 | INFO | Rank 0 | Train Epoch: 0 [47520/250314 (19%)]\tLoss: 0.607995\tData (t) 0.338\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:36 | INFO | Rank 0 | Train Epoch: 0 [47552/250314 (19%)]\tLoss: 1.047942\tData (t) 0.371\tBatch (t) 0.582\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:36 | INFO | Rank 0 | Train Epoch: 0 [47584/250314 (19%)]\tLoss: 1.746848\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:37 | INFO | Rank 0 | Train Epoch: 0 [47616/250314 (19%)]\tLoss: 1.361221\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:37 | INFO | Rank 0 | Train Epoch: 0 [47648/250314 (19%)]\tLoss: 0.946357\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:38 | INFO | Rank 0 | Train Epoch: 0 [47680/250314 (19%)]\tLoss: 0.820449\tData (t) 0.357\tBatch (t) 0.569\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:38 | INFO | Rank 0 | Train Epoch: 0 [47712/250314 (19%)]\tLoss: 0.965501\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:39 | INFO | Rank 0 | Train Epoch: 0 [47744/250314 (19%)]\tLoss: 1.108190\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:39 | INFO | Rank 0 | Train Epoch: 0 [47776/250314 (19%)]\tLoss: 0.995342\tData (t) 0.342\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:40 | INFO | Rank 0 | Train Epoch: 0 [47808/250314 (19%)]\tLoss: 0.763080\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:40 | INFO | Rank 0 | Train Epoch: 0 [47840/250314 (19%)]\tLoss: 0.928720\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:41 | INFO | Rank 0 | Train Epoch: 0 [47872/250314 (19%)]\tLoss: 1.008631\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:41 | INFO | Rank 0 | Train Epoch: 0 [47904/250314 (19%)]\tLoss: 0.792336\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:42 | INFO | Rank 0 | Train Epoch: 0 [47936/250314 (19%)]\tLoss: 1.067587\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:42 | INFO | Rank 0 | Train Epoch: 0 [47968/250314 (19%)]\tLoss: 0.643634\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:43 | INFO | Rank 0 | Train Epoch: 0 [48000/250314 (19%)]\tLoss: 1.200810\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:43 | INFO | Rank 0 | Train Epoch: 0 [48032/250314 (19%)]\tLoss: 0.976525\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:44 | INFO | Rank 0 | Train Epoch: 0 [48064/250314 (19%)]\tLoss: 1.042535\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:44 | INFO | Rank 0 | Train Epoch: 0 [48096/250314 (19%)]\tLoss: 1.067767\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:45 | INFO | Rank 0 | Train Epoch: 0 [48128/250314 (19%)]\tLoss: 0.942739\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:45 | INFO | Rank 0 | Train Epoch: 0 [48160/250314 (19%)]\tLoss: 0.904754\tData (t) 0.338\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:46 | INFO | Rank 0 | Train Epoch: 0 [48192/250314 (19%)]\tLoss: 0.758466\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:46 | INFO | Rank 0 | Train Epoch: 0 [48224/250314 (19%)]\tLoss: 1.230388\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:47 | INFO | Rank 0 | Train Epoch: 0 [48256/250314 (19%)]\tLoss: 1.207418\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:47 | INFO | Rank 0 | Train Epoch: 0 [48288/250314 (19%)]\tLoss: 0.879762\tData (t) 0.222\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:48 | INFO | Rank 0 | Train Epoch: 0 [48320/250314 (19%)]\tLoss: 0.845115\tData (t) 0.340\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:48 | INFO | Rank 0 | Train Epoch: 0 [48352/250314 (19%)]\tLoss: 1.206760\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:49 | INFO | Rank 0 | Train Epoch: 0 [48384/250314 (19%)]\tLoss: 0.733809\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:49 | INFO | Rank 0 | Train Epoch: 0 [48416/250314 (19%)]\tLoss: 0.707640\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:50 | INFO | Rank 0 | Train Epoch: 0 [48448/250314 (19%)]\tLoss: 0.837516\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:50 | INFO | Rank 0 | Train Epoch: 0 [48480/250314 (19%)]\tLoss: 0.577860\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:51 | INFO | Rank 0 | Train Epoch: 0 [48512/250314 (19%)]\tLoss: 1.167355\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:51 | INFO | Rank 0 | Train Epoch: 0 [48544/250314 (19%)]\tLoss: 0.727395\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:52 | INFO | Rank 0 | Train Epoch: 0 [48576/250314 (19%)]\tLoss: 1.085340\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:52 | INFO | Rank 0 | Train Epoch: 0 [48608/250314 (19%)]\tLoss: 1.057040\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:53 | INFO | Rank 0 | Train Epoch: 0 [48640/250314 (19%)]\tLoss: 0.880180\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:53 | INFO | Rank 0 | Train Epoch: 0 [48672/250314 (19%)]\tLoss: 0.902656\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:54 | INFO | Rank 0 | Train Epoch: 0 [48704/250314 (19%)]\tLoss: 1.245349\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:54 | INFO | Rank 0 | Train Epoch: 0 [48736/250314 (19%)]\tLoss: 0.728467\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:55 | INFO | Rank 0 | Train Epoch: 0 [48768/250314 (19%)]\tLoss: 1.216993\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:55 | INFO | Rank 0 | Train Epoch: 0 [48800/250314 (19%)]\tLoss: 0.925756\tData (t) 0.206\tBatch (t) 0.417\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:56 | INFO | Rank 0 | Train Epoch: 0 [48832/250314 (20%)]\tLoss: 0.652565\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:56 | INFO | Rank 0 | Train Epoch: 0 [48864/250314 (20%)]\tLoss: 0.819376\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:57 | INFO | Rank 0 | Train Epoch: 0 [48896/250314 (20%)]\tLoss: 0.757071\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:57 | INFO | Rank 0 | Train Epoch: 0 [48928/250314 (20%)]\tLoss: 0.980420\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:58 | INFO | Rank 0 | Train Epoch: 0 [48960/250314 (20%)]\tLoss: 0.843966\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:58 | INFO | Rank 0 | Train Epoch: 0 [48992/250314 (20%)]\tLoss: 0.930788\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:59 | INFO | Rank 0 | Train Epoch: 0 [49024/250314 (20%)]\tLoss: 0.945942\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:22:59 | INFO | Rank 0 | Train Epoch: 0 [49056/250314 (20%)]\tLoss: 0.864527\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:00 | INFO | Rank 0 | Train Epoch: 0 [49088/250314 (20%)]\tLoss: 1.167129\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:00 | INFO | Rank 0 | Train Epoch: 0 [49120/250314 (20%)]\tLoss: 0.864241\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:01 | INFO | Rank 0 | Train Epoch: 0 [49152/250314 (20%)]\tLoss: 1.092676\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:01 | INFO | Rank 0 | Train Epoch: 0 [49184/250314 (20%)]\tLoss: 1.148577\tData (t) 0.353\tBatch (t) 0.564\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:02 | INFO | Rank 0 | Train Epoch: 0 [49216/250314 (20%)]\tLoss: 1.206023\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:02 | INFO | Rank 0 | Train Epoch: 0 [49248/250314 (20%)]\tLoss: 1.165155\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:03 | INFO | Rank 0 | Train Epoch: 0 [49280/250314 (20%)]\tLoss: 1.022834\tData (t) 0.355\tBatch (t) 0.569\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:03 | INFO | Rank 0 | Train Epoch: 0 [49312/250314 (20%)]\tLoss: 1.140262\tData (t) 0.198\tBatch (t) 0.409\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:04 | INFO | Rank 0 | Train Epoch: 0 [49344/250314 (20%)]\tLoss: 0.959269\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:04 | INFO | Rank 0 | Train Epoch: 0 [49376/250314 (20%)]\tLoss: 1.159590\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:05 | INFO | Rank 0 | Train Epoch: 0 [49408/250314 (20%)]\tLoss: 0.898094\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:05 | INFO | Rank 0 | Train Epoch: 0 [49440/250314 (20%)]\tLoss: 1.108379\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:06 | INFO | Rank 0 | Train Epoch: 0 [49472/250314 (20%)]\tLoss: 0.956778\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:06 | INFO | Rank 0 | Train Epoch: 0 [49504/250314 (20%)]\tLoss: 0.391986\tData (t) 0.526\tBatch (t) 0.737\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:07 | INFO | Rank 0 | Train Epoch: 0 [49536/250314 (20%)]\tLoss: 1.186028\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:08 | INFO | Rank 0 | Train Epoch: 0 [49568/250314 (20%)]\tLoss: 1.165104\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:08 | INFO | Rank 0 | Train Epoch: 0 [49600/250314 (20%)]\tLoss: 1.267131\tData (t) 0.329\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:09 | INFO | Rank 0 | Train Epoch: 0 [49632/250314 (20%)]\tLoss: 0.683991\tData (t) 0.350\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:09 | INFO | Rank 0 | Train Epoch: 0 [49664/250314 (20%)]\tLoss: 0.709586\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:10 | INFO | Rank 0 | Train Epoch: 0 [49696/250314 (20%)]\tLoss: 1.189464\tData (t) 0.340\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:10 | INFO | Rank 0 | Train Epoch: 0 [49728/250314 (20%)]\tLoss: 1.193690\tData (t) 0.326\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:11 | INFO | Rank 0 | Train Epoch: 0 [49760/250314 (20%)]\tLoss: 1.108205\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:11 | INFO | Rank 0 | Train Epoch: 0 [49792/250314 (20%)]\tLoss: 0.734542\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:12 | INFO | Rank 0 | Train Epoch: 0 [49824/250314 (20%)]\tLoss: 1.213565\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:12 | INFO | Rank 0 | Train Epoch: 0 [49856/250314 (20%)]\tLoss: 0.743638\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:13 | INFO | Rank 0 | Train Epoch: 0 [49888/250314 (20%)]\tLoss: 0.559898\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:13 | INFO | Rank 0 | Train Epoch: 0 [49920/250314 (20%)]\tLoss: 0.784949\tData (t) 0.314\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:14 | INFO | Rank 0 | Train Epoch: 0 [49952/250314 (20%)]\tLoss: 1.092358\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:14 | INFO | Rank 0 | Train Epoch: 0 [49984/250314 (20%)]\tLoss: 1.147503\tData (t) 0.339\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:15 | INFO | Rank 0 | Train Epoch: 0 [50016/250314 (20%)]\tLoss: 1.189718\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:15 | INFO | Rank 0 | Train Epoch: 0 [50048/250314 (20%)]\tLoss: 0.872627\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:16 | INFO | Rank 0 | Train Epoch: 0 [50080/250314 (20%)]\tLoss: 1.111602\tData (t) 0.229\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:16 | INFO | Rank 0 | Train Epoch: 0 [50112/250314 (20%)]\tLoss: 0.824102\tData (t) 0.318\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:17 | INFO | Rank 0 | Train Epoch: 0 [50144/250314 (20%)]\tLoss: 1.036402\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:17 | INFO | Rank 0 | Train Epoch: 0 [50176/250314 (20%)]\tLoss: 0.710937\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:18 | INFO | Rank 0 | Train Epoch: 0 [50208/250314 (20%)]\tLoss: 1.093433\tData (t) 0.221\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:18 | INFO | Rank 0 | Train Epoch: 0 [50240/250314 (20%)]\tLoss: 1.147029\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:19 | INFO | Rank 0 | Train Epoch: 0 [50272/250314 (20%)]\tLoss: 0.716147\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:19 | INFO | Rank 0 | Train Epoch: 0 [50304/250314 (20%)]\tLoss: 0.959186\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:20 | INFO | Rank 0 | Train Epoch: 0 [50336/250314 (20%)]\tLoss: 0.768005\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:20 | INFO | Rank 0 | Train Epoch: 0 [50368/250314 (20%)]\tLoss: 0.931592\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:21 | INFO | Rank 0 | Train Epoch: 0 [50400/250314 (20%)]\tLoss: 0.692721\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:21 | INFO | Rank 0 | Train Epoch: 0 [50432/250314 (20%)]\tLoss: 0.982035\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:22 | INFO | Rank 0 | Train Epoch: 0 [50464/250314 (20%)]\tLoss: 1.285215\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:22 | INFO | Rank 0 | Train Epoch: 0 [50496/250314 (20%)]\tLoss: 1.219347\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:23 | INFO | Rank 0 | Train Epoch: 0 [50528/250314 (20%)]\tLoss: 0.982127\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:23 | INFO | Rank 0 | Train Epoch: 0 [50560/250314 (20%)]\tLoss: 0.701650\tData (t) 0.348\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:24 | INFO | Rank 0 | Train Epoch: 0 [50592/250314 (20%)]\tLoss: 0.942687\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:24 | INFO | Rank 0 | Train Epoch: 0 [50624/250314 (20%)]\tLoss: 1.175178\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:25 | INFO | Rank 0 | Train Epoch: 0 [50656/250314 (20%)]\tLoss: 0.943916\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.600\n",
      "2022-11-09,13:23:25 | INFO | Rank 0 | Train Epoch: 0 [50688/250314 (20%)]\tLoss: 0.901994\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:26 | INFO | Rank 0 | Train Epoch: 0 [50720/250314 (20%)]\tLoss: 0.574674\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:26 | INFO | Rank 0 | Train Epoch: 0 [50752/250314 (20%)]\tLoss: 1.058990\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:26 | INFO | Rank 0 | Train Epoch: 0 [50784/250314 (20%)]\tLoss: 1.031494\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:27 | INFO | Rank 0 | Train Epoch: 0 [50816/250314 (20%)]\tLoss: 0.877771\tData (t) 0.336\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:27 | INFO | Rank 0 | Train Epoch: 0 [50848/250314 (20%)]\tLoss: 1.213777\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:28 | INFO | Rank 0 | Train Epoch: 0 [50880/250314 (20%)]\tLoss: 0.935025\tData (t) 0.332\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:29 | INFO | Rank 0 | Train Epoch: 0 [50912/250314 (20%)]\tLoss: 0.971188\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:29 | INFO | Rank 0 | Train Epoch: 0 [50944/250314 (20%)]\tLoss: 1.038577\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:30 | INFO | Rank 0 | Train Epoch: 0 [50976/250314 (20%)]\tLoss: 0.759875\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:30 | INFO | Rank 0 | Train Epoch: 0 [51008/250314 (20%)]\tLoss: 1.011184\tData (t) 0.225\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:30 | INFO | Rank 0 | Train Epoch: 0 [51040/250314 (20%)]\tLoss: 1.311085\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:31 | INFO | Rank 0 | Train Epoch: 0 [51072/250314 (20%)]\tLoss: 1.400856\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:31 | INFO | Rank 0 | Train Epoch: 0 [51104/250314 (20%)]\tLoss: 0.969406\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:32 | INFO | Rank 0 | Train Epoch: 0 [51136/250314 (20%)]\tLoss: 0.817699\tData (t) 0.317\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:32 | INFO | Rank 0 | Train Epoch: 0 [51168/250314 (20%)]\tLoss: 0.903519\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:33 | INFO | Rank 0 | Train Epoch: 0 [51200/250314 (20%)]\tLoss: 1.100747\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:33 | INFO | Rank 0 | Train Epoch: 0 [51232/250314 (20%)]\tLoss: 0.681854\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:34 | INFO | Rank 0 | Train Epoch: 0 [51264/250314 (20%)]\tLoss: 0.794827\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:34 | INFO | Rank 0 | Train Epoch: 0 [51296/250314 (20%)]\tLoss: 0.831438\tData (t) 0.295\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:35 | INFO | Rank 0 | Train Epoch: 0 [51328/250314 (21%)]\tLoss: 1.455438\tData (t) 0.318\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:35 | INFO | Rank 0 | Train Epoch: 0 [51360/250314 (21%)]\tLoss: 0.670296\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:36 | INFO | Rank 0 | Train Epoch: 0 [51392/250314 (21%)]\tLoss: 0.863766\tData (t) 0.238\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:36 | INFO | Rank 0 | Train Epoch: 0 [51424/250314 (21%)]\tLoss: 1.016933\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:37 | INFO | Rank 0 | Train Epoch: 0 [51456/250314 (21%)]\tLoss: 0.977092\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:37 | INFO | Rank 0 | Train Epoch: 0 [51488/250314 (21%)]\tLoss: 1.323306\tData (t) 0.317\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:38 | INFO | Rank 0 | Train Epoch: 0 [51520/250314 (21%)]\tLoss: 0.713277\tData (t) 0.344\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:39 | INFO | Rank 0 | Train Epoch: 0 [51552/250314 (21%)]\tLoss: 0.929400\tData (t) 0.462\tBatch (t) 0.673\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:39 | INFO | Rank 0 | Train Epoch: 0 [51584/250314 (21%)]\tLoss: 1.330644\tData (t) 0.347\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:40 | INFO | Rank 0 | Train Epoch: 0 [51616/250314 (21%)]\tLoss: 1.167456\tData (t) 0.213\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:40 | INFO | Rank 0 | Train Epoch: 0 [51648/250314 (21%)]\tLoss: 1.004716\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:41 | INFO | Rank 0 | Train Epoch: 0 [51680/250314 (21%)]\tLoss: 1.468122\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:41 | INFO | Rank 0 | Train Epoch: 0 [51712/250314 (21%)]\tLoss: 1.287810\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:42 | INFO | Rank 0 | Train Epoch: 0 [51744/250314 (21%)]\tLoss: 0.736556\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:42 | INFO | Rank 0 | Train Epoch: 0 [51776/250314 (21%)]\tLoss: 0.698006\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:43 | INFO | Rank 0 | Train Epoch: 0 [51808/250314 (21%)]\tLoss: 0.907880\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:43 | INFO | Rank 0 | Train Epoch: 0 [51840/250314 (21%)]\tLoss: 0.943205\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:44 | INFO | Rank 0 | Train Epoch: 0 [51872/250314 (21%)]\tLoss: 0.841834\tData (t) 0.348\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:44 | INFO | Rank 0 | Train Epoch: 0 [51904/250314 (21%)]\tLoss: 0.711263\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:45 | INFO | Rank 0 | Train Epoch: 0 [51936/250314 (21%)]\tLoss: 0.862624\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:45 | INFO | Rank 0 | Train Epoch: 0 [51968/250314 (21%)]\tLoss: 1.155836\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:46 | INFO | Rank 0 | Train Epoch: 0 [52000/250314 (21%)]\tLoss: 1.335433\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:46 | INFO | Rank 0 | Train Epoch: 0 [52032/250314 (21%)]\tLoss: 0.976783\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:47 | INFO | Rank 0 | Train Epoch: 0 [52064/250314 (21%)]\tLoss: 0.944574\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:47 | INFO | Rank 0 | Train Epoch: 0 [52096/250314 (21%)]\tLoss: 1.196863\tData (t) 0.345\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:48 | INFO | Rank 0 | Train Epoch: 0 [52128/250314 (21%)]\tLoss: 1.185567\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:48 | INFO | Rank 0 | Train Epoch: 0 [52160/250314 (21%)]\tLoss: 0.864523\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:49 | INFO | Rank 0 | Train Epoch: 0 [52192/250314 (21%)]\tLoss: 1.496243\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:49 | INFO | Rank 0 | Train Epoch: 0 [52224/250314 (21%)]\tLoss: 1.363327\tData (t) 0.345\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:50 | INFO | Rank 0 | Train Epoch: 0 [52256/250314 (21%)]\tLoss: 1.060437\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:50 | INFO | Rank 0 | Train Epoch: 0 [52288/250314 (21%)]\tLoss: 0.927720\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:51 | INFO | Rank 0 | Train Epoch: 0 [52320/250314 (21%)]\tLoss: 0.883507\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:51 | INFO | Rank 0 | Train Epoch: 0 [52352/250314 (21%)]\tLoss: 0.909444\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:52 | INFO | Rank 0 | Train Epoch: 0 [52384/250314 (21%)]\tLoss: 1.243002\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:52 | INFO | Rank 0 | Train Epoch: 0 [52416/250314 (21%)]\tLoss: 1.254575\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:53 | INFO | Rank 0 | Train Epoch: 0 [52448/250314 (21%)]\tLoss: 1.078598\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:53 | INFO | Rank 0 | Train Epoch: 0 [52480/250314 (21%)]\tLoss: 1.135187\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:54 | INFO | Rank 0 | Train Epoch: 0 [52512/250314 (21%)]\tLoss: 1.128257\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:54 | INFO | Rank 0 | Train Epoch: 0 [52544/250314 (21%)]\tLoss: 0.927186\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:55 | INFO | Rank 0 | Train Epoch: 0 [52576/250314 (21%)]\tLoss: 0.784238\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:55 | INFO | Rank 0 | Train Epoch: 0 [52608/250314 (21%)]\tLoss: 1.046668\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:56 | INFO | Rank 0 | Train Epoch: 0 [52640/250314 (21%)]\tLoss: 1.136226\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:56 | INFO | Rank 0 | Train Epoch: 0 [52672/250314 (21%)]\tLoss: 0.687926\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:57 | INFO | Rank 0 | Train Epoch: 0 [52704/250314 (21%)]\tLoss: 1.193556\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:57 | INFO | Rank 0 | Train Epoch: 0 [52736/250314 (21%)]\tLoss: 0.905562\tData (t) 0.453\tBatch (t) 0.665\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:58 | INFO | Rank 0 | Train Epoch: 0 [52768/250314 (21%)]\tLoss: 0.991330\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:58 | INFO | Rank 0 | Train Epoch: 0 [52800/250314 (21%)]\tLoss: 0.793333\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:59 | INFO | Rank 0 | Train Epoch: 0 [52832/250314 (21%)]\tLoss: 1.119938\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:23:59 | INFO | Rank 0 | Train Epoch: 0 [52864/250314 (21%)]\tLoss: 1.108948\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:00 | INFO | Rank 0 | Train Epoch: 0 [52896/250314 (21%)]\tLoss: 1.150144\tData (t) 0.332\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:00 | INFO | Rank 0 | Train Epoch: 0 [52928/250314 (21%)]\tLoss: 0.921498\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:01 | INFO | Rank 0 | Train Epoch: 0 [52960/250314 (21%)]\tLoss: 0.601830\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:01 | INFO | Rank 0 | Train Epoch: 0 [52992/250314 (21%)]\tLoss: 1.064374\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:02 | INFO | Rank 0 | Train Epoch: 0 [53024/250314 (21%)]\tLoss: 0.901361\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:02 | INFO | Rank 0 | Train Epoch: 0 [53056/250314 (21%)]\tLoss: 0.798841\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:03 | INFO | Rank 0 | Train Epoch: 0 [53088/250314 (21%)]\tLoss: 0.631365\tData (t) 0.349\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:03 | INFO | Rank 0 | Train Epoch: 0 [53120/250314 (21%)]\tLoss: 0.539522\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:04 | INFO | Rank 0 | Train Epoch: 0 [53152/250314 (21%)]\tLoss: 0.783031\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:04 | INFO | Rank 0 | Train Epoch: 0 [53184/250314 (21%)]\tLoss: 1.383511\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:05 | INFO | Rank 0 | Train Epoch: 0 [53216/250314 (21%)]\tLoss: 0.758811\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:05 | INFO | Rank 0 | Train Epoch: 0 [53248/250314 (21%)]\tLoss: 0.912402\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:06 | INFO | Rank 0 | Train Epoch: 0 [53280/250314 (21%)]\tLoss: 1.308282\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:06 | INFO | Rank 0 | Train Epoch: 0 [53312/250314 (21%)]\tLoss: 0.859427\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:07 | INFO | Rank 0 | Train Epoch: 0 [53344/250314 (21%)]\tLoss: 1.200583\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:07 | INFO | Rank 0 | Train Epoch: 0 [53376/250314 (21%)]\tLoss: 1.119023\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:08 | INFO | Rank 0 | Train Epoch: 0 [53408/250314 (21%)]\tLoss: 1.114726\tData (t) 0.347\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:08 | INFO | Rank 0 | Train Epoch: 0 [53440/250314 (21%)]\tLoss: 1.146072\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:09 | INFO | Rank 0 | Train Epoch: 0 [53472/250314 (21%)]\tLoss: 0.958789\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:09 | INFO | Rank 0 | Train Epoch: 0 [53504/250314 (21%)]\tLoss: 1.238228\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:10 | INFO | Rank 0 | Train Epoch: 0 [53536/250314 (21%)]\tLoss: 0.973177\tData (t) 0.328\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:10 | INFO | Rank 0 | Train Epoch: 0 [53568/250314 (21%)]\tLoss: 0.880452\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:11 | INFO | Rank 0 | Train Epoch: 0 [53600/250314 (21%)]\tLoss: 0.922572\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:11 | INFO | Rank 0 | Train Epoch: 0 [53632/250314 (21%)]\tLoss: 1.035186\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:12 | INFO | Rank 0 | Train Epoch: 0 [53664/250314 (21%)]\tLoss: 0.862884\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:12 | INFO | Rank 0 | Train Epoch: 0 [53696/250314 (21%)]\tLoss: 0.913547\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:13 | INFO | Rank 0 | Train Epoch: 0 [53728/250314 (21%)]\tLoss: 0.844579\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:14 | INFO | Rank 0 | Train Epoch: 0 [53760/250314 (21%)]\tLoss: 0.823628\tData (t) 0.390\tBatch (t) 0.601\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:14 | INFO | Rank 0 | Train Epoch: 0 [53792/250314 (21%)]\tLoss: 1.092743\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:15 | INFO | Rank 0 | Train Epoch: 0 [53824/250314 (22%)]\tLoss: 1.033908\tData (t) 0.399\tBatch (t) 0.611\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:15 | INFO | Rank 0 | Train Epoch: 0 [53856/250314 (22%)]\tLoss: 1.373606\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:16 | INFO | Rank 0 | Train Epoch: 0 [53888/250314 (22%)]\tLoss: 0.803378\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:16 | INFO | Rank 0 | Train Epoch: 0 [53920/250314 (22%)]\tLoss: 0.536676\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:17 | INFO | Rank 0 | Train Epoch: 0 [53952/250314 (22%)]\tLoss: 0.999079\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:17 | INFO | Rank 0 | Train Epoch: 0 [53984/250314 (22%)]\tLoss: 0.702638\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:17 | INFO | Rank 0 | Train Epoch: 0 [54016/250314 (22%)]\tLoss: 0.647038\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:18 | INFO | Rank 0 | Train Epoch: 0 [54048/250314 (22%)]\tLoss: 0.843419\tData (t) 0.338\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:19 | INFO | Rank 0 | Train Epoch: 0 [54080/250314 (22%)]\tLoss: 0.649663\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:19 | INFO | Rank 0 | Train Epoch: 0 [54112/250314 (22%)]\tLoss: 0.766308\tData (t) 0.216\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:19 | INFO | Rank 0 | Train Epoch: 0 [54144/250314 (22%)]\tLoss: 0.868029\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:20 | INFO | Rank 0 | Train Epoch: 0 [54176/250314 (22%)]\tLoss: 1.095932\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:21 | INFO | Rank 0 | Train Epoch: 0 [54208/250314 (22%)]\tLoss: 0.607464\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:21 | INFO | Rank 0 | Train Epoch: 0 [54240/250314 (22%)]\tLoss: 0.975846\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:22 | INFO | Rank 0 | Train Epoch: 0 [54272/250314 (22%)]\tLoss: 1.161176\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:22 | INFO | Rank 0 | Train Epoch: 0 [54304/250314 (22%)]\tLoss: 1.234119\tData (t) 0.199\tBatch (t) 0.411\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:22 | INFO | Rank 0 | Train Epoch: 0 [54336/250314 (22%)]\tLoss: 0.498595\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:23 | INFO | Rank 0 | Train Epoch: 0 [54368/250314 (22%)]\tLoss: 0.811546\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:23 | INFO | Rank 0 | Train Epoch: 0 [54400/250314 (22%)]\tLoss: 1.010963\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:24 | INFO | Rank 0 | Train Epoch: 0 [54432/250314 (22%)]\tLoss: 1.032547\tData (t) 0.186\tBatch (t) 0.397\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:24 | INFO | Rank 0 | Train Epoch: 0 [54464/250314 (22%)]\tLoss: 0.964422\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:25 | INFO | Rank 0 | Train Epoch: 0 [54496/250314 (22%)]\tLoss: 0.560180\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:25 | INFO | Rank 0 | Train Epoch: 0 [54528/250314 (22%)]\tLoss: 1.001703\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:26 | INFO | Rank 0 | Train Epoch: 0 [54560/250314 (22%)]\tLoss: 0.982935\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:26 | INFO | Rank 0 | Train Epoch: 0 [54592/250314 (22%)]\tLoss: 0.755284\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:27 | INFO | Rank 0 | Train Epoch: 0 [54624/250314 (22%)]\tLoss: 1.157148\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:27 | INFO | Rank 0 | Train Epoch: 0 [54656/250314 (22%)]\tLoss: 1.186029\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:28 | INFO | Rank 0 | Train Epoch: 0 [54688/250314 (22%)]\tLoss: 0.735197\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:28 | INFO | Rank 0 | Train Epoch: 0 [54720/250314 (22%)]\tLoss: 1.075925\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:29 | INFO | Rank 0 | Train Epoch: 0 [54752/250314 (22%)]\tLoss: 0.970301\tData (t) 0.381\tBatch (t) 0.592\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:29 | INFO | Rank 0 | Train Epoch: 0 [54784/250314 (22%)]\tLoss: 1.077990\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:30 | INFO | Rank 0 | Train Epoch: 0 [54816/250314 (22%)]\tLoss: 1.459402\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:30 | INFO | Rank 0 | Train Epoch: 0 [54848/250314 (22%)]\tLoss: 0.923925\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:31 | INFO | Rank 0 | Train Epoch: 0 [54880/250314 (22%)]\tLoss: 0.759000\tData (t) 0.307\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:31 | INFO | Rank 0 | Train Epoch: 0 [54912/250314 (22%)]\tLoss: 1.046678\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:32 | INFO | Rank 0 | Train Epoch: 0 [54944/250314 (22%)]\tLoss: 1.005674\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:32 | INFO | Rank 0 | Train Epoch: 0 [54976/250314 (22%)]\tLoss: 0.891844\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:33 | INFO | Rank 0 | Train Epoch: 0 [55008/250314 (22%)]\tLoss: 0.810055\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:33 | INFO | Rank 0 | Train Epoch: 0 [55040/250314 (22%)]\tLoss: 1.052446\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:34 | INFO | Rank 0 | Train Epoch: 0 [55072/250314 (22%)]\tLoss: 1.580982\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:34 | INFO | Rank 0 | Train Epoch: 0 [55104/250314 (22%)]\tLoss: 1.201647\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:35 | INFO | Rank 0 | Train Epoch: 0 [55136/250314 (22%)]\tLoss: 1.164100\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:35 | INFO | Rank 0 | Train Epoch: 0 [55168/250314 (22%)]\tLoss: 1.117528\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:36 | INFO | Rank 0 | Train Epoch: 0 [55200/250314 (22%)]\tLoss: 0.851800\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:36 | INFO | Rank 0 | Train Epoch: 0 [55232/250314 (22%)]\tLoss: 0.940414\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:37 | INFO | Rank 0 | Train Epoch: 0 [55264/250314 (22%)]\tLoss: 0.950764\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:37 | INFO | Rank 0 | Train Epoch: 0 [55296/250314 (22%)]\tLoss: 1.108611\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:38 | INFO | Rank 0 | Train Epoch: 0 [55328/250314 (22%)]\tLoss: 0.836495\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:38 | INFO | Rank 0 | Train Epoch: 0 [55360/250314 (22%)]\tLoss: 0.886954\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:39 | INFO | Rank 0 | Train Epoch: 0 [55392/250314 (22%)]\tLoss: 0.883760\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:39 | INFO | Rank 0 | Train Epoch: 0 [55424/250314 (22%)]\tLoss: 1.298651\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:40 | INFO | Rank 0 | Train Epoch: 0 [55456/250314 (22%)]\tLoss: 1.161493\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:40 | INFO | Rank 0 | Train Epoch: 0 [55488/250314 (22%)]\tLoss: 1.135036\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:41 | INFO | Rank 0 | Train Epoch: 0 [55520/250314 (22%)]\tLoss: 0.774593\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:41 | INFO | Rank 0 | Train Epoch: 0 [55552/250314 (22%)]\tLoss: 0.699920\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:42 | INFO | Rank 0 | Train Epoch: 0 [55584/250314 (22%)]\tLoss: 1.103264\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:42 | INFO | Rank 0 | Train Epoch: 0 [55616/250314 (22%)]\tLoss: 0.696008\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:43 | INFO | Rank 0 | Train Epoch: 0 [55648/250314 (22%)]\tLoss: 0.908611\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:43 | INFO | Rank 0 | Train Epoch: 0 [55680/250314 (22%)]\tLoss: 0.935034\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:44 | INFO | Rank 0 | Train Epoch: 0 [55712/250314 (22%)]\tLoss: 0.866374\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:44 | INFO | Rank 0 | Train Epoch: 0 [55744/250314 (22%)]\tLoss: 0.832415\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:45 | INFO | Rank 0 | Train Epoch: 0 [55776/250314 (22%)]\tLoss: 1.203760\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:45 | INFO | Rank 0 | Train Epoch: 0 [55808/250314 (22%)]\tLoss: 1.152936\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:46 | INFO | Rank 0 | Train Epoch: 0 [55840/250314 (22%)]\tLoss: 0.742469\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:46 | INFO | Rank 0 | Train Epoch: 0 [55872/250314 (22%)]\tLoss: 1.249019\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:47 | INFO | Rank 0 | Train Epoch: 0 [55904/250314 (22%)]\tLoss: 1.091773\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:47 | INFO | Rank 0 | Train Epoch: 0 [55936/250314 (22%)]\tLoss: 0.571633\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:48 | INFO | Rank 0 | Train Epoch: 0 [55968/250314 (22%)]\tLoss: 0.705024\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:48 | INFO | Rank 0 | Train Epoch: 0 [56000/250314 (22%)]\tLoss: 0.932541\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:49 | INFO | Rank 0 | Train Epoch: 0 [56032/250314 (22%)]\tLoss: 0.738007\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:49 | INFO | Rank 0 | Train Epoch: 0 [56064/250314 (22%)]\tLoss: 1.121819\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:50 | INFO | Rank 0 | Train Epoch: 0 [56096/250314 (22%)]\tLoss: 1.262023\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:50 | INFO | Rank 0 | Train Epoch: 0 [56128/250314 (22%)]\tLoss: 0.734267\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:51 | INFO | Rank 0 | Train Epoch: 0 [56160/250314 (22%)]\tLoss: 1.238569\tData (t) 0.455\tBatch (t) 0.667\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:52 | INFO | Rank 0 | Train Epoch: 0 [56192/250314 (22%)]\tLoss: 1.022760\tData (t) 0.330\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:52 | INFO | Rank 0 | Train Epoch: 0 [56224/250314 (22%)]\tLoss: 0.545187\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:53 | INFO | Rank 0 | Train Epoch: 0 [56256/250314 (22%)]\tLoss: 1.198474\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:53 | INFO | Rank 0 | Train Epoch: 0 [56288/250314 (22%)]\tLoss: 0.993879\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:54 | INFO | Rank 0 | Train Epoch: 0 [56320/250314 (23%)]\tLoss: 0.825972\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:54 | INFO | Rank 0 | Train Epoch: 0 [56352/250314 (23%)]\tLoss: 0.841404\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:54 | INFO | Rank 0 | Train Epoch: 0 [56384/250314 (23%)]\tLoss: 0.829951\tData (t) 0.202\tBatch (t) 0.413\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:55 | INFO | Rank 0 | Train Epoch: 0 [56416/250314 (23%)]\tLoss: 0.720377\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:55 | INFO | Rank 0 | Train Epoch: 0 [56448/250314 (23%)]\tLoss: 0.907098\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:56 | INFO | Rank 0 | Train Epoch: 0 [56480/250314 (23%)]\tLoss: 0.928679\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:56 | INFO | Rank 0 | Train Epoch: 0 [56512/250314 (23%)]\tLoss: 1.209612\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:57 | INFO | Rank 0 | Train Epoch: 0 [56544/250314 (23%)]\tLoss: 1.102490\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:57 | INFO | Rank 0 | Train Epoch: 0 [56576/250314 (23%)]\tLoss: 1.161036\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:58 | INFO | Rank 0 | Train Epoch: 0 [56608/250314 (23%)]\tLoss: 0.935190\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:58 | INFO | Rank 0 | Train Epoch: 0 [56640/250314 (23%)]\tLoss: 0.814349\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:59 | INFO | Rank 0 | Train Epoch: 0 [56672/250314 (23%)]\tLoss: 1.254709\tData (t) 0.339\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:24:59 | INFO | Rank 0 | Train Epoch: 0 [56704/250314 (23%)]\tLoss: 0.911105\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:00 | INFO | Rank 0 | Train Epoch: 0 [56736/250314 (23%)]\tLoss: 0.998020\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:00 | INFO | Rank 0 | Train Epoch: 0 [56768/250314 (23%)]\tLoss: 1.235593\tData (t) 0.335\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:01 | INFO | Rank 0 | Train Epoch: 0 [56800/250314 (23%)]\tLoss: 1.027345\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:01 | INFO | Rank 0 | Train Epoch: 0 [56832/250314 (23%)]\tLoss: 0.639479\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:02 | INFO | Rank 0 | Train Epoch: 0 [56864/250314 (23%)]\tLoss: 0.800382\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:02 | INFO | Rank 0 | Train Epoch: 0 [56896/250314 (23%)]\tLoss: 0.875398\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:03 | INFO | Rank 0 | Train Epoch: 0 [56928/250314 (23%)]\tLoss: 1.008534\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:03 | INFO | Rank 0 | Train Epoch: 0 [56960/250314 (23%)]\tLoss: 0.800538\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:04 | INFO | Rank 0 | Train Epoch: 0 [56992/250314 (23%)]\tLoss: 1.428721\tData (t) 0.338\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:04 | INFO | Rank 0 | Train Epoch: 0 [57024/250314 (23%)]\tLoss: 0.891991\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:05 | INFO | Rank 0 | Train Epoch: 0 [57056/250314 (23%)]\tLoss: 0.975654\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:05 | INFO | Rank 0 | Train Epoch: 0 [57088/250314 (23%)]\tLoss: 1.161183\tData (t) 0.335\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:06 | INFO | Rank 0 | Train Epoch: 0 [57120/250314 (23%)]\tLoss: 1.200060\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:06 | INFO | Rank 0 | Train Epoch: 0 [57152/250314 (23%)]\tLoss: 0.702707\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:07 | INFO | Rank 0 | Train Epoch: 0 [57184/250314 (23%)]\tLoss: 0.998560\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:07 | INFO | Rank 0 | Train Epoch: 0 [57216/250314 (23%)]\tLoss: 1.209353\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:08 | INFO | Rank 0 | Train Epoch: 0 [57248/250314 (23%)]\tLoss: 0.854793\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:08 | INFO | Rank 0 | Train Epoch: 0 [57280/250314 (23%)]\tLoss: 1.239453\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:09 | INFO | Rank 0 | Train Epoch: 0 [57312/250314 (23%)]\tLoss: 0.980555\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:09 | INFO | Rank 0 | Train Epoch: 0 [57344/250314 (23%)]\tLoss: 1.277406\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:10 | INFO | Rank 0 | Train Epoch: 0 [57376/250314 (23%)]\tLoss: 0.829423\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:10 | INFO | Rank 0 | Train Epoch: 0 [57408/250314 (23%)]\tLoss: 1.089373\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:11 | INFO | Rank 0 | Train Epoch: 0 [57440/250314 (23%)]\tLoss: 1.196424\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:11 | INFO | Rank 0 | Train Epoch: 0 [57472/250314 (23%)]\tLoss: 1.141861\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:12 | INFO | Rank 0 | Train Epoch: 0 [57504/250314 (23%)]\tLoss: 0.921185\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:12 | INFO | Rank 0 | Train Epoch: 0 [57536/250314 (23%)]\tLoss: 0.761596\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:13 | INFO | Rank 0 | Train Epoch: 0 [57568/250314 (23%)]\tLoss: 1.008419\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:13 | INFO | Rank 0 | Train Epoch: 0 [57600/250314 (23%)]\tLoss: 0.919353\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:14 | INFO | Rank 0 | Train Epoch: 0 [57632/250314 (23%)]\tLoss: 0.839490\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:14 | INFO | Rank 0 | Train Epoch: 0 [57664/250314 (23%)]\tLoss: 0.955434\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:15 | INFO | Rank 0 | Train Epoch: 0 [57696/250314 (23%)]\tLoss: 0.839142\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:15 | INFO | Rank 0 | Train Epoch: 0 [57728/250314 (23%)]\tLoss: 1.019886\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:16 | INFO | Rank 0 | Train Epoch: 0 [57760/250314 (23%)]\tLoss: 0.760247\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:16 | INFO | Rank 0 | Train Epoch: 0 [57792/250314 (23%)]\tLoss: 1.162908\tData (t) 0.199\tBatch (t) 0.411\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:17 | INFO | Rank 0 | Train Epoch: 0 [57824/250314 (23%)]\tLoss: 0.797618\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:17 | INFO | Rank 0 | Train Epoch: 0 [57856/250314 (23%)]\tLoss: 0.753361\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:18 | INFO | Rank 0 | Train Epoch: 0 [57888/250314 (23%)]\tLoss: 0.617530\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:18 | INFO | Rank 0 | Train Epoch: 0 [57920/250314 (23%)]\tLoss: 0.940605\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:19 | INFO | Rank 0 | Train Epoch: 0 [57952/250314 (23%)]\tLoss: 0.588915\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:19 | INFO | Rank 0 | Train Epoch: 0 [57984/250314 (23%)]\tLoss: 0.732613\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:20 | INFO | Rank 0 | Train Epoch: 0 [58016/250314 (23%)]\tLoss: 0.639573\tData (t) 0.363\tBatch (t) 0.574\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:20 | INFO | Rank 0 | Train Epoch: 0 [58048/250314 (23%)]\tLoss: 1.166808\tData (t) 0.344\tBatch (t) 0.555\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:21 | INFO | Rank 0 | Train Epoch: 0 [58080/250314 (23%)]\tLoss: 0.690816\tData (t) 0.325\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:21 | INFO | Rank 0 | Train Epoch: 0 [58112/250314 (23%)]\tLoss: 1.088660\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:22 | INFO | Rank 0 | Train Epoch: 0 [58144/250314 (23%)]\tLoss: 0.777740\tData (t) 0.323\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:22 | INFO | Rank 0 | Train Epoch: 0 [58176/250314 (23%)]\tLoss: 0.929108\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:23 | INFO | Rank 0 | Train Epoch: 0 [58208/250314 (23%)]\tLoss: 1.368651\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:23 | INFO | Rank 0 | Train Epoch: 0 [58240/250314 (23%)]\tLoss: 0.927954\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:24 | INFO | Rank 0 | Train Epoch: 0 [58272/250314 (23%)]\tLoss: 0.793468\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:24 | INFO | Rank 0 | Train Epoch: 0 [58304/250314 (23%)]\tLoss: 0.712891\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:25 | INFO | Rank 0 | Train Epoch: 0 [58336/250314 (23%)]\tLoss: 1.243469\tData (t) 0.293\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:25 | INFO | Rank 0 | Train Epoch: 0 [58368/250314 (23%)]\tLoss: 0.813551\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:26 | INFO | Rank 0 | Train Epoch: 0 [58400/250314 (23%)]\tLoss: 0.785412\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:26 | INFO | Rank 0 | Train Epoch: 0 [58432/250314 (23%)]\tLoss: 0.962259\tData (t) 0.334\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:27 | INFO | Rank 0 | Train Epoch: 0 [58464/250314 (23%)]\tLoss: 1.172147\tData (t) 0.194\tBatch (t) 0.406\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:28 | INFO | Rank 0 | Train Epoch: 0 [58496/250314 (23%)]\tLoss: 0.926647\tData (t) 0.588\tBatch (t) 0.799\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:28 | INFO | Rank 0 | Train Epoch: 0 [58528/250314 (23%)]\tLoss: 0.692331\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:29 | INFO | Rank 0 | Train Epoch: 0 [58560/250314 (23%)]\tLoss: 1.047407\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:29 | INFO | Rank 0 | Train Epoch: 0 [58592/250314 (23%)]\tLoss: 0.997400\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:29 | INFO | Rank 0 | Train Epoch: 0 [58624/250314 (23%)]\tLoss: 0.975620\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:30 | INFO | Rank 0 | Train Epoch: 0 [58656/250314 (23%)]\tLoss: 0.730283\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:30 | INFO | Rank 0 | Train Epoch: 0 [58688/250314 (23%)]\tLoss: 0.672441\tData (t) 0.208\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:31 | INFO | Rank 0 | Train Epoch: 0 [58720/250314 (23%)]\tLoss: 0.834617\tData (t) 0.242\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:31 | INFO | Rank 0 | Train Epoch: 0 [58752/250314 (23%)]\tLoss: 0.760709\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:32 | INFO | Rank 0 | Train Epoch: 0 [58784/250314 (23%)]\tLoss: 0.628219\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:32 | INFO | Rank 0 | Train Epoch: 0 [58816/250314 (23%)]\tLoss: 1.382840\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:33 | INFO | Rank 0 | Train Epoch: 0 [58848/250314 (24%)]\tLoss: 0.892899\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:33 | INFO | Rank 0 | Train Epoch: 0 [58880/250314 (24%)]\tLoss: 1.102875\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:34 | INFO | Rank 0 | Train Epoch: 0 [58912/250314 (24%)]\tLoss: 1.118057\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:34 | INFO | Rank 0 | Train Epoch: 0 [58944/250314 (24%)]\tLoss: 0.920847\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:35 | INFO | Rank 0 | Train Epoch: 0 [58976/250314 (24%)]\tLoss: 1.108762\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:35 | INFO | Rank 0 | Train Epoch: 0 [59008/250314 (24%)]\tLoss: 0.562181\tData (t) 0.218\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:36 | INFO | Rank 0 | Train Epoch: 0 [59040/250314 (24%)]\tLoss: 0.852667\tData (t) 0.227\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:36 | INFO | Rank 0 | Train Epoch: 0 [59072/250314 (24%)]\tLoss: 0.855800\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:37 | INFO | Rank 0 | Train Epoch: 0 [59104/250314 (24%)]\tLoss: 0.675157\tData (t) 0.226\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:37 | INFO | Rank 0 | Train Epoch: 0 [59136/250314 (24%)]\tLoss: 0.997398\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:38 | INFO | Rank 0 | Train Epoch: 0 [59168/250314 (24%)]\tLoss: 0.673109\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:38 | INFO | Rank 0 | Train Epoch: 0 [59200/250314 (24%)]\tLoss: 0.874496\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:39 | INFO | Rank 0 | Train Epoch: 0 [59232/250314 (24%)]\tLoss: 1.141143\tData (t) 0.217\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:39 | INFO | Rank 0 | Train Epoch: 0 [59264/250314 (24%)]\tLoss: 1.229935\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:40 | INFO | Rank 0 | Train Epoch: 0 [59296/250314 (24%)]\tLoss: 0.861304\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:40 | INFO | Rank 0 | Train Epoch: 0 [59328/250314 (24%)]\tLoss: 0.888208\tData (t) 0.336\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:41 | INFO | Rank 0 | Train Epoch: 0 [59360/250314 (24%)]\tLoss: 0.618813\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:41 | INFO | Rank 0 | Train Epoch: 0 [59392/250314 (24%)]\tLoss: 0.917412\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:42 | INFO | Rank 0 | Train Epoch: 0 [59424/250314 (24%)]\tLoss: 0.656731\tData (t) 0.228\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:42 | INFO | Rank 0 | Train Epoch: 0 [59456/250314 (24%)]\tLoss: 0.898499\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:43 | INFO | Rank 0 | Train Epoch: 0 [59488/250314 (24%)]\tLoss: 0.549511\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:43 | INFO | Rank 0 | Train Epoch: 0 [59520/250314 (24%)]\tLoss: 1.289119\tData (t) 0.366\tBatch (t) 0.577\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:44 | INFO | Rank 0 | Train Epoch: 0 [59552/250314 (24%)]\tLoss: 1.055392\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:44 | INFO | Rank 0 | Train Epoch: 0 [59584/250314 (24%)]\tLoss: 0.789466\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:45 | INFO | Rank 0 | Train Epoch: 0 [59616/250314 (24%)]\tLoss: 0.533692\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:45 | INFO | Rank 0 | Train Epoch: 0 [59648/250314 (24%)]\tLoss: 0.685246\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:46 | INFO | Rank 0 | Train Epoch: 0 [59680/250314 (24%)]\tLoss: 0.831840\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:46 | INFO | Rank 0 | Train Epoch: 0 [59712/250314 (24%)]\tLoss: 0.567548\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:47 | INFO | Rank 0 | Train Epoch: 0 [59744/250314 (24%)]\tLoss: 0.728109\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:47 | INFO | Rank 0 | Train Epoch: 0 [59776/250314 (24%)]\tLoss: 1.438744\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:47 | INFO | Rank 0 | Train Epoch: 0 [59808/250314 (24%)]\tLoss: 0.711630\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:48 | INFO | Rank 0 | Train Epoch: 0 [59840/250314 (24%)]\tLoss: 0.908314\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:48 | INFO | Rank 0 | Train Epoch: 0 [59872/250314 (24%)]\tLoss: 0.882431\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:49 | INFO | Rank 0 | Train Epoch: 0 [59904/250314 (24%)]\tLoss: 0.776638\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:49 | INFO | Rank 0 | Train Epoch: 0 [59936/250314 (24%)]\tLoss: 1.369435\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:50 | INFO | Rank 0 | Train Epoch: 0 [59968/250314 (24%)]\tLoss: 0.778504\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:50 | INFO | Rank 0 | Train Epoch: 0 [60000/250314 (24%)]\tLoss: 0.742968\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:51 | INFO | Rank 0 | Train Epoch: 0 [60032/250314 (24%)]\tLoss: 1.130685\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:51 | INFO | Rank 0 | Train Epoch: 0 [60064/250314 (24%)]\tLoss: 0.989604\tData (t) 0.226\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:52 | INFO | Rank 0 | Train Epoch: 0 [60096/250314 (24%)]\tLoss: 0.891905\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:52 | INFO | Rank 0 | Train Epoch: 0 [60128/250314 (24%)]\tLoss: 1.639485\tData (t) 0.218\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:53 | INFO | Rank 0 | Train Epoch: 0 [60160/250314 (24%)]\tLoss: 1.166922\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:53 | INFO | Rank 0 | Train Epoch: 0 [60192/250314 (24%)]\tLoss: 0.901918\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:54 | INFO | Rank 0 | Train Epoch: 0 [60224/250314 (24%)]\tLoss: 0.747564\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:54 | INFO | Rank 0 | Train Epoch: 0 [60256/250314 (24%)]\tLoss: 0.857159\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:55 | INFO | Rank 0 | Train Epoch: 0 [60288/250314 (24%)]\tLoss: 1.768554\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:55 | INFO | Rank 0 | Train Epoch: 0 [60320/250314 (24%)]\tLoss: 1.076278\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:56 | INFO | Rank 0 | Train Epoch: 0 [60352/250314 (24%)]\tLoss: 0.886624\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.599\n",
      "2022-11-09,13:25:56 | INFO | Rank 0 | Train Epoch: 0 [60384/250314 (24%)]\tLoss: 0.859537\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:25:57 | INFO | Rank 0 | Train Epoch: 0 [60416/250314 (24%)]\tLoss: 1.065981\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:25:57 | INFO | Rank 0 | Train Epoch: 0 [60448/250314 (24%)]\tLoss: 0.846747\tData (t) 0.354\tBatch (t) 0.565\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:25:58 | INFO | Rank 0 | Train Epoch: 0 [60480/250314 (24%)]\tLoss: 0.881622\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:25:58 | INFO | Rank 0 | Train Epoch: 0 [60512/250314 (24%)]\tLoss: 0.914142\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:25:59 | INFO | Rank 0 | Train Epoch: 0 [60544/250314 (24%)]\tLoss: 1.298306\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:25:59 | INFO | Rank 0 | Train Epoch: 0 [60576/250314 (24%)]\tLoss: 1.032584\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:00 | INFO | Rank 0 | Train Epoch: 0 [60608/250314 (24%)]\tLoss: 0.879807\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:00 | INFO | Rank 0 | Train Epoch: 0 [60640/250314 (24%)]\tLoss: 1.304728\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:01 | INFO | Rank 0 | Train Epoch: 0 [60672/250314 (24%)]\tLoss: 0.777166\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:01 | INFO | Rank 0 | Train Epoch: 0 [60704/250314 (24%)]\tLoss: 0.905413\tData (t) 0.338\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:02 | INFO | Rank 0 | Train Epoch: 0 [60736/250314 (24%)]\tLoss: 0.750200\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:02 | INFO | Rank 0 | Train Epoch: 0 [60768/250314 (24%)]\tLoss: 0.828001\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:03 | INFO | Rank 0 | Train Epoch: 0 [60800/250314 (24%)]\tLoss: 1.107937\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:03 | INFO | Rank 0 | Train Epoch: 0 [60832/250314 (24%)]\tLoss: 0.933485\tData (t) 0.218\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:04 | INFO | Rank 0 | Train Epoch: 0 [60864/250314 (24%)]\tLoss: 1.401283\tData (t) 0.434\tBatch (t) 0.645\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:04 | INFO | Rank 0 | Train Epoch: 0 [60896/250314 (24%)]\tLoss: 0.770629\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:05 | INFO | Rank 0 | Train Epoch: 0 [60928/250314 (24%)]\tLoss: 0.846462\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:05 | INFO | Rank 0 | Train Epoch: 0 [60960/250314 (24%)]\tLoss: 1.078074\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:06 | INFO | Rank 0 | Train Epoch: 0 [60992/250314 (24%)]\tLoss: 0.884062\tData (t) 0.354\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:06 | INFO | Rank 0 | Train Epoch: 0 [61024/250314 (24%)]\tLoss: 0.670354\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:07 | INFO | Rank 0 | Train Epoch: 0 [61056/250314 (24%)]\tLoss: 1.248639\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:07 | INFO | Rank 0 | Train Epoch: 0 [61088/250314 (24%)]\tLoss: 0.437993\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:08 | INFO | Rank 0 | Train Epoch: 0 [61120/250314 (24%)]\tLoss: 0.592633\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:08 | INFO | Rank 0 | Train Epoch: 0 [61152/250314 (24%)]\tLoss: 0.783219\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:09 | INFO | Rank 0 | Train Epoch: 0 [61184/250314 (24%)]\tLoss: 0.852635\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:09 | INFO | Rank 0 | Train Epoch: 0 [61216/250314 (24%)]\tLoss: 0.889849\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:10 | INFO | Rank 0 | Train Epoch: 0 [61248/250314 (24%)]\tLoss: 1.139443\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:11 | INFO | Rank 0 | Train Epoch: 0 [61280/250314 (24%)]\tLoss: 0.996801\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:11 | INFO | Rank 0 | Train Epoch: 0 [61312/250314 (24%)]\tLoss: 0.667972\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:12 | INFO | Rank 0 | Train Epoch: 0 [61344/250314 (25%)]\tLoss: 0.709081\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:12 | INFO | Rank 0 | Train Epoch: 0 [61376/250314 (25%)]\tLoss: 0.588901\tData (t) 0.197\tBatch (t) 0.409\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:12 | INFO | Rank 0 | Train Epoch: 0 [61408/250314 (25%)]\tLoss: 0.731965\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:13 | INFO | Rank 0 | Train Epoch: 0 [61440/250314 (25%)]\tLoss: 0.785618\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:13 | INFO | Rank 0 | Train Epoch: 0 [61472/250314 (25%)]\tLoss: 0.693398\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:14 | INFO | Rank 0 | Train Epoch: 0 [61504/250314 (25%)]\tLoss: 1.352838\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:14 | INFO | Rank 0 | Train Epoch: 0 [61536/250314 (25%)]\tLoss: 0.867614\tData (t) 0.307\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:15 | INFO | Rank 0 | Train Epoch: 0 [61568/250314 (25%)]\tLoss: 0.683154\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:15 | INFO | Rank 0 | Train Epoch: 0 [61600/250314 (25%)]\tLoss: 0.887181\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:16 | INFO | Rank 0 | Train Epoch: 0 [61632/250314 (25%)]\tLoss: 1.133903\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:16 | INFO | Rank 0 | Train Epoch: 0 [61664/250314 (25%)]\tLoss: 0.705487\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:17 | INFO | Rank 0 | Train Epoch: 0 [61696/250314 (25%)]\tLoss: 0.803436\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:17 | INFO | Rank 0 | Train Epoch: 0 [61728/250314 (25%)]\tLoss: 0.612741\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:18 | INFO | Rank 0 | Train Epoch: 0 [61760/250314 (25%)]\tLoss: 0.851345\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:18 | INFO | Rank 0 | Train Epoch: 0 [61792/250314 (25%)]\tLoss: 0.981302\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:19 | INFO | Rank 0 | Train Epoch: 0 [61824/250314 (25%)]\tLoss: 0.567518\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:19 | INFO | Rank 0 | Train Epoch: 0 [61856/250314 (25%)]\tLoss: 1.509703\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:20 | INFO | Rank 0 | Train Epoch: 0 [61888/250314 (25%)]\tLoss: 0.905520\tData (t) 0.321\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:20 | INFO | Rank 0 | Train Epoch: 0 [61920/250314 (25%)]\tLoss: 1.109167\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:21 | INFO | Rank 0 | Train Epoch: 0 [61952/250314 (25%)]\tLoss: 1.063212\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:21 | INFO | Rank 0 | Train Epoch: 0 [61984/250314 (25%)]\tLoss: 0.958006\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:22 | INFO | Rank 0 | Train Epoch: 0 [62016/250314 (25%)]\tLoss: 0.722822\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:22 | INFO | Rank 0 | Train Epoch: 0 [62048/250314 (25%)]\tLoss: 1.077797\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:23 | INFO | Rank 0 | Train Epoch: 0 [62080/250314 (25%)]\tLoss: 1.089029\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:23 | INFO | Rank 0 | Train Epoch: 0 [62112/250314 (25%)]\tLoss: 0.976763\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:24 | INFO | Rank 0 | Train Epoch: 0 [62144/250314 (25%)]\tLoss: 1.154662\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:24 | INFO | Rank 0 | Train Epoch: 0 [62176/250314 (25%)]\tLoss: 0.652587\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:25 | INFO | Rank 0 | Train Epoch: 0 [62208/250314 (25%)]\tLoss: 0.964370\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:25 | INFO | Rank 0 | Train Epoch: 0 [62240/250314 (25%)]\tLoss: 0.882091\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:26 | INFO | Rank 0 | Train Epoch: 0 [62272/250314 (25%)]\tLoss: 0.875443\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:26 | INFO | Rank 0 | Train Epoch: 0 [62304/250314 (25%)]\tLoss: 0.657525\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:27 | INFO | Rank 0 | Train Epoch: 0 [62336/250314 (25%)]\tLoss: 1.111706\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:27 | INFO | Rank 0 | Train Epoch: 0 [62368/250314 (25%)]\tLoss: 0.775107\tData (t) 0.219\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:27 | INFO | Rank 0 | Train Epoch: 0 [62400/250314 (25%)]\tLoss: 0.889870\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:28 | INFO | Rank 0 | Train Epoch: 0 [62432/250314 (25%)]\tLoss: 1.054088\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:28 | INFO | Rank 0 | Train Epoch: 0 [62464/250314 (25%)]\tLoss: 1.022391\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:29 | INFO | Rank 0 | Train Epoch: 0 [62496/250314 (25%)]\tLoss: 0.992052\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:29 | INFO | Rank 0 | Train Epoch: 0 [62528/250314 (25%)]\tLoss: 1.026002\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:30 | INFO | Rank 0 | Train Epoch: 0 [62560/250314 (25%)]\tLoss: 1.236011\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:30 | INFO | Rank 0 | Train Epoch: 0 [62592/250314 (25%)]\tLoss: 0.943726\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:31 | INFO | Rank 0 | Train Epoch: 0 [62624/250314 (25%)]\tLoss: 1.028533\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:31 | INFO | Rank 0 | Train Epoch: 0 [62656/250314 (25%)]\tLoss: 0.929399\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:32 | INFO | Rank 0 | Train Epoch: 0 [62688/250314 (25%)]\tLoss: 0.658630\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:32 | INFO | Rank 0 | Train Epoch: 0 [62720/250314 (25%)]\tLoss: 0.651340\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:33 | INFO | Rank 0 | Train Epoch: 0 [62752/250314 (25%)]\tLoss: 1.185081\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:33 | INFO | Rank 0 | Train Epoch: 0 [62784/250314 (25%)]\tLoss: 1.188249\tData (t) 0.222\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:34 | INFO | Rank 0 | Train Epoch: 0 [62816/250314 (25%)]\tLoss: 1.036856\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:34 | INFO | Rank 0 | Train Epoch: 0 [62848/250314 (25%)]\tLoss: 1.010434\tData (t) 0.193\tBatch (t) 0.405\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:35 | INFO | Rank 0 | Train Epoch: 0 [62880/250314 (25%)]\tLoss: 0.756007\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:35 | INFO | Rank 0 | Train Epoch: 0 [62912/250314 (25%)]\tLoss: 1.094647\tData (t) 0.328\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:36 | INFO | Rank 0 | Train Epoch: 0 [62944/250314 (25%)]\tLoss: 1.284346\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:36 | INFO | Rank 0 | Train Epoch: 0 [62976/250314 (25%)]\tLoss: 1.063096\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:37 | INFO | Rank 0 | Train Epoch: 0 [63008/250314 (25%)]\tLoss: 0.887481\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:37 | INFO | Rank 0 | Train Epoch: 0 [63040/250314 (25%)]\tLoss: 0.988415\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:38 | INFO | Rank 0 | Train Epoch: 0 [63072/250314 (25%)]\tLoss: 1.026493\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:38 | INFO | Rank 0 | Train Epoch: 0 [63104/250314 (25%)]\tLoss: 0.652653\tData (t) 0.221\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:39 | INFO | Rank 0 | Train Epoch: 0 [63136/250314 (25%)]\tLoss: 0.981711\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:39 | INFO | Rank 0 | Train Epoch: 0 [63168/250314 (25%)]\tLoss: 0.841134\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:40 | INFO | Rank 0 | Train Epoch: 0 [63200/250314 (25%)]\tLoss: 1.002026\tData (t) 0.390\tBatch (t) 0.601\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:40 | INFO | Rank 0 | Train Epoch: 0 [63232/250314 (25%)]\tLoss: 0.737298\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:41 | INFO | Rank 0 | Train Epoch: 0 [63264/250314 (25%)]\tLoss: 0.900836\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:41 | INFO | Rank 0 | Train Epoch: 0 [63296/250314 (25%)]\tLoss: 0.854966\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:42 | INFO | Rank 0 | Train Epoch: 0 [63328/250314 (25%)]\tLoss: 0.830368\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:42 | INFO | Rank 0 | Train Epoch: 0 [63360/250314 (25%)]\tLoss: 1.390953\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:43 | INFO | Rank 0 | Train Epoch: 0 [63392/250314 (25%)]\tLoss: 1.065767\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:43 | INFO | Rank 0 | Train Epoch: 0 [63424/250314 (25%)]\tLoss: 0.769009\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:44 | INFO | Rank 0 | Train Epoch: 0 [63456/250314 (25%)]\tLoss: 0.915045\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:44 | INFO | Rank 0 | Train Epoch: 0 [63488/250314 (25%)]\tLoss: 0.676495\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:45 | INFO | Rank 0 | Train Epoch: 0 [63520/250314 (25%)]\tLoss: 0.978280\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:45 | INFO | Rank 0 | Train Epoch: 0 [63552/250314 (25%)]\tLoss: 0.745008\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:46 | INFO | Rank 0 | Train Epoch: 0 [63584/250314 (25%)]\tLoss: 1.076505\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:46 | INFO | Rank 0 | Train Epoch: 0 [63616/250314 (25%)]\tLoss: 0.710299\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:47 | INFO | Rank 0 | Train Epoch: 0 [63648/250314 (25%)]\tLoss: 1.114432\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:47 | INFO | Rank 0 | Train Epoch: 0 [63680/250314 (25%)]\tLoss: 0.674301\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:48 | INFO | Rank 0 | Train Epoch: 0 [63712/250314 (25%)]\tLoss: 0.980810\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:48 | INFO | Rank 0 | Train Epoch: 0 [63744/250314 (25%)]\tLoss: 1.101555\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:49 | INFO | Rank 0 | Train Epoch: 0 [63776/250314 (25%)]\tLoss: 1.265711\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:49 | INFO | Rank 0 | Train Epoch: 0 [63808/250314 (25%)]\tLoss: 0.792671\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:50 | INFO | Rank 0 | Train Epoch: 0 [63840/250314 (26%)]\tLoss: 0.543910\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:50 | INFO | Rank 0 | Train Epoch: 0 [63872/250314 (26%)]\tLoss: 0.547476\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:50 | INFO | Rank 0 | Train Epoch: 0 [63904/250314 (26%)]\tLoss: 0.841905\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:51 | INFO | Rank 0 | Train Epoch: 0 [63936/250314 (26%)]\tLoss: 0.698002\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:51 | INFO | Rank 0 | Train Epoch: 0 [63968/250314 (26%)]\tLoss: 0.909590\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:52 | INFO | Rank 0 | Train Epoch: 0 [64000/250314 (26%)]\tLoss: 0.723210\tData (t) 0.321\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:53 | INFO | Rank 0 | Train Epoch: 0 [64032/250314 (26%)]\tLoss: 1.252492\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:53 | INFO | Rank 0 | Train Epoch: 0 [64064/250314 (26%)]\tLoss: 0.905782\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:53 | INFO | Rank 0 | Train Epoch: 0 [64096/250314 (26%)]\tLoss: 1.212921\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:54 | INFO | Rank 0 | Train Epoch: 0 [64128/250314 (26%)]\tLoss: 1.103393\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:55 | INFO | Rank 0 | Train Epoch: 0 [64160/250314 (26%)]\tLoss: 1.050998\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:55 | INFO | Rank 0 | Train Epoch: 0 [64192/250314 (26%)]\tLoss: 1.041660\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:56 | INFO | Rank 0 | Train Epoch: 0 [64224/250314 (26%)]\tLoss: 1.087526\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:56 | INFO | Rank 0 | Train Epoch: 0 [64256/250314 (26%)]\tLoss: 0.872401\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:56 | INFO | Rank 0 | Train Epoch: 0 [64288/250314 (26%)]\tLoss: 1.150401\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:57 | INFO | Rank 0 | Train Epoch: 0 [64320/250314 (26%)]\tLoss: 0.677068\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:57 | INFO | Rank 0 | Train Epoch: 0 [64352/250314 (26%)]\tLoss: 0.855601\tData (t) 0.321\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:58 | INFO | Rank 0 | Train Epoch: 0 [64384/250314 (26%)]\tLoss: 0.717709\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:58 | INFO | Rank 0 | Train Epoch: 0 [64416/250314 (26%)]\tLoss: 0.742288\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:59 | INFO | Rank 0 | Train Epoch: 0 [64448/250314 (26%)]\tLoss: 1.136735\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:26:59 | INFO | Rank 0 | Train Epoch: 0 [64480/250314 (26%)]\tLoss: 0.697350\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:00 | INFO | Rank 0 | Train Epoch: 0 [64512/250314 (26%)]\tLoss: 1.010170\tData (t) 0.214\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:00 | INFO | Rank 0 | Train Epoch: 0 [64544/250314 (26%)]\tLoss: 1.008092\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:01 | INFO | Rank 0 | Train Epoch: 0 [64576/250314 (26%)]\tLoss: 0.900704\tData (t) 0.233\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:01 | INFO | Rank 0 | Train Epoch: 0 [64608/250314 (26%)]\tLoss: 0.975705\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:02 | INFO | Rank 0 | Train Epoch: 0 [64640/250314 (26%)]\tLoss: 1.227132\tData (t) 0.228\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:02 | INFO | Rank 0 | Train Epoch: 0 [64672/250314 (26%)]\tLoss: 1.065249\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:03 | INFO | Rank 0 | Train Epoch: 0 [64704/250314 (26%)]\tLoss: 1.148231\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:03 | INFO | Rank 0 | Train Epoch: 0 [64736/250314 (26%)]\tLoss: 0.798048\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:04 | INFO | Rank 0 | Train Epoch: 0 [64768/250314 (26%)]\tLoss: 0.860292\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:04 | INFO | Rank 0 | Train Epoch: 0 [64800/250314 (26%)]\tLoss: 0.752390\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:05 | INFO | Rank 0 | Train Epoch: 0 [64832/250314 (26%)]\tLoss: 0.735033\tData (t) 0.209\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:05 | INFO | Rank 0 | Train Epoch: 0 [64864/250314 (26%)]\tLoss: 0.673530\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:06 | INFO | Rank 0 | Train Epoch: 0 [64896/250314 (26%)]\tLoss: 1.021909\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:06 | INFO | Rank 0 | Train Epoch: 0 [64928/250314 (26%)]\tLoss: 0.764819\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:07 | INFO | Rank 0 | Train Epoch: 0 [64960/250314 (26%)]\tLoss: 0.523947\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:07 | INFO | Rank 0 | Train Epoch: 0 [64992/250314 (26%)]\tLoss: 1.308937\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:07 | INFO | Rank 0 | Train Epoch: 0 [65024/250314 (26%)]\tLoss: 0.641762\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:08 | INFO | Rank 0 | Train Epoch: 0 [65056/250314 (26%)]\tLoss: 0.994566\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:09 | INFO | Rank 0 | Train Epoch: 0 [65088/250314 (26%)]\tLoss: 1.060418\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:09 | INFO | Rank 0 | Train Epoch: 0 [65120/250314 (26%)]\tLoss: 0.479655\tData (t) 0.242\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:09 | INFO | Rank 0 | Train Epoch: 0 [65152/250314 (26%)]\tLoss: 0.559873\tData (t) 0.216\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:10 | INFO | Rank 0 | Train Epoch: 0 [65184/250314 (26%)]\tLoss: 0.680229\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:10 | INFO | Rank 0 | Train Epoch: 0 [65216/250314 (26%)]\tLoss: 0.935850\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:11 | INFO | Rank 0 | Train Epoch: 0 [65248/250314 (26%)]\tLoss: 0.819707\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:11 | INFO | Rank 0 | Train Epoch: 0 [65280/250314 (26%)]\tLoss: 1.034927\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:12 | INFO | Rank 0 | Train Epoch: 0 [65312/250314 (26%)]\tLoss: 1.230839\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:12 | INFO | Rank 0 | Train Epoch: 0 [65344/250314 (26%)]\tLoss: 0.901860\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:13 | INFO | Rank 0 | Train Epoch: 0 [65376/250314 (26%)]\tLoss: 0.696184\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:13 | INFO | Rank 0 | Train Epoch: 0 [65408/250314 (26%)]\tLoss: 0.982571\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:14 | INFO | Rank 0 | Train Epoch: 0 [65440/250314 (26%)]\tLoss: 0.639478\tData (t) 0.250\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:14 | INFO | Rank 0 | Train Epoch: 0 [65472/250314 (26%)]\tLoss: 1.356993\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:15 | INFO | Rank 0 | Train Epoch: 0 [65504/250314 (26%)]\tLoss: 0.700835\tData (t) 0.321\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:15 | INFO | Rank 0 | Train Epoch: 0 [65536/250314 (26%)]\tLoss: 1.061927\tData (t) 0.391\tBatch (t) 0.603\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:16 | INFO | Rank 0 | Train Epoch: 0 [65568/250314 (26%)]\tLoss: 0.817558\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:16 | INFO | Rank 0 | Train Epoch: 0 [65600/250314 (26%)]\tLoss: 0.771493\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:17 | INFO | Rank 0 | Train Epoch: 0 [65632/250314 (26%)]\tLoss: 1.262890\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:17 | INFO | Rank 0 | Train Epoch: 0 [65664/250314 (26%)]\tLoss: 0.865013\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:18 | INFO | Rank 0 | Train Epoch: 0 [65696/250314 (26%)]\tLoss: 1.300827\tData (t) 0.380\tBatch (t) 0.592\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:19 | INFO | Rank 0 | Train Epoch: 0 [65728/250314 (26%)]\tLoss: 1.076858\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:19 | INFO | Rank 0 | Train Epoch: 0 [65760/250314 (26%)]\tLoss: 0.840403\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:20 | INFO | Rank 0 | Train Epoch: 0 [65792/250314 (26%)]\tLoss: 0.793856\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:20 | INFO | Rank 0 | Train Epoch: 0 [65824/250314 (26%)]\tLoss: 1.183810\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:21 | INFO | Rank 0 | Train Epoch: 0 [65856/250314 (26%)]\tLoss: 0.714078\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:21 | INFO | Rank 0 | Train Epoch: 0 [65888/250314 (26%)]\tLoss: 0.987688\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:22 | INFO | Rank 0 | Train Epoch: 0 [65920/250314 (26%)]\tLoss: 1.196929\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:22 | INFO | Rank 0 | Train Epoch: 0 [65952/250314 (26%)]\tLoss: 1.087984\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:23 | INFO | Rank 0 | Train Epoch: 0 [65984/250314 (26%)]\tLoss: 0.956730\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:23 | INFO | Rank 0 | Train Epoch: 0 [66016/250314 (26%)]\tLoss: 0.976301\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:24 | INFO | Rank 0 | Train Epoch: 0 [66048/250314 (26%)]\tLoss: 1.123031\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:24 | INFO | Rank 0 | Train Epoch: 0 [66080/250314 (26%)]\tLoss: 0.564635\tData (t) 0.330\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:25 | INFO | Rank 0 | Train Epoch: 0 [66112/250314 (26%)]\tLoss: 0.765155\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:25 | INFO | Rank 0 | Train Epoch: 0 [66144/250314 (26%)]\tLoss: 0.507513\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:26 | INFO | Rank 0 | Train Epoch: 0 [66176/250314 (26%)]\tLoss: 0.941428\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:26 | INFO | Rank 0 | Train Epoch: 0 [66208/250314 (26%)]\tLoss: 1.262040\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:27 | INFO | Rank 0 | Train Epoch: 0 [66240/250314 (26%)]\tLoss: 0.992436\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:27 | INFO | Rank 0 | Train Epoch: 0 [66272/250314 (26%)]\tLoss: 0.826541\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:28 | INFO | Rank 0 | Train Epoch: 0 [66304/250314 (26%)]\tLoss: 0.813151\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:28 | INFO | Rank 0 | Train Epoch: 0 [66336/250314 (27%)]\tLoss: 0.837629\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:29 | INFO | Rank 0 | Train Epoch: 0 [66368/250314 (27%)]\tLoss: 0.922734\tData (t) 0.375\tBatch (t) 0.587\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:29 | INFO | Rank 0 | Train Epoch: 0 [66400/250314 (27%)]\tLoss: 0.841282\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:30 | INFO | Rank 0 | Train Epoch: 0 [66432/250314 (27%)]\tLoss: 0.636919\tData (t) 0.206\tBatch (t) 0.418\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:30 | INFO | Rank 0 | Train Epoch: 0 [66464/250314 (27%)]\tLoss: 0.769626\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:31 | INFO | Rank 0 | Train Epoch: 0 [66496/250314 (27%)]\tLoss: 1.188146\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:31 | INFO | Rank 0 | Train Epoch: 0 [66528/250314 (27%)]\tLoss: 0.954997\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:32 | INFO | Rank 0 | Train Epoch: 0 [66560/250314 (27%)]\tLoss: 0.730188\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:32 | INFO | Rank 0 | Train Epoch: 0 [66592/250314 (27%)]\tLoss: 0.875080\tData (t) 0.286\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:32 | INFO | Rank 0 | Train Epoch: 0 [66624/250314 (27%)]\tLoss: 0.795293\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:33 | INFO | Rank 0 | Train Epoch: 0 [66656/250314 (27%)]\tLoss: 0.740286\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:34 | INFO | Rank 0 | Train Epoch: 0 [66688/250314 (27%)]\tLoss: 1.060319\tData (t) 0.365\tBatch (t) 0.577\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:34 | INFO | Rank 0 | Train Epoch: 0 [66720/250314 (27%)]\tLoss: 0.930139\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:34 | INFO | Rank 0 | Train Epoch: 0 [66752/250314 (27%)]\tLoss: 0.853401\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:35 | INFO | Rank 0 | Train Epoch: 0 [66784/250314 (27%)]\tLoss: 0.494912\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:35 | INFO | Rank 0 | Train Epoch: 0 [66816/250314 (27%)]\tLoss: 1.085967\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:36 | INFO | Rank 0 | Train Epoch: 0 [66848/250314 (27%)]\tLoss: 0.872312\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:36 | INFO | Rank 0 | Train Epoch: 0 [66880/250314 (27%)]\tLoss: 0.605691\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:37 | INFO | Rank 0 | Train Epoch: 0 [66912/250314 (27%)]\tLoss: 0.556833\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:37 | INFO | Rank 0 | Train Epoch: 0 [66944/250314 (27%)]\tLoss: 0.951816\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:38 | INFO | Rank 0 | Train Epoch: 0 [66976/250314 (27%)]\tLoss: 1.180427\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:38 | INFO | Rank 0 | Train Epoch: 0 [67008/250314 (27%)]\tLoss: 1.293202\tData (t) 0.212\tBatch (t) 0.423\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:39 | INFO | Rank 0 | Train Epoch: 0 [67040/250314 (27%)]\tLoss: 1.089331\tData (t) 0.434\tBatch (t) 0.645\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:39 | INFO | Rank 0 | Train Epoch: 0 [67072/250314 (27%)]\tLoss: 1.308607\tData (t) 0.229\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:40 | INFO | Rank 0 | Train Epoch: 0 [67104/250314 (27%)]\tLoss: 1.137253\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:40 | INFO | Rank 0 | Train Epoch: 0 [67136/250314 (27%)]\tLoss: 0.950600\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:41 | INFO | Rank 0 | Train Epoch: 0 [67168/250314 (27%)]\tLoss: 1.322963\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:41 | INFO | Rank 0 | Train Epoch: 0 [67200/250314 (27%)]\tLoss: 0.749014\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:42 | INFO | Rank 0 | Train Epoch: 0 [67232/250314 (27%)]\tLoss: 0.946274\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:42 | INFO | Rank 0 | Train Epoch: 0 [67264/250314 (27%)]\tLoss: 0.809879\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:43 | INFO | Rank 0 | Train Epoch: 0 [67296/250314 (27%)]\tLoss: 1.085879\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:43 | INFO | Rank 0 | Train Epoch: 0 [67328/250314 (27%)]\tLoss: 0.837642\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:44 | INFO | Rank 0 | Train Epoch: 0 [67360/250314 (27%)]\tLoss: 0.853224\tData (t) 0.363\tBatch (t) 0.574\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:44 | INFO | Rank 0 | Train Epoch: 0 [67392/250314 (27%)]\tLoss: 1.042058\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:45 | INFO | Rank 0 | Train Epoch: 0 [67424/250314 (27%)]\tLoss: 0.860636\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:45 | INFO | Rank 0 | Train Epoch: 0 [67456/250314 (27%)]\tLoss: 0.552960\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:46 | INFO | Rank 0 | Train Epoch: 0 [67488/250314 (27%)]\tLoss: 0.740009\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:46 | INFO | Rank 0 | Train Epoch: 0 [67520/250314 (27%)]\tLoss: 0.755468\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:47 | INFO | Rank 0 | Train Epoch: 0 [67552/250314 (27%)]\tLoss: 1.308596\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:47 | INFO | Rank 0 | Train Epoch: 0 [67584/250314 (27%)]\tLoss: 0.940688\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:48 | INFO | Rank 0 | Train Epoch: 0 [67616/250314 (27%)]\tLoss: 0.585330\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:48 | INFO | Rank 0 | Train Epoch: 0 [67648/250314 (27%)]\tLoss: 0.972322\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:49 | INFO | Rank 0 | Train Epoch: 0 [67680/250314 (27%)]\tLoss: 0.843145\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:49 | INFO | Rank 0 | Train Epoch: 0 [67712/250314 (27%)]\tLoss: 0.828357\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:50 | INFO | Rank 0 | Train Epoch: 0 [67744/250314 (27%)]\tLoss: 0.929702\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:50 | INFO | Rank 0 | Train Epoch: 0 [67776/250314 (27%)]\tLoss: 0.737428\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:51 | INFO | Rank 0 | Train Epoch: 0 [67808/250314 (27%)]\tLoss: 1.032543\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:51 | INFO | Rank 0 | Train Epoch: 0 [67840/250314 (27%)]\tLoss: 0.883297\tData (t) 0.368\tBatch (t) 0.580\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:52 | INFO | Rank 0 | Train Epoch: 0 [67872/250314 (27%)]\tLoss: 1.464399\tData (t) 0.328\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:52 | INFO | Rank 0 | Train Epoch: 0 [67904/250314 (27%)]\tLoss: 1.341117\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:53 | INFO | Rank 0 | Train Epoch: 0 [67936/250314 (27%)]\tLoss: 1.078185\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:53 | INFO | Rank 0 | Train Epoch: 0 [67968/250314 (27%)]\tLoss: 1.774038\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:54 | INFO | Rank 0 | Train Epoch: 0 [68000/250314 (27%)]\tLoss: 0.913579\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:54 | INFO | Rank 0 | Train Epoch: 0 [68032/250314 (27%)]\tLoss: 1.049592\tData (t) 0.340\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:55 | INFO | Rank 0 | Train Epoch: 0 [68064/250314 (27%)]\tLoss: 1.082813\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:55 | INFO | Rank 0 | Train Epoch: 0 [68096/250314 (27%)]\tLoss: 1.006878\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:56 | INFO | Rank 0 | Train Epoch: 0 [68128/250314 (27%)]\tLoss: 0.750878\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:56 | INFO | Rank 0 | Train Epoch: 0 [68160/250314 (27%)]\tLoss: 1.031749\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:57 | INFO | Rank 0 | Train Epoch: 0 [68192/250314 (27%)]\tLoss: 0.964042\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:57 | INFO | Rank 0 | Train Epoch: 0 [68224/250314 (27%)]\tLoss: 1.100285\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:58 | INFO | Rank 0 | Train Epoch: 0 [68256/250314 (27%)]\tLoss: 0.728420\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:58 | INFO | Rank 0 | Train Epoch: 0 [68288/250314 (27%)]\tLoss: 1.137588\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:59 | INFO | Rank 0 | Train Epoch: 0 [68320/250314 (27%)]\tLoss: 0.753237\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:27:59 | INFO | Rank 0 | Train Epoch: 0 [68352/250314 (27%)]\tLoss: 0.345607\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:00 | INFO | Rank 0 | Train Epoch: 0 [68384/250314 (27%)]\tLoss: 1.395454\tData (t) 0.383\tBatch (t) 0.594\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:00 | INFO | Rank 0 | Train Epoch: 0 [68416/250314 (27%)]\tLoss: 1.280021\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:01 | INFO | Rank 0 | Train Epoch: 0 [68448/250314 (27%)]\tLoss: 0.572337\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:01 | INFO | Rank 0 | Train Epoch: 0 [68480/250314 (27%)]\tLoss: 0.854707\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:02 | INFO | Rank 0 | Train Epoch: 0 [68512/250314 (27%)]\tLoss: 0.832176\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:02 | INFO | Rank 0 | Train Epoch: 0 [68544/250314 (27%)]\tLoss: 0.511858\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:03 | INFO | Rank 0 | Train Epoch: 0 [68576/250314 (27%)]\tLoss: 0.456235\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:03 | INFO | Rank 0 | Train Epoch: 0 [68608/250314 (27%)]\tLoss: 1.042327\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:04 | INFO | Rank 0 | Train Epoch: 0 [68640/250314 (27%)]\tLoss: 0.756897\tData (t) 0.345\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:04 | INFO | Rank 0 | Train Epoch: 0 [68672/250314 (27%)]\tLoss: 0.947239\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:05 | INFO | Rank 0 | Train Epoch: 0 [68704/250314 (27%)]\tLoss: 0.914621\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:05 | INFO | Rank 0 | Train Epoch: 0 [68736/250314 (27%)]\tLoss: 0.914552\tData (t) 0.214\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:06 | INFO | Rank 0 | Train Epoch: 0 [68768/250314 (27%)]\tLoss: 1.034249\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:06 | INFO | Rank 0 | Train Epoch: 0 [68800/250314 (27%)]\tLoss: 1.157830\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:07 | INFO | Rank 0 | Train Epoch: 0 [68832/250314 (27%)]\tLoss: 1.158370\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:07 | INFO | Rank 0 | Train Epoch: 0 [68864/250314 (28%)]\tLoss: 0.738136\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:08 | INFO | Rank 0 | Train Epoch: 0 [68896/250314 (28%)]\tLoss: 1.200834\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:08 | INFO | Rank 0 | Train Epoch: 0 [68928/250314 (28%)]\tLoss: 0.946077\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:08 | INFO | Rank 0 | Train Epoch: 0 [68960/250314 (28%)]\tLoss: 1.007735\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:09 | INFO | Rank 0 | Train Epoch: 0 [68992/250314 (28%)]\tLoss: 0.855731\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:09 | INFO | Rank 0 | Train Epoch: 0 [69024/250314 (28%)]\tLoss: 0.773211\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:10 | INFO | Rank 0 | Train Epoch: 0 [69056/250314 (28%)]\tLoss: 0.473570\tData (t) 0.419\tBatch (t) 0.631\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:11 | INFO | Rank 0 | Train Epoch: 0 [69088/250314 (28%)]\tLoss: 0.794770\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:11 | INFO | Rank 0 | Train Epoch: 0 [69120/250314 (28%)]\tLoss: 1.244878\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:12 | INFO | Rank 0 | Train Epoch: 0 [69152/250314 (28%)]\tLoss: 0.729439\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:12 | INFO | Rank 0 | Train Epoch: 0 [69184/250314 (28%)]\tLoss: 0.805926\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:13 | INFO | Rank 0 | Train Epoch: 0 [69216/250314 (28%)]\tLoss: 1.362627\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:13 | INFO | Rank 0 | Train Epoch: 0 [69248/250314 (28%)]\tLoss: 0.803017\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:13 | INFO | Rank 0 | Train Epoch: 0 [69280/250314 (28%)]\tLoss: 1.098680\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:14 | INFO | Rank 0 | Train Epoch: 0 [69312/250314 (28%)]\tLoss: 0.744711\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:14 | INFO | Rank 0 | Train Epoch: 0 [69344/250314 (28%)]\tLoss: 1.157196\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:15 | INFO | Rank 0 | Train Epoch: 0 [69376/250314 (28%)]\tLoss: 1.011822\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:16 | INFO | Rank 0 | Train Epoch: 0 [69408/250314 (28%)]\tLoss: 0.800917\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:16 | INFO | Rank 0 | Train Epoch: 0 [69440/250314 (28%)]\tLoss: 0.932294\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:17 | INFO | Rank 0 | Train Epoch: 0 [69472/250314 (28%)]\tLoss: 0.830184\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:17 | INFO | Rank 0 | Train Epoch: 0 [69504/250314 (28%)]\tLoss: 0.685277\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:17 | INFO | Rank 0 | Train Epoch: 0 [69536/250314 (28%)]\tLoss: 0.825020\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:18 | INFO | Rank 0 | Train Epoch: 0 [69568/250314 (28%)]\tLoss: 0.772247\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:18 | INFO | Rank 0 | Train Epoch: 0 [69600/250314 (28%)]\tLoss: 1.176608\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:19 | INFO | Rank 0 | Train Epoch: 0 [69632/250314 (28%)]\tLoss: 0.913168\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:19 | INFO | Rank 0 | Train Epoch: 0 [69664/250314 (28%)]\tLoss: 0.611801\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:20 | INFO | Rank 0 | Train Epoch: 0 [69696/250314 (28%)]\tLoss: 0.944388\tData (t) 0.320\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:20 | INFO | Rank 0 | Train Epoch: 0 [69728/250314 (28%)]\tLoss: 1.029331\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:21 | INFO | Rank 0 | Train Epoch: 0 [69760/250314 (28%)]\tLoss: 0.520945\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:21 | INFO | Rank 0 | Train Epoch: 0 [69792/250314 (28%)]\tLoss: 1.298483\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:22 | INFO | Rank 0 | Train Epoch: 0 [69824/250314 (28%)]\tLoss: 0.552781\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:22 | INFO | Rank 0 | Train Epoch: 0 [69856/250314 (28%)]\tLoss: 1.114681\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:23 | INFO | Rank 0 | Train Epoch: 0 [69888/250314 (28%)]\tLoss: 1.270058\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:23 | INFO | Rank 0 | Train Epoch: 0 [69920/250314 (28%)]\tLoss: 1.055676\tData (t) 0.210\tBatch (t) 0.422\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:24 | INFO | Rank 0 | Train Epoch: 0 [69952/250314 (28%)]\tLoss: 1.031919\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:24 | INFO | Rank 0 | Train Epoch: 0 [69984/250314 (28%)]\tLoss: 1.367591\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:25 | INFO | Rank 0 | Train Epoch: 0 [70016/250314 (28%)]\tLoss: 0.742608\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:25 | INFO | Rank 0 | Train Epoch: 0 [70048/250314 (28%)]\tLoss: 1.398042\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:26 | INFO | Rank 0 | Train Epoch: 0 [70080/250314 (28%)]\tLoss: 0.624796\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:26 | INFO | Rank 0 | Train Epoch: 0 [70112/250314 (28%)]\tLoss: 0.422092\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:27 | INFO | Rank 0 | Train Epoch: 0 [70144/250314 (28%)]\tLoss: 0.988814\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:27 | INFO | Rank 0 | Train Epoch: 0 [70176/250314 (28%)]\tLoss: 0.778760\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:28 | INFO | Rank 0 | Train Epoch: 0 [70208/250314 (28%)]\tLoss: 0.617811\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:28 | INFO | Rank 0 | Train Epoch: 0 [70240/250314 (28%)]\tLoss: 0.469983\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:29 | INFO | Rank 0 | Train Epoch: 0 [70272/250314 (28%)]\tLoss: 1.120601\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:29 | INFO | Rank 0 | Train Epoch: 0 [70304/250314 (28%)]\tLoss: 0.744129\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:30 | INFO | Rank 0 | Train Epoch: 0 [70336/250314 (28%)]\tLoss: 1.154111\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:30 | INFO | Rank 0 | Train Epoch: 0 [70368/250314 (28%)]\tLoss: 0.897670\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:31 | INFO | Rank 0 | Train Epoch: 0 [70400/250314 (28%)]\tLoss: 0.840037\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:31 | INFO | Rank 0 | Train Epoch: 0 [70432/250314 (28%)]\tLoss: 0.714704\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:32 | INFO | Rank 0 | Train Epoch: 0 [70464/250314 (28%)]\tLoss: 0.845400\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:32 | INFO | Rank 0 | Train Epoch: 0 [70496/250314 (28%)]\tLoss: 1.539346\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:33 | INFO | Rank 0 | Train Epoch: 0 [70528/250314 (28%)]\tLoss: 0.710069\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:33 | INFO | Rank 0 | Train Epoch: 0 [70560/250314 (28%)]\tLoss: 1.507156\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:34 | INFO | Rank 0 | Train Epoch: 0 [70592/250314 (28%)]\tLoss: 0.999232\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:34 | INFO | Rank 0 | Train Epoch: 0 [70624/250314 (28%)]\tLoss: 1.281902\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:35 | INFO | Rank 0 | Train Epoch: 0 [70656/250314 (28%)]\tLoss: 0.938773\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:35 | INFO | Rank 0 | Train Epoch: 0 [70688/250314 (28%)]\tLoss: 1.360497\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:36 | INFO | Rank 0 | Train Epoch: 0 [70720/250314 (28%)]\tLoss: 0.849551\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:36 | INFO | Rank 0 | Train Epoch: 0 [70752/250314 (28%)]\tLoss: 0.622004\tData (t) 0.215\tBatch (t) 0.426\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:36 | INFO | Rank 0 | Train Epoch: 0 [70784/250314 (28%)]\tLoss: 1.103731\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:37 | INFO | Rank 0 | Train Epoch: 0 [70816/250314 (28%)]\tLoss: 1.113550\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:37 | INFO | Rank 0 | Train Epoch: 0 [70848/250314 (28%)]\tLoss: 1.171790\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:38 | INFO | Rank 0 | Train Epoch: 0 [70880/250314 (28%)]\tLoss: 1.001855\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:38 | INFO | Rank 0 | Train Epoch: 0 [70912/250314 (28%)]\tLoss: 0.821516\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:39 | INFO | Rank 0 | Train Epoch: 0 [70944/250314 (28%)]\tLoss: 0.986323\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:39 | INFO | Rank 0 | Train Epoch: 0 [70976/250314 (28%)]\tLoss: 0.899067\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:40 | INFO | Rank 0 | Train Epoch: 0 [71008/250314 (28%)]\tLoss: 0.836097\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:40 | INFO | Rank 0 | Train Epoch: 0 [71040/250314 (28%)]\tLoss: 0.906568\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:41 | INFO | Rank 0 | Train Epoch: 0 [71072/250314 (28%)]\tLoss: 0.908462\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:41 | INFO | Rank 0 | Train Epoch: 0 [71104/250314 (28%)]\tLoss: 1.015400\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:42 | INFO | Rank 0 | Train Epoch: 0 [71136/250314 (28%)]\tLoss: 0.947738\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:42 | INFO | Rank 0 | Train Epoch: 0 [71168/250314 (28%)]\tLoss: 1.278759\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:43 | INFO | Rank 0 | Train Epoch: 0 [71200/250314 (28%)]\tLoss: 0.596226\tData (t) 0.202\tBatch (t) 0.414\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:43 | INFO | Rank 0 | Train Epoch: 0 [71232/250314 (28%)]\tLoss: 0.868740\tData (t) 0.357\tBatch (t) 0.569\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:44 | INFO | Rank 0 | Train Epoch: 0 [71264/250314 (28%)]\tLoss: 0.722944\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:44 | INFO | Rank 0 | Train Epoch: 0 [71296/250314 (28%)]\tLoss: 0.680300\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:45 | INFO | Rank 0 | Train Epoch: 0 [71328/250314 (28%)]\tLoss: 0.940887\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:45 | INFO | Rank 0 | Train Epoch: 0 [71360/250314 (29%)]\tLoss: 0.630941\tData (t) 0.233\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:46 | INFO | Rank 0 | Train Epoch: 0 [71392/250314 (29%)]\tLoss: 0.964418\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:46 | INFO | Rank 0 | Train Epoch: 0 [71424/250314 (29%)]\tLoss: 0.650928\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:47 | INFO | Rank 0 | Train Epoch: 0 [71456/250314 (29%)]\tLoss: 1.169215\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:47 | INFO | Rank 0 | Train Epoch: 0 [71488/250314 (29%)]\tLoss: 0.866424\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:48 | INFO | Rank 0 | Train Epoch: 0 [71520/250314 (29%)]\tLoss: 1.369930\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:48 | INFO | Rank 0 | Train Epoch: 0 [71552/250314 (29%)]\tLoss: 0.573087\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:49 | INFO | Rank 0 | Train Epoch: 0 [71584/250314 (29%)]\tLoss: 0.769806\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:49 | INFO | Rank 0 | Train Epoch: 0 [71616/250314 (29%)]\tLoss: 1.056436\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:50 | INFO | Rank 0 | Train Epoch: 0 [71648/250314 (29%)]\tLoss: 1.255020\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:50 | INFO | Rank 0 | Train Epoch: 0 [71680/250314 (29%)]\tLoss: 0.981292\tData (t) 0.362\tBatch (t) 0.573\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:51 | INFO | Rank 0 | Train Epoch: 0 [71712/250314 (29%)]\tLoss: 1.004030\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:51 | INFO | Rank 0 | Train Epoch: 0 [71744/250314 (29%)]\tLoss: 0.714690\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:52 | INFO | Rank 0 | Train Epoch: 0 [71776/250314 (29%)]\tLoss: 1.105820\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:52 | INFO | Rank 0 | Train Epoch: 0 [71808/250314 (29%)]\tLoss: 0.727939\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:52 | INFO | Rank 0 | Train Epoch: 0 [71840/250314 (29%)]\tLoss: 0.936523\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:53 | INFO | Rank 0 | Train Epoch: 0 [71872/250314 (29%)]\tLoss: 0.911767\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:53 | INFO | Rank 0 | Train Epoch: 0 [71904/250314 (29%)]\tLoss: 0.873963\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:54 | INFO | Rank 0 | Train Epoch: 0 [71936/250314 (29%)]\tLoss: 1.238605\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:54 | INFO | Rank 0 | Train Epoch: 0 [71968/250314 (29%)]\tLoss: 0.872800\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:55 | INFO | Rank 0 | Train Epoch: 0 [72000/250314 (29%)]\tLoss: 0.768672\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:55 | INFO | Rank 0 | Train Epoch: 0 [72032/250314 (29%)]\tLoss: 1.021321\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:56 | INFO | Rank 0 | Train Epoch: 0 [72064/250314 (29%)]\tLoss: 1.035078\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:56 | INFO | Rank 0 | Train Epoch: 0 [72096/250314 (29%)]\tLoss: 0.467973\tData (t) 0.271\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:57 | INFO | Rank 0 | Train Epoch: 0 [72128/250314 (29%)]\tLoss: 0.728620\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:57 | INFO | Rank 0 | Train Epoch: 0 [72160/250314 (29%)]\tLoss: 0.788290\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:58 | INFO | Rank 0 | Train Epoch: 0 [72192/250314 (29%)]\tLoss: 1.110126\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:58 | INFO | Rank 0 | Train Epoch: 0 [72224/250314 (29%)]\tLoss: 0.988164\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:59 | INFO | Rank 0 | Train Epoch: 0 [72256/250314 (29%)]\tLoss: 1.027521\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:28:59 | INFO | Rank 0 | Train Epoch: 0 [72288/250314 (29%)]\tLoss: 1.223430\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:29:00 | INFO | Rank 0 | Train Epoch: 0 [72320/250314 (29%)]\tLoss: 0.906964\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:29:00 | INFO | Rank 0 | Train Epoch: 0 [72352/250314 (29%)]\tLoss: 0.733657\tData (t) 0.349\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:29:01 | INFO | Rank 0 | Train Epoch: 0 [72384/250314 (29%)]\tLoss: 0.696607\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.598\n",
      "2022-11-09,13:29:01 | INFO | Rank 0 | Train Epoch: 0 [72416/250314 (29%)]\tLoss: 1.175465\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:02 | INFO | Rank 0 | Train Epoch: 0 [72448/250314 (29%)]\tLoss: 0.765228\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:02 | INFO | Rank 0 | Train Epoch: 0 [72480/250314 (29%)]\tLoss: 0.907558\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:03 | INFO | Rank 0 | Train Epoch: 0 [72512/250314 (29%)]\tLoss: 1.075626\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:03 | INFO | Rank 0 | Train Epoch: 0 [72544/250314 (29%)]\tLoss: 0.820421\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:04 | INFO | Rank 0 | Train Epoch: 0 [72576/250314 (29%)]\tLoss: 0.764286\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:04 | INFO | Rank 0 | Train Epoch: 0 [72608/250314 (29%)]\tLoss: 1.010375\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:05 | INFO | Rank 0 | Train Epoch: 0 [72640/250314 (29%)]\tLoss: 0.677123\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:05 | INFO | Rank 0 | Train Epoch: 0 [72672/250314 (29%)]\tLoss: 0.725141\tData (t) 0.218\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:06 | INFO | Rank 0 | Train Epoch: 0 [72704/250314 (29%)]\tLoss: 0.654514\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:06 | INFO | Rank 0 | Train Epoch: 0 [72736/250314 (29%)]\tLoss: 1.154345\tData (t) 0.328\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:07 | INFO | Rank 0 | Train Epoch: 0 [72768/250314 (29%)]\tLoss: 0.713393\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:07 | INFO | Rank 0 | Train Epoch: 0 [72800/250314 (29%)]\tLoss: 1.042432\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:08 | INFO | Rank 0 | Train Epoch: 0 [72832/250314 (29%)]\tLoss: 0.630392\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:08 | INFO | Rank 0 | Train Epoch: 0 [72864/250314 (29%)]\tLoss: 1.171655\tData (t) 0.342\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:09 | INFO | Rank 0 | Train Epoch: 0 [72896/250314 (29%)]\tLoss: 0.802739\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:09 | INFO | Rank 0 | Train Epoch: 0 [72928/250314 (29%)]\tLoss: 1.136470\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:10 | INFO | Rank 0 | Train Epoch: 0 [72960/250314 (29%)]\tLoss: 0.546534\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:10 | INFO | Rank 0 | Train Epoch: 0 [72992/250314 (29%)]\tLoss: 0.835168\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:11 | INFO | Rank 0 | Train Epoch: 0 [73024/250314 (29%)]\tLoss: 0.701422\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:11 | INFO | Rank 0 | Train Epoch: 0 [73056/250314 (29%)]\tLoss: 0.438353\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:12 | INFO | Rank 0 | Train Epoch: 0 [73088/250314 (29%)]\tLoss: 1.530656\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:12 | INFO | Rank 0 | Train Epoch: 0 [73120/250314 (29%)]\tLoss: 0.809068\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:13 | INFO | Rank 0 | Train Epoch: 0 [73152/250314 (29%)]\tLoss: 0.952996\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:13 | INFO | Rank 0 | Train Epoch: 0 [73184/250314 (29%)]\tLoss: 0.754277\tData (t) 0.207\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:14 | INFO | Rank 0 | Train Epoch: 0 [73216/250314 (29%)]\tLoss: 0.618918\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:14 | INFO | Rank 0 | Train Epoch: 0 [73248/250314 (29%)]\tLoss: 0.830534\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:15 | INFO | Rank 0 | Train Epoch: 0 [73280/250314 (29%)]\tLoss: 0.394564\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:15 | INFO | Rank 0 | Train Epoch: 0 [73312/250314 (29%)]\tLoss: 1.072872\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:16 | INFO | Rank 0 | Train Epoch: 0 [73344/250314 (29%)]\tLoss: 1.100451\tData (t) 0.229\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:16 | INFO | Rank 0 | Train Epoch: 0 [73376/250314 (29%)]\tLoss: 0.718355\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:17 | INFO | Rank 0 | Train Epoch: 0 [73408/250314 (29%)]\tLoss: 1.379250\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:17 | INFO | Rank 0 | Train Epoch: 0 [73440/250314 (29%)]\tLoss: 0.800204\tData (t) 0.350\tBatch (t) 0.562\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:18 | INFO | Rank 0 | Train Epoch: 0 [73472/250314 (29%)]\tLoss: 1.016491\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:18 | INFO | Rank 0 | Train Epoch: 0 [73504/250314 (29%)]\tLoss: 0.514598\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:19 | INFO | Rank 0 | Train Epoch: 0 [73536/250314 (29%)]\tLoss: 0.989081\tData (t) 0.188\tBatch (t) 0.400\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:19 | INFO | Rank 0 | Train Epoch: 0 [73568/250314 (29%)]\tLoss: 0.808454\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:20 | INFO | Rank 0 | Train Epoch: 0 [73600/250314 (29%)]\tLoss: 0.744560\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:20 | INFO | Rank 0 | Train Epoch: 0 [73632/250314 (29%)]\tLoss: 0.800815\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:20 | INFO | Rank 0 | Train Epoch: 0 [73664/250314 (29%)]\tLoss: 1.082362\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:21 | INFO | Rank 0 | Train Epoch: 0 [73696/250314 (29%)]\tLoss: 0.579797\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:21 | INFO | Rank 0 | Train Epoch: 0 [73728/250314 (29%)]\tLoss: 1.269965\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:22 | INFO | Rank 0 | Train Epoch: 0 [73760/250314 (29%)]\tLoss: 0.713572\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:23 | INFO | Rank 0 | Train Epoch: 0 [73792/250314 (29%)]\tLoss: 0.827616\tData (t) 0.361\tBatch (t) 0.573\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:23 | INFO | Rank 0 | Train Epoch: 0 [73824/250314 (29%)]\tLoss: 0.993823\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:23 | INFO | Rank 0 | Train Epoch: 0 [73856/250314 (30%)]\tLoss: 0.491828\tData (t) 0.209\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:24 | INFO | Rank 0 | Train Epoch: 0 [73888/250314 (30%)]\tLoss: 1.025376\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:24 | INFO | Rank 0 | Train Epoch: 0 [73920/250314 (30%)]\tLoss: 0.834065\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:25 | INFO | Rank 0 | Train Epoch: 0 [73952/250314 (30%)]\tLoss: 0.917055\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:25 | INFO | Rank 0 | Train Epoch: 0 [73984/250314 (30%)]\tLoss: 0.860448\tData (t) 0.204\tBatch (t) 0.416\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:26 | INFO | Rank 0 | Train Epoch: 0 [74016/250314 (30%)]\tLoss: 1.016519\tData (t) 0.221\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:26 | INFO | Rank 0 | Train Epoch: 0 [74048/250314 (30%)]\tLoss: 1.003746\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:27 | INFO | Rank 0 | Train Epoch: 0 [74080/250314 (30%)]\tLoss: 1.305392\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:27 | INFO | Rank 0 | Train Epoch: 0 [74112/250314 (30%)]\tLoss: 1.057345\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:28 | INFO | Rank 0 | Train Epoch: 0 [74144/250314 (30%)]\tLoss: 0.698351\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:28 | INFO | Rank 0 | Train Epoch: 0 [74176/250314 (30%)]\tLoss: 0.602854\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:29 | INFO | Rank 0 | Train Epoch: 0 [74208/250314 (30%)]\tLoss: 1.082745\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:29 | INFO | Rank 0 | Train Epoch: 0 [74240/250314 (30%)]\tLoss: 0.567250\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:30 | INFO | Rank 0 | Train Epoch: 0 [74272/250314 (30%)]\tLoss: 0.599718\tData (t) 0.222\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:30 | INFO | Rank 0 | Train Epoch: 0 [74304/250314 (30%)]\tLoss: 0.645736\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:31 | INFO | Rank 0 | Train Epoch: 0 [74336/250314 (30%)]\tLoss: 0.859399\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:31 | INFO | Rank 0 | Train Epoch: 0 [74368/250314 (30%)]\tLoss: 1.047484\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:32 | INFO | Rank 0 | Train Epoch: 0 [74400/250314 (30%)]\tLoss: 0.827764\tData (t) 0.258\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:32 | INFO | Rank 0 | Train Epoch: 0 [74432/250314 (30%)]\tLoss: 0.859492\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:33 | INFO | Rank 0 | Train Epoch: 0 [74464/250314 (30%)]\tLoss: 1.147845\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:33 | INFO | Rank 0 | Train Epoch: 0 [74496/250314 (30%)]\tLoss: 0.874740\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:34 | INFO | Rank 0 | Train Epoch: 0 [74528/250314 (30%)]\tLoss: 0.838817\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:34 | INFO | Rank 0 | Train Epoch: 0 [74560/250314 (30%)]\tLoss: 0.636973\tData (t) 0.224\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:34 | INFO | Rank 0 | Train Epoch: 0 [74592/250314 (30%)]\tLoss: 0.631603\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:35 | INFO | Rank 0 | Train Epoch: 0 [74624/250314 (30%)]\tLoss: 1.170861\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:36 | INFO | Rank 0 | Train Epoch: 0 [74656/250314 (30%)]\tLoss: 0.498771\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:36 | INFO | Rank 0 | Train Epoch: 0 [74688/250314 (30%)]\tLoss: 0.617074\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:36 | INFO | Rank 0 | Train Epoch: 0 [74720/250314 (30%)]\tLoss: 0.605021\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:37 | INFO | Rank 0 | Train Epoch: 0 [74752/250314 (30%)]\tLoss: 0.780832\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:37 | INFO | Rank 0 | Train Epoch: 0 [74784/250314 (30%)]\tLoss: 0.809269\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:38 | INFO | Rank 0 | Train Epoch: 0 [74816/250314 (30%)]\tLoss: 1.022363\tData (t) 0.320\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:38 | INFO | Rank 0 | Train Epoch: 0 [74848/250314 (30%)]\tLoss: 0.932716\tData (t) 0.255\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:39 | INFO | Rank 0 | Train Epoch: 0 [74880/250314 (30%)]\tLoss: 0.905323\tData (t) 0.358\tBatch (t) 0.570\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:40 | INFO | Rank 0 | Train Epoch: 0 [74912/250314 (30%)]\tLoss: 0.963211\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:40 | INFO | Rank 0 | Train Epoch: 0 [74944/250314 (30%)]\tLoss: 0.939000\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:41 | INFO | Rank 0 | Train Epoch: 0 [74976/250314 (30%)]\tLoss: 1.021447\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:41 | INFO | Rank 0 | Train Epoch: 0 [75008/250314 (30%)]\tLoss: 0.685306\tData (t) 0.345\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:42 | INFO | Rank 0 | Train Epoch: 0 [75040/250314 (30%)]\tLoss: 0.556667\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:42 | INFO | Rank 0 | Train Epoch: 0 [75072/250314 (30%)]\tLoss: 0.592661\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:43 | INFO | Rank 0 | Train Epoch: 0 [75104/250314 (30%)]\tLoss: 1.061284\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:43 | INFO | Rank 0 | Train Epoch: 0 [75136/250314 (30%)]\tLoss: 0.756395\tData (t) 0.394\tBatch (t) 0.606\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:44 | INFO | Rank 0 | Train Epoch: 0 [75168/250314 (30%)]\tLoss: 0.916885\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:44 | INFO | Rank 0 | Train Epoch: 0 [75200/250314 (30%)]\tLoss: 0.908430\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:45 | INFO | Rank 0 | Train Epoch: 0 [75232/250314 (30%)]\tLoss: 1.236776\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:45 | INFO | Rank 0 | Train Epoch: 0 [75264/250314 (30%)]\tLoss: 1.042177\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:46 | INFO | Rank 0 | Train Epoch: 0 [75296/250314 (30%)]\tLoss: 1.180071\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:46 | INFO | Rank 0 | Train Epoch: 0 [75328/250314 (30%)]\tLoss: 0.824649\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:47 | INFO | Rank 0 | Train Epoch: 0 [75360/250314 (30%)]\tLoss: 0.929870\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:47 | INFO | Rank 0 | Train Epoch: 0 [75392/250314 (30%)]\tLoss: 0.718895\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:48 | INFO | Rank 0 | Train Epoch: 0 [75424/250314 (30%)]\tLoss: 1.037103\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:48 | INFO | Rank 0 | Train Epoch: 0 [75456/250314 (30%)]\tLoss: 1.032701\tData (t) 0.401\tBatch (t) 0.613\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:49 | INFO | Rank 0 | Train Epoch: 0 [75488/250314 (30%)]\tLoss: 1.282216\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:49 | INFO | Rank 0 | Train Epoch: 0 [75520/250314 (30%)]\tLoss: 0.831621\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:50 | INFO | Rank 0 | Train Epoch: 0 [75552/250314 (30%)]\tLoss: 0.958059\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:50 | INFO | Rank 0 | Train Epoch: 0 [75584/250314 (30%)]\tLoss: 0.628170\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:51 | INFO | Rank 0 | Train Epoch: 0 [75616/250314 (30%)]\tLoss: 0.712972\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:51 | INFO | Rank 0 | Train Epoch: 0 [75648/250314 (30%)]\tLoss: 0.821433\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:52 | INFO | Rank 0 | Train Epoch: 0 [75680/250314 (30%)]\tLoss: 0.836743\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:52 | INFO | Rank 0 | Train Epoch: 0 [75712/250314 (30%)]\tLoss: 0.507594\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:53 | INFO | Rank 0 | Train Epoch: 0 [75744/250314 (30%)]\tLoss: 1.321224\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:53 | INFO | Rank 0 | Train Epoch: 0 [75776/250314 (30%)]\tLoss: 0.841329\tData (t) 0.351\tBatch (t) 0.563\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:54 | INFO | Rank 0 | Train Epoch: 0 [75808/250314 (30%)]\tLoss: 1.057990\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:54 | INFO | Rank 0 | Train Epoch: 0 [75840/250314 (30%)]\tLoss: 1.268003\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:55 | INFO | Rank 0 | Train Epoch: 0 [75872/250314 (30%)]\tLoss: 0.785741\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:55 | INFO | Rank 0 | Train Epoch: 0 [75904/250314 (30%)]\tLoss: 0.485300\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:56 | INFO | Rank 0 | Train Epoch: 0 [75936/250314 (30%)]\tLoss: 0.559502\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:56 | INFO | Rank 0 | Train Epoch: 0 [75968/250314 (30%)]\tLoss: 1.010351\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:57 | INFO | Rank 0 | Train Epoch: 0 [76000/250314 (30%)]\tLoss: 0.633552\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:57 | INFO | Rank 0 | Train Epoch: 0 [76032/250314 (30%)]\tLoss: 1.470982\tData (t) 0.233\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:58 | INFO | Rank 0 | Train Epoch: 0 [76064/250314 (30%)]\tLoss: 0.639524\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:58 | INFO | Rank 0 | Train Epoch: 0 [76096/250314 (30%)]\tLoss: 0.564653\tData (t) 0.345\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:59 | INFO | Rank 0 | Train Epoch: 0 [76128/250314 (30%)]\tLoss: 1.191753\tData (t) 0.357\tBatch (t) 0.568\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:29:59 | INFO | Rank 0 | Train Epoch: 0 [76160/250314 (30%)]\tLoss: 1.191346\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:00 | INFO | Rank 0 | Train Epoch: 0 [76192/250314 (30%)]\tLoss: 0.868704\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:00 | INFO | Rank 0 | Train Epoch: 0 [76224/250314 (30%)]\tLoss: 0.608828\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:01 | INFO | Rank 0 | Train Epoch: 0 [76256/250314 (30%)]\tLoss: 0.813533\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:01 | INFO | Rank 0 | Train Epoch: 0 [76288/250314 (30%)]\tLoss: 0.810277\tData (t) 0.225\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:02 | INFO | Rank 0 | Train Epoch: 0 [76320/250314 (30%)]\tLoss: 0.628360\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:02 | INFO | Rank 0 | Train Epoch: 0 [76352/250314 (31%)]\tLoss: 1.015113\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:03 | INFO | Rank 0 | Train Epoch: 0 [76384/250314 (31%)]\tLoss: 0.481670\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:03 | INFO | Rank 0 | Train Epoch: 0 [76416/250314 (31%)]\tLoss: 1.591468\tData (t) 0.227\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:04 | INFO | Rank 0 | Train Epoch: 0 [76448/250314 (31%)]\tLoss: 1.047876\tData (t) 0.330\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:04 | INFO | Rank 0 | Train Epoch: 0 [76480/250314 (31%)]\tLoss: 1.006280\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:05 | INFO | Rank 0 | Train Epoch: 0 [76512/250314 (31%)]\tLoss: 0.487059\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:05 | INFO | Rank 0 | Train Epoch: 0 [76544/250314 (31%)]\tLoss: 0.791646\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:06 | INFO | Rank 0 | Train Epoch: 0 [76576/250314 (31%)]\tLoss: 1.071407\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:06 | INFO | Rank 0 | Train Epoch: 0 [76608/250314 (31%)]\tLoss: 0.722972\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:07 | INFO | Rank 0 | Train Epoch: 0 [76640/250314 (31%)]\tLoss: 1.371361\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:07 | INFO | Rank 0 | Train Epoch: 0 [76672/250314 (31%)]\tLoss: 0.463777\tData (t) 0.331\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:08 | INFO | Rank 0 | Train Epoch: 0 [76704/250314 (31%)]\tLoss: 0.664706\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:08 | INFO | Rank 0 | Train Epoch: 0 [76736/250314 (31%)]\tLoss: 0.401570\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:09 | INFO | Rank 0 | Train Epoch: 0 [76768/250314 (31%)]\tLoss: 0.855823\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:09 | INFO | Rank 0 | Train Epoch: 0 [76800/250314 (31%)]\tLoss: 1.291206\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:09 | INFO | Rank 0 | Train Epoch: 0 [76832/250314 (31%)]\tLoss: 0.655393\tData (t) 0.215\tBatch (t) 0.426\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:10 | INFO | Rank 0 | Train Epoch: 0 [76864/250314 (31%)]\tLoss: 0.817566\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:10 | INFO | Rank 0 | Train Epoch: 0 [76896/250314 (31%)]\tLoss: 1.175056\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:11 | INFO | Rank 0 | Train Epoch: 0 [76928/250314 (31%)]\tLoss: 0.709108\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:11 | INFO | Rank 0 | Train Epoch: 0 [76960/250314 (31%)]\tLoss: 1.189241\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:12 | INFO | Rank 0 | Train Epoch: 0 [76992/250314 (31%)]\tLoss: 0.635786\tData (t) 0.224\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:12 | INFO | Rank 0 | Train Epoch: 0 [77024/250314 (31%)]\tLoss: 0.697338\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:13 | INFO | Rank 0 | Train Epoch: 0 [77056/250314 (31%)]\tLoss: 1.003875\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:13 | INFO | Rank 0 | Train Epoch: 0 [77088/250314 (31%)]\tLoss: 1.009018\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:14 | INFO | Rank 0 | Train Epoch: 0 [77120/250314 (31%)]\tLoss: 1.129991\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:14 | INFO | Rank 0 | Train Epoch: 0 [77152/250314 (31%)]\tLoss: 0.724559\tData (t) 0.314\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:15 | INFO | Rank 0 | Train Epoch: 0 [77184/250314 (31%)]\tLoss: 0.613686\tData (t) 0.325\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:15 | INFO | Rank 0 | Train Epoch: 0 [77216/250314 (31%)]\tLoss: 0.704003\tData (t) 0.287\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:16 | INFO | Rank 0 | Train Epoch: 0 [77248/250314 (31%)]\tLoss: 1.113829\tData (t) 0.214\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:16 | INFO | Rank 0 | Train Epoch: 0 [77280/250314 (31%)]\tLoss: 0.774538\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:17 | INFO | Rank 0 | Train Epoch: 0 [77312/250314 (31%)]\tLoss: 0.669593\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:17 | INFO | Rank 0 | Train Epoch: 0 [77344/250314 (31%)]\tLoss: 0.958590\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:18 | INFO | Rank 0 | Train Epoch: 0 [77376/250314 (31%)]\tLoss: 0.921237\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:18 | INFO | Rank 0 | Train Epoch: 0 [77408/250314 (31%)]\tLoss: 0.801211\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:19 | INFO | Rank 0 | Train Epoch: 0 [77440/250314 (31%)]\tLoss: 0.544640\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:19 | INFO | Rank 0 | Train Epoch: 0 [77472/250314 (31%)]\tLoss: 1.010169\tData (t) 0.370\tBatch (t) 0.582\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:20 | INFO | Rank 0 | Train Epoch: 0 [77504/250314 (31%)]\tLoss: 0.928473\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:20 | INFO | Rank 0 | Train Epoch: 0 [77536/250314 (31%)]\tLoss: 0.992817\tData (t) 0.219\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:21 | INFO | Rank 0 | Train Epoch: 0 [77568/250314 (31%)]\tLoss: 1.342825\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:21 | INFO | Rank 0 | Train Epoch: 0 [77600/250314 (31%)]\tLoss: 1.072438\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:22 | INFO | Rank 0 | Train Epoch: 0 [77632/250314 (31%)]\tLoss: 0.834782\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:22 | INFO | Rank 0 | Train Epoch: 0 [77664/250314 (31%)]\tLoss: 0.767577\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:23 | INFO | Rank 0 | Train Epoch: 0 [77696/250314 (31%)]\tLoss: 0.882555\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:23 | INFO | Rank 0 | Train Epoch: 0 [77728/250314 (31%)]\tLoss: 1.511915\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:24 | INFO | Rank 0 | Train Epoch: 0 [77760/250314 (31%)]\tLoss: 0.771995\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:24 | INFO | Rank 0 | Train Epoch: 0 [77792/250314 (31%)]\tLoss: 1.012743\tData (t) 0.213\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:25 | INFO | Rank 0 | Train Epoch: 0 [77824/250314 (31%)]\tLoss: 0.512160\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:25 | INFO | Rank 0 | Train Epoch: 0 [77856/250314 (31%)]\tLoss: 1.001152\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:26 | INFO | Rank 0 | Train Epoch: 0 [77888/250314 (31%)]\tLoss: 0.452388\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:26 | INFO | Rank 0 | Train Epoch: 0 [77920/250314 (31%)]\tLoss: 0.850933\tData (t) 0.208\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:26 | INFO | Rank 0 | Train Epoch: 0 [77952/250314 (31%)]\tLoss: 1.154497\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:27 | INFO | Rank 0 | Train Epoch: 0 [77984/250314 (31%)]\tLoss: 0.885337\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:27 | INFO | Rank 0 | Train Epoch: 0 [78016/250314 (31%)]\tLoss: 0.713355\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:28 | INFO | Rank 0 | Train Epoch: 0 [78048/250314 (31%)]\tLoss: 0.768950\tData (t) 0.304\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:28 | INFO | Rank 0 | Train Epoch: 0 [78080/250314 (31%)]\tLoss: 0.763421\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:29 | INFO | Rank 0 | Train Epoch: 0 [78112/250314 (31%)]\tLoss: 0.726639\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:29 | INFO | Rank 0 | Train Epoch: 0 [78144/250314 (31%)]\tLoss: 1.115858\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:30 | INFO | Rank 0 | Train Epoch: 0 [78176/250314 (31%)]\tLoss: 1.072533\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:30 | INFO | Rank 0 | Train Epoch: 0 [78208/250314 (31%)]\tLoss: 0.960071\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:31 | INFO | Rank 0 | Train Epoch: 0 [78240/250314 (31%)]\tLoss: 1.422028\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:31 | INFO | Rank 0 | Train Epoch: 0 [78272/250314 (31%)]\tLoss: 1.162239\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:32 | INFO | Rank 0 | Train Epoch: 0 [78304/250314 (31%)]\tLoss: 0.823571\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:32 | INFO | Rank 0 | Train Epoch: 0 [78336/250314 (31%)]\tLoss: 0.956109\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:33 | INFO | Rank 0 | Train Epoch: 0 [78368/250314 (31%)]\tLoss: 0.587414\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:33 | INFO | Rank 0 | Train Epoch: 0 [78400/250314 (31%)]\tLoss: 0.799825\tData (t) 0.221\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:34 | INFO | Rank 0 | Train Epoch: 0 [78432/250314 (31%)]\tLoss: 0.850914\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:34 | INFO | Rank 0 | Train Epoch: 0 [78464/250314 (31%)]\tLoss: 0.798355\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:35 | INFO | Rank 0 | Train Epoch: 0 [78496/250314 (31%)]\tLoss: 0.917559\tData (t) 0.431\tBatch (t) 0.643\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:36 | INFO | Rank 0 | Train Epoch: 0 [78528/250314 (31%)]\tLoss: 0.494484\tData (t) 0.309\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:36 | INFO | Rank 0 | Train Epoch: 0 [78560/250314 (31%)]\tLoss: 1.236137\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:36 | INFO | Rank 0 | Train Epoch: 0 [78592/250314 (31%)]\tLoss: 0.718629\tData (t) 0.178\tBatch (t) 0.390\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:37 | INFO | Rank 0 | Train Epoch: 0 [78624/250314 (31%)]\tLoss: 1.034694\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:37 | INFO | Rank 0 | Train Epoch: 0 [78656/250314 (31%)]\tLoss: 0.728406\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:38 | INFO | Rank 0 | Train Epoch: 0 [78688/250314 (31%)]\tLoss: 0.963523\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:38 | INFO | Rank 0 | Train Epoch: 0 [78720/250314 (31%)]\tLoss: 0.717211\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:39 | INFO | Rank 0 | Train Epoch: 0 [78752/250314 (31%)]\tLoss: 1.258044\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:39 | INFO | Rank 0 | Train Epoch: 0 [78784/250314 (31%)]\tLoss: 0.907729\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:40 | INFO | Rank 0 | Train Epoch: 0 [78816/250314 (31%)]\tLoss: 0.877159\tData (t) 0.336\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:40 | INFO | Rank 0 | Train Epoch: 0 [78848/250314 (32%)]\tLoss: 0.560079\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:41 | INFO | Rank 0 | Train Epoch: 0 [78880/250314 (32%)]\tLoss: 1.021152\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:41 | INFO | Rank 0 | Train Epoch: 0 [78912/250314 (32%)]\tLoss: 0.468907\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:42 | INFO | Rank 0 | Train Epoch: 0 [78944/250314 (32%)]\tLoss: 1.293292\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:42 | INFO | Rank 0 | Train Epoch: 0 [78976/250314 (32%)]\tLoss: 1.077734\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:43 | INFO | Rank 0 | Train Epoch: 0 [79008/250314 (32%)]\tLoss: 0.439436\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:43 | INFO | Rank 0 | Train Epoch: 0 [79040/250314 (32%)]\tLoss: 0.806471\tData (t) 0.284\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:44 | INFO | Rank 0 | Train Epoch: 0 [79072/250314 (32%)]\tLoss: 0.875827\tData (t) 0.238\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:44 | INFO | Rank 0 | Train Epoch: 0 [79104/250314 (32%)]\tLoss: 0.920209\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:45 | INFO | Rank 0 | Train Epoch: 0 [79136/250314 (32%)]\tLoss: 0.617734\tData (t) 0.486\tBatch (t) 0.698\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:46 | INFO | Rank 0 | Train Epoch: 0 [79168/250314 (32%)]\tLoss: 0.957411\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:46 | INFO | Rank 0 | Train Epoch: 0 [79200/250314 (32%)]\tLoss: 1.097333\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:47 | INFO | Rank 0 | Train Epoch: 0 [79232/250314 (32%)]\tLoss: 1.014687\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:47 | INFO | Rank 0 | Train Epoch: 0 [79264/250314 (32%)]\tLoss: 0.730873\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:47 | INFO | Rank 0 | Train Epoch: 0 [79296/250314 (32%)]\tLoss: 0.570742\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:48 | INFO | Rank 0 | Train Epoch: 0 [79328/250314 (32%)]\tLoss: 0.499467\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:48 | INFO | Rank 0 | Train Epoch: 0 [79360/250314 (32%)]\tLoss: 1.100717\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:49 | INFO | Rank 0 | Train Epoch: 0 [79392/250314 (32%)]\tLoss: 0.716027\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:49 | INFO | Rank 0 | Train Epoch: 0 [79424/250314 (32%)]\tLoss: 0.787580\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:50 | INFO | Rank 0 | Train Epoch: 0 [79456/250314 (32%)]\tLoss: 0.937777\tData (t) 0.357\tBatch (t) 0.569\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:51 | INFO | Rank 0 | Train Epoch: 0 [79488/250314 (32%)]\tLoss: 0.846728\tData (t) 0.495\tBatch (t) 0.706\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:51 | INFO | Rank 0 | Train Epoch: 0 [79520/250314 (32%)]\tLoss: 0.550438\tData (t) 0.438\tBatch (t) 0.650\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:52 | INFO | Rank 0 | Train Epoch: 0 [79552/250314 (32%)]\tLoss: 1.068220\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:52 | INFO | Rank 0 | Train Epoch: 0 [79584/250314 (32%)]\tLoss: 0.613811\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:53 | INFO | Rank 0 | Train Epoch: 0 [79616/250314 (32%)]\tLoss: 0.985268\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:53 | INFO | Rank 0 | Train Epoch: 0 [79648/250314 (32%)]\tLoss: 0.909271\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:54 | INFO | Rank 0 | Train Epoch: 0 [79680/250314 (32%)]\tLoss: 1.041853\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:54 | INFO | Rank 0 | Train Epoch: 0 [79712/250314 (32%)]\tLoss: 0.529119\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:55 | INFO | Rank 0 | Train Epoch: 0 [79744/250314 (32%)]\tLoss: 0.908330\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:55 | INFO | Rank 0 | Train Epoch: 0 [79776/250314 (32%)]\tLoss: 0.756441\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:56 | INFO | Rank 0 | Train Epoch: 0 [79808/250314 (32%)]\tLoss: 0.554533\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:56 | INFO | Rank 0 | Train Epoch: 0 [79840/250314 (32%)]\tLoss: 0.753779\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:57 | INFO | Rank 0 | Train Epoch: 0 [79872/250314 (32%)]\tLoss: 0.712547\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:57 | INFO | Rank 0 | Train Epoch: 0 [79904/250314 (32%)]\tLoss: 0.896023\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:58 | INFO | Rank 0 | Train Epoch: 0 [79936/250314 (32%)]\tLoss: 1.119553\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:58 | INFO | Rank 0 | Train Epoch: 0 [79968/250314 (32%)]\tLoss: 0.701634\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:59 | INFO | Rank 0 | Train Epoch: 0 [80000/250314 (32%)]\tLoss: 0.928631\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:30:59 | INFO | Rank 0 | Train Epoch: 0 [80032/250314 (32%)]\tLoss: 0.765956\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:00 | INFO | Rank 0 | Train Epoch: 0 [80064/250314 (32%)]\tLoss: 0.830379\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:00 | INFO | Rank 0 | Train Epoch: 0 [80096/250314 (32%)]\tLoss: 0.808139\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:01 | INFO | Rank 0 | Train Epoch: 0 [80128/250314 (32%)]\tLoss: 0.642436\tData (t) 0.318\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:01 | INFO | Rank 0 | Train Epoch: 0 [80160/250314 (32%)]\tLoss: 0.878921\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:02 | INFO | Rank 0 | Train Epoch: 0 [80192/250314 (32%)]\tLoss: 1.066730\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:02 | INFO | Rank 0 | Train Epoch: 0 [80224/250314 (32%)]\tLoss: 1.069480\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:03 | INFO | Rank 0 | Train Epoch: 0 [80256/250314 (32%)]\tLoss: 0.821388\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:03 | INFO | Rank 0 | Train Epoch: 0 [80288/250314 (32%)]\tLoss: 0.701646\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:04 | INFO | Rank 0 | Train Epoch: 0 [80320/250314 (32%)]\tLoss: 1.041204\tData (t) 0.212\tBatch (t) 0.423\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:04 | INFO | Rank 0 | Train Epoch: 0 [80352/250314 (32%)]\tLoss: 0.509530\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:05 | INFO | Rank 0 | Train Epoch: 0 [80384/250314 (32%)]\tLoss: 0.587994\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:05 | INFO | Rank 0 | Train Epoch: 0 [80416/250314 (32%)]\tLoss: 0.950668\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:05 | INFO | Rank 0 | Train Epoch: 0 [80448/250314 (32%)]\tLoss: 0.646943\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:06 | INFO | Rank 0 | Train Epoch: 0 [80480/250314 (32%)]\tLoss: 0.397040\tData (t) 0.370\tBatch (t) 0.582\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:07 | INFO | Rank 0 | Train Epoch: 0 [80512/250314 (32%)]\tLoss: 1.005470\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:07 | INFO | Rank 0 | Train Epoch: 0 [80544/250314 (32%)]\tLoss: 0.945315\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:08 | INFO | Rank 0 | Train Epoch: 0 [80576/250314 (32%)]\tLoss: 1.084617\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:08 | INFO | Rank 0 | Train Epoch: 0 [80608/250314 (32%)]\tLoss: 0.837793\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:08 | INFO | Rank 0 | Train Epoch: 0 [80640/250314 (32%)]\tLoss: 0.524370\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:09 | INFO | Rank 0 | Train Epoch: 0 [80672/250314 (32%)]\tLoss: 0.698133\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:09 | INFO | Rank 0 | Train Epoch: 0 [80704/250314 (32%)]\tLoss: 0.676316\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:10 | INFO | Rank 0 | Train Epoch: 0 [80736/250314 (32%)]\tLoss: 1.093611\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:10 | INFO | Rank 0 | Train Epoch: 0 [80768/250314 (32%)]\tLoss: 0.783032\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:11 | INFO | Rank 0 | Train Epoch: 0 [80800/250314 (32%)]\tLoss: 1.231868\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:11 | INFO | Rank 0 | Train Epoch: 0 [80832/250314 (32%)]\tLoss: 0.825988\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:12 | INFO | Rank 0 | Train Epoch: 0 [80864/250314 (32%)]\tLoss: 0.568401\tData (t) 0.317\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:12 | INFO | Rank 0 | Train Epoch: 0 [80896/250314 (32%)]\tLoss: 0.851213\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:13 | INFO | Rank 0 | Train Epoch: 0 [80928/250314 (32%)]\tLoss: 1.185434\tData (t) 0.336\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:13 | INFO | Rank 0 | Train Epoch: 0 [80960/250314 (32%)]\tLoss: 0.711671\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:14 | INFO | Rank 0 | Train Epoch: 0 [80992/250314 (32%)]\tLoss: 0.980506\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:14 | INFO | Rank 0 | Train Epoch: 0 [81024/250314 (32%)]\tLoss: 1.062853\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:15 | INFO | Rank 0 | Train Epoch: 0 [81056/250314 (32%)]\tLoss: 1.181877\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:15 | INFO | Rank 0 | Train Epoch: 0 [81088/250314 (32%)]\tLoss: 0.987230\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:16 | INFO | Rank 0 | Train Epoch: 0 [81120/250314 (32%)]\tLoss: 0.928536\tData (t) 0.345\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:16 | INFO | Rank 0 | Train Epoch: 0 [81152/250314 (32%)]\tLoss: 0.781582\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:17 | INFO | Rank 0 | Train Epoch: 0 [81184/250314 (32%)]\tLoss: 1.055401\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:17 | INFO | Rank 0 | Train Epoch: 0 [81216/250314 (32%)]\tLoss: 0.861772\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:18 | INFO | Rank 0 | Train Epoch: 0 [81248/250314 (32%)]\tLoss: 1.446779\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:18 | INFO | Rank 0 | Train Epoch: 0 [81280/250314 (32%)]\tLoss: 0.960213\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:19 | INFO | Rank 0 | Train Epoch: 0 [81312/250314 (32%)]\tLoss: 0.777714\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:19 | INFO | Rank 0 | Train Epoch: 0 [81344/250314 (32%)]\tLoss: 0.919210\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:20 | INFO | Rank 0 | Train Epoch: 0 [81376/250314 (33%)]\tLoss: 1.174206\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:21 | INFO | Rank 0 | Train Epoch: 0 [81408/250314 (33%)]\tLoss: 0.652744\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:21 | INFO | Rank 0 | Train Epoch: 0 [81440/250314 (33%)]\tLoss: 0.910005\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:22 | INFO | Rank 0 | Train Epoch: 0 [81472/250314 (33%)]\tLoss: 0.968837\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:22 | INFO | Rank 0 | Train Epoch: 0 [81504/250314 (33%)]\tLoss: 0.897865\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:23 | INFO | Rank 0 | Train Epoch: 0 [81536/250314 (33%)]\tLoss: 0.704384\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:23 | INFO | Rank 0 | Train Epoch: 0 [81568/250314 (33%)]\tLoss: 0.944938\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:23 | INFO | Rank 0 | Train Epoch: 0 [81600/250314 (33%)]\tLoss: 0.553949\tData (t) 0.219\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:24 | INFO | Rank 0 | Train Epoch: 0 [81632/250314 (33%)]\tLoss: 0.866558\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:24 | INFO | Rank 0 | Train Epoch: 0 [81664/250314 (33%)]\tLoss: 0.785548\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:25 | INFO | Rank 0 | Train Epoch: 0 [81696/250314 (33%)]\tLoss: 0.840549\tData (t) 0.225\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:25 | INFO | Rank 0 | Train Epoch: 0 [81728/250314 (33%)]\tLoss: 0.588459\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:26 | INFO | Rank 0 | Train Epoch: 0 [81760/250314 (33%)]\tLoss: 0.826787\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:26 | INFO | Rank 0 | Train Epoch: 0 [81792/250314 (33%)]\tLoss: 0.619924\tData (t) 0.213\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:27 | INFO | Rank 0 | Train Epoch: 0 [81824/250314 (33%)]\tLoss: 0.684306\tData (t) 0.500\tBatch (t) 0.712\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:28 | INFO | Rank 0 | Train Epoch: 0 [81856/250314 (33%)]\tLoss: 1.044827\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:28 | INFO | Rank 0 | Train Epoch: 0 [81888/250314 (33%)]\tLoss: 0.662328\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:29 | INFO | Rank 0 | Train Epoch: 0 [81920/250314 (33%)]\tLoss: 0.828786\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:29 | INFO | Rank 0 | Train Epoch: 0 [81952/250314 (33%)]\tLoss: 1.054264\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:30 | INFO | Rank 0 | Train Epoch: 0 [81984/250314 (33%)]\tLoss: 0.742573\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:30 | INFO | Rank 0 | Train Epoch: 0 [82016/250314 (33%)]\tLoss: 1.144677\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:31 | INFO | Rank 0 | Train Epoch: 0 [82048/250314 (33%)]\tLoss: 0.684650\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:31 | INFO | Rank 0 | Train Epoch: 0 [82080/250314 (33%)]\tLoss: 1.092098\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:32 | INFO | Rank 0 | Train Epoch: 0 [82112/250314 (33%)]\tLoss: 0.573267\tData (t) 0.230\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:32 | INFO | Rank 0 | Train Epoch: 0 [82144/250314 (33%)]\tLoss: 0.453378\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:33 | INFO | Rank 0 | Train Epoch: 0 [82176/250314 (33%)]\tLoss: 0.703522\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:33 | INFO | Rank 0 | Train Epoch: 0 [82208/250314 (33%)]\tLoss: 0.657737\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:34 | INFO | Rank 0 | Train Epoch: 0 [82240/250314 (33%)]\tLoss: 0.729343\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:34 | INFO | Rank 0 | Train Epoch: 0 [82272/250314 (33%)]\tLoss: 1.067062\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:35 | INFO | Rank 0 | Train Epoch: 0 [82304/250314 (33%)]\tLoss: 0.643030\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:35 | INFO | Rank 0 | Train Epoch: 0 [82336/250314 (33%)]\tLoss: 0.986045\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:36 | INFO | Rank 0 | Train Epoch: 0 [82368/250314 (33%)]\tLoss: 0.726081\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:36 | INFO | Rank 0 | Train Epoch: 0 [82400/250314 (33%)]\tLoss: 0.644305\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:37 | INFO | Rank 0 | Train Epoch: 0 [82432/250314 (33%)]\tLoss: 0.929965\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:37 | INFO | Rank 0 | Train Epoch: 0 [82464/250314 (33%)]\tLoss: 0.745718\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:38 | INFO | Rank 0 | Train Epoch: 0 [82496/250314 (33%)]\tLoss: 0.530916\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:38 | INFO | Rank 0 | Train Epoch: 0 [82528/250314 (33%)]\tLoss: 0.464254\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:38 | INFO | Rank 0 | Train Epoch: 0 [82560/250314 (33%)]\tLoss: 1.117348\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:39 | INFO | Rank 0 | Train Epoch: 0 [82592/250314 (33%)]\tLoss: 1.128234\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:40 | INFO | Rank 0 | Train Epoch: 0 [82624/250314 (33%)]\tLoss: 0.841452\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:40 | INFO | Rank 0 | Train Epoch: 0 [82656/250314 (33%)]\tLoss: 0.420126\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:41 | INFO | Rank 0 | Train Epoch: 0 [82688/250314 (33%)]\tLoss: 1.184901\tData (t) 0.356\tBatch (t) 0.567\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:41 | INFO | Rank 0 | Train Epoch: 0 [82720/250314 (33%)]\tLoss: 0.762542\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:41 | INFO | Rank 0 | Train Epoch: 0 [82752/250314 (33%)]\tLoss: 0.813913\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:42 | INFO | Rank 0 | Train Epoch: 0 [82784/250314 (33%)]\tLoss: 0.533682\tData (t) 0.223\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:42 | INFO | Rank 0 | Train Epoch: 0 [82816/250314 (33%)]\tLoss: 0.766138\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:43 | INFO | Rank 0 | Train Epoch: 0 [82848/250314 (33%)]\tLoss: 0.444456\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:43 | INFO | Rank 0 | Train Epoch: 0 [82880/250314 (33%)]\tLoss: 1.043157\tData (t) 0.217\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:44 | INFO | Rank 0 | Train Epoch: 0 [82912/250314 (33%)]\tLoss: 0.930529\tData (t) 0.229\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:44 | INFO | Rank 0 | Train Epoch: 0 [82944/250314 (33%)]\tLoss: 0.567825\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:45 | INFO | Rank 0 | Train Epoch: 0 [82976/250314 (33%)]\tLoss: 1.526349\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:45 | INFO | Rank 0 | Train Epoch: 0 [83008/250314 (33%)]\tLoss: 0.626749\tData (t) 0.212\tBatch (t) 0.423\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:46 | INFO | Rank 0 | Train Epoch: 0 [83040/250314 (33%)]\tLoss: 0.683232\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:46 | INFO | Rank 0 | Train Epoch: 0 [83072/250314 (33%)]\tLoss: 0.850007\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:46 | INFO | Rank 0 | Train Epoch: 0 [83104/250314 (33%)]\tLoss: 0.921598\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:47 | INFO | Rank 0 | Train Epoch: 0 [83136/250314 (33%)]\tLoss: 0.713305\tData (t) 0.356\tBatch (t) 0.567\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:48 | INFO | Rank 0 | Train Epoch: 0 [83168/250314 (33%)]\tLoss: 0.705169\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:48 | INFO | Rank 0 | Train Epoch: 0 [83200/250314 (33%)]\tLoss: 1.237914\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:48 | INFO | Rank 0 | Train Epoch: 0 [83232/250314 (33%)]\tLoss: 0.905965\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:49 | INFO | Rank 0 | Train Epoch: 0 [83264/250314 (33%)]\tLoss: 0.736158\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:49 | INFO | Rank 0 | Train Epoch: 0 [83296/250314 (33%)]\tLoss: 0.738717\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:50 | INFO | Rank 0 | Train Epoch: 0 [83328/250314 (33%)]\tLoss: 0.607056\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:50 | INFO | Rank 0 | Train Epoch: 0 [83360/250314 (33%)]\tLoss: 0.738616\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:51 | INFO | Rank 0 | Train Epoch: 0 [83392/250314 (33%)]\tLoss: 0.635891\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:51 | INFO | Rank 0 | Train Epoch: 0 [83424/250314 (33%)]\tLoss: 0.953770\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:52 | INFO | Rank 0 | Train Epoch: 0 [83456/250314 (33%)]\tLoss: 0.888008\tData (t) 0.347\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:53 | INFO | Rank 0 | Train Epoch: 0 [83488/250314 (33%)]\tLoss: 1.025262\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:53 | INFO | Rank 0 | Train Epoch: 0 [83520/250314 (33%)]\tLoss: 1.456913\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:53 | INFO | Rank 0 | Train Epoch: 0 [83552/250314 (33%)]\tLoss: 0.731224\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:54 | INFO | Rank 0 | Train Epoch: 0 [83584/250314 (33%)]\tLoss: 0.778815\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:54 | INFO | Rank 0 | Train Epoch: 0 [83616/250314 (33%)]\tLoss: 0.649882\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:55 | INFO | Rank 0 | Train Epoch: 0 [83648/250314 (33%)]\tLoss: 1.061490\tData (t) 0.344\tBatch (t) 0.555\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:56 | INFO | Rank 0 | Train Epoch: 0 [83680/250314 (33%)]\tLoss: 0.683347\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:56 | INFO | Rank 0 | Train Epoch: 0 [83712/250314 (33%)]\tLoss: 0.673889\tData (t) 0.196\tBatch (t) 0.407\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:56 | INFO | Rank 0 | Train Epoch: 0 [83744/250314 (33%)]\tLoss: 1.075191\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:57 | INFO | Rank 0 | Train Epoch: 0 [83776/250314 (33%)]\tLoss: 1.069804\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:57 | INFO | Rank 0 | Train Epoch: 0 [83808/250314 (33%)]\tLoss: 0.779646\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:58 | INFO | Rank 0 | Train Epoch: 0 [83840/250314 (33%)]\tLoss: 0.813276\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:58 | INFO | Rank 0 | Train Epoch: 0 [83872/250314 (34%)]\tLoss: 1.368309\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:59 | INFO | Rank 0 | Train Epoch: 0 [83904/250314 (34%)]\tLoss: 0.706103\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:31:59 | INFO | Rank 0 | Train Epoch: 0 [83936/250314 (34%)]\tLoss: 0.780781\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:00 | INFO | Rank 0 | Train Epoch: 0 [83968/250314 (34%)]\tLoss: 1.013436\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:00 | INFO | Rank 0 | Train Epoch: 0 [84000/250314 (34%)]\tLoss: 0.765779\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:01 | INFO | Rank 0 | Train Epoch: 0 [84032/250314 (34%)]\tLoss: 0.826824\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:01 | INFO | Rank 0 | Train Epoch: 0 [84064/250314 (34%)]\tLoss: 0.957725\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:02 | INFO | Rank 0 | Train Epoch: 0 [84096/250314 (34%)]\tLoss: 0.947047\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:02 | INFO | Rank 0 | Train Epoch: 0 [84128/250314 (34%)]\tLoss: 0.961242\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:03 | INFO | Rank 0 | Train Epoch: 0 [84160/250314 (34%)]\tLoss: 0.476544\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:03 | INFO | Rank 0 | Train Epoch: 0 [84192/250314 (34%)]\tLoss: 0.672463\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:04 | INFO | Rank 0 | Train Epoch: 0 [84224/250314 (34%)]\tLoss: 0.756120\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:04 | INFO | Rank 0 | Train Epoch: 0 [84256/250314 (34%)]\tLoss: 0.773243\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:05 | INFO | Rank 0 | Train Epoch: 0 [84288/250314 (34%)]\tLoss: 0.732169\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:05 | INFO | Rank 0 | Train Epoch: 0 [84320/250314 (34%)]\tLoss: 0.690770\tData (t) 0.215\tBatch (t) 0.426\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:06 | INFO | Rank 0 | Train Epoch: 0 [84352/250314 (34%)]\tLoss: 0.500197\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:06 | INFO | Rank 0 | Train Epoch: 0 [84384/250314 (34%)]\tLoss: 0.629357\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:07 | INFO | Rank 0 | Train Epoch: 0 [84416/250314 (34%)]\tLoss: 1.187866\tData (t) 0.333\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:07 | INFO | Rank 0 | Train Epoch: 0 [84448/250314 (34%)]\tLoss: 0.741313\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:08 | INFO | Rank 0 | Train Epoch: 0 [84480/250314 (34%)]\tLoss: 0.890783\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:08 | INFO | Rank 0 | Train Epoch: 0 [84512/250314 (34%)]\tLoss: 1.388676\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:09 | INFO | Rank 0 | Train Epoch: 0 [84544/250314 (34%)]\tLoss: 0.689479\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:09 | INFO | Rank 0 | Train Epoch: 0 [84576/250314 (34%)]\tLoss: 0.614406\tData (t) 0.190\tBatch (t) 0.402\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:10 | INFO | Rank 0 | Train Epoch: 0 [84608/250314 (34%)]\tLoss: 1.268333\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:10 | INFO | Rank 0 | Train Epoch: 0 [84640/250314 (34%)]\tLoss: 0.974255\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:11 | INFO | Rank 0 | Train Epoch: 0 [84672/250314 (34%)]\tLoss: 0.584703\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:11 | INFO | Rank 0 | Train Epoch: 0 [84704/250314 (34%)]\tLoss: 0.641801\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:12 | INFO | Rank 0 | Train Epoch: 0 [84736/250314 (34%)]\tLoss: 0.883775\tData (t) 0.179\tBatch (t) 0.390\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:12 | INFO | Rank 0 | Train Epoch: 0 [84768/250314 (34%)]\tLoss: 0.762802\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:13 | INFO | Rank 0 | Train Epoch: 0 [84800/250314 (34%)]\tLoss: 0.775291\tData (t) 0.343\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:13 | INFO | Rank 0 | Train Epoch: 0 [84832/250314 (34%)]\tLoss: 0.764252\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:14 | INFO | Rank 0 | Train Epoch: 0 [84864/250314 (34%)]\tLoss: 1.076214\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:14 | INFO | Rank 0 | Train Epoch: 0 [84896/250314 (34%)]\tLoss: 0.795793\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:15 | INFO | Rank 0 | Train Epoch: 0 [84928/250314 (34%)]\tLoss: 0.883899\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:15 | INFO | Rank 0 | Train Epoch: 0 [84960/250314 (34%)]\tLoss: 1.199865\tData (t) 0.264\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:16 | INFO | Rank 0 | Train Epoch: 0 [84992/250314 (34%)]\tLoss: 0.831932\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:16 | INFO | Rank 0 | Train Epoch: 0 [85024/250314 (34%)]\tLoss: 0.926873\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:17 | INFO | Rank 0 | Train Epoch: 0 [85056/250314 (34%)]\tLoss: 0.822494\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:17 | INFO | Rank 0 | Train Epoch: 0 [85088/250314 (34%)]\tLoss: 0.789460\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:18 | INFO | Rank 0 | Train Epoch: 0 [85120/250314 (34%)]\tLoss: 1.217595\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:18 | INFO | Rank 0 | Train Epoch: 0 [85152/250314 (34%)]\tLoss: 0.911586\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:19 | INFO | Rank 0 | Train Epoch: 0 [85184/250314 (34%)]\tLoss: 1.121044\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:19 | INFO | Rank 0 | Train Epoch: 0 [85216/250314 (34%)]\tLoss: 1.280839\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:19 | INFO | Rank 0 | Train Epoch: 0 [85248/250314 (34%)]\tLoss: 0.933971\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:20 | INFO | Rank 0 | Train Epoch: 0 [85280/250314 (34%)]\tLoss: 0.589639\tData (t) 0.276\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:20 | INFO | Rank 0 | Train Epoch: 0 [85312/250314 (34%)]\tLoss: 1.085663\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:21 | INFO | Rank 0 | Train Epoch: 0 [85344/250314 (34%)]\tLoss: 0.508239\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:21 | INFO | Rank 0 | Train Epoch: 0 [85376/250314 (34%)]\tLoss: 0.704092\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:22 | INFO | Rank 0 | Train Epoch: 0 [85408/250314 (34%)]\tLoss: 0.981516\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:22 | INFO | Rank 0 | Train Epoch: 0 [85440/250314 (34%)]\tLoss: 1.259484\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:23 | INFO | Rank 0 | Train Epoch: 0 [85472/250314 (34%)]\tLoss: 1.179417\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:23 | INFO | Rank 0 | Train Epoch: 0 [85504/250314 (34%)]\tLoss: 0.750861\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:24 | INFO | Rank 0 | Train Epoch: 0 [85536/250314 (34%)]\tLoss: 0.995813\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:24 | INFO | Rank 0 | Train Epoch: 0 [85568/250314 (34%)]\tLoss: 0.668040\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:25 | INFO | Rank 0 | Train Epoch: 0 [85600/250314 (34%)]\tLoss: 1.116506\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:25 | INFO | Rank 0 | Train Epoch: 0 [85632/250314 (34%)]\tLoss: 0.736513\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:26 | INFO | Rank 0 | Train Epoch: 0 [85664/250314 (34%)]\tLoss: 1.146969\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:26 | INFO | Rank 0 | Train Epoch: 0 [85696/250314 (34%)]\tLoss: 0.722360\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:27 | INFO | Rank 0 | Train Epoch: 0 [85728/250314 (34%)]\tLoss: 0.961114\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:27 | INFO | Rank 0 | Train Epoch: 0 [85760/250314 (34%)]\tLoss: 0.862192\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:28 | INFO | Rank 0 | Train Epoch: 0 [85792/250314 (34%)]\tLoss: 0.771691\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:28 | INFO | Rank 0 | Train Epoch: 0 [85824/250314 (34%)]\tLoss: 0.823688\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:29 | INFO | Rank 0 | Train Epoch: 0 [85856/250314 (34%)]\tLoss: 0.727369\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:29 | INFO | Rank 0 | Train Epoch: 0 [85888/250314 (34%)]\tLoss: 1.065011\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:30 | INFO | Rank 0 | Train Epoch: 0 [85920/250314 (34%)]\tLoss: 0.749581\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:30 | INFO | Rank 0 | Train Epoch: 0 [85952/250314 (34%)]\tLoss: 0.883270\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:31 | INFO | Rank 0 | Train Epoch: 0 [85984/250314 (34%)]\tLoss: 0.653487\tData (t) 0.261\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:31 | INFO | Rank 0 | Train Epoch: 0 [86016/250314 (34%)]\tLoss: 0.978062\tData (t) 0.271\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:32 | INFO | Rank 0 | Train Epoch: 0 [86048/250314 (34%)]\tLoss: 0.796333\tData (t) 0.216\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:32 | INFO | Rank 0 | Train Epoch: 0 [86080/250314 (34%)]\tLoss: 0.908453\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:33 | INFO | Rank 0 | Train Epoch: 0 [86112/250314 (34%)]\tLoss: 0.945450\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:33 | INFO | Rank 0 | Train Epoch: 0 [86144/250314 (34%)]\tLoss: 0.748691\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:33 | INFO | Rank 0 | Train Epoch: 0 [86176/250314 (34%)]\tLoss: 0.627353\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:34 | INFO | Rank 0 | Train Epoch: 0 [86208/250314 (34%)]\tLoss: 0.582503\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:34 | INFO | Rank 0 | Train Epoch: 0 [86240/250314 (34%)]\tLoss: 0.724626\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:35 | INFO | Rank 0 | Train Epoch: 0 [86272/250314 (34%)]\tLoss: 0.918023\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.597\n",
      "2022-11-09,13:32:35 | INFO | Rank 0 | Train Epoch: 0 [86304/250314 (34%)]\tLoss: 0.861061\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:36 | INFO | Rank 0 | Train Epoch: 0 [86336/250314 (34%)]\tLoss: 0.759659\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:36 | INFO | Rank 0 | Train Epoch: 0 [86368/250314 (35%)]\tLoss: 1.166226\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:37 | INFO | Rank 0 | Train Epoch: 0 [86400/250314 (35%)]\tLoss: 1.097200\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:37 | INFO | Rank 0 | Train Epoch: 0 [86432/250314 (35%)]\tLoss: 0.658467\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:38 | INFO | Rank 0 | Train Epoch: 0 [86464/250314 (35%)]\tLoss: 0.887963\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:38 | INFO | Rank 0 | Train Epoch: 0 [86496/250314 (35%)]\tLoss: 0.623977\tData (t) 0.214\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:39 | INFO | Rank 0 | Train Epoch: 0 [86528/250314 (35%)]\tLoss: 0.620881\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:39 | INFO | Rank 0 | Train Epoch: 0 [86560/250314 (35%)]\tLoss: 1.251207\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:40 | INFO | Rank 0 | Train Epoch: 0 [86592/250314 (35%)]\tLoss: 0.926971\tData (t) 0.318\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:40 | INFO | Rank 0 | Train Epoch: 0 [86624/250314 (35%)]\tLoss: 1.010361\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:41 | INFO | Rank 0 | Train Epoch: 0 [86656/250314 (35%)]\tLoss: 0.959015\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:41 | INFO | Rank 0 | Train Epoch: 0 [86688/250314 (35%)]\tLoss: 0.838448\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:42 | INFO | Rank 0 | Train Epoch: 0 [86720/250314 (35%)]\tLoss: 1.491273\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:42 | INFO | Rank 0 | Train Epoch: 0 [86752/250314 (35%)]\tLoss: 0.468556\tData (t) 0.236\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:43 | INFO | Rank 0 | Train Epoch: 0 [86784/250314 (35%)]\tLoss: 0.675584\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:43 | INFO | Rank 0 | Train Epoch: 0 [86816/250314 (35%)]\tLoss: 0.720829\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:44 | INFO | Rank 0 | Train Epoch: 0 [86848/250314 (35%)]\tLoss: 0.836848\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:44 | INFO | Rank 0 | Train Epoch: 0 [86880/250314 (35%)]\tLoss: 0.591469\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:45 | INFO | Rank 0 | Train Epoch: 0 [86912/250314 (35%)]\tLoss: 1.332411\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:45 | INFO | Rank 0 | Train Epoch: 0 [86944/250314 (35%)]\tLoss: 1.243193\tData (t) 0.336\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:46 | INFO | Rank 0 | Train Epoch: 0 [86976/250314 (35%)]\tLoss: 0.845383\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:46 | INFO | Rank 0 | Train Epoch: 0 [87008/250314 (35%)]\tLoss: 0.767550\tData (t) 0.212\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:47 | INFO | Rank 0 | Train Epoch: 0 [87040/250314 (35%)]\tLoss: 0.983124\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:47 | INFO | Rank 0 | Train Epoch: 0 [87072/250314 (35%)]\tLoss: 0.600831\tData (t) 0.338\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:48 | INFO | Rank 0 | Train Epoch: 0 [87104/250314 (35%)]\tLoss: 0.826657\tData (t) 0.352\tBatch (t) 0.564\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:48 | INFO | Rank 0 | Train Epoch: 0 [87136/250314 (35%)]\tLoss: 0.658422\tData (t) 0.324\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:49 | INFO | Rank 0 | Train Epoch: 0 [87168/250314 (35%)]\tLoss: 1.216491\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:49 | INFO | Rank 0 | Train Epoch: 0 [87200/250314 (35%)]\tLoss: 1.071750\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:50 | INFO | Rank 0 | Train Epoch: 0 [87232/250314 (35%)]\tLoss: 0.888475\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:50 | INFO | Rank 0 | Train Epoch: 0 [87264/250314 (35%)]\tLoss: 0.874691\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:51 | INFO | Rank 0 | Train Epoch: 0 [87296/250314 (35%)]\tLoss: 1.082189\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:51 | INFO | Rank 0 | Train Epoch: 0 [87328/250314 (35%)]\tLoss: 0.582301\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:52 | INFO | Rank 0 | Train Epoch: 0 [87360/250314 (35%)]\tLoss: 0.624657\tData (t) 0.333\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:52 | INFO | Rank 0 | Train Epoch: 0 [87392/250314 (35%)]\tLoss: 0.483621\tData (t) 0.225\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:53 | INFO | Rank 0 | Train Epoch: 0 [87424/250314 (35%)]\tLoss: 1.186826\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:53 | INFO | Rank 0 | Train Epoch: 0 [87456/250314 (35%)]\tLoss: 0.856636\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:54 | INFO | Rank 0 | Train Epoch: 0 [87488/250314 (35%)]\tLoss: 1.043192\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:54 | INFO | Rank 0 | Train Epoch: 0 [87520/250314 (35%)]\tLoss: 1.316564\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:55 | INFO | Rank 0 | Train Epoch: 0 [87552/250314 (35%)]\tLoss: 0.620306\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:55 | INFO | Rank 0 | Train Epoch: 0 [87584/250314 (35%)]\tLoss: 0.938817\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:56 | INFO | Rank 0 | Train Epoch: 0 [87616/250314 (35%)]\tLoss: 0.944053\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:56 | INFO | Rank 0 | Train Epoch: 0 [87648/250314 (35%)]\tLoss: 0.640571\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:57 | INFO | Rank 0 | Train Epoch: 0 [87680/250314 (35%)]\tLoss: 1.045737\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:57 | INFO | Rank 0 | Train Epoch: 0 [87712/250314 (35%)]\tLoss: 0.364579\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:58 | INFO | Rank 0 | Train Epoch: 0 [87744/250314 (35%)]\tLoss: 0.884288\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:58 | INFO | Rank 0 | Train Epoch: 0 [87776/250314 (35%)]\tLoss: 0.503415\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:59 | INFO | Rank 0 | Train Epoch: 0 [87808/250314 (35%)]\tLoss: 0.470448\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:32:59 | INFO | Rank 0 | Train Epoch: 0 [87840/250314 (35%)]\tLoss: 0.801074\tData (t) 0.318\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:00 | INFO | Rank 0 | Train Epoch: 0 [87872/250314 (35%)]\tLoss: 1.174946\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:00 | INFO | Rank 0 | Train Epoch: 0 [87904/250314 (35%)]\tLoss: 0.729645\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:01 | INFO | Rank 0 | Train Epoch: 0 [87936/250314 (35%)]\tLoss: 0.896946\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:01 | INFO | Rank 0 | Train Epoch: 0 [87968/250314 (35%)]\tLoss: 1.306617\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:02 | INFO | Rank 0 | Train Epoch: 0 [88000/250314 (35%)]\tLoss: 0.800639\tData (t) 0.217\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:02 | INFO | Rank 0 | Train Epoch: 0 [88032/250314 (35%)]\tLoss: 0.666047\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:03 | INFO | Rank 0 | Train Epoch: 0 [88064/250314 (35%)]\tLoss: 0.931619\tData (t) 0.212\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:03 | INFO | Rank 0 | Train Epoch: 0 [88096/250314 (35%)]\tLoss: 0.935077\tData (t) 0.224\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:04 | INFO | Rank 0 | Train Epoch: 0 [88128/250314 (35%)]\tLoss: 0.696759\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:04 | INFO | Rank 0 | Train Epoch: 0 [88160/250314 (35%)]\tLoss: 0.835003\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:04 | INFO | Rank 0 | Train Epoch: 0 [88192/250314 (35%)]\tLoss: 0.645137\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:05 | INFO | Rank 0 | Train Epoch: 0 [88224/250314 (35%)]\tLoss: 0.832547\tData (t) 0.216\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:05 | INFO | Rank 0 | Train Epoch: 0 [88256/250314 (35%)]\tLoss: 0.660933\tData (t) 0.331\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:06 | INFO | Rank 0 | Train Epoch: 0 [88288/250314 (35%)]\tLoss: 0.529899\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:06 | INFO | Rank 0 | Train Epoch: 0 [88320/250314 (35%)]\tLoss: 0.978557\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:07 | INFO | Rank 0 | Train Epoch: 0 [88352/250314 (35%)]\tLoss: 0.945451\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:07 | INFO | Rank 0 | Train Epoch: 0 [88384/250314 (35%)]\tLoss: 0.536992\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:08 | INFO | Rank 0 | Train Epoch: 0 [88416/250314 (35%)]\tLoss: 0.695501\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:08 | INFO | Rank 0 | Train Epoch: 0 [88448/250314 (35%)]\tLoss: 1.089719\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:09 | INFO | Rank 0 | Train Epoch: 0 [88480/250314 (35%)]\tLoss: 1.221766\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:09 | INFO | Rank 0 | Train Epoch: 0 [88512/250314 (35%)]\tLoss: 0.553560\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:10 | INFO | Rank 0 | Train Epoch: 0 [88544/250314 (35%)]\tLoss: 0.614159\tData (t) 0.333\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:10 | INFO | Rank 0 | Train Epoch: 0 [88576/250314 (35%)]\tLoss: 0.822904\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:11 | INFO | Rank 0 | Train Epoch: 0 [88608/250314 (35%)]\tLoss: 0.528815\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:11 | INFO | Rank 0 | Train Epoch: 0 [88640/250314 (35%)]\tLoss: 0.996958\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:12 | INFO | Rank 0 | Train Epoch: 0 [88672/250314 (35%)]\tLoss: 0.419496\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:12 | INFO | Rank 0 | Train Epoch: 0 [88704/250314 (35%)]\tLoss: 0.843487\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:13 | INFO | Rank 0 | Train Epoch: 0 [88736/250314 (35%)]\tLoss: 0.573780\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:13 | INFO | Rank 0 | Train Epoch: 0 [88768/250314 (35%)]\tLoss: 0.917303\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:14 | INFO | Rank 0 | Train Epoch: 0 [88800/250314 (35%)]\tLoss: 0.763279\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:14 | INFO | Rank 0 | Train Epoch: 0 [88832/250314 (35%)]\tLoss: 0.946208\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:15 | INFO | Rank 0 | Train Epoch: 0 [88864/250314 (36%)]\tLoss: 0.782268\tData (t) 0.500\tBatch (t) 0.711\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:16 | INFO | Rank 0 | Train Epoch: 0 [88896/250314 (36%)]\tLoss: 0.623930\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:16 | INFO | Rank 0 | Train Epoch: 0 [88928/250314 (36%)]\tLoss: 0.553485\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:17 | INFO | Rank 0 | Train Epoch: 0 [88960/250314 (36%)]\tLoss: 0.527253\tData (t) 0.220\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:17 | INFO | Rank 0 | Train Epoch: 0 [88992/250314 (36%)]\tLoss: 0.823905\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:18 | INFO | Rank 0 | Train Epoch: 0 [89024/250314 (36%)]\tLoss: 0.541902\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:18 | INFO | Rank 0 | Train Epoch: 0 [89056/250314 (36%)]\tLoss: 0.555119\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:18 | INFO | Rank 0 | Train Epoch: 0 [89088/250314 (36%)]\tLoss: 0.421760\tData (t) 0.227\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:19 | INFO | Rank 0 | Train Epoch: 0 [89120/250314 (36%)]\tLoss: 0.457035\tData (t) 0.360\tBatch (t) 0.572\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:20 | INFO | Rank 0 | Train Epoch: 0 [89152/250314 (36%)]\tLoss: 0.619214\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:20 | INFO | Rank 0 | Train Epoch: 0 [89184/250314 (36%)]\tLoss: 0.585992\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:21 | INFO | Rank 0 | Train Epoch: 0 [89216/250314 (36%)]\tLoss: 0.666033\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:21 | INFO | Rank 0 | Train Epoch: 0 [89248/250314 (36%)]\tLoss: 0.651116\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:21 | INFO | Rank 0 | Train Epoch: 0 [89280/250314 (36%)]\tLoss: 0.348639\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:22 | INFO | Rank 0 | Train Epoch: 0 [89312/250314 (36%)]\tLoss: 0.743800\tData (t) 0.202\tBatch (t) 0.413\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:22 | INFO | Rank 0 | Train Epoch: 0 [89344/250314 (36%)]\tLoss: 1.012812\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:23 | INFO | Rank 0 | Train Epoch: 0 [89376/250314 (36%)]\tLoss: 0.981380\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:23 | INFO | Rank 0 | Train Epoch: 0 [89408/250314 (36%)]\tLoss: 0.795510\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:24 | INFO | Rank 0 | Train Epoch: 0 [89440/250314 (36%)]\tLoss: 0.790294\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:24 | INFO | Rank 0 | Train Epoch: 0 [89472/250314 (36%)]\tLoss: 0.990178\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:25 | INFO | Rank 0 | Train Epoch: 0 [89504/250314 (36%)]\tLoss: 0.522156\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:25 | INFO | Rank 0 | Train Epoch: 0 [89536/250314 (36%)]\tLoss: 0.691272\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:26 | INFO | Rank 0 | Train Epoch: 0 [89568/250314 (36%)]\tLoss: 0.803918\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:26 | INFO | Rank 0 | Train Epoch: 0 [89600/250314 (36%)]\tLoss: 0.535987\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:27 | INFO | Rank 0 | Train Epoch: 0 [89632/250314 (36%)]\tLoss: 0.355713\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:27 | INFO | Rank 0 | Train Epoch: 0 [89664/250314 (36%)]\tLoss: 0.507666\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:28 | INFO | Rank 0 | Train Epoch: 0 [89696/250314 (36%)]\tLoss: 0.924308\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:28 | INFO | Rank 0 | Train Epoch: 0 [89728/250314 (36%)]\tLoss: 1.042867\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:29 | INFO | Rank 0 | Train Epoch: 0 [89760/250314 (36%)]\tLoss: 1.387851\tData (t) 0.413\tBatch (t) 0.625\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:29 | INFO | Rank 0 | Train Epoch: 0 [89792/250314 (36%)]\tLoss: 0.857490\tData (t) 0.330\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:30 | INFO | Rank 0 | Train Epoch: 0 [89824/250314 (36%)]\tLoss: 0.617510\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:30 | INFO | Rank 0 | Train Epoch: 0 [89856/250314 (36%)]\tLoss: 1.370907\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:31 | INFO | Rank 0 | Train Epoch: 0 [89888/250314 (36%)]\tLoss: 0.669724\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:31 | INFO | Rank 0 | Train Epoch: 0 [89920/250314 (36%)]\tLoss: 0.528328\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:32 | INFO | Rank 0 | Train Epoch: 0 [89952/250314 (36%)]\tLoss: 0.769639\tData (t) 0.330\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:32 | INFO | Rank 0 | Train Epoch: 0 [89984/250314 (36%)]\tLoss: 0.612789\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:33 | INFO | Rank 0 | Train Epoch: 0 [90016/250314 (36%)]\tLoss: 0.865740\tData (t) 0.215\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:33 | INFO | Rank 0 | Train Epoch: 0 [90048/250314 (36%)]\tLoss: 0.561513\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:34 | INFO | Rank 0 | Train Epoch: 0 [90080/250314 (36%)]\tLoss: 0.951687\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:34 | INFO | Rank 0 | Train Epoch: 0 [90112/250314 (36%)]\tLoss: 0.832805\tData (t) 0.354\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:35 | INFO | Rank 0 | Train Epoch: 0 [90144/250314 (36%)]\tLoss: 0.736001\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:35 | INFO | Rank 0 | Train Epoch: 0 [90176/250314 (36%)]\tLoss: 0.867235\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:36 | INFO | Rank 0 | Train Epoch: 0 [90208/250314 (36%)]\tLoss: 1.084110\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:36 | INFO | Rank 0 | Train Epoch: 0 [90240/250314 (36%)]\tLoss: 0.672133\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:37 | INFO | Rank 0 | Train Epoch: 0 [90272/250314 (36%)]\tLoss: 0.892137\tData (t) 0.214\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:37 | INFO | Rank 0 | Train Epoch: 0 [90304/250314 (36%)]\tLoss: 0.535947\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:38 | INFO | Rank 0 | Train Epoch: 0 [90336/250314 (36%)]\tLoss: 1.122694\tData (t) 0.205\tBatch (t) 0.417\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:38 | INFO | Rank 0 | Train Epoch: 0 [90368/250314 (36%)]\tLoss: 0.927064\tData (t) 0.330\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:39 | INFO | Rank 0 | Train Epoch: 0 [90400/250314 (36%)]\tLoss: 0.822876\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:39 | INFO | Rank 0 | Train Epoch: 0 [90432/250314 (36%)]\tLoss: 0.876020\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:40 | INFO | Rank 0 | Train Epoch: 0 [90464/250314 (36%)]\tLoss: 0.864807\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:40 | INFO | Rank 0 | Train Epoch: 0 [90496/250314 (36%)]\tLoss: 0.508506\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:41 | INFO | Rank 0 | Train Epoch: 0 [90528/250314 (36%)]\tLoss: 0.761675\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:41 | INFO | Rank 0 | Train Epoch: 0 [90560/250314 (36%)]\tLoss: 0.767805\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:42 | INFO | Rank 0 | Train Epoch: 0 [90592/250314 (36%)]\tLoss: 1.111444\tData (t) 0.238\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:42 | INFO | Rank 0 | Train Epoch: 0 [90624/250314 (36%)]\tLoss: 0.996059\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:42 | INFO | Rank 0 | Train Epoch: 0 [90656/250314 (36%)]\tLoss: 0.896896\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:43 | INFO | Rank 0 | Train Epoch: 0 [90688/250314 (36%)]\tLoss: 0.807988\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:44 | INFO | Rank 0 | Train Epoch: 0 [90720/250314 (36%)]\tLoss: 1.308623\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:44 | INFO | Rank 0 | Train Epoch: 0 [90752/250314 (36%)]\tLoss: 0.730767\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:44 | INFO | Rank 0 | Train Epoch: 0 [90784/250314 (36%)]\tLoss: 1.086544\tData (t) 0.282\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:45 | INFO | Rank 0 | Train Epoch: 0 [90816/250314 (36%)]\tLoss: 1.072094\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:45 | INFO | Rank 0 | Train Epoch: 0 [90848/250314 (36%)]\tLoss: 0.839721\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:46 | INFO | Rank 0 | Train Epoch: 0 [90880/250314 (36%)]\tLoss: 0.933233\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:47 | INFO | Rank 0 | Train Epoch: 0 [90912/250314 (36%)]\tLoss: 1.003680\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:47 | INFO | Rank 0 | Train Epoch: 0 [90944/250314 (36%)]\tLoss: 1.167928\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:48 | INFO | Rank 0 | Train Epoch: 0 [90976/250314 (36%)]\tLoss: 1.342285\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:48 | INFO | Rank 0 | Train Epoch: 0 [91008/250314 (36%)]\tLoss: 0.957041\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:49 | INFO | Rank 0 | Train Epoch: 0 [91040/250314 (36%)]\tLoss: 0.713380\tData (t) 0.317\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:49 | INFO | Rank 0 | Train Epoch: 0 [91072/250314 (36%)]\tLoss: 0.957132\tData (t) 0.225\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:49 | INFO | Rank 0 | Train Epoch: 0 [91104/250314 (36%)]\tLoss: 0.785414\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:50 | INFO | Rank 0 | Train Epoch: 0 [91136/250314 (36%)]\tLoss: 0.551162\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:50 | INFO | Rank 0 | Train Epoch: 0 [91168/250314 (36%)]\tLoss: 0.936277\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:51 | INFO | Rank 0 | Train Epoch: 0 [91200/250314 (36%)]\tLoss: 1.033916\tData (t) 0.246\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:51 | INFO | Rank 0 | Train Epoch: 0 [91232/250314 (36%)]\tLoss: 0.658803\tData (t) 0.340\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:52 | INFO | Rank 0 | Train Epoch: 0 [91264/250314 (36%)]\tLoss: 0.953019\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:52 | INFO | Rank 0 | Train Epoch: 0 [91296/250314 (36%)]\tLoss: 0.941285\tData (t) 0.244\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:53 | INFO | Rank 0 | Train Epoch: 0 [91328/250314 (36%)]\tLoss: 1.215281\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:53 | INFO | Rank 0 | Train Epoch: 0 [91360/250314 (36%)]\tLoss: 1.207299\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:54 | INFO | Rank 0 | Train Epoch: 0 [91392/250314 (37%)]\tLoss: 1.639467\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:54 | INFO | Rank 0 | Train Epoch: 0 [91424/250314 (37%)]\tLoss: 0.700197\tData (t) 0.378\tBatch (t) 0.589\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:55 | INFO | Rank 0 | Train Epoch: 0 [91456/250314 (37%)]\tLoss: 0.661690\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:55 | INFO | Rank 0 | Train Epoch: 0 [91488/250314 (37%)]\tLoss: 0.764291\tData (t) 0.193\tBatch (t) 0.405\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:56 | INFO | Rank 0 | Train Epoch: 0 [91520/250314 (37%)]\tLoss: 0.817842\tData (t) 0.320\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:56 | INFO | Rank 0 | Train Epoch: 0 [91552/250314 (37%)]\tLoss: 0.617194\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:57 | INFO | Rank 0 | Train Epoch: 0 [91584/250314 (37%)]\tLoss: 0.964672\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:57 | INFO | Rank 0 | Train Epoch: 0 [91616/250314 (37%)]\tLoss: 0.824462\tData (t) 0.390\tBatch (t) 0.602\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:58 | INFO | Rank 0 | Train Epoch: 0 [91648/250314 (37%)]\tLoss: 0.784726\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:58 | INFO | Rank 0 | Train Epoch: 0 [91680/250314 (37%)]\tLoss: 0.603184\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:59 | INFO | Rank 0 | Train Epoch: 0 [91712/250314 (37%)]\tLoss: 0.970614\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:33:59 | INFO | Rank 0 | Train Epoch: 0 [91744/250314 (37%)]\tLoss: 0.993134\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:00 | INFO | Rank 0 | Train Epoch: 0 [91776/250314 (37%)]\tLoss: 0.783468\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:00 | INFO | Rank 0 | Train Epoch: 0 [91808/250314 (37%)]\tLoss: 0.925376\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:01 | INFO | Rank 0 | Train Epoch: 0 [91840/250314 (37%)]\tLoss: 0.665247\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:01 | INFO | Rank 0 | Train Epoch: 0 [91872/250314 (37%)]\tLoss: 0.484440\tData (t) 0.223\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:02 | INFO | Rank 0 | Train Epoch: 0 [91904/250314 (37%)]\tLoss: 0.926673\tData (t) 0.307\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:02 | INFO | Rank 0 | Train Epoch: 0 [91936/250314 (37%)]\tLoss: 0.994564\tData (t) 0.264\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:03 | INFO | Rank 0 | Train Epoch: 0 [91968/250314 (37%)]\tLoss: 0.634102\tData (t) 0.254\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:03 | INFO | Rank 0 | Train Epoch: 0 [92000/250314 (37%)]\tLoss: 0.569519\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:04 | INFO | Rank 0 | Train Epoch: 0 [92032/250314 (37%)]\tLoss: 0.688395\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:04 | INFO | Rank 0 | Train Epoch: 0 [92064/250314 (37%)]\tLoss: 0.746775\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:05 | INFO | Rank 0 | Train Epoch: 0 [92096/250314 (37%)]\tLoss: 0.848681\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:05 | INFO | Rank 0 | Train Epoch: 0 [92128/250314 (37%)]\tLoss: 0.801054\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:06 | INFO | Rank 0 | Train Epoch: 0 [92160/250314 (37%)]\tLoss: 1.147053\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:06 | INFO | Rank 0 | Train Epoch: 0 [92192/250314 (37%)]\tLoss: 0.649109\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:07 | INFO | Rank 0 | Train Epoch: 0 [92224/250314 (37%)]\tLoss: 0.626655\tData (t) 0.372\tBatch (t) 0.584\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:07 | INFO | Rank 0 | Train Epoch: 0 [92256/250314 (37%)]\tLoss: 0.823892\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:08 | INFO | Rank 0 | Train Epoch: 0 [92288/250314 (37%)]\tLoss: 0.667554\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:08 | INFO | Rank 0 | Train Epoch: 0 [92320/250314 (37%)]\tLoss: 1.119856\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:09 | INFO | Rank 0 | Train Epoch: 0 [92352/250314 (37%)]\tLoss: 0.894243\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:09 | INFO | Rank 0 | Train Epoch: 0 [92384/250314 (37%)]\tLoss: 0.702990\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:10 | INFO | Rank 0 | Train Epoch: 0 [92416/250314 (37%)]\tLoss: 0.911155\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:10 | INFO | Rank 0 | Train Epoch: 0 [92448/250314 (37%)]\tLoss: 0.841159\tData (t) 0.347\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:11 | INFO | Rank 0 | Train Epoch: 0 [92480/250314 (37%)]\tLoss: 0.748917\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:11 | INFO | Rank 0 | Train Epoch: 0 [92512/250314 (37%)]\tLoss: 0.724668\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:12 | INFO | Rank 0 | Train Epoch: 0 [92544/250314 (37%)]\tLoss: 0.890898\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:12 | INFO | Rank 0 | Train Epoch: 0 [92576/250314 (37%)]\tLoss: 0.900394\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:13 | INFO | Rank 0 | Train Epoch: 0 [92608/250314 (37%)]\tLoss: 0.918065\tData (t) 0.221\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:13 | INFO | Rank 0 | Train Epoch: 0 [92640/250314 (37%)]\tLoss: 0.896170\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:14 | INFO | Rank 0 | Train Epoch: 0 [92672/250314 (37%)]\tLoss: 0.202227\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:14 | INFO | Rank 0 | Train Epoch: 0 [92704/250314 (37%)]\tLoss: 0.909157\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:15 | INFO | Rank 0 | Train Epoch: 0 [92736/250314 (37%)]\tLoss: 1.107784\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:15 | INFO | Rank 0 | Train Epoch: 0 [92768/250314 (37%)]\tLoss: 0.731959\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:16 | INFO | Rank 0 | Train Epoch: 0 [92800/250314 (37%)]\tLoss: 0.998575\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:16 | INFO | Rank 0 | Train Epoch: 0 [92832/250314 (37%)]\tLoss: 0.542259\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:17 | INFO | Rank 0 | Train Epoch: 0 [92864/250314 (37%)]\tLoss: 0.434340\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:17 | INFO | Rank 0 | Train Epoch: 0 [92896/250314 (37%)]\tLoss: 0.857448\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:18 | INFO | Rank 0 | Train Epoch: 0 [92928/250314 (37%)]\tLoss: 0.920381\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:18 | INFO | Rank 0 | Train Epoch: 0 [92960/250314 (37%)]\tLoss: 0.517452\tData (t) 0.277\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:19 | INFO | Rank 0 | Train Epoch: 0 [92992/250314 (37%)]\tLoss: 0.988380\tData (t) 0.233\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:19 | INFO | Rank 0 | Train Epoch: 0 [93024/250314 (37%)]\tLoss: 1.182653\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:19 | INFO | Rank 0 | Train Epoch: 0 [93056/250314 (37%)]\tLoss: 0.759925\tData (t) 0.224\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:20 | INFO | Rank 0 | Train Epoch: 0 [93088/250314 (37%)]\tLoss: 0.754093\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:21 | INFO | Rank 0 | Train Epoch: 0 [93120/250314 (37%)]\tLoss: 0.648674\tData (t) 0.318\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:21 | INFO | Rank 0 | Train Epoch: 0 [93152/250314 (37%)]\tLoss: 0.703028\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:21 | INFO | Rank 0 | Train Epoch: 0 [93184/250314 (37%)]\tLoss: 0.558171\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:22 | INFO | Rank 0 | Train Epoch: 0 [93216/250314 (37%)]\tLoss: 0.538693\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:22 | INFO | Rank 0 | Train Epoch: 0 [93248/250314 (37%)]\tLoss: 0.709008\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:23 | INFO | Rank 0 | Train Epoch: 0 [93280/250314 (37%)]\tLoss: 0.852461\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:23 | INFO | Rank 0 | Train Epoch: 0 [93312/250314 (37%)]\tLoss: 0.682692\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:24 | INFO | Rank 0 | Train Epoch: 0 [93344/250314 (37%)]\tLoss: 1.052913\tData (t) 0.195\tBatch (t) 0.408\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:24 | INFO | Rank 0 | Train Epoch: 0 [93376/250314 (37%)]\tLoss: 0.870201\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:25 | INFO | Rank 0 | Train Epoch: 0 [93408/250314 (37%)]\tLoss: 0.602042\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:25 | INFO | Rank 0 | Train Epoch: 0 [93440/250314 (37%)]\tLoss: 0.868874\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:26 | INFO | Rank 0 | Train Epoch: 0 [93472/250314 (37%)]\tLoss: 0.756431\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:26 | INFO | Rank 0 | Train Epoch: 0 [93504/250314 (37%)]\tLoss: 0.489922\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:27 | INFO | Rank 0 | Train Epoch: 0 [93536/250314 (37%)]\tLoss: 0.968098\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:27 | INFO | Rank 0 | Train Epoch: 0 [93568/250314 (37%)]\tLoss: 1.115861\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:28 | INFO | Rank 0 | Train Epoch: 0 [93600/250314 (37%)]\tLoss: 1.118174\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:28 | INFO | Rank 0 | Train Epoch: 0 [93632/250314 (37%)]\tLoss: 0.807039\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:29 | INFO | Rank 0 | Train Epoch: 0 [93664/250314 (37%)]\tLoss: 0.961735\tData (t) 0.299\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:29 | INFO | Rank 0 | Train Epoch: 0 [93696/250314 (37%)]\tLoss: 0.804433\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:30 | INFO | Rank 0 | Train Epoch: 0 [93728/250314 (37%)]\tLoss: 0.579644\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:30 | INFO | Rank 0 | Train Epoch: 0 [93760/250314 (37%)]\tLoss: 1.101718\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:31 | INFO | Rank 0 | Train Epoch: 0 [93792/250314 (37%)]\tLoss: 0.799939\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:31 | INFO | Rank 0 | Train Epoch: 0 [93824/250314 (37%)]\tLoss: 0.575738\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:32 | INFO | Rank 0 | Train Epoch: 0 [93856/250314 (37%)]\tLoss: 0.641884\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:32 | INFO | Rank 0 | Train Epoch: 0 [93888/250314 (38%)]\tLoss: 1.102815\tData (t) 0.230\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:33 | INFO | Rank 0 | Train Epoch: 0 [93920/250314 (38%)]\tLoss: 1.106489\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:33 | INFO | Rank 0 | Train Epoch: 0 [93952/250314 (38%)]\tLoss: 0.823560\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:34 | INFO | Rank 0 | Train Epoch: 0 [93984/250314 (38%)]\tLoss: 0.859977\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:34 | INFO | Rank 0 | Train Epoch: 0 [94016/250314 (38%)]\tLoss: 0.881782\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:35 | INFO | Rank 0 | Train Epoch: 0 [94048/250314 (38%)]\tLoss: 1.030023\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:35 | INFO | Rank 0 | Train Epoch: 0 [94080/250314 (38%)]\tLoss: 1.487087\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:36 | INFO | Rank 0 | Train Epoch: 0 [94112/250314 (38%)]\tLoss: 1.140260\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:36 | INFO | Rank 0 | Train Epoch: 0 [94144/250314 (38%)]\tLoss: 0.797459\tData (t) 0.226\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:36 | INFO | Rank 0 | Train Epoch: 0 [94176/250314 (38%)]\tLoss: 0.855181\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:37 | INFO | Rank 0 | Train Epoch: 0 [94208/250314 (38%)]\tLoss: 0.799376\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:37 | INFO | Rank 0 | Train Epoch: 0 [94240/250314 (38%)]\tLoss: 0.814354\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:38 | INFO | Rank 0 | Train Epoch: 0 [94272/250314 (38%)]\tLoss: 0.550110\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:38 | INFO | Rank 0 | Train Epoch: 0 [94304/250314 (38%)]\tLoss: 0.661138\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:39 | INFO | Rank 0 | Train Epoch: 0 [94336/250314 (38%)]\tLoss: 0.838274\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:39 | INFO | Rank 0 | Train Epoch: 0 [94368/250314 (38%)]\tLoss: 0.709891\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:40 | INFO | Rank 0 | Train Epoch: 0 [94400/250314 (38%)]\tLoss: 0.654742\tData (t) 0.356\tBatch (t) 0.567\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:40 | INFO | Rank 0 | Train Epoch: 0 [94432/250314 (38%)]\tLoss: 0.624143\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:41 | INFO | Rank 0 | Train Epoch: 0 [94464/250314 (38%)]\tLoss: 0.830884\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:41 | INFO | Rank 0 | Train Epoch: 0 [94496/250314 (38%)]\tLoss: 0.752275\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:42 | INFO | Rank 0 | Train Epoch: 0 [94528/250314 (38%)]\tLoss: 0.748128\tData (t) 0.200\tBatch (t) 0.412\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:42 | INFO | Rank 0 | Train Epoch: 0 [94560/250314 (38%)]\tLoss: 0.694704\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:43 | INFO | Rank 0 | Train Epoch: 0 [94592/250314 (38%)]\tLoss: 0.927029\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:43 | INFO | Rank 0 | Train Epoch: 0 [94624/250314 (38%)]\tLoss: 0.914409\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:44 | INFO | Rank 0 | Train Epoch: 0 [94656/250314 (38%)]\tLoss: 0.921924\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:44 | INFO | Rank 0 | Train Epoch: 0 [94688/250314 (38%)]\tLoss: 0.682688\tData (t) 0.233\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:45 | INFO | Rank 0 | Train Epoch: 0 [94720/250314 (38%)]\tLoss: 0.626134\tData (t) 0.229\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:45 | INFO | Rank 0 | Train Epoch: 0 [94752/250314 (38%)]\tLoss: 0.789307\tData (t) 0.244\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:46 | INFO | Rank 0 | Train Epoch: 0 [94784/250314 (38%)]\tLoss: 0.795696\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:46 | INFO | Rank 0 | Train Epoch: 0 [94816/250314 (38%)]\tLoss: 0.662678\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:47 | INFO | Rank 0 | Train Epoch: 0 [94848/250314 (38%)]\tLoss: 1.407587\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:47 | INFO | Rank 0 | Train Epoch: 0 [94880/250314 (38%)]\tLoss: 0.883556\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:48 | INFO | Rank 0 | Train Epoch: 0 [94912/250314 (38%)]\tLoss: 0.664858\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:48 | INFO | Rank 0 | Train Epoch: 0 [94944/250314 (38%)]\tLoss: 1.194984\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:49 | INFO | Rank 0 | Train Epoch: 0 [94976/250314 (38%)]\tLoss: 0.702430\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:49 | INFO | Rank 0 | Train Epoch: 0 [95008/250314 (38%)]\tLoss: 0.764057\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:50 | INFO | Rank 0 | Train Epoch: 0 [95040/250314 (38%)]\tLoss: 0.920237\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:50 | INFO | Rank 0 | Train Epoch: 0 [95072/250314 (38%)]\tLoss: 1.393637\tData (t) 0.481\tBatch (t) 0.692\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:51 | INFO | Rank 0 | Train Epoch: 0 [95104/250314 (38%)]\tLoss: 1.067484\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:51 | INFO | Rank 0 | Train Epoch: 0 [95136/250314 (38%)]\tLoss: 0.455216\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:52 | INFO | Rank 0 | Train Epoch: 0 [95168/250314 (38%)]\tLoss: 0.614347\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:52 | INFO | Rank 0 | Train Epoch: 0 [95200/250314 (38%)]\tLoss: 0.578502\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:53 | INFO | Rank 0 | Train Epoch: 0 [95232/250314 (38%)]\tLoss: 0.884187\tData (t) 0.213\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:53 | INFO | Rank 0 | Train Epoch: 0 [95264/250314 (38%)]\tLoss: 0.907608\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:54 | INFO | Rank 0 | Train Epoch: 0 [95296/250314 (38%)]\tLoss: 0.731611\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:54 | INFO | Rank 0 | Train Epoch: 0 [95328/250314 (38%)]\tLoss: 0.692654\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:54 | INFO | Rank 0 | Train Epoch: 0 [95360/250314 (38%)]\tLoss: 0.643899\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:55 | INFO | Rank 0 | Train Epoch: 0 [95392/250314 (38%)]\tLoss: 0.345078\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:55 | INFO | Rank 0 | Train Epoch: 0 [95424/250314 (38%)]\tLoss: 0.728762\tData (t) 0.213\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:56 | INFO | Rank 0 | Train Epoch: 0 [95456/250314 (38%)]\tLoss: 0.883920\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:56 | INFO | Rank 0 | Train Epoch: 0 [95488/250314 (38%)]\tLoss: 0.882426\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:57 | INFO | Rank 0 | Train Epoch: 0 [95520/250314 (38%)]\tLoss: 1.137415\tData (t) 0.314\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:57 | INFO | Rank 0 | Train Epoch: 0 [95552/250314 (38%)]\tLoss: 1.036057\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:58 | INFO | Rank 0 | Train Epoch: 0 [95584/250314 (38%)]\tLoss: 1.032716\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:58 | INFO | Rank 0 | Train Epoch: 0 [95616/250314 (38%)]\tLoss: 1.109846\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:59 | INFO | Rank 0 | Train Epoch: 0 [95648/250314 (38%)]\tLoss: 0.837625\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:34:59 | INFO | Rank 0 | Train Epoch: 0 [95680/250314 (38%)]\tLoss: 0.791087\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:00 | INFO | Rank 0 | Train Epoch: 0 [95712/250314 (38%)]\tLoss: 1.071688\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:00 | INFO | Rank 0 | Train Epoch: 0 [95744/250314 (38%)]\tLoss: 0.699963\tData (t) 0.215\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:01 | INFO | Rank 0 | Train Epoch: 0 [95776/250314 (38%)]\tLoss: 0.804709\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:01 | INFO | Rank 0 | Train Epoch: 0 [95808/250314 (38%)]\tLoss: 0.925498\tData (t) 0.221\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:02 | INFO | Rank 0 | Train Epoch: 0 [95840/250314 (38%)]\tLoss: 0.775166\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:02 | INFO | Rank 0 | Train Epoch: 0 [95872/250314 (38%)]\tLoss: 0.673024\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:03 | INFO | Rank 0 | Train Epoch: 0 [95904/250314 (38%)]\tLoss: 0.774848\tData (t) 0.219\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:03 | INFO | Rank 0 | Train Epoch: 0 [95936/250314 (38%)]\tLoss: 0.775795\tData (t) 0.169\tBatch (t) 0.381\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:03 | INFO | Rank 0 | Train Epoch: 0 [95968/250314 (38%)]\tLoss: 0.688095\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:04 | INFO | Rank 0 | Train Epoch: 0 [96000/250314 (38%)]\tLoss: 0.794705\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:04 | INFO | Rank 0 | Train Epoch: 0 [96032/250314 (38%)]\tLoss: 1.446264\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:05 | INFO | Rank 0 | Train Epoch: 0 [96064/250314 (38%)]\tLoss: 1.329060\tData (t) 0.199\tBatch (t) 0.410\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:05 | INFO | Rank 0 | Train Epoch: 0 [96096/250314 (38%)]\tLoss: 0.433006\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:06 | INFO | Rank 0 | Train Epoch: 0 [96128/250314 (38%)]\tLoss: 0.651939\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:06 | INFO | Rank 0 | Train Epoch: 0 [96160/250314 (38%)]\tLoss: 0.722369\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:07 | INFO | Rank 0 | Train Epoch: 0 [96192/250314 (38%)]\tLoss: 0.920046\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:07 | INFO | Rank 0 | Train Epoch: 0 [96224/250314 (38%)]\tLoss: 0.953171\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:08 | INFO | Rank 0 | Train Epoch: 0 [96256/250314 (38%)]\tLoss: 0.518945\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:08 | INFO | Rank 0 | Train Epoch: 0 [96288/250314 (38%)]\tLoss: 0.562669\tData (t) 0.238\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:09 | INFO | Rank 0 | Train Epoch: 0 [96320/250314 (38%)]\tLoss: 0.619945\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:09 | INFO | Rank 0 | Train Epoch: 0 [96352/250314 (38%)]\tLoss: 0.917094\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:10 | INFO | Rank 0 | Train Epoch: 0 [96384/250314 (39%)]\tLoss: 0.554426\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:10 | INFO | Rank 0 | Train Epoch: 0 [96416/250314 (39%)]\tLoss: 1.093445\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:11 | INFO | Rank 0 | Train Epoch: 0 [96448/250314 (39%)]\tLoss: 1.101811\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:11 | INFO | Rank 0 | Train Epoch: 0 [96480/250314 (39%)]\tLoss: 0.563472\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:12 | INFO | Rank 0 | Train Epoch: 0 [96512/250314 (39%)]\tLoss: 0.819654\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:12 | INFO | Rank 0 | Train Epoch: 0 [96544/250314 (39%)]\tLoss: 0.633775\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:13 | INFO | Rank 0 | Train Epoch: 0 [96576/250314 (39%)]\tLoss: 1.043794\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:13 | INFO | Rank 0 | Train Epoch: 0 [96608/250314 (39%)]\tLoss: 0.585156\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:14 | INFO | Rank 0 | Train Epoch: 0 [96640/250314 (39%)]\tLoss: 0.918262\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:14 | INFO | Rank 0 | Train Epoch: 0 [96672/250314 (39%)]\tLoss: 0.802107\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:15 | INFO | Rank 0 | Train Epoch: 0 [96704/250314 (39%)]\tLoss: 0.837952\tData (t) 0.217\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:15 | INFO | Rank 0 | Train Epoch: 0 [96736/250314 (39%)]\tLoss: 0.770581\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:16 | INFO | Rank 0 | Train Epoch: 0 [96768/250314 (39%)]\tLoss: 0.492841\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:16 | INFO | Rank 0 | Train Epoch: 0 [96800/250314 (39%)]\tLoss: 0.966756\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:17 | INFO | Rank 0 | Train Epoch: 0 [96832/250314 (39%)]\tLoss: 1.000686\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:17 | INFO | Rank 0 | Train Epoch: 0 [96864/250314 (39%)]\tLoss: 0.901784\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:18 | INFO | Rank 0 | Train Epoch: 0 [96896/250314 (39%)]\tLoss: 0.720949\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:18 | INFO | Rank 0 | Train Epoch: 0 [96928/250314 (39%)]\tLoss: 0.610973\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:18 | INFO | Rank 0 | Train Epoch: 0 [96960/250314 (39%)]\tLoss: 0.783626\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:19 | INFO | Rank 0 | Train Epoch: 0 [96992/250314 (39%)]\tLoss: 0.649252\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:19 | INFO | Rank 0 | Train Epoch: 0 [97024/250314 (39%)]\tLoss: 0.943710\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:20 | INFO | Rank 0 | Train Epoch: 0 [97056/250314 (39%)]\tLoss: 0.658811\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:20 | INFO | Rank 0 | Train Epoch: 0 [97088/250314 (39%)]\tLoss: 0.847839\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:21 | INFO | Rank 0 | Train Epoch: 0 [97120/250314 (39%)]\tLoss: 1.190153\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:21 | INFO | Rank 0 | Train Epoch: 0 [97152/250314 (39%)]\tLoss: 1.041042\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:22 | INFO | Rank 0 | Train Epoch: 0 [97184/250314 (39%)]\tLoss: 1.359068\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:22 | INFO | Rank 0 | Train Epoch: 0 [97216/250314 (39%)]\tLoss: 0.908842\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:23 | INFO | Rank 0 | Train Epoch: 0 [97248/250314 (39%)]\tLoss: 0.835965\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:23 | INFO | Rank 0 | Train Epoch: 0 [97280/250314 (39%)]\tLoss: 0.832908\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:24 | INFO | Rank 0 | Train Epoch: 0 [97312/250314 (39%)]\tLoss: 0.770403\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:24 | INFO | Rank 0 | Train Epoch: 0 [97344/250314 (39%)]\tLoss: 0.648653\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:25 | INFO | Rank 0 | Train Epoch: 0 [97376/250314 (39%)]\tLoss: 0.516347\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:25 | INFO | Rank 0 | Train Epoch: 0 [97408/250314 (39%)]\tLoss: 0.949467\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:26 | INFO | Rank 0 | Train Epoch: 0 [97440/250314 (39%)]\tLoss: 0.920546\tData (t) 0.327\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:26 | INFO | Rank 0 | Train Epoch: 0 [97472/250314 (39%)]\tLoss: 0.983797\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:27 | INFO | Rank 0 | Train Epoch: 0 [97504/250314 (39%)]\tLoss: 0.945301\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:27 | INFO | Rank 0 | Train Epoch: 0 [97536/250314 (39%)]\tLoss: 0.913212\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:28 | INFO | Rank 0 | Train Epoch: 0 [97568/250314 (39%)]\tLoss: 0.770413\tData (t) 0.368\tBatch (t) 0.580\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:28 | INFO | Rank 0 | Train Epoch: 0 [97600/250314 (39%)]\tLoss: 0.699330\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:29 | INFO | Rank 0 | Train Epoch: 0 [97632/250314 (39%)]\tLoss: 0.983490\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:30 | INFO | Rank 0 | Train Epoch: 0 [97664/250314 (39%)]\tLoss: 0.683621\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:30 | INFO | Rank 0 | Train Epoch: 0 [97696/250314 (39%)]\tLoss: 0.629789\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:30 | INFO | Rank 0 | Train Epoch: 0 [97728/250314 (39%)]\tLoss: 0.592308\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:31 | INFO | Rank 0 | Train Epoch: 0 [97760/250314 (39%)]\tLoss: 0.902464\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:31 | INFO | Rank 0 | Train Epoch: 0 [97792/250314 (39%)]\tLoss: 0.574735\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:32 | INFO | Rank 0 | Train Epoch: 0 [97824/250314 (39%)]\tLoss: 0.772758\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:32 | INFO | Rank 0 | Train Epoch: 0 [97856/250314 (39%)]\tLoss: 1.130114\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:33 | INFO | Rank 0 | Train Epoch: 0 [97888/250314 (39%)]\tLoss: 0.897687\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:33 | INFO | Rank 0 | Train Epoch: 0 [97920/250314 (39%)]\tLoss: 0.602085\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:34 | INFO | Rank 0 | Train Epoch: 0 [97952/250314 (39%)]\tLoss: 0.735781\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:34 | INFO | Rank 0 | Train Epoch: 0 [97984/250314 (39%)]\tLoss: 0.679532\tData (t) 0.321\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:35 | INFO | Rank 0 | Train Epoch: 0 [98016/250314 (39%)]\tLoss: 0.555668\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:35 | INFO | Rank 0 | Train Epoch: 0 [98048/250314 (39%)]\tLoss: 0.714714\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:36 | INFO | Rank 0 | Train Epoch: 0 [98080/250314 (39%)]\tLoss: 0.444074\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:36 | INFO | Rank 0 | Train Epoch: 0 [98112/250314 (39%)]\tLoss: 0.846835\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:37 | INFO | Rank 0 | Train Epoch: 0 [98144/250314 (39%)]\tLoss: 0.597849\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:37 | INFO | Rank 0 | Train Epoch: 0 [98176/250314 (39%)]\tLoss: 1.251559\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:38 | INFO | Rank 0 | Train Epoch: 0 [98208/250314 (39%)]\tLoss: 0.478401\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:38 | INFO | Rank 0 | Train Epoch: 0 [98240/250314 (39%)]\tLoss: 0.587019\tData (t) 0.369\tBatch (t) 0.581\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:39 | INFO | Rank 0 | Train Epoch: 0 [98272/250314 (39%)]\tLoss: 1.227073\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:39 | INFO | Rank 0 | Train Epoch: 0 [98304/250314 (39%)]\tLoss: 0.410394\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:40 | INFO | Rank 0 | Train Epoch: 0 [98336/250314 (39%)]\tLoss: 1.165715\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:40 | INFO | Rank 0 | Train Epoch: 0 [98368/250314 (39%)]\tLoss: 0.765542\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:41 | INFO | Rank 0 | Train Epoch: 0 [98400/250314 (39%)]\tLoss: 0.871267\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:41 | INFO | Rank 0 | Train Epoch: 0 [98432/250314 (39%)]\tLoss: 0.885393\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:42 | INFO | Rank 0 | Train Epoch: 0 [98464/250314 (39%)]\tLoss: 0.667268\tData (t) 0.192\tBatch (t) 0.403\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:42 | INFO | Rank 0 | Train Epoch: 0 [98496/250314 (39%)]\tLoss: 0.538592\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:43 | INFO | Rank 0 | Train Epoch: 0 [98528/250314 (39%)]\tLoss: 0.900727\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:43 | INFO | Rank 0 | Train Epoch: 0 [98560/250314 (39%)]\tLoss: 1.250484\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:44 | INFO | Rank 0 | Train Epoch: 0 [98592/250314 (39%)]\tLoss: 0.452475\tData (t) 0.389\tBatch (t) 0.601\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:44 | INFO | Rank 0 | Train Epoch: 0 [98624/250314 (39%)]\tLoss: 0.825956\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:45 | INFO | Rank 0 | Train Epoch: 0 [98656/250314 (39%)]\tLoss: 0.726366\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:45 | INFO | Rank 0 | Train Epoch: 0 [98688/250314 (39%)]\tLoss: 1.231257\tData (t) 0.318\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:46 | INFO | Rank 0 | Train Epoch: 0 [98720/250314 (39%)]\tLoss: 0.589369\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:46 | INFO | Rank 0 | Train Epoch: 0 [98752/250314 (39%)]\tLoss: 0.829770\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:47 | INFO | Rank 0 | Train Epoch: 0 [98784/250314 (39%)]\tLoss: 0.982180\tData (t) 0.442\tBatch (t) 0.654\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:48 | INFO | Rank 0 | Train Epoch: 0 [98816/250314 (39%)]\tLoss: 0.361764\tData (t) 0.363\tBatch (t) 0.575\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:48 | INFO | Rank 0 | Train Epoch: 0 [98848/250314 (39%)]\tLoss: 1.102144\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:49 | INFO | Rank 0 | Train Epoch: 0 [98880/250314 (40%)]\tLoss: 0.631994\tData (t) 0.369\tBatch (t) 0.581\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:49 | INFO | Rank 0 | Train Epoch: 0 [98912/250314 (40%)]\tLoss: 0.885070\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:50 | INFO | Rank 0 | Train Epoch: 0 [98944/250314 (40%)]\tLoss: 0.683244\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:50 | INFO | Rank 0 | Train Epoch: 0 [98976/250314 (40%)]\tLoss: 0.565210\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:51 | INFO | Rank 0 | Train Epoch: 0 [99008/250314 (40%)]\tLoss: 1.138211\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:51 | INFO | Rank 0 | Train Epoch: 0 [99040/250314 (40%)]\tLoss: 0.575592\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:52 | INFO | Rank 0 | Train Epoch: 0 [99072/250314 (40%)]\tLoss: 1.131975\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:52 | INFO | Rank 0 | Train Epoch: 0 [99104/250314 (40%)]\tLoss: 1.175491\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:53 | INFO | Rank 0 | Train Epoch: 0 [99136/250314 (40%)]\tLoss: 0.642012\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:53 | INFO | Rank 0 | Train Epoch: 0 [99168/250314 (40%)]\tLoss: 0.892363\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:54 | INFO | Rank 0 | Train Epoch: 0 [99200/250314 (40%)]\tLoss: 1.110680\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:54 | INFO | Rank 0 | Train Epoch: 0 [99232/250314 (40%)]\tLoss: 0.904220\tData (t) 0.347\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:55 | INFO | Rank 0 | Train Epoch: 0 [99264/250314 (40%)]\tLoss: 0.968155\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:55 | INFO | Rank 0 | Train Epoch: 0 [99296/250314 (40%)]\tLoss: 1.091286\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:56 | INFO | Rank 0 | Train Epoch: 0 [99328/250314 (40%)]\tLoss: 1.100640\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:56 | INFO | Rank 0 | Train Epoch: 0 [99360/250314 (40%)]\tLoss: 0.620441\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:57 | INFO | Rank 0 | Train Epoch: 0 [99392/250314 (40%)]\tLoss: 0.762258\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:57 | INFO | Rank 0 | Train Epoch: 0 [99424/250314 (40%)]\tLoss: 1.002116\tData (t) 0.343\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:58 | INFO | Rank 0 | Train Epoch: 0 [99456/250314 (40%)]\tLoss: 0.537761\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:58 | INFO | Rank 0 | Train Epoch: 0 [99488/250314 (40%)]\tLoss: 0.886247\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:59 | INFO | Rank 0 | Train Epoch: 0 [99520/250314 (40%)]\tLoss: 0.876483\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:35:59 | INFO | Rank 0 | Train Epoch: 0 [99552/250314 (40%)]\tLoss: 1.112413\tData (t) 0.337\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:00 | INFO | Rank 0 | Train Epoch: 0 [99584/250314 (40%)]\tLoss: 0.508953\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:00 | INFO | Rank 0 | Train Epoch: 0 [99616/250314 (40%)]\tLoss: 0.591864\tData (t) 0.206\tBatch (t) 0.417\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:01 | INFO | Rank 0 | Train Epoch: 0 [99648/250314 (40%)]\tLoss: 0.583601\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:01 | INFO | Rank 0 | Train Epoch: 0 [99680/250314 (40%)]\tLoss: 0.689394\tData (t) 0.229\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:01 | INFO | Rank 0 | Train Epoch: 0 [99712/250314 (40%)]\tLoss: 0.810937\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:02 | INFO | Rank 0 | Train Epoch: 0 [99744/250314 (40%)]\tLoss: 0.830798\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:03 | INFO | Rank 0 | Train Epoch: 0 [99776/250314 (40%)]\tLoss: 1.044563\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:03 | INFO | Rank 0 | Train Epoch: 0 [99808/250314 (40%)]\tLoss: 0.976422\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:03 | INFO | Rank 0 | Train Epoch: 0 [99840/250314 (40%)]\tLoss: 0.635111\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:04 | INFO | Rank 0 | Train Epoch: 0 [99872/250314 (40%)]\tLoss: 1.222595\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:04 | INFO | Rank 0 | Train Epoch: 0 [99904/250314 (40%)]\tLoss: 0.535175\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:05 | INFO | Rank 0 | Train Epoch: 0 [99936/250314 (40%)]\tLoss: 0.470619\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:05 | INFO | Rank 0 | Train Epoch: 0 [99968/250314 (40%)]\tLoss: 1.120829\tData (t) 0.239\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:06 | INFO | Rank 0 | Train Epoch: 0 [100000/250314 (40%)]\tLoss: 0.653582\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:06 | INFO | Rank 0 | Train Epoch: 0 [100032/250314 (40%)]\tLoss: 0.685133\tData (t) 0.210\tBatch (t) 0.421\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:07 | INFO | Rank 0 | Train Epoch: 0 [100064/250314 (40%)]\tLoss: 0.645189\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:07 | INFO | Rank 0 | Train Epoch: 0 [100096/250314 (40%)]\tLoss: 0.795806\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:08 | INFO | Rank 0 | Train Epoch: 0 [100128/250314 (40%)]\tLoss: 0.554379\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:08 | INFO | Rank 0 | Train Epoch: 0 [100160/250314 (40%)]\tLoss: 0.841411\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:09 | INFO | Rank 0 | Train Epoch: 0 [100192/250314 (40%)]\tLoss: 1.088062\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:09 | INFO | Rank 0 | Train Epoch: 0 [100224/250314 (40%)]\tLoss: 0.646341\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:10 | INFO | Rank 0 | Train Epoch: 0 [100256/250314 (40%)]\tLoss: 0.715157\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:10 | INFO | Rank 0 | Train Epoch: 0 [100288/250314 (40%)]\tLoss: 1.397327\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:11 | INFO | Rank 0 | Train Epoch: 0 [100320/250314 (40%)]\tLoss: 0.987979\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:11 | INFO | Rank 0 | Train Epoch: 0 [100352/250314 (40%)]\tLoss: 0.736912\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:12 | INFO | Rank 0 | Train Epoch: 0 [100384/250314 (40%)]\tLoss: 1.010849\tData (t) 0.325\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:12 | INFO | Rank 0 | Train Epoch: 0 [100416/250314 (40%)]\tLoss: 1.070939\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:13 | INFO | Rank 0 | Train Epoch: 0 [100448/250314 (40%)]\tLoss: 0.885684\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:13 | INFO | Rank 0 | Train Epoch: 0 [100480/250314 (40%)]\tLoss: 1.183419\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:14 | INFO | Rank 0 | Train Epoch: 0 [100512/250314 (40%)]\tLoss: 0.498536\tData (t) 0.220\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:14 | INFO | Rank 0 | Train Epoch: 0 [100544/250314 (40%)]\tLoss: 0.819347\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:15 | INFO | Rank 0 | Train Epoch: 0 [100576/250314 (40%)]\tLoss: 0.821608\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:15 | INFO | Rank 0 | Train Epoch: 0 [100608/250314 (40%)]\tLoss: 1.001455\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:16 | INFO | Rank 0 | Train Epoch: 0 [100640/250314 (40%)]\tLoss: 0.521515\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:16 | INFO | Rank 0 | Train Epoch: 0 [100672/250314 (40%)]\tLoss: 0.917513\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:17 | INFO | Rank 0 | Train Epoch: 0 [100704/250314 (40%)]\tLoss: 1.164162\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:17 | INFO | Rank 0 | Train Epoch: 0 [100736/250314 (40%)]\tLoss: 1.016961\tData (t) 0.217\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.596\n",
      "2022-11-09,13:36:18 | INFO | Rank 0 | Train Epoch: 0 [100768/250314 (40%)]\tLoss: 0.783678\tData (t) 0.349\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:18 | INFO | Rank 0 | Train Epoch: 0 [100800/250314 (40%)]\tLoss: 0.875351\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:19 | INFO | Rank 0 | Train Epoch: 0 [100832/250314 (40%)]\tLoss: 1.156184\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:19 | INFO | Rank 0 | Train Epoch: 0 [100864/250314 (40%)]\tLoss: 0.604863\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:20 | INFO | Rank 0 | Train Epoch: 0 [100896/250314 (40%)]\tLoss: 0.545428\tData (t) 0.222\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:20 | INFO | Rank 0 | Train Epoch: 0 [100928/250314 (40%)]\tLoss: 0.744506\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:20 | INFO | Rank 0 | Train Epoch: 0 [100960/250314 (40%)]\tLoss: 0.753636\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:21 | INFO | Rank 0 | Train Epoch: 0 [100992/250314 (40%)]\tLoss: 0.674276\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:21 | INFO | Rank 0 | Train Epoch: 0 [101024/250314 (40%)]\tLoss: 0.581663\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:22 | INFO | Rank 0 | Train Epoch: 0 [101056/250314 (40%)]\tLoss: 1.056830\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:22 | INFO | Rank 0 | Train Epoch: 0 [101088/250314 (40%)]\tLoss: 0.824985\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:23 | INFO | Rank 0 | Train Epoch: 0 [101120/250314 (40%)]\tLoss: 0.938491\tData (t) 0.341\tBatch (t) 0.553\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:23 | INFO | Rank 0 | Train Epoch: 0 [101152/250314 (40%)]\tLoss: 0.538450\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:24 | INFO | Rank 0 | Train Epoch: 0 [101184/250314 (40%)]\tLoss: 1.049648\tData (t) 0.226\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:24 | INFO | Rank 0 | Train Epoch: 0 [101216/250314 (40%)]\tLoss: 0.661250\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:25 | INFO | Rank 0 | Train Epoch: 0 [101248/250314 (40%)]\tLoss: 1.028536\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:25 | INFO | Rank 0 | Train Epoch: 0 [101280/250314 (40%)]\tLoss: 0.895552\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:26 | INFO | Rank 0 | Train Epoch: 0 [101312/250314 (40%)]\tLoss: 0.716854\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:26 | INFO | Rank 0 | Train Epoch: 0 [101344/250314 (40%)]\tLoss: 0.504418\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:27 | INFO | Rank 0 | Train Epoch: 0 [101376/250314 (41%)]\tLoss: 0.721304\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:27 | INFO | Rank 0 | Train Epoch: 0 [101408/250314 (41%)]\tLoss: 0.867883\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:28 | INFO | Rank 0 | Train Epoch: 0 [101440/250314 (41%)]\tLoss: 0.764853\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:28 | INFO | Rank 0 | Train Epoch: 0 [101472/250314 (41%)]\tLoss: 0.914806\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:29 | INFO | Rank 0 | Train Epoch: 0 [101504/250314 (41%)]\tLoss: 0.854052\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:29 | INFO | Rank 0 | Train Epoch: 0 [101536/250314 (41%)]\tLoss: 0.763745\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:30 | INFO | Rank 0 | Train Epoch: 0 [101568/250314 (41%)]\tLoss: 1.096426\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:30 | INFO | Rank 0 | Train Epoch: 0 [101600/250314 (41%)]\tLoss: 0.710138\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:31 | INFO | Rank 0 | Train Epoch: 0 [101632/250314 (41%)]\tLoss: 0.901805\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:31 | INFO | Rank 0 | Train Epoch: 0 [101664/250314 (41%)]\tLoss: 0.673622\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:32 | INFO | Rank 0 | Train Epoch: 0 [101696/250314 (41%)]\tLoss: 1.008998\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:32 | INFO | Rank 0 | Train Epoch: 0 [101728/250314 (41%)]\tLoss: 1.007052\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:32 | INFO | Rank 0 | Train Epoch: 0 [101760/250314 (41%)]\tLoss: 0.697501\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:33 | INFO | Rank 0 | Train Epoch: 0 [101792/250314 (41%)]\tLoss: 0.745372\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:33 | INFO | Rank 0 | Train Epoch: 0 [101824/250314 (41%)]\tLoss: 0.855358\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:34 | INFO | Rank 0 | Train Epoch: 0 [101856/250314 (41%)]\tLoss: 0.678058\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:34 | INFO | Rank 0 | Train Epoch: 0 [101888/250314 (41%)]\tLoss: 0.500756\tData (t) 0.201\tBatch (t) 0.413\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:35 | INFO | Rank 0 | Train Epoch: 0 [101920/250314 (41%)]\tLoss: 0.663358\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:35 | INFO | Rank 0 | Train Epoch: 0 [101952/250314 (41%)]\tLoss: 1.208506\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:36 | INFO | Rank 0 | Train Epoch: 0 [101984/250314 (41%)]\tLoss: 0.732935\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:36 | INFO | Rank 0 | Train Epoch: 0 [102016/250314 (41%)]\tLoss: 0.702877\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:37 | INFO | Rank 0 | Train Epoch: 0 [102048/250314 (41%)]\tLoss: 0.345145\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:37 | INFO | Rank 0 | Train Epoch: 0 [102080/250314 (41%)]\tLoss: 0.478866\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:38 | INFO | Rank 0 | Train Epoch: 0 [102112/250314 (41%)]\tLoss: 1.124206\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:38 | INFO | Rank 0 | Train Epoch: 0 [102144/250314 (41%)]\tLoss: 0.655493\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:39 | INFO | Rank 0 | Train Epoch: 0 [102176/250314 (41%)]\tLoss: 1.213863\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:39 | INFO | Rank 0 | Train Epoch: 0 [102208/250314 (41%)]\tLoss: 0.569792\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:40 | INFO | Rank 0 | Train Epoch: 0 [102240/250314 (41%)]\tLoss: 1.107908\tData (t) 0.238\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:40 | INFO | Rank 0 | Train Epoch: 0 [102272/250314 (41%)]\tLoss: 0.728280\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:41 | INFO | Rank 0 | Train Epoch: 0 [102304/250314 (41%)]\tLoss: 0.903047\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:41 | INFO | Rank 0 | Train Epoch: 0 [102336/250314 (41%)]\tLoss: 0.885595\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:42 | INFO | Rank 0 | Train Epoch: 0 [102368/250314 (41%)]\tLoss: 1.043615\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:42 | INFO | Rank 0 | Train Epoch: 0 [102400/250314 (41%)]\tLoss: 0.599672\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:43 | INFO | Rank 0 | Train Epoch: 0 [102432/250314 (41%)]\tLoss: 0.869859\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:43 | INFO | Rank 0 | Train Epoch: 0 [102464/250314 (41%)]\tLoss: 1.134082\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:44 | INFO | Rank 0 | Train Epoch: 0 [102496/250314 (41%)]\tLoss: 0.626248\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:44 | INFO | Rank 0 | Train Epoch: 0 [102528/250314 (41%)]\tLoss: 0.640852\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:45 | INFO | Rank 0 | Train Epoch: 0 [102560/250314 (41%)]\tLoss: 0.553450\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:45 | INFO | Rank 0 | Train Epoch: 0 [102592/250314 (41%)]\tLoss: 0.546356\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:46 | INFO | Rank 0 | Train Epoch: 0 [102624/250314 (41%)]\tLoss: 1.024955\tData (t) 0.361\tBatch (t) 0.573\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:46 | INFO | Rank 0 | Train Epoch: 0 [102656/250314 (41%)]\tLoss: 0.802773\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:47 | INFO | Rank 0 | Train Epoch: 0 [102688/250314 (41%)]\tLoss: 0.752154\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:47 | INFO | Rank 0 | Train Epoch: 0 [102720/250314 (41%)]\tLoss: 0.747173\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:48 | INFO | Rank 0 | Train Epoch: 0 [102752/250314 (41%)]\tLoss: 0.675083\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:48 | INFO | Rank 0 | Train Epoch: 0 [102784/250314 (41%)]\tLoss: 0.645960\tData (t) 0.331\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:49 | INFO | Rank 0 | Train Epoch: 0 [102816/250314 (41%)]\tLoss: 0.470104\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:49 | INFO | Rank 0 | Train Epoch: 0 [102848/250314 (41%)]\tLoss: 0.684857\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:49 | INFO | Rank 0 | Train Epoch: 0 [102880/250314 (41%)]\tLoss: 0.527835\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:50 | INFO | Rank 0 | Train Epoch: 0 [102912/250314 (41%)]\tLoss: 0.804682\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:50 | INFO | Rank 0 | Train Epoch: 0 [102944/250314 (41%)]\tLoss: 0.790136\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:51 | INFO | Rank 0 | Train Epoch: 0 [102976/250314 (41%)]\tLoss: 0.820252\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:51 | INFO | Rank 0 | Train Epoch: 0 [103008/250314 (41%)]\tLoss: 1.038893\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:52 | INFO | Rank 0 | Train Epoch: 0 [103040/250314 (41%)]\tLoss: 0.828771\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:52 | INFO | Rank 0 | Train Epoch: 0 [103072/250314 (41%)]\tLoss: 0.554827\tData (t) 0.314\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:53 | INFO | Rank 0 | Train Epoch: 0 [103104/250314 (41%)]\tLoss: 1.005788\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:53 | INFO | Rank 0 | Train Epoch: 0 [103136/250314 (41%)]\tLoss: 1.077047\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:54 | INFO | Rank 0 | Train Epoch: 0 [103168/250314 (41%)]\tLoss: 1.022582\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:54 | INFO | Rank 0 | Train Epoch: 0 [103200/250314 (41%)]\tLoss: 0.816874\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:55 | INFO | Rank 0 | Train Epoch: 0 [103232/250314 (41%)]\tLoss: 1.024338\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:55 | INFO | Rank 0 | Train Epoch: 0 [103264/250314 (41%)]\tLoss: 0.339733\tData (t) 0.223\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:56 | INFO | Rank 0 | Train Epoch: 0 [103296/250314 (41%)]\tLoss: 0.708894\tData (t) 0.222\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:56 | INFO | Rank 0 | Train Epoch: 0 [103328/250314 (41%)]\tLoss: 0.682645\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:57 | INFO | Rank 0 | Train Epoch: 0 [103360/250314 (41%)]\tLoss: 0.466034\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:57 | INFO | Rank 0 | Train Epoch: 0 [103392/250314 (41%)]\tLoss: 0.924605\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:58 | INFO | Rank 0 | Train Epoch: 0 [103424/250314 (41%)]\tLoss: 1.102665\tData (t) 0.330\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:58 | INFO | Rank 0 | Train Epoch: 0 [103456/250314 (41%)]\tLoss: 0.761952\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:59 | INFO | Rank 0 | Train Epoch: 0 [103488/250314 (41%)]\tLoss: 0.645177\tData (t) 0.355\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:36:59 | INFO | Rank 0 | Train Epoch: 0 [103520/250314 (41%)]\tLoss: 0.588661\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:00 | INFO | Rank 0 | Train Epoch: 0 [103552/250314 (41%)]\tLoss: 0.888422\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:00 | INFO | Rank 0 | Train Epoch: 0 [103584/250314 (41%)]\tLoss: 0.636964\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:01 | INFO | Rank 0 | Train Epoch: 0 [103616/250314 (41%)]\tLoss: 0.763993\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:01 | INFO | Rank 0 | Train Epoch: 0 [103648/250314 (41%)]\tLoss: 0.568804\tData (t) 0.353\tBatch (t) 0.564\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:02 | INFO | Rank 0 | Train Epoch: 0 [103680/250314 (41%)]\tLoss: 0.888421\tData (t) 0.325\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:02 | INFO | Rank 0 | Train Epoch: 0 [103712/250314 (41%)]\tLoss: 0.649156\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:03 | INFO | Rank 0 | Train Epoch: 0 [103744/250314 (41%)]\tLoss: 0.605062\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:03 | INFO | Rank 0 | Train Epoch: 0 [103776/250314 (41%)]\tLoss: 0.925780\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:04 | INFO | Rank 0 | Train Epoch: 0 [103808/250314 (41%)]\tLoss: 0.880576\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:04 | INFO | Rank 0 | Train Epoch: 0 [103840/250314 (41%)]\tLoss: 1.086891\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:05 | INFO | Rank 0 | Train Epoch: 0 [103872/250314 (41%)]\tLoss: 0.627957\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:05 | INFO | Rank 0 | Train Epoch: 0 [103904/250314 (42%)]\tLoss: 0.594440\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:06 | INFO | Rank 0 | Train Epoch: 0 [103936/250314 (42%)]\tLoss: 0.610061\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:06 | INFO | Rank 0 | Train Epoch: 0 [103968/250314 (42%)]\tLoss: 0.508166\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:07 | INFO | Rank 0 | Train Epoch: 0 [104000/250314 (42%)]\tLoss: 0.976299\tData (t) 0.326\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:07 | INFO | Rank 0 | Train Epoch: 0 [104032/250314 (42%)]\tLoss: 0.754247\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:08 | INFO | Rank 0 | Train Epoch: 0 [104064/250314 (42%)]\tLoss: 0.801197\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:08 | INFO | Rank 0 | Train Epoch: 0 [104096/250314 (42%)]\tLoss: 0.822847\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:09 | INFO | Rank 0 | Train Epoch: 0 [104128/250314 (42%)]\tLoss: 0.772050\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:09 | INFO | Rank 0 | Train Epoch: 0 [104160/250314 (42%)]\tLoss: 0.600869\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:10 | INFO | Rank 0 | Train Epoch: 0 [104192/250314 (42%)]\tLoss: 0.864118\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:10 | INFO | Rank 0 | Train Epoch: 0 [104224/250314 (42%)]\tLoss: 0.946401\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:11 | INFO | Rank 0 | Train Epoch: 0 [104256/250314 (42%)]\tLoss: 1.347276\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:11 | INFO | Rank 0 | Train Epoch: 0 [104288/250314 (42%)]\tLoss: 0.547997\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:12 | INFO | Rank 0 | Train Epoch: 0 [104320/250314 (42%)]\tLoss: 0.969109\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:12 | INFO | Rank 0 | Train Epoch: 0 [104352/250314 (42%)]\tLoss: 1.182673\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:13 | INFO | Rank 0 | Train Epoch: 0 [104384/250314 (42%)]\tLoss: 0.948940\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:13 | INFO | Rank 0 | Train Epoch: 0 [104416/250314 (42%)]\tLoss: 0.884480\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:13 | INFO | Rank 0 | Train Epoch: 0 [104448/250314 (42%)]\tLoss: 1.067108\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:14 | INFO | Rank 0 | Train Epoch: 0 [104480/250314 (42%)]\tLoss: 0.603858\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:14 | INFO | Rank 0 | Train Epoch: 0 [104512/250314 (42%)]\tLoss: 0.708277\tData (t) 0.317\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:15 | INFO | Rank 0 | Train Epoch: 0 [104544/250314 (42%)]\tLoss: 0.517004\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:15 | INFO | Rank 0 | Train Epoch: 0 [104576/250314 (42%)]\tLoss: 0.515910\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:16 | INFO | Rank 0 | Train Epoch: 0 [104608/250314 (42%)]\tLoss: 0.936390\tData (t) 0.191\tBatch (t) 0.403\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:16 | INFO | Rank 0 | Train Epoch: 0 [104640/250314 (42%)]\tLoss: 0.837547\tData (t) 0.233\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:17 | INFO | Rank 0 | Train Epoch: 0 [104672/250314 (42%)]\tLoss: 0.882800\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:17 | INFO | Rank 0 | Train Epoch: 0 [104704/250314 (42%)]\tLoss: 1.230065\tData (t) 0.233\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:18 | INFO | Rank 0 | Train Epoch: 0 [104736/250314 (42%)]\tLoss: 0.673882\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:18 | INFO | Rank 0 | Train Epoch: 0 [104768/250314 (42%)]\tLoss: 0.914014\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:19 | INFO | Rank 0 | Train Epoch: 0 [104800/250314 (42%)]\tLoss: 1.144170\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:19 | INFO | Rank 0 | Train Epoch: 0 [104832/250314 (42%)]\tLoss: 0.946694\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:20 | INFO | Rank 0 | Train Epoch: 0 [104864/250314 (42%)]\tLoss: 0.322805\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:20 | INFO | Rank 0 | Train Epoch: 0 [104896/250314 (42%)]\tLoss: 0.594353\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:21 | INFO | Rank 0 | Train Epoch: 0 [104928/250314 (42%)]\tLoss: 0.663675\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:21 | INFO | Rank 0 | Train Epoch: 0 [104960/250314 (42%)]\tLoss: 0.812079\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:22 | INFO | Rank 0 | Train Epoch: 0 [104992/250314 (42%)]\tLoss: 0.752684\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:22 | INFO | Rank 0 | Train Epoch: 0 [105024/250314 (42%)]\tLoss: 0.600136\tData (t) 0.341\tBatch (t) 0.553\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:23 | INFO | Rank 0 | Train Epoch: 0 [105056/250314 (42%)]\tLoss: 0.999049\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:23 | INFO | Rank 0 | Train Epoch: 0 [105088/250314 (42%)]\tLoss: 0.807667\tData (t) 0.281\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:24 | INFO | Rank 0 | Train Epoch: 0 [105120/250314 (42%)]\tLoss: 0.770265\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:24 | INFO | Rank 0 | Train Epoch: 0 [105152/250314 (42%)]\tLoss: 0.370685\tData (t) 0.219\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:25 | INFO | Rank 0 | Train Epoch: 0 [105184/250314 (42%)]\tLoss: 0.938122\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:25 | INFO | Rank 0 | Train Epoch: 0 [105216/250314 (42%)]\tLoss: 0.938348\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:26 | INFO | Rank 0 | Train Epoch: 0 [105248/250314 (42%)]\tLoss: 0.788204\tData (t) 0.325\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:26 | INFO | Rank 0 | Train Epoch: 0 [105280/250314 (42%)]\tLoss: 0.818997\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:26 | INFO | Rank 0 | Train Epoch: 0 [105312/250314 (42%)]\tLoss: 0.825870\tData (t) 0.228\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:27 | INFO | Rank 0 | Train Epoch: 0 [105344/250314 (42%)]\tLoss: 0.493223\tData (t) 0.208\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:27 | INFO | Rank 0 | Train Epoch: 0 [105376/250314 (42%)]\tLoss: 0.749245\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:28 | INFO | Rank 0 | Train Epoch: 0 [105408/250314 (42%)]\tLoss: 1.010172\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:28 | INFO | Rank 0 | Train Epoch: 0 [105440/250314 (42%)]\tLoss: 0.641557\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:29 | INFO | Rank 0 | Train Epoch: 0 [105472/250314 (42%)]\tLoss: 0.659806\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:29 | INFO | Rank 0 | Train Epoch: 0 [105504/250314 (42%)]\tLoss: 0.818852\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:30 | INFO | Rank 0 | Train Epoch: 0 [105536/250314 (42%)]\tLoss: 0.804730\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:30 | INFO | Rank 0 | Train Epoch: 0 [105568/250314 (42%)]\tLoss: 0.787158\tData (t) 0.206\tBatch (t) 0.417\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:31 | INFO | Rank 0 | Train Epoch: 0 [105600/250314 (42%)]\tLoss: 0.603592\tData (t) 0.216\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:31 | INFO | Rank 0 | Train Epoch: 0 [105632/250314 (42%)]\tLoss: 0.546552\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:32 | INFO | Rank 0 | Train Epoch: 0 [105664/250314 (42%)]\tLoss: 0.707863\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:32 | INFO | Rank 0 | Train Epoch: 0 [105696/250314 (42%)]\tLoss: 0.559322\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:33 | INFO | Rank 0 | Train Epoch: 0 [105728/250314 (42%)]\tLoss: 1.148644\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:33 | INFO | Rank 0 | Train Epoch: 0 [105760/250314 (42%)]\tLoss: 0.938990\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:34 | INFO | Rank 0 | Train Epoch: 0 [105792/250314 (42%)]\tLoss: 0.719857\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:34 | INFO | Rank 0 | Train Epoch: 0 [105824/250314 (42%)]\tLoss: 0.745433\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:35 | INFO | Rank 0 | Train Epoch: 0 [105856/250314 (42%)]\tLoss: 0.699550\tData (t) 0.346\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:35 | INFO | Rank 0 | Train Epoch: 0 [105888/250314 (42%)]\tLoss: 0.733284\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:36 | INFO | Rank 0 | Train Epoch: 0 [105920/250314 (42%)]\tLoss: 0.821927\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:36 | INFO | Rank 0 | Train Epoch: 0 [105952/250314 (42%)]\tLoss: 1.329510\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:37 | INFO | Rank 0 | Train Epoch: 0 [105984/250314 (42%)]\tLoss: 0.943375\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:37 | INFO | Rank 0 | Train Epoch: 0 [106016/250314 (42%)]\tLoss: 0.486001\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:38 | INFO | Rank 0 | Train Epoch: 0 [106048/250314 (42%)]\tLoss: 0.834371\tData (t) 0.391\tBatch (t) 0.602\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:38 | INFO | Rank 0 | Train Epoch: 0 [106080/250314 (42%)]\tLoss: 0.999384\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:39 | INFO | Rank 0 | Train Epoch: 0 [106112/250314 (42%)]\tLoss: 0.712598\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:39 | INFO | Rank 0 | Train Epoch: 0 [106144/250314 (42%)]\tLoss: 0.851012\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:40 | INFO | Rank 0 | Train Epoch: 0 [106176/250314 (42%)]\tLoss: 0.332945\tData (t) 0.188\tBatch (t) 0.399\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:40 | INFO | Rank 0 | Train Epoch: 0 [106208/250314 (42%)]\tLoss: 0.953691\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:41 | INFO | Rank 0 | Train Epoch: 0 [106240/250314 (42%)]\tLoss: 0.674736\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:41 | INFO | Rank 0 | Train Epoch: 0 [106272/250314 (42%)]\tLoss: 0.831461\tData (t) 0.208\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:41 | INFO | Rank 0 | Train Epoch: 0 [106304/250314 (42%)]\tLoss: 0.641213\tData (t) 0.214\tBatch (t) 0.426\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:42 | INFO | Rank 0 | Train Epoch: 0 [106336/250314 (42%)]\tLoss: 1.230466\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:42 | INFO | Rank 0 | Train Epoch: 0 [106368/250314 (42%)]\tLoss: 0.914038\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:43 | INFO | Rank 0 | Train Epoch: 0 [106400/250314 (43%)]\tLoss: 0.765925\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:43 | INFO | Rank 0 | Train Epoch: 0 [106432/250314 (43%)]\tLoss: 0.722650\tData (t) 0.221\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:44 | INFO | Rank 0 | Train Epoch: 0 [106464/250314 (43%)]\tLoss: 1.308307\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:44 | INFO | Rank 0 | Train Epoch: 0 [106496/250314 (43%)]\tLoss: 0.759186\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:45 | INFO | Rank 0 | Train Epoch: 0 [106528/250314 (43%)]\tLoss: 0.814156\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:45 | INFO | Rank 0 | Train Epoch: 0 [106560/250314 (43%)]\tLoss: 0.845889\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:46 | INFO | Rank 0 | Train Epoch: 0 [106592/250314 (43%)]\tLoss: 0.742225\tData (t) 0.238\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:46 | INFO | Rank 0 | Train Epoch: 0 [106624/250314 (43%)]\tLoss: 0.713274\tData (t) 0.341\tBatch (t) 0.553\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:47 | INFO | Rank 0 | Train Epoch: 0 [106656/250314 (43%)]\tLoss: 0.640956\tData (t) 0.221\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:47 | INFO | Rank 0 | Train Epoch: 0 [106688/250314 (43%)]\tLoss: 0.859125\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:48 | INFO | Rank 0 | Train Epoch: 0 [106720/250314 (43%)]\tLoss: 0.737880\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:48 | INFO | Rank 0 | Train Epoch: 0 [106752/250314 (43%)]\tLoss: 0.737572\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:48 | INFO | Rank 0 | Train Epoch: 0 [106784/250314 (43%)]\tLoss: 0.563167\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:49 | INFO | Rank 0 | Train Epoch: 0 [106816/250314 (43%)]\tLoss: 0.572016\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:49 | INFO | Rank 0 | Train Epoch: 0 [106848/250314 (43%)]\tLoss: 0.750756\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:50 | INFO | Rank 0 | Train Epoch: 0 [106880/250314 (43%)]\tLoss: 0.549861\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:50 | INFO | Rank 0 | Train Epoch: 0 [106912/250314 (43%)]\tLoss: 1.183161\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:51 | INFO | Rank 0 | Train Epoch: 0 [106944/250314 (43%)]\tLoss: 0.624206\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:51 | INFO | Rank 0 | Train Epoch: 0 [106976/250314 (43%)]\tLoss: 1.271999\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:52 | INFO | Rank 0 | Train Epoch: 0 [107008/250314 (43%)]\tLoss: 0.725898\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:52 | INFO | Rank 0 | Train Epoch: 0 [107040/250314 (43%)]\tLoss: 0.826535\tData (t) 0.313\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:53 | INFO | Rank 0 | Train Epoch: 0 [107072/250314 (43%)]\tLoss: 1.440042\tData (t) 0.317\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:53 | INFO | Rank 0 | Train Epoch: 0 [107104/250314 (43%)]\tLoss: 0.566996\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:54 | INFO | Rank 0 | Train Epoch: 0 [107136/250314 (43%)]\tLoss: 1.080237\tData (t) 0.331\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:54 | INFO | Rank 0 | Train Epoch: 0 [107168/250314 (43%)]\tLoss: 0.701332\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:55 | INFO | Rank 0 | Train Epoch: 0 [107200/250314 (43%)]\tLoss: 0.552008\tData (t) 0.220\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:55 | INFO | Rank 0 | Train Epoch: 0 [107232/250314 (43%)]\tLoss: 0.467163\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:56 | INFO | Rank 0 | Train Epoch: 0 [107264/250314 (43%)]\tLoss: 1.152428\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:56 | INFO | Rank 0 | Train Epoch: 0 [107296/250314 (43%)]\tLoss: 1.105453\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:57 | INFO | Rank 0 | Train Epoch: 0 [107328/250314 (43%)]\tLoss: 0.891528\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:57 | INFO | Rank 0 | Train Epoch: 0 [107360/250314 (43%)]\tLoss: 0.425606\tData (t) 0.209\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:58 | INFO | Rank 0 | Train Epoch: 0 [107392/250314 (43%)]\tLoss: 0.976898\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:58 | INFO | Rank 0 | Train Epoch: 0 [107424/250314 (43%)]\tLoss: 1.120111\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:59 | INFO | Rank 0 | Train Epoch: 0 [107456/250314 (43%)]\tLoss: 0.597401\tData (t) 0.217\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:37:59 | INFO | Rank 0 | Train Epoch: 0 [107488/250314 (43%)]\tLoss: 0.655707\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:00 | INFO | Rank 0 | Train Epoch: 0 [107520/250314 (43%)]\tLoss: 1.223086\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:00 | INFO | Rank 0 | Train Epoch: 0 [107552/250314 (43%)]\tLoss: 0.961116\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:01 | INFO | Rank 0 | Train Epoch: 0 [107584/250314 (43%)]\tLoss: 0.858937\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:01 | INFO | Rank 0 | Train Epoch: 0 [107616/250314 (43%)]\tLoss: 1.444462\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:02 | INFO | Rank 0 | Train Epoch: 0 [107648/250314 (43%)]\tLoss: 0.532655\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:02 | INFO | Rank 0 | Train Epoch: 0 [107680/250314 (43%)]\tLoss: 0.594375\tData (t) 0.215\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:02 | INFO | Rank 0 | Train Epoch: 0 [107712/250314 (43%)]\tLoss: 0.453532\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:03 | INFO | Rank 0 | Train Epoch: 0 [107744/250314 (43%)]\tLoss: 0.585398\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:03 | INFO | Rank 0 | Train Epoch: 0 [107776/250314 (43%)]\tLoss: 0.743986\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:04 | INFO | Rank 0 | Train Epoch: 0 [107808/250314 (43%)]\tLoss: 1.045620\tData (t) 0.233\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:04 | INFO | Rank 0 | Train Epoch: 0 [107840/250314 (43%)]\tLoss: 0.590396\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:05 | INFO | Rank 0 | Train Epoch: 0 [107872/250314 (43%)]\tLoss: 0.640303\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:05 | INFO | Rank 0 | Train Epoch: 0 [107904/250314 (43%)]\tLoss: 0.564113\tData (t) 0.203\tBatch (t) 0.414\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:06 | INFO | Rank 0 | Train Epoch: 0 [107936/250314 (43%)]\tLoss: 0.868448\tData (t) 0.318\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:06 | INFO | Rank 0 | Train Epoch: 0 [107968/250314 (43%)]\tLoss: 0.932276\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:07 | INFO | Rank 0 | Train Epoch: 0 [108000/250314 (43%)]\tLoss: 0.851825\tData (t) 0.332\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:07 | INFO | Rank 0 | Train Epoch: 0 [108032/250314 (43%)]\tLoss: 0.490060\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:08 | INFO | Rank 0 | Train Epoch: 0 [108064/250314 (43%)]\tLoss: 0.308295\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:08 | INFO | Rank 0 | Train Epoch: 0 [108096/250314 (43%)]\tLoss: 0.812441\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:09 | INFO | Rank 0 | Train Epoch: 0 [108128/250314 (43%)]\tLoss: 0.916749\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:09 | INFO | Rank 0 | Train Epoch: 0 [108160/250314 (43%)]\tLoss: 0.913474\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:10 | INFO | Rank 0 | Train Epoch: 0 [108192/250314 (43%)]\tLoss: 0.610925\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:10 | INFO | Rank 0 | Train Epoch: 0 [108224/250314 (43%)]\tLoss: 1.297205\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:11 | INFO | Rank 0 | Train Epoch: 0 [108256/250314 (43%)]\tLoss: 0.858518\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:11 | INFO | Rank 0 | Train Epoch: 0 [108288/250314 (43%)]\tLoss: 0.688979\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:12 | INFO | Rank 0 | Train Epoch: 0 [108320/250314 (43%)]\tLoss: 0.743943\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:12 | INFO | Rank 0 | Train Epoch: 0 [108352/250314 (43%)]\tLoss: 0.763183\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:13 | INFO | Rank 0 | Train Epoch: 0 [108384/250314 (43%)]\tLoss: 0.922914\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:13 | INFO | Rank 0 | Train Epoch: 0 [108416/250314 (43%)]\tLoss: 0.943616\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:14 | INFO | Rank 0 | Train Epoch: 0 [108448/250314 (43%)]\tLoss: 0.967966\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:14 | INFO | Rank 0 | Train Epoch: 0 [108480/250314 (43%)]\tLoss: 0.632425\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:15 | INFO | Rank 0 | Train Epoch: 0 [108512/250314 (43%)]\tLoss: 0.583929\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:15 | INFO | Rank 0 | Train Epoch: 0 [108544/250314 (43%)]\tLoss: 1.043518\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:16 | INFO | Rank 0 | Train Epoch: 0 [108576/250314 (43%)]\tLoss: 0.922370\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:16 | INFO | Rank 0 | Train Epoch: 0 [108608/250314 (43%)]\tLoss: 1.329994\tData (t) 0.217\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:17 | INFO | Rank 0 | Train Epoch: 0 [108640/250314 (43%)]\tLoss: 0.645475\tData (t) 0.217\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:17 | INFO | Rank 0 | Train Epoch: 0 [108672/250314 (43%)]\tLoss: 0.839613\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:18 | INFO | Rank 0 | Train Epoch: 0 [108704/250314 (43%)]\tLoss: 0.658496\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:18 | INFO | Rank 0 | Train Epoch: 0 [108736/250314 (43%)]\tLoss: 0.494314\tData (t) 0.164\tBatch (t) 0.375\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:18 | INFO | Rank 0 | Train Epoch: 0 [108768/250314 (43%)]\tLoss: 0.410873\tData (t) 0.217\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:19 | INFO | Rank 0 | Train Epoch: 0 [108800/250314 (43%)]\tLoss: 0.833505\tData (t) 0.367\tBatch (t) 0.578\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:19 | INFO | Rank 0 | Train Epoch: 0 [108832/250314 (43%)]\tLoss: 0.714817\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:20 | INFO | Rank 0 | Train Epoch: 0 [108864/250314 (43%)]\tLoss: 0.742738\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:20 | INFO | Rank 0 | Train Epoch: 0 [108896/250314 (44%)]\tLoss: 0.562489\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:21 | INFO | Rank 0 | Train Epoch: 0 [108928/250314 (44%)]\tLoss: 1.000001\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:21 | INFO | Rank 0 | Train Epoch: 0 [108960/250314 (44%)]\tLoss: 0.822241\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:22 | INFO | Rank 0 | Train Epoch: 0 [108992/250314 (44%)]\tLoss: 1.134115\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:22 | INFO | Rank 0 | Train Epoch: 0 [109024/250314 (44%)]\tLoss: 0.838087\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:23 | INFO | Rank 0 | Train Epoch: 0 [109056/250314 (44%)]\tLoss: 0.520950\tData (t) 0.271\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:23 | INFO | Rank 0 | Train Epoch: 0 [109088/250314 (44%)]\tLoss: 0.911150\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:24 | INFO | Rank 0 | Train Epoch: 0 [109120/250314 (44%)]\tLoss: 0.715207\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:24 | INFO | Rank 0 | Train Epoch: 0 [109152/250314 (44%)]\tLoss: 0.703063\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:25 | INFO | Rank 0 | Train Epoch: 0 [109184/250314 (44%)]\tLoss: 0.904503\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:25 | INFO | Rank 0 | Train Epoch: 0 [109216/250314 (44%)]\tLoss: 0.809649\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:26 | INFO | Rank 0 | Train Epoch: 0 [109248/250314 (44%)]\tLoss: 0.533746\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:26 | INFO | Rank 0 | Train Epoch: 0 [109280/250314 (44%)]\tLoss: 0.470471\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:27 | INFO | Rank 0 | Train Epoch: 0 [109312/250314 (44%)]\tLoss: 0.669442\tData (t) 0.217\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:27 | INFO | Rank 0 | Train Epoch: 0 [109344/250314 (44%)]\tLoss: 0.656516\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:28 | INFO | Rank 0 | Train Epoch: 0 [109376/250314 (44%)]\tLoss: 0.656954\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:28 | INFO | Rank 0 | Train Epoch: 0 [109408/250314 (44%)]\tLoss: 0.831252\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:29 | INFO | Rank 0 | Train Epoch: 0 [109440/250314 (44%)]\tLoss: 0.463773\tData (t) 0.275\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:29 | INFO | Rank 0 | Train Epoch: 0 [109472/250314 (44%)]\tLoss: 0.992455\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:29 | INFO | Rank 0 | Train Epoch: 0 [109504/250314 (44%)]\tLoss: 0.259691\tData (t) 0.229\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:30 | INFO | Rank 0 | Train Epoch: 0 [109536/250314 (44%)]\tLoss: 0.569250\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:30 | INFO | Rank 0 | Train Epoch: 0 [109568/250314 (44%)]\tLoss: 1.097463\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:31 | INFO | Rank 0 | Train Epoch: 0 [109600/250314 (44%)]\tLoss: 0.673028\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:31 | INFO | Rank 0 | Train Epoch: 0 [109632/250314 (44%)]\tLoss: 0.837225\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:32 | INFO | Rank 0 | Train Epoch: 0 [109664/250314 (44%)]\tLoss: 0.684137\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:32 | INFO | Rank 0 | Train Epoch: 0 [109696/250314 (44%)]\tLoss: 0.748573\tData (t) 0.191\tBatch (t) 0.402\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:33 | INFO | Rank 0 | Train Epoch: 0 [109728/250314 (44%)]\tLoss: 1.159000\tData (t) 0.380\tBatch (t) 0.592\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:33 | INFO | Rank 0 | Train Epoch: 0 [109760/250314 (44%)]\tLoss: 0.451144\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:34 | INFO | Rank 0 | Train Epoch: 0 [109792/250314 (44%)]\tLoss: 0.437502\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:34 | INFO | Rank 0 | Train Epoch: 0 [109824/250314 (44%)]\tLoss: 0.491076\tData (t) 0.226\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:35 | INFO | Rank 0 | Train Epoch: 0 [109856/250314 (44%)]\tLoss: 0.947340\tData (t) 0.277\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:35 | INFO | Rank 0 | Train Epoch: 0 [109888/250314 (44%)]\tLoss: 0.858822\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:36 | INFO | Rank 0 | Train Epoch: 0 [109920/250314 (44%)]\tLoss: 0.782047\tData (t) 0.280\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:36 | INFO | Rank 0 | Train Epoch: 0 [109952/250314 (44%)]\tLoss: 0.874611\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:37 | INFO | Rank 0 | Train Epoch: 0 [109984/250314 (44%)]\tLoss: 0.701756\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:37 | INFO | Rank 0 | Train Epoch: 0 [110016/250314 (44%)]\tLoss: 0.654044\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:38 | INFO | Rank 0 | Train Epoch: 0 [110048/250314 (44%)]\tLoss: 0.495628\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:38 | INFO | Rank 0 | Train Epoch: 0 [110080/250314 (44%)]\tLoss: 0.690452\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:39 | INFO | Rank 0 | Train Epoch: 0 [110112/250314 (44%)]\tLoss: 0.557872\tData (t) 0.211\tBatch (t) 0.422\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:39 | INFO | Rank 0 | Train Epoch: 0 [110144/250314 (44%)]\tLoss: 0.886102\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:40 | INFO | Rank 0 | Train Epoch: 0 [110176/250314 (44%)]\tLoss: 0.612923\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:40 | INFO | Rank 0 | Train Epoch: 0 [110208/250314 (44%)]\tLoss: 1.162008\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:41 | INFO | Rank 0 | Train Epoch: 0 [110240/250314 (44%)]\tLoss: 0.749466\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:41 | INFO | Rank 0 | Train Epoch: 0 [110272/250314 (44%)]\tLoss: 0.903532\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:41 | INFO | Rank 0 | Train Epoch: 0 [110304/250314 (44%)]\tLoss: 0.738212\tData (t) 0.212\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:42 | INFO | Rank 0 | Train Epoch: 0 [110336/250314 (44%)]\tLoss: 0.530700\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:42 | INFO | Rank 0 | Train Epoch: 0 [110368/250314 (44%)]\tLoss: 0.536881\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:43 | INFO | Rank 0 | Train Epoch: 0 [110400/250314 (44%)]\tLoss: 0.782462\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:43 | INFO | Rank 0 | Train Epoch: 0 [110432/250314 (44%)]\tLoss: 0.720222\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:44 | INFO | Rank 0 | Train Epoch: 0 [110464/250314 (44%)]\tLoss: 0.695215\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:44 | INFO | Rank 0 | Train Epoch: 0 [110496/250314 (44%)]\tLoss: 0.943939\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:45 | INFO | Rank 0 | Train Epoch: 0 [110528/250314 (44%)]\tLoss: 0.936449\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:45 | INFO | Rank 0 | Train Epoch: 0 [110560/250314 (44%)]\tLoss: 1.041301\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:46 | INFO | Rank 0 | Train Epoch: 0 [110592/250314 (44%)]\tLoss: 0.856361\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:46 | INFO | Rank 0 | Train Epoch: 0 [110624/250314 (44%)]\tLoss: 1.021176\tData (t) 0.364\tBatch (t) 0.575\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:47 | INFO | Rank 0 | Train Epoch: 0 [110656/250314 (44%)]\tLoss: 0.652291\tData (t) 0.334\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:47 | INFO | Rank 0 | Train Epoch: 0 [110688/250314 (44%)]\tLoss: 0.526125\tData (t) 0.244\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:48 | INFO | Rank 0 | Train Epoch: 0 [110720/250314 (44%)]\tLoss: 0.605325\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:48 | INFO | Rank 0 | Train Epoch: 0 [110752/250314 (44%)]\tLoss: 0.630269\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:49 | INFO | Rank 0 | Train Epoch: 0 [110784/250314 (44%)]\tLoss: 0.779477\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:49 | INFO | Rank 0 | Train Epoch: 0 [110816/250314 (44%)]\tLoss: 1.006407\tData (t) 0.403\tBatch (t) 0.614\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:50 | INFO | Rank 0 | Train Epoch: 0 [110848/250314 (44%)]\tLoss: 1.061376\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:50 | INFO | Rank 0 | Train Epoch: 0 [110880/250314 (44%)]\tLoss: 0.746763\tData (t) 0.220\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:51 | INFO | Rank 0 | Train Epoch: 0 [110912/250314 (44%)]\tLoss: 0.762280\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:51 | INFO | Rank 0 | Train Epoch: 0 [110944/250314 (44%)]\tLoss: 0.697465\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:52 | INFO | Rank 0 | Train Epoch: 0 [110976/250314 (44%)]\tLoss: 0.742592\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:52 | INFO | Rank 0 | Train Epoch: 0 [111008/250314 (44%)]\tLoss: 1.005397\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:53 | INFO | Rank 0 | Train Epoch: 0 [111040/250314 (44%)]\tLoss: 0.654335\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:53 | INFO | Rank 0 | Train Epoch: 0 [111072/250314 (44%)]\tLoss: 0.693279\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:54 | INFO | Rank 0 | Train Epoch: 0 [111104/250314 (44%)]\tLoss: 0.873308\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:54 | INFO | Rank 0 | Train Epoch: 0 [111136/250314 (44%)]\tLoss: 0.903883\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:55 | INFO | Rank 0 | Train Epoch: 0 [111168/250314 (44%)]\tLoss: 0.934271\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:55 | INFO | Rank 0 | Train Epoch: 0 [111200/250314 (44%)]\tLoss: 1.171581\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:56 | INFO | Rank 0 | Train Epoch: 0 [111232/250314 (44%)]\tLoss: 0.486901\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:56 | INFO | Rank 0 | Train Epoch: 0 [111264/250314 (44%)]\tLoss: 0.727918\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:57 | INFO | Rank 0 | Train Epoch: 0 [111296/250314 (44%)]\tLoss: 0.707712\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:57 | INFO | Rank 0 | Train Epoch: 0 [111328/250314 (44%)]\tLoss: 0.508269\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:58 | INFO | Rank 0 | Train Epoch: 0 [111360/250314 (44%)]\tLoss: 0.965047\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:58 | INFO | Rank 0 | Train Epoch: 0 [111392/250314 (45%)]\tLoss: 0.624672\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:58 | INFO | Rank 0 | Train Epoch: 0 [111424/250314 (45%)]\tLoss: 0.883603\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:59 | INFO | Rank 0 | Train Epoch: 0 [111456/250314 (45%)]\tLoss: 0.912886\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:38:59 | INFO | Rank 0 | Train Epoch: 0 [111488/250314 (45%)]\tLoss: 0.871596\tData (t) 0.314\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:00 | INFO | Rank 0 | Train Epoch: 0 [111520/250314 (45%)]\tLoss: 0.511346\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:00 | INFO | Rank 0 | Train Epoch: 0 [111552/250314 (45%)]\tLoss: 0.827880\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:01 | INFO | Rank 0 | Train Epoch: 0 [111584/250314 (45%)]\tLoss: 0.897111\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:01 | INFO | Rank 0 | Train Epoch: 0 [111616/250314 (45%)]\tLoss: 0.583737\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:02 | INFO | Rank 0 | Train Epoch: 0 [111648/250314 (45%)]\tLoss: 0.644398\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:02 | INFO | Rank 0 | Train Epoch: 0 [111680/250314 (45%)]\tLoss: 0.501359\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:03 | INFO | Rank 0 | Train Epoch: 0 [111712/250314 (45%)]\tLoss: 0.900798\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:03 | INFO | Rank 0 | Train Epoch: 0 [111744/250314 (45%)]\tLoss: 0.802359\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:04 | INFO | Rank 0 | Train Epoch: 0 [111776/250314 (45%)]\tLoss: 0.523356\tData (t) 0.212\tBatch (t) 0.423\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:04 | INFO | Rank 0 | Train Epoch: 0 [111808/250314 (45%)]\tLoss: 0.898767\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:05 | INFO | Rank 0 | Train Epoch: 0 [111840/250314 (45%)]\tLoss: 1.092041\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:05 | INFO | Rank 0 | Train Epoch: 0 [111872/250314 (45%)]\tLoss: 0.969178\tData (t) 0.353\tBatch (t) 0.565\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:06 | INFO | Rank 0 | Train Epoch: 0 [111904/250314 (45%)]\tLoss: 0.481410\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:06 | INFO | Rank 0 | Train Epoch: 0 [111936/250314 (45%)]\tLoss: 1.297702\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:07 | INFO | Rank 0 | Train Epoch: 0 [111968/250314 (45%)]\tLoss: 0.333091\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:07 | INFO | Rank 0 | Train Epoch: 0 [112000/250314 (45%)]\tLoss: 0.824444\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:08 | INFO | Rank 0 | Train Epoch: 0 [112032/250314 (45%)]\tLoss: 1.037380\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:08 | INFO | Rank 0 | Train Epoch: 0 [112064/250314 (45%)]\tLoss: 0.636231\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:09 | INFO | Rank 0 | Train Epoch: 0 [112096/250314 (45%)]\tLoss: 0.681944\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:09 | INFO | Rank 0 | Train Epoch: 0 [112128/250314 (45%)]\tLoss: 0.450320\tData (t) 0.233\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:10 | INFO | Rank 0 | Train Epoch: 0 [112160/250314 (45%)]\tLoss: 0.692221\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:10 | INFO | Rank 0 | Train Epoch: 0 [112192/250314 (45%)]\tLoss: 1.056382\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:11 | INFO | Rank 0 | Train Epoch: 0 [112224/250314 (45%)]\tLoss: 1.056583\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:11 | INFO | Rank 0 | Train Epoch: 0 [112256/250314 (45%)]\tLoss: 1.044758\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:12 | INFO | Rank 0 | Train Epoch: 0 [112288/250314 (45%)]\tLoss: 1.092401\tData (t) 0.214\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:12 | INFO | Rank 0 | Train Epoch: 0 [112320/250314 (45%)]\tLoss: 0.536014\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:12 | INFO | Rank 0 | Train Epoch: 0 [112352/250314 (45%)]\tLoss: 0.574730\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:13 | INFO | Rank 0 | Train Epoch: 0 [112384/250314 (45%)]\tLoss: 0.575738\tData (t) 0.312\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:13 | INFO | Rank 0 | Train Epoch: 0 [112416/250314 (45%)]\tLoss: 0.643823\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:14 | INFO | Rank 0 | Train Epoch: 0 [112448/250314 (45%)]\tLoss: 0.676836\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:14 | INFO | Rank 0 | Train Epoch: 0 [112480/250314 (45%)]\tLoss: 1.061551\tData (t) 0.216\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:15 | INFO | Rank 0 | Train Epoch: 0 [112512/250314 (45%)]\tLoss: 1.105402\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:15 | INFO | Rank 0 | Train Epoch: 0 [112544/250314 (45%)]\tLoss: 0.802803\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:16 | INFO | Rank 0 | Train Epoch: 0 [112576/250314 (45%)]\tLoss: 0.681457\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:16 | INFO | Rank 0 | Train Epoch: 0 [112608/250314 (45%)]\tLoss: 0.876084\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:17 | INFO | Rank 0 | Train Epoch: 0 [112640/250314 (45%)]\tLoss: 0.554613\tData (t) 0.207\tBatch (t) 0.418\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:17 | INFO | Rank 0 | Train Epoch: 0 [112672/250314 (45%)]\tLoss: 0.683646\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:18 | INFO | Rank 0 | Train Epoch: 0 [112704/250314 (45%)]\tLoss: 0.656815\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:18 | INFO | Rank 0 | Train Epoch: 0 [112736/250314 (45%)]\tLoss: 0.808670\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:19 | INFO | Rank 0 | Train Epoch: 0 [112768/250314 (45%)]\tLoss: 0.536443\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:19 | INFO | Rank 0 | Train Epoch: 0 [112800/250314 (45%)]\tLoss: 0.681732\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:20 | INFO | Rank 0 | Train Epoch: 0 [112832/250314 (45%)]\tLoss: 0.918844\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:20 | INFO | Rank 0 | Train Epoch: 0 [112864/250314 (45%)]\tLoss: 0.933528\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:21 | INFO | Rank 0 | Train Epoch: 0 [112896/250314 (45%)]\tLoss: 0.757883\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:21 | INFO | Rank 0 | Train Epoch: 0 [112928/250314 (45%)]\tLoss: 0.842524\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:22 | INFO | Rank 0 | Train Epoch: 0 [112960/250314 (45%)]\tLoss: 0.869503\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:22 | INFO | Rank 0 | Train Epoch: 0 [112992/250314 (45%)]\tLoss: 0.682230\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:23 | INFO | Rank 0 | Train Epoch: 0 [113024/250314 (45%)]\tLoss: 0.598062\tData (t) 0.429\tBatch (t) 0.641\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:23 | INFO | Rank 0 | Train Epoch: 0 [113056/250314 (45%)]\tLoss: 0.804952\tData (t) 0.351\tBatch (t) 0.562\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:24 | INFO | Rank 0 | Train Epoch: 0 [113088/250314 (45%)]\tLoss: 0.418785\tData (t) 0.216\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:24 | INFO | Rank 0 | Train Epoch: 0 [113120/250314 (45%)]\tLoss: 0.832459\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:25 | INFO | Rank 0 | Train Epoch: 0 [113152/250314 (45%)]\tLoss: 0.650700\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:25 | INFO | Rank 0 | Train Epoch: 0 [113184/250314 (45%)]\tLoss: 0.990164\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:26 | INFO | Rank 0 | Train Epoch: 0 [113216/250314 (45%)]\tLoss: 0.897644\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:26 | INFO | Rank 0 | Train Epoch: 0 [113248/250314 (45%)]\tLoss: 0.494001\tData (t) 0.333\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:27 | INFO | Rank 0 | Train Epoch: 0 [113280/250314 (45%)]\tLoss: 1.261321\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:27 | INFO | Rank 0 | Train Epoch: 0 [113312/250314 (45%)]\tLoss: 0.515593\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:28 | INFO | Rank 0 | Train Epoch: 0 [113344/250314 (45%)]\tLoss: 0.465195\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:28 | INFO | Rank 0 | Train Epoch: 0 [113376/250314 (45%)]\tLoss: 0.567747\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:29 | INFO | Rank 0 | Train Epoch: 0 [113408/250314 (45%)]\tLoss: 0.858263\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:29 | INFO | Rank 0 | Train Epoch: 0 [113440/250314 (45%)]\tLoss: 0.625535\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:30 | INFO | Rank 0 | Train Epoch: 0 [113472/250314 (45%)]\tLoss: 0.679738\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:30 | INFO | Rank 0 | Train Epoch: 0 [113504/250314 (45%)]\tLoss: 0.644276\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:30 | INFO | Rank 0 | Train Epoch: 0 [113536/250314 (45%)]\tLoss: 0.738935\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:31 | INFO | Rank 0 | Train Epoch: 0 [113568/250314 (45%)]\tLoss: 0.987935\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:31 | INFO | Rank 0 | Train Epoch: 0 [113600/250314 (45%)]\tLoss: 0.958109\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:32 | INFO | Rank 0 | Train Epoch: 0 [113632/250314 (45%)]\tLoss: 0.801342\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:32 | INFO | Rank 0 | Train Epoch: 0 [113664/250314 (45%)]\tLoss: 0.836932\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:33 | INFO | Rank 0 | Train Epoch: 0 [113696/250314 (45%)]\tLoss: 1.146492\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:33 | INFO | Rank 0 | Train Epoch: 0 [113728/250314 (45%)]\tLoss: 0.931949\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:34 | INFO | Rank 0 | Train Epoch: 0 [113760/250314 (45%)]\tLoss: 0.325919\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:34 | INFO | Rank 0 | Train Epoch: 0 [113792/250314 (45%)]\tLoss: 0.849776\tData (t) 0.293\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:35 | INFO | Rank 0 | Train Epoch: 0 [113824/250314 (45%)]\tLoss: 0.910839\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:35 | INFO | Rank 0 | Train Epoch: 0 [113856/250314 (45%)]\tLoss: 0.632067\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:36 | INFO | Rank 0 | Train Epoch: 0 [113888/250314 (45%)]\tLoss: 0.856454\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:36 | INFO | Rank 0 | Train Epoch: 0 [113920/250314 (46%)]\tLoss: 0.695531\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:37 | INFO | Rank 0 | Train Epoch: 0 [113952/250314 (46%)]\tLoss: 0.976884\tData (t) 0.338\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:37 | INFO | Rank 0 | Train Epoch: 0 [113984/250314 (46%)]\tLoss: 0.815282\tData (t) 0.231\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:38 | INFO | Rank 0 | Train Epoch: 0 [114016/250314 (46%)]\tLoss: 0.682239\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:38 | INFO | Rank 0 | Train Epoch: 0 [114048/250314 (46%)]\tLoss: 0.803207\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:39 | INFO | Rank 0 | Train Epoch: 0 [114080/250314 (46%)]\tLoss: 0.878256\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:39 | INFO | Rank 0 | Train Epoch: 0 [114112/250314 (46%)]\tLoss: 0.836780\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:40 | INFO | Rank 0 | Train Epoch: 0 [114144/250314 (46%)]\tLoss: 1.064842\tData (t) 0.312\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:40 | INFO | Rank 0 | Train Epoch: 0 [114176/250314 (46%)]\tLoss: 1.178350\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:41 | INFO | Rank 0 | Train Epoch: 0 [114208/250314 (46%)]\tLoss: 0.866619\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:41 | INFO | Rank 0 | Train Epoch: 0 [114240/250314 (46%)]\tLoss: 0.590055\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:42 | INFO | Rank 0 | Train Epoch: 0 [114272/250314 (46%)]\tLoss: 0.948074\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:42 | INFO | Rank 0 | Train Epoch: 0 [114304/250314 (46%)]\tLoss: 0.989620\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:43 | INFO | Rank 0 | Train Epoch: 0 [114336/250314 (46%)]\tLoss: 1.240983\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:43 | INFO | Rank 0 | Train Epoch: 0 [114368/250314 (46%)]\tLoss: 0.752784\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:44 | INFO | Rank 0 | Train Epoch: 0 [114400/250314 (46%)]\tLoss: 0.528177\tData (t) 0.321\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:44 | INFO | Rank 0 | Train Epoch: 0 [114432/250314 (46%)]\tLoss: 0.411821\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:45 | INFO | Rank 0 | Train Epoch: 0 [114464/250314 (46%)]\tLoss: 0.714741\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:45 | INFO | Rank 0 | Train Epoch: 0 [114496/250314 (46%)]\tLoss: 0.858747\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:46 | INFO | Rank 0 | Train Epoch: 0 [114528/250314 (46%)]\tLoss: 0.506764\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:46 | INFO | Rank 0 | Train Epoch: 0 [114560/250314 (46%)]\tLoss: 1.162577\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:47 | INFO | Rank 0 | Train Epoch: 0 [114592/250314 (46%)]\tLoss: 0.523872\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:47 | INFO | Rank 0 | Train Epoch: 0 [114624/250314 (46%)]\tLoss: 1.237384\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:48 | INFO | Rank 0 | Train Epoch: 0 [114656/250314 (46%)]\tLoss: 0.960064\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:48 | INFO | Rank 0 | Train Epoch: 0 [114688/250314 (46%)]\tLoss: 0.839395\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:49 | INFO | Rank 0 | Train Epoch: 0 [114720/250314 (46%)]\tLoss: 1.172530\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:49 | INFO | Rank 0 | Train Epoch: 0 [114752/250314 (46%)]\tLoss: 0.442237\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:50 | INFO | Rank 0 | Train Epoch: 0 [114784/250314 (46%)]\tLoss: 0.774230\tData (t) 0.295\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:50 | INFO | Rank 0 | Train Epoch: 0 [114816/250314 (46%)]\tLoss: 1.144559\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:51 | INFO | Rank 0 | Train Epoch: 0 [114848/250314 (46%)]\tLoss: 0.765580\tData (t) 0.340\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:51 | INFO | Rank 0 | Train Epoch: 0 [114880/250314 (46%)]\tLoss: 0.398208\tData (t) 0.220\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:52 | INFO | Rank 0 | Train Epoch: 0 [114912/250314 (46%)]\tLoss: 1.027878\tData (t) 0.357\tBatch (t) 0.568\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:52 | INFO | Rank 0 | Train Epoch: 0 [114944/250314 (46%)]\tLoss: 0.707983\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:53 | INFO | Rank 0 | Train Epoch: 0 [114976/250314 (46%)]\tLoss: 0.797693\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:53 | INFO | Rank 0 | Train Epoch: 0 [115008/250314 (46%)]\tLoss: 0.718177\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:54 | INFO | Rank 0 | Train Epoch: 0 [115040/250314 (46%)]\tLoss: 0.515643\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:54 | INFO | Rank 0 | Train Epoch: 0 [115072/250314 (46%)]\tLoss: 0.696180\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:55 | INFO | Rank 0 | Train Epoch: 0 [115104/250314 (46%)]\tLoss: 0.544387\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:55 | INFO | Rank 0 | Train Epoch: 0 [115136/250314 (46%)]\tLoss: 0.890569\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:56 | INFO | Rank 0 | Train Epoch: 0 [115168/250314 (46%)]\tLoss: 1.134498\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:56 | INFO | Rank 0 | Train Epoch: 0 [115200/250314 (46%)]\tLoss: 0.834653\tData (t) 0.318\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:57 | INFO | Rank 0 | Train Epoch: 0 [115232/250314 (46%)]\tLoss: 0.759164\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:57 | INFO | Rank 0 | Train Epoch: 0 [115264/250314 (46%)]\tLoss: 0.707953\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:58 | INFO | Rank 0 | Train Epoch: 0 [115296/250314 (46%)]\tLoss: 0.968381\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:58 | INFO | Rank 0 | Train Epoch: 0 [115328/250314 (46%)]\tLoss: 0.784245\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:59 | INFO | Rank 0 | Train Epoch: 0 [115360/250314 (46%)]\tLoss: 0.937317\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:39:59 | INFO | Rank 0 | Train Epoch: 0 [115392/250314 (46%)]\tLoss: 0.862593\tData (t) 0.433\tBatch (t) 0.644\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:00 | INFO | Rank 0 | Train Epoch: 0 [115424/250314 (46%)]\tLoss: 0.828272\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:00 | INFO | Rank 0 | Train Epoch: 0 [115456/250314 (46%)]\tLoss: 0.875710\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:01 | INFO | Rank 0 | Train Epoch: 0 [115488/250314 (46%)]\tLoss: 0.288715\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:01 | INFO | Rank 0 | Train Epoch: 0 [115520/250314 (46%)]\tLoss: 0.634026\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:02 | INFO | Rank 0 | Train Epoch: 0 [115552/250314 (46%)]\tLoss: 1.453188\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:02 | INFO | Rank 0 | Train Epoch: 0 [115584/250314 (46%)]\tLoss: 0.696864\tData (t) 0.335\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:03 | INFO | Rank 0 | Train Epoch: 0 [115616/250314 (46%)]\tLoss: 0.657320\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:03 | INFO | Rank 0 | Train Epoch: 0 [115648/250314 (46%)]\tLoss: 0.265907\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:04 | INFO | Rank 0 | Train Epoch: 0 [115680/250314 (46%)]\tLoss: 0.731720\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:04 | INFO | Rank 0 | Train Epoch: 0 [115712/250314 (46%)]\tLoss: 0.806771\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:05 | INFO | Rank 0 | Train Epoch: 0 [115744/250314 (46%)]\tLoss: 0.777092\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:05 | INFO | Rank 0 | Train Epoch: 0 [115776/250314 (46%)]\tLoss: 0.758052\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:06 | INFO | Rank 0 | Train Epoch: 0 [115808/250314 (46%)]\tLoss: 0.712077\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:06 | INFO | Rank 0 | Train Epoch: 0 [115840/250314 (46%)]\tLoss: 0.682762\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:07 | INFO | Rank 0 | Train Epoch: 0 [115872/250314 (46%)]\tLoss: 0.639083\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:07 | INFO | Rank 0 | Train Epoch: 0 [115904/250314 (46%)]\tLoss: 1.020342\tData (t) 0.540\tBatch (t) 0.752\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:08 | INFO | Rank 0 | Train Epoch: 0 [115936/250314 (46%)]\tLoss: 0.736220\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:08 | INFO | Rank 0 | Train Epoch: 0 [115968/250314 (46%)]\tLoss: 0.518569\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:09 | INFO | Rank 0 | Train Epoch: 0 [116000/250314 (46%)]\tLoss: 0.867022\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:09 | INFO | Rank 0 | Train Epoch: 0 [116032/250314 (46%)]\tLoss: 0.909483\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:10 | INFO | Rank 0 | Train Epoch: 0 [116064/250314 (46%)]\tLoss: 0.597124\tData (t) 0.299\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:10 | INFO | Rank 0 | Train Epoch: 0 [116096/250314 (46%)]\tLoss: 1.112507\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:11 | INFO | Rank 0 | Train Epoch: 0 [116128/250314 (46%)]\tLoss: 0.476435\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:11 | INFO | Rank 0 | Train Epoch: 0 [116160/250314 (46%)]\tLoss: 1.136582\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:12 | INFO | Rank 0 | Train Epoch: 0 [116192/250314 (46%)]\tLoss: 0.795053\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:12 | INFO | Rank 0 | Train Epoch: 0 [116224/250314 (46%)]\tLoss: 0.610323\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:13 | INFO | Rank 0 | Train Epoch: 0 [116256/250314 (46%)]\tLoss: 0.385019\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:13 | INFO | Rank 0 | Train Epoch: 0 [116288/250314 (46%)]\tLoss: 0.858348\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:14 | INFO | Rank 0 | Train Epoch: 0 [116320/250314 (46%)]\tLoss: 0.596311\tData (t) 0.314\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:14 | INFO | Rank 0 | Train Epoch: 0 [116352/250314 (46%)]\tLoss: 0.765659\tData (t) 0.290\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:15 | INFO | Rank 0 | Train Epoch: 0 [116384/250314 (46%)]\tLoss: 0.979180\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:15 | INFO | Rank 0 | Train Epoch: 0 [116416/250314 (47%)]\tLoss: 0.782549\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:16 | INFO | Rank 0 | Train Epoch: 0 [116448/250314 (47%)]\tLoss: 0.715410\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:16 | INFO | Rank 0 | Train Epoch: 0 [116480/250314 (47%)]\tLoss: 0.394321\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:17 | INFO | Rank 0 | Train Epoch: 0 [116512/250314 (47%)]\tLoss: 0.418319\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:17 | INFO | Rank 0 | Train Epoch: 0 [116544/250314 (47%)]\tLoss: 0.537801\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:18 | INFO | Rank 0 | Train Epoch: 0 [116576/250314 (47%)]\tLoss: 0.773950\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:18 | INFO | Rank 0 | Train Epoch: 0 [116608/250314 (47%)]\tLoss: 1.126603\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:19 | INFO | Rank 0 | Train Epoch: 0 [116640/250314 (47%)]\tLoss: 0.720767\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:19 | INFO | Rank 0 | Train Epoch: 0 [116672/250314 (47%)]\tLoss: 1.145614\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:20 | INFO | Rank 0 | Train Epoch: 0 [116704/250314 (47%)]\tLoss: 0.454169\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:20 | INFO | Rank 0 | Train Epoch: 0 [116736/250314 (47%)]\tLoss: 0.859870\tData (t) 0.206\tBatch (t) 0.418\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:21 | INFO | Rank 0 | Train Epoch: 0 [116768/250314 (47%)]\tLoss: 0.707785\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:21 | INFO | Rank 0 | Train Epoch: 0 [116800/250314 (47%)]\tLoss: 0.801777\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:22 | INFO | Rank 0 | Train Epoch: 0 [116832/250314 (47%)]\tLoss: 0.726701\tData (t) 0.230\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:22 | INFO | Rank 0 | Train Epoch: 0 [116864/250314 (47%)]\tLoss: 0.714018\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:23 | INFO | Rank 0 | Train Epoch: 0 [116896/250314 (47%)]\tLoss: 0.499493\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:23 | INFO | Rank 0 | Train Epoch: 0 [116928/250314 (47%)]\tLoss: 0.592243\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:24 | INFO | Rank 0 | Train Epoch: 0 [116960/250314 (47%)]\tLoss: 0.827853\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:24 | INFO | Rank 0 | Train Epoch: 0 [116992/250314 (47%)]\tLoss: 0.658576\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:24 | INFO | Rank 0 | Train Epoch: 0 [117024/250314 (47%)]\tLoss: 0.667508\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:25 | INFO | Rank 0 | Train Epoch: 0 [117056/250314 (47%)]\tLoss: 0.519293\tData (t) 0.326\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:25 | INFO | Rank 0 | Train Epoch: 0 [117088/250314 (47%)]\tLoss: 0.638662\tData (t) 0.213\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:26 | INFO | Rank 0 | Train Epoch: 0 [117120/250314 (47%)]\tLoss: 0.594486\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:26 | INFO | Rank 0 | Train Epoch: 0 [117152/250314 (47%)]\tLoss: 0.524105\tData (t) 0.176\tBatch (t) 0.387\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:27 | INFO | Rank 0 | Train Epoch: 0 [117184/250314 (47%)]\tLoss: 0.610212\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:27 | INFO | Rank 0 | Train Epoch: 0 [117216/250314 (47%)]\tLoss: 0.407070\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:28 | INFO | Rank 0 | Train Epoch: 0 [117248/250314 (47%)]\tLoss: 0.831840\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:28 | INFO | Rank 0 | Train Epoch: 0 [117280/250314 (47%)]\tLoss: 1.092118\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:29 | INFO | Rank 0 | Train Epoch: 0 [117312/250314 (47%)]\tLoss: 0.743622\tData (t) 0.224\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:29 | INFO | Rank 0 | Train Epoch: 0 [117344/250314 (47%)]\tLoss: 1.159690\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:30 | INFO | Rank 0 | Train Epoch: 0 [117376/250314 (47%)]\tLoss: 0.990411\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:30 | INFO | Rank 0 | Train Epoch: 0 [117408/250314 (47%)]\tLoss: 0.875833\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:31 | INFO | Rank 0 | Train Epoch: 0 [117440/250314 (47%)]\tLoss: 0.983425\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:31 | INFO | Rank 0 | Train Epoch: 0 [117472/250314 (47%)]\tLoss: 0.800826\tData (t) 0.197\tBatch (t) 0.408\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:32 | INFO | Rank 0 | Train Epoch: 0 [117504/250314 (47%)]\tLoss: 0.634278\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:32 | INFO | Rank 0 | Train Epoch: 0 [117536/250314 (47%)]\tLoss: 1.290958\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:32 | INFO | Rank 0 | Train Epoch: 0 [117568/250314 (47%)]\tLoss: 0.685598\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:33 | INFO | Rank 0 | Train Epoch: 0 [117600/250314 (47%)]\tLoss: 0.712540\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:33 | INFO | Rank 0 | Train Epoch: 0 [117632/250314 (47%)]\tLoss: 0.458457\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.595\n",
      "2022-11-09,13:40:34 | INFO | Rank 0 | Train Epoch: 0 [117664/250314 (47%)]\tLoss: 0.849693\tData (t) 0.214\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:34 | INFO | Rank 0 | Train Epoch: 0 [117696/250314 (47%)]\tLoss: 0.828794\tData (t) 0.225\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:35 | INFO | Rank 0 | Train Epoch: 0 [117728/250314 (47%)]\tLoss: 0.551098\tData (t) 0.343\tBatch (t) 0.555\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:35 | INFO | Rank 0 | Train Epoch: 0 [117760/250314 (47%)]\tLoss: 0.891860\tData (t) 0.333\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:36 | INFO | Rank 0 | Train Epoch: 0 [117792/250314 (47%)]\tLoss: 0.497203\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:36 | INFO | Rank 0 | Train Epoch: 0 [117824/250314 (47%)]\tLoss: 0.790996\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:37 | INFO | Rank 0 | Train Epoch: 0 [117856/250314 (47%)]\tLoss: 0.686386\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:37 | INFO | Rank 0 | Train Epoch: 0 [117888/250314 (47%)]\tLoss: 1.058619\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:38 | INFO | Rank 0 | Train Epoch: 0 [117920/250314 (47%)]\tLoss: 0.476432\tData (t) 0.356\tBatch (t) 0.567\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:38 | INFO | Rank 0 | Train Epoch: 0 [117952/250314 (47%)]\tLoss: 0.561806\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:39 | INFO | Rank 0 | Train Epoch: 0 [117984/250314 (47%)]\tLoss: 0.780248\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:39 | INFO | Rank 0 | Train Epoch: 0 [118016/250314 (47%)]\tLoss: 0.916577\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:40 | INFO | Rank 0 | Train Epoch: 0 [118048/250314 (47%)]\tLoss: 0.748528\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:40 | INFO | Rank 0 | Train Epoch: 0 [118080/250314 (47%)]\tLoss: 0.927199\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:41 | INFO | Rank 0 | Train Epoch: 0 [118112/250314 (47%)]\tLoss: 0.611622\tData (t) 0.333\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:41 | INFO | Rank 0 | Train Epoch: 0 [118144/250314 (47%)]\tLoss: 0.800112\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:42 | INFO | Rank 0 | Train Epoch: 0 [118176/250314 (47%)]\tLoss: 0.558843\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:42 | INFO | Rank 0 | Train Epoch: 0 [118208/250314 (47%)]\tLoss: 0.945127\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:43 | INFO | Rank 0 | Train Epoch: 0 [118240/250314 (47%)]\tLoss: 0.865400\tData (t) 0.337\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:44 | INFO | Rank 0 | Train Epoch: 0 [118272/250314 (47%)]\tLoss: 0.709788\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:44 | INFO | Rank 0 | Train Epoch: 0 [118304/250314 (47%)]\tLoss: 0.538278\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:44 | INFO | Rank 0 | Train Epoch: 0 [118336/250314 (47%)]\tLoss: 0.502095\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:45 | INFO | Rank 0 | Train Epoch: 0 [118368/250314 (47%)]\tLoss: 0.494220\tData (t) 0.217\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:45 | INFO | Rank 0 | Train Epoch: 0 [118400/250314 (47%)]\tLoss: 1.072574\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:46 | INFO | Rank 0 | Train Epoch: 0 [118432/250314 (47%)]\tLoss: 0.734985\tData (t) 0.256\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:46 | INFO | Rank 0 | Train Epoch: 0 [118464/250314 (47%)]\tLoss: 0.604471\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:47 | INFO | Rank 0 | Train Epoch: 0 [118496/250314 (47%)]\tLoss: 1.138253\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:47 | INFO | Rank 0 | Train Epoch: 0 [118528/250314 (47%)]\tLoss: 0.900976\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:48 | INFO | Rank 0 | Train Epoch: 0 [118560/250314 (47%)]\tLoss: 0.770264\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:48 | INFO | Rank 0 | Train Epoch: 0 [118592/250314 (47%)]\tLoss: 0.819781\tData (t) 0.420\tBatch (t) 0.631\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:49 | INFO | Rank 0 | Train Epoch: 0 [118624/250314 (47%)]\tLoss: 0.410710\tData (t) 0.338\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:49 | INFO | Rank 0 | Train Epoch: 0 [118656/250314 (47%)]\tLoss: 0.753690\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:50 | INFO | Rank 0 | Train Epoch: 0 [118688/250314 (47%)]\tLoss: 1.522491\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:50 | INFO | Rank 0 | Train Epoch: 0 [118720/250314 (47%)]\tLoss: 0.615087\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:51 | INFO | Rank 0 | Train Epoch: 0 [118752/250314 (47%)]\tLoss: 0.798370\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:51 | INFO | Rank 0 | Train Epoch: 0 [118784/250314 (47%)]\tLoss: 1.053133\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:52 | INFO | Rank 0 | Train Epoch: 0 [118816/250314 (47%)]\tLoss: 0.702595\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:52 | INFO | Rank 0 | Train Epoch: 0 [118848/250314 (47%)]\tLoss: 0.679233\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:53 | INFO | Rank 0 | Train Epoch: 0 [118880/250314 (47%)]\tLoss: 0.808700\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:53 | INFO | Rank 0 | Train Epoch: 0 [118912/250314 (48%)]\tLoss: 0.559553\tData (t) 0.397\tBatch (t) 0.609\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:54 | INFO | Rank 0 | Train Epoch: 0 [118944/250314 (48%)]\tLoss: 0.570720\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:54 | INFO | Rank 0 | Train Epoch: 0 [118976/250314 (48%)]\tLoss: 0.807982\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:55 | INFO | Rank 0 | Train Epoch: 0 [119008/250314 (48%)]\tLoss: 0.579261\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:55 | INFO | Rank 0 | Train Epoch: 0 [119040/250314 (48%)]\tLoss: 0.894554\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:56 | INFO | Rank 0 | Train Epoch: 0 [119072/250314 (48%)]\tLoss: 0.994037\tData (t) 0.197\tBatch (t) 0.409\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:56 | INFO | Rank 0 | Train Epoch: 0 [119104/250314 (48%)]\tLoss: 1.057574\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:57 | INFO | Rank 0 | Train Epoch: 0 [119136/250314 (48%)]\tLoss: 0.756658\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:57 | INFO | Rank 0 | Train Epoch: 0 [119168/250314 (48%)]\tLoss: 0.766352\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:58 | INFO | Rank 0 | Train Epoch: 0 [119200/250314 (48%)]\tLoss: 0.788436\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:58 | INFO | Rank 0 | Train Epoch: 0 [119232/250314 (48%)]\tLoss: 0.560379\tData (t) 0.357\tBatch (t) 0.569\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:59 | INFO | Rank 0 | Train Epoch: 0 [119264/250314 (48%)]\tLoss: 1.178734\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:40:59 | INFO | Rank 0 | Train Epoch: 0 [119296/250314 (48%)]\tLoss: 0.655408\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:00 | INFO | Rank 0 | Train Epoch: 0 [119328/250314 (48%)]\tLoss: 0.640419\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:00 | INFO | Rank 0 | Train Epoch: 0 [119360/250314 (48%)]\tLoss: 1.098504\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:01 | INFO | Rank 0 | Train Epoch: 0 [119392/250314 (48%)]\tLoss: 0.638249\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:01 | INFO | Rank 0 | Train Epoch: 0 [119424/250314 (48%)]\tLoss: 1.022636\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:02 | INFO | Rank 0 | Train Epoch: 0 [119456/250314 (48%)]\tLoss: 0.919406\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:02 | INFO | Rank 0 | Train Epoch: 0 [119488/250314 (48%)]\tLoss: 0.758385\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:03 | INFO | Rank 0 | Train Epoch: 0 [119520/250314 (48%)]\tLoss: 0.830810\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:03 | INFO | Rank 0 | Train Epoch: 0 [119552/250314 (48%)]\tLoss: 0.408416\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:04 | INFO | Rank 0 | Train Epoch: 0 [119584/250314 (48%)]\tLoss: 0.700647\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:04 | INFO | Rank 0 | Train Epoch: 0 [119616/250314 (48%)]\tLoss: 1.036699\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:05 | INFO | Rank 0 | Train Epoch: 0 [119648/250314 (48%)]\tLoss: 0.890520\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:05 | INFO | Rank 0 | Train Epoch: 0 [119680/250314 (48%)]\tLoss: 0.833288\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:06 | INFO | Rank 0 | Train Epoch: 0 [119712/250314 (48%)]\tLoss: 0.858583\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:06 | INFO | Rank 0 | Train Epoch: 0 [119744/250314 (48%)]\tLoss: 0.381174\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:07 | INFO | Rank 0 | Train Epoch: 0 [119776/250314 (48%)]\tLoss: 0.791082\tData (t) 0.220\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:07 | INFO | Rank 0 | Train Epoch: 0 [119808/250314 (48%)]\tLoss: 1.053163\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:08 | INFO | Rank 0 | Train Epoch: 0 [119840/250314 (48%)]\tLoss: 0.732618\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:08 | INFO | Rank 0 | Train Epoch: 0 [119872/250314 (48%)]\tLoss: 0.966557\tData (t) 0.214\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:09 | INFO | Rank 0 | Train Epoch: 0 [119904/250314 (48%)]\tLoss: 0.366704\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:09 | INFO | Rank 0 | Train Epoch: 0 [119936/250314 (48%)]\tLoss: 0.743258\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:10 | INFO | Rank 0 | Train Epoch: 0 [119968/250314 (48%)]\tLoss: 0.653856\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:10 | INFO | Rank 0 | Train Epoch: 0 [120000/250314 (48%)]\tLoss: 0.839092\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:11 | INFO | Rank 0 | Train Epoch: 0 [120032/250314 (48%)]\tLoss: 0.775378\tData (t) 0.494\tBatch (t) 0.706\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:11 | INFO | Rank 0 | Train Epoch: 0 [120064/250314 (48%)]\tLoss: 1.007968\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:12 | INFO | Rank 0 | Train Epoch: 0 [120096/250314 (48%)]\tLoss: 0.675959\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:12 | INFO | Rank 0 | Train Epoch: 0 [120128/250314 (48%)]\tLoss: 0.616530\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:13 | INFO | Rank 0 | Train Epoch: 0 [120160/250314 (48%)]\tLoss: 0.570397\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:13 | INFO | Rank 0 | Train Epoch: 0 [120192/250314 (48%)]\tLoss: 0.693862\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:14 | INFO | Rank 0 | Train Epoch: 0 [120224/250314 (48%)]\tLoss: 0.833357\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:14 | INFO | Rank 0 | Train Epoch: 0 [120256/250314 (48%)]\tLoss: 0.840187\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:15 | INFO | Rank 0 | Train Epoch: 0 [120288/250314 (48%)]\tLoss: 0.704374\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:15 | INFO | Rank 0 | Train Epoch: 0 [120320/250314 (48%)]\tLoss: 0.720695\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:16 | INFO | Rank 0 | Train Epoch: 0 [120352/250314 (48%)]\tLoss: 1.401440\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:16 | INFO | Rank 0 | Train Epoch: 0 [120384/250314 (48%)]\tLoss: 1.151262\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:17 | INFO | Rank 0 | Train Epoch: 0 [120416/250314 (48%)]\tLoss: 0.893643\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:17 | INFO | Rank 0 | Train Epoch: 0 [120448/250314 (48%)]\tLoss: 1.166177\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:18 | INFO | Rank 0 | Train Epoch: 0 [120480/250314 (48%)]\tLoss: 0.452393\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:18 | INFO | Rank 0 | Train Epoch: 0 [120512/250314 (48%)]\tLoss: 0.720406\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:18 | INFO | Rank 0 | Train Epoch: 0 [120544/250314 (48%)]\tLoss: 0.814781\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:19 | INFO | Rank 0 | Train Epoch: 0 [120576/250314 (48%)]\tLoss: 0.924406\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:20 | INFO | Rank 0 | Train Epoch: 0 [120608/250314 (48%)]\tLoss: 0.974587\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:20 | INFO | Rank 0 | Train Epoch: 0 [120640/250314 (48%)]\tLoss: 1.225128\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:21 | INFO | Rank 0 | Train Epoch: 0 [120672/250314 (48%)]\tLoss: 0.506274\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:21 | INFO | Rank 0 | Train Epoch: 0 [120704/250314 (48%)]\tLoss: 0.736386\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:21 | INFO | Rank 0 | Train Epoch: 0 [120736/250314 (48%)]\tLoss: 0.772722\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:22 | INFO | Rank 0 | Train Epoch: 0 [120768/250314 (48%)]\tLoss: 0.711265\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:22 | INFO | Rank 0 | Train Epoch: 0 [120800/250314 (48%)]\tLoss: 0.678669\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:23 | INFO | Rank 0 | Train Epoch: 0 [120832/250314 (48%)]\tLoss: 0.867820\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:23 | INFO | Rank 0 | Train Epoch: 0 [120864/250314 (48%)]\tLoss: 0.715195\tData (t) 0.210\tBatch (t) 0.421\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:24 | INFO | Rank 0 | Train Epoch: 0 [120896/250314 (48%)]\tLoss: 0.432002\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:24 | INFO | Rank 0 | Train Epoch: 0 [120928/250314 (48%)]\tLoss: 0.689433\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:25 | INFO | Rank 0 | Train Epoch: 0 [120960/250314 (48%)]\tLoss: 0.675566\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:25 | INFO | Rank 0 | Train Epoch: 0 [120992/250314 (48%)]\tLoss: 0.909521\tData (t) 0.208\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:26 | INFO | Rank 0 | Train Epoch: 0 [121024/250314 (48%)]\tLoss: 0.884125\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:26 | INFO | Rank 0 | Train Epoch: 0 [121056/250314 (48%)]\tLoss: 0.652461\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:27 | INFO | Rank 0 | Train Epoch: 0 [121088/250314 (48%)]\tLoss: 1.358177\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:27 | INFO | Rank 0 | Train Epoch: 0 [121120/250314 (48%)]\tLoss: 0.462208\tData (t) 0.235\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:28 | INFO | Rank 0 | Train Epoch: 0 [121152/250314 (48%)]\tLoss: 1.153760\tData (t) 0.274\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:28 | INFO | Rank 0 | Train Epoch: 0 [121184/250314 (48%)]\tLoss: 1.089070\tData (t) 0.226\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:28 | INFO | Rank 0 | Train Epoch: 0 [121216/250314 (48%)]\tLoss: 0.553568\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:29 | INFO | Rank 0 | Train Epoch: 0 [121248/250314 (48%)]\tLoss: 0.781878\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:29 | INFO | Rank 0 | Train Epoch: 0 [121280/250314 (48%)]\tLoss: 0.723518\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:30 | INFO | Rank 0 | Train Epoch: 0 [121312/250314 (48%)]\tLoss: 1.128149\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:30 | INFO | Rank 0 | Train Epoch: 0 [121344/250314 (48%)]\tLoss: 0.944936\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:31 | INFO | Rank 0 | Train Epoch: 0 [121376/250314 (48%)]\tLoss: 0.806748\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:32 | INFO | Rank 0 | Train Epoch: 0 [121408/250314 (49%)]\tLoss: 0.888404\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:32 | INFO | Rank 0 | Train Epoch: 0 [121440/250314 (49%)]\tLoss: 0.771026\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:32 | INFO | Rank 0 | Train Epoch: 0 [121472/250314 (49%)]\tLoss: 0.549114\tData (t) 0.257\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:33 | INFO | Rank 0 | Train Epoch: 0 [121504/250314 (49%)]\tLoss: 0.701409\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:33 | INFO | Rank 0 | Train Epoch: 0 [121536/250314 (49%)]\tLoss: 0.364921\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:34 | INFO | Rank 0 | Train Epoch: 0 [121568/250314 (49%)]\tLoss: 0.826515\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:34 | INFO | Rank 0 | Train Epoch: 0 [121600/250314 (49%)]\tLoss: 0.846708\tData (t) 0.184\tBatch (t) 0.396\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:35 | INFO | Rank 0 | Train Epoch: 0 [121632/250314 (49%)]\tLoss: 0.718993\tData (t) 0.321\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:35 | INFO | Rank 0 | Train Epoch: 0 [121664/250314 (49%)]\tLoss: 0.610916\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:36 | INFO | Rank 0 | Train Epoch: 0 [121696/250314 (49%)]\tLoss: 0.554682\tData (t) 0.314\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:36 | INFO | Rank 0 | Train Epoch: 0 [121728/250314 (49%)]\tLoss: 1.310407\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:37 | INFO | Rank 0 | Train Epoch: 0 [121760/250314 (49%)]\tLoss: 0.521765\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:37 | INFO | Rank 0 | Train Epoch: 0 [121792/250314 (49%)]\tLoss: 0.413229\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:38 | INFO | Rank 0 | Train Epoch: 0 [121824/250314 (49%)]\tLoss: 0.741690\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:38 | INFO | Rank 0 | Train Epoch: 0 [121856/250314 (49%)]\tLoss: 1.041545\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:39 | INFO | Rank 0 | Train Epoch: 0 [121888/250314 (49%)]\tLoss: 0.492979\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:39 | INFO | Rank 0 | Train Epoch: 0 [121920/250314 (49%)]\tLoss: 1.355126\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:40 | INFO | Rank 0 | Train Epoch: 0 [121952/250314 (49%)]\tLoss: 0.823350\tData (t) 0.317\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:40 | INFO | Rank 0 | Train Epoch: 0 [121984/250314 (49%)]\tLoss: 0.994498\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:41 | INFO | Rank 0 | Train Epoch: 0 [122016/250314 (49%)]\tLoss: 1.346491\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:41 | INFO | Rank 0 | Train Epoch: 0 [122048/250314 (49%)]\tLoss: 0.996493\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:42 | INFO | Rank 0 | Train Epoch: 0 [122080/250314 (49%)]\tLoss: 0.699207\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:42 | INFO | Rank 0 | Train Epoch: 0 [122112/250314 (49%)]\tLoss: 0.504615\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:43 | INFO | Rank 0 | Train Epoch: 0 [122144/250314 (49%)]\tLoss: 0.966173\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:43 | INFO | Rank 0 | Train Epoch: 0 [122176/250314 (49%)]\tLoss: 0.946477\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:44 | INFO | Rank 0 | Train Epoch: 0 [122208/250314 (49%)]\tLoss: 1.357221\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:44 | INFO | Rank 0 | Train Epoch: 0 [122240/250314 (49%)]\tLoss: 0.943613\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:45 | INFO | Rank 0 | Train Epoch: 0 [122272/250314 (49%)]\tLoss: 0.484559\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:45 | INFO | Rank 0 | Train Epoch: 0 [122304/250314 (49%)]\tLoss: 0.836678\tData (t) 0.354\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:46 | INFO | Rank 0 | Train Epoch: 0 [122336/250314 (49%)]\tLoss: 1.239391\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:46 | INFO | Rank 0 | Train Epoch: 0 [122368/250314 (49%)]\tLoss: 0.839881\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:47 | INFO | Rank 0 | Train Epoch: 0 [122400/250314 (49%)]\tLoss: 0.327763\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:47 | INFO | Rank 0 | Train Epoch: 0 [122432/250314 (49%)]\tLoss: 0.803508\tData (t) 0.385\tBatch (t) 0.597\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:48 | INFO | Rank 0 | Train Epoch: 0 [122464/250314 (49%)]\tLoss: 1.119611\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:48 | INFO | Rank 0 | Train Epoch: 0 [122496/250314 (49%)]\tLoss: 0.782744\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:49 | INFO | Rank 0 | Train Epoch: 0 [122528/250314 (49%)]\tLoss: 0.926061\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:49 | INFO | Rank 0 | Train Epoch: 0 [122560/250314 (49%)]\tLoss: 0.657912\tData (t) 0.213\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:50 | INFO | Rank 0 | Train Epoch: 0 [122592/250314 (49%)]\tLoss: 1.045339\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:50 | INFO | Rank 0 | Train Epoch: 0 [122624/250314 (49%)]\tLoss: 0.792397\tData (t) 0.394\tBatch (t) 0.606\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:51 | INFO | Rank 0 | Train Epoch: 0 [122656/250314 (49%)]\tLoss: 0.704059\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:51 | INFO | Rank 0 | Train Epoch: 0 [122688/250314 (49%)]\tLoss: 0.439140\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:52 | INFO | Rank 0 | Train Epoch: 0 [122720/250314 (49%)]\tLoss: 0.692181\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:52 | INFO | Rank 0 | Train Epoch: 0 [122752/250314 (49%)]\tLoss: 0.623704\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:53 | INFO | Rank 0 | Train Epoch: 0 [122784/250314 (49%)]\tLoss: 0.834706\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:53 | INFO | Rank 0 | Train Epoch: 0 [122816/250314 (49%)]\tLoss: 0.617879\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:54 | INFO | Rank 0 | Train Epoch: 0 [122848/250314 (49%)]\tLoss: 1.245743\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:54 | INFO | Rank 0 | Train Epoch: 0 [122880/250314 (49%)]\tLoss: 0.702274\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:55 | INFO | Rank 0 | Train Epoch: 0 [122912/250314 (49%)]\tLoss: 0.930146\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:55 | INFO | Rank 0 | Train Epoch: 0 [122944/250314 (49%)]\tLoss: 0.934680\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:56 | INFO | Rank 0 | Train Epoch: 0 [122976/250314 (49%)]\tLoss: 0.750971\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:56 | INFO | Rank 0 | Train Epoch: 0 [123008/250314 (49%)]\tLoss: 0.527930\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:57 | INFO | Rank 0 | Train Epoch: 0 [123040/250314 (49%)]\tLoss: 0.601104\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:57 | INFO | Rank 0 | Train Epoch: 0 [123072/250314 (49%)]\tLoss: 1.180481\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:58 | INFO | Rank 0 | Train Epoch: 0 [123104/250314 (49%)]\tLoss: 0.991694\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:58 | INFO | Rank 0 | Train Epoch: 0 [123136/250314 (49%)]\tLoss: 0.392754\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:59 | INFO | Rank 0 | Train Epoch: 0 [123168/250314 (49%)]\tLoss: 0.559863\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:59 | INFO | Rank 0 | Train Epoch: 0 [123200/250314 (49%)]\tLoss: 0.674478\tData (t) 0.226\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:41:59 | INFO | Rank 0 | Train Epoch: 0 [123232/250314 (49%)]\tLoss: 0.771058\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:00 | INFO | Rank 0 | Train Epoch: 0 [123264/250314 (49%)]\tLoss: 0.534941\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:00 | INFO | Rank 0 | Train Epoch: 0 [123296/250314 (49%)]\tLoss: 1.020229\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:01 | INFO | Rank 0 | Train Epoch: 0 [123328/250314 (49%)]\tLoss: 0.824935\tData (t) 0.329\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:02 | INFO | Rank 0 | Train Epoch: 0 [123360/250314 (49%)]\tLoss: 0.607062\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:02 | INFO | Rank 0 | Train Epoch: 0 [123392/250314 (49%)]\tLoss: 0.567819\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:02 | INFO | Rank 0 | Train Epoch: 0 [123424/250314 (49%)]\tLoss: 0.475720\tData (t) 0.211\tBatch (t) 0.422\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:03 | INFO | Rank 0 | Train Epoch: 0 [123456/250314 (49%)]\tLoss: 0.652448\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:03 | INFO | Rank 0 | Train Epoch: 0 [123488/250314 (49%)]\tLoss: 0.820449\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:04 | INFO | Rank 0 | Train Epoch: 0 [123520/250314 (49%)]\tLoss: 0.710272\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:04 | INFO | Rank 0 | Train Epoch: 0 [123552/250314 (49%)]\tLoss: 0.460810\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:05 | INFO | Rank 0 | Train Epoch: 0 [123584/250314 (49%)]\tLoss: 0.478010\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:05 | INFO | Rank 0 | Train Epoch: 0 [123616/250314 (49%)]\tLoss: 0.600090\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:06 | INFO | Rank 0 | Train Epoch: 0 [123648/250314 (49%)]\tLoss: 1.014106\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:06 | INFO | Rank 0 | Train Epoch: 0 [123680/250314 (49%)]\tLoss: 0.557983\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:07 | INFO | Rank 0 | Train Epoch: 0 [123712/250314 (49%)]\tLoss: 0.583221\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:07 | INFO | Rank 0 | Train Epoch: 0 [123744/250314 (49%)]\tLoss: 0.695706\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:08 | INFO | Rank 0 | Train Epoch: 0 [123776/250314 (49%)]\tLoss: 1.078474\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:08 | INFO | Rank 0 | Train Epoch: 0 [123808/250314 (49%)]\tLoss: 0.624669\tData (t) 0.198\tBatch (t) 0.410\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:09 | INFO | Rank 0 | Train Epoch: 0 [123840/250314 (49%)]\tLoss: 0.459753\tData (t) 0.229\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:09 | INFO | Rank 0 | Train Epoch: 0 [123872/250314 (49%)]\tLoss: 0.859403\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:10 | INFO | Rank 0 | Train Epoch: 0 [123904/250314 (50%)]\tLoss: 1.039441\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:10 | INFO | Rank 0 | Train Epoch: 0 [123936/250314 (50%)]\tLoss: 1.012259\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:11 | INFO | Rank 0 | Train Epoch: 0 [123968/250314 (50%)]\tLoss: 0.459899\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:11 | INFO | Rank 0 | Train Epoch: 0 [124000/250314 (50%)]\tLoss: 0.462546\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:12 | INFO | Rank 0 | Train Epoch: 0 [124032/250314 (50%)]\tLoss: 1.214582\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:12 | INFO | Rank 0 | Train Epoch: 0 [124064/250314 (50%)]\tLoss: 0.756893\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:13 | INFO | Rank 0 | Train Epoch: 0 [124096/250314 (50%)]\tLoss: 0.638243\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:13 | INFO | Rank 0 | Train Epoch: 0 [124128/250314 (50%)]\tLoss: 0.497026\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:13 | INFO | Rank 0 | Train Epoch: 0 [124160/250314 (50%)]\tLoss: 0.627296\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:14 | INFO | Rank 0 | Train Epoch: 0 [124192/250314 (50%)]\tLoss: 1.161050\tData (t) 0.341\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:14 | INFO | Rank 0 | Train Epoch: 0 [124224/250314 (50%)]\tLoss: 0.514037\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:15 | INFO | Rank 0 | Train Epoch: 0 [124256/250314 (50%)]\tLoss: 0.657723\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:16 | INFO | Rank 0 | Train Epoch: 0 [124288/250314 (50%)]\tLoss: 0.992725\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:16 | INFO | Rank 0 | Train Epoch: 0 [124320/250314 (50%)]\tLoss: 0.521925\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:17 | INFO | Rank 0 | Train Epoch: 0 [124352/250314 (50%)]\tLoss: 0.646238\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:17 | INFO | Rank 0 | Train Epoch: 0 [124384/250314 (50%)]\tLoss: 0.580967\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:17 | INFO | Rank 0 | Train Epoch: 0 [124416/250314 (50%)]\tLoss: 1.176648\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:18 | INFO | Rank 0 | Train Epoch: 0 [124448/250314 (50%)]\tLoss: 0.697693\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:18 | INFO | Rank 0 | Train Epoch: 0 [124480/250314 (50%)]\tLoss: 0.691591\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:19 | INFO | Rank 0 | Train Epoch: 0 [124512/250314 (50%)]\tLoss: 0.984099\tData (t) 0.262\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:19 | INFO | Rank 0 | Train Epoch: 0 [124544/250314 (50%)]\tLoss: 0.819370\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:20 | INFO | Rank 0 | Train Epoch: 0 [124576/250314 (50%)]\tLoss: 0.799294\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:20 | INFO | Rank 0 | Train Epoch: 0 [124608/250314 (50%)]\tLoss: 1.169576\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:21 | INFO | Rank 0 | Train Epoch: 0 [124640/250314 (50%)]\tLoss: 0.701772\tData (t) 0.214\tBatch (t) 0.426\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:21 | INFO | Rank 0 | Train Epoch: 0 [124672/250314 (50%)]\tLoss: 0.908963\tData (t) 0.351\tBatch (t) 0.562\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:22 | INFO | Rank 0 | Train Epoch: 0 [124704/250314 (50%)]\tLoss: 0.801146\tData (t) 0.222\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:22 | INFO | Rank 0 | Train Epoch: 0 [124736/250314 (50%)]\tLoss: 0.706479\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:23 | INFO | Rank 0 | Train Epoch: 0 [124768/250314 (50%)]\tLoss: 0.588406\tData (t) 0.592\tBatch (t) 0.803\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:24 | INFO | Rank 0 | Train Epoch: 0 [124800/250314 (50%)]\tLoss: 0.489834\tData (t) 0.355\tBatch (t) 0.567\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:24 | INFO | Rank 0 | Train Epoch: 0 [124832/250314 (50%)]\tLoss: 0.639622\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:25 | INFO | Rank 0 | Train Epoch: 0 [124864/250314 (50%)]\tLoss: 0.797915\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:25 | INFO | Rank 0 | Train Epoch: 0 [124896/250314 (50%)]\tLoss: 0.868109\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:26 | INFO | Rank 0 | Train Epoch: 0 [124928/250314 (50%)]\tLoss: 0.365508\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:26 | INFO | Rank 0 | Train Epoch: 0 [124960/250314 (50%)]\tLoss: 0.946784\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:27 | INFO | Rank 0 | Train Epoch: 0 [124992/250314 (50%)]\tLoss: 1.038887\tData (t) 0.356\tBatch (t) 0.567\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:27 | INFO | Rank 0 | Train Epoch: 0 [125024/250314 (50%)]\tLoss: 0.792690\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:28 | INFO | Rank 0 | Train Epoch: 0 [125056/250314 (50%)]\tLoss: 0.752994\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:28 | INFO | Rank 0 | Train Epoch: 0 [125088/250314 (50%)]\tLoss: 0.883075\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:29 | INFO | Rank 0 | Train Epoch: 0 [125120/250314 (50%)]\tLoss: 0.815524\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:29 | INFO | Rank 0 | Train Epoch: 0 [125152/250314 (50%)]\tLoss: 0.535561\tData (t) 0.204\tBatch (t) 0.416\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:30 | INFO | Rank 0 | Train Epoch: 0 [125184/250314 (50%)]\tLoss: 1.099182\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:30 | INFO | Rank 0 | Train Epoch: 0 [125216/250314 (50%)]\tLoss: 0.526490\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:31 | INFO | Rank 0 | Train Epoch: 0 [125248/250314 (50%)]\tLoss: 0.685256\tData (t) 0.350\tBatch (t) 0.562\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:31 | INFO | Rank 0 | Train Epoch: 0 [125280/250314 (50%)]\tLoss: 0.831801\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:32 | INFO | Rank 0 | Train Epoch: 0 [125312/250314 (50%)]\tLoss: 1.192524\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:32 | INFO | Rank 0 | Train Epoch: 0 [125344/250314 (50%)]\tLoss: 0.779977\tData (t) 0.397\tBatch (t) 0.609\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:33 | INFO | Rank 0 | Train Epoch: 0 [125376/250314 (50%)]\tLoss: 0.559801\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:33 | INFO | Rank 0 | Train Epoch: 0 [125408/250314 (50%)]\tLoss: 0.597404\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:34 | INFO | Rank 0 | Train Epoch: 0 [125440/250314 (50%)]\tLoss: 1.374387\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:34 | INFO | Rank 0 | Train Epoch: 0 [125472/250314 (50%)]\tLoss: 0.936411\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:35 | INFO | Rank 0 | Train Epoch: 0 [125504/250314 (50%)]\tLoss: 0.583358\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:35 | INFO | Rank 0 | Train Epoch: 0 [125536/250314 (50%)]\tLoss: 1.135693\tData (t) 0.228\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:36 | INFO | Rank 0 | Train Epoch: 0 [125568/250314 (50%)]\tLoss: 0.716687\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:36 | INFO | Rank 0 | Train Epoch: 0 [125600/250314 (50%)]\tLoss: 0.764703\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:37 | INFO | Rank 0 | Train Epoch: 0 [125632/250314 (50%)]\tLoss: 0.754914\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:37 | INFO | Rank 0 | Train Epoch: 0 [125664/250314 (50%)]\tLoss: 0.728457\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:38 | INFO | Rank 0 | Train Epoch: 0 [125696/250314 (50%)]\tLoss: 0.637824\tData (t) 0.330\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:38 | INFO | Rank 0 | Train Epoch: 0 [125728/250314 (50%)]\tLoss: 0.575596\tData (t) 0.324\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:39 | INFO | Rank 0 | Train Epoch: 0 [125760/250314 (50%)]\tLoss: 1.009730\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:39 | INFO | Rank 0 | Train Epoch: 0 [125792/250314 (50%)]\tLoss: 0.752455\tData (t) 0.331\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:40 | INFO | Rank 0 | Train Epoch: 0 [125824/250314 (50%)]\tLoss: 0.593676\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:40 | INFO | Rank 0 | Train Epoch: 0 [125856/250314 (50%)]\tLoss: 0.513479\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:41 | INFO | Rank 0 | Train Epoch: 0 [125888/250314 (50%)]\tLoss: 0.677675\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:41 | INFO | Rank 0 | Train Epoch: 0 [125920/250314 (50%)]\tLoss: 0.597584\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:42 | INFO | Rank 0 | Train Epoch: 0 [125952/250314 (50%)]\tLoss: 0.559088\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:42 | INFO | Rank 0 | Train Epoch: 0 [125984/250314 (50%)]\tLoss: 0.751085\tData (t) 0.403\tBatch (t) 0.615\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:43 | INFO | Rank 0 | Train Epoch: 0 [126016/250314 (50%)]\tLoss: 0.502646\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:43 | INFO | Rank 0 | Train Epoch: 0 [126048/250314 (50%)]\tLoss: 0.589905\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:44 | INFO | Rank 0 | Train Epoch: 0 [126080/250314 (50%)]\tLoss: 0.718268\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:44 | INFO | Rank 0 | Train Epoch: 0 [126112/250314 (50%)]\tLoss: 0.725169\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:45 | INFO | Rank 0 | Train Epoch: 0 [126144/250314 (50%)]\tLoss: 0.805980\tData (t) 0.320\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:45 | INFO | Rank 0 | Train Epoch: 0 [126176/250314 (50%)]\tLoss: 0.512846\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:46 | INFO | Rank 0 | Train Epoch: 0 [126208/250314 (50%)]\tLoss: 0.428224\tData (t) 0.211\tBatch (t) 0.422\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:46 | INFO | Rank 0 | Train Epoch: 0 [126240/250314 (50%)]\tLoss: 1.010768\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:47 | INFO | Rank 0 | Train Epoch: 0 [126272/250314 (50%)]\tLoss: 0.753920\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:47 | INFO | Rank 0 | Train Epoch: 0 [126304/250314 (50%)]\tLoss: 0.830553\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:48 | INFO | Rank 0 | Train Epoch: 0 [126336/250314 (50%)]\tLoss: 0.819955\tData (t) 0.349\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:48 | INFO | Rank 0 | Train Epoch: 0 [126368/250314 (50%)]\tLoss: 0.409574\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:49 | INFO | Rank 0 | Train Epoch: 0 [126400/250314 (50%)]\tLoss: 0.565814\tData (t) 0.222\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:49 | INFO | Rank 0 | Train Epoch: 0 [126432/250314 (51%)]\tLoss: 0.777155\tData (t) 0.266\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:50 | INFO | Rank 0 | Train Epoch: 0 [126464/250314 (51%)]\tLoss: 0.717270\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:50 | INFO | Rank 0 | Train Epoch: 0 [126496/250314 (51%)]\tLoss: 0.659069\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:51 | INFO | Rank 0 | Train Epoch: 0 [126528/250314 (51%)]\tLoss: 0.869328\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:51 | INFO | Rank 0 | Train Epoch: 0 [126560/250314 (51%)]\tLoss: 0.794458\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:52 | INFO | Rank 0 | Train Epoch: 0 [126592/250314 (51%)]\tLoss: 0.840895\tData (t) 0.188\tBatch (t) 0.399\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:52 | INFO | Rank 0 | Train Epoch: 0 [126624/250314 (51%)]\tLoss: 1.219478\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:52 | INFO | Rank 0 | Train Epoch: 0 [126656/250314 (51%)]\tLoss: 0.649852\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:53 | INFO | Rank 0 | Train Epoch: 0 [126688/250314 (51%)]\tLoss: 0.950597\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:53 | INFO | Rank 0 | Train Epoch: 0 [126720/250314 (51%)]\tLoss: 0.812521\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:54 | INFO | Rank 0 | Train Epoch: 0 [126752/250314 (51%)]\tLoss: 1.023826\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:54 | INFO | Rank 0 | Train Epoch: 0 [126784/250314 (51%)]\tLoss: 0.978530\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:55 | INFO | Rank 0 | Train Epoch: 0 [126816/250314 (51%)]\tLoss: 0.317394\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:55 | INFO | Rank 0 | Train Epoch: 0 [126848/250314 (51%)]\tLoss: 1.209729\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:56 | INFO | Rank 0 | Train Epoch: 0 [126880/250314 (51%)]\tLoss: 0.563388\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:56 | INFO | Rank 0 | Train Epoch: 0 [126912/250314 (51%)]\tLoss: 0.878400\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:57 | INFO | Rank 0 | Train Epoch: 0 [126944/250314 (51%)]\tLoss: 0.967317\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:57 | INFO | Rank 0 | Train Epoch: 0 [126976/250314 (51%)]\tLoss: 0.700857\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:58 | INFO | Rank 0 | Train Epoch: 0 [127008/250314 (51%)]\tLoss: 0.864545\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:58 | INFO | Rank 0 | Train Epoch: 0 [127040/250314 (51%)]\tLoss: 0.493267\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:42:59 | INFO | Rank 0 | Train Epoch: 0 [127072/250314 (51%)]\tLoss: 0.565885\tData (t) 0.640\tBatch (t) 0.851\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:00 | INFO | Rank 0 | Train Epoch: 0 [127104/250314 (51%)]\tLoss: 0.872756\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:00 | INFO | Rank 0 | Train Epoch: 0 [127136/250314 (51%)]\tLoss: 0.713992\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:01 | INFO | Rank 0 | Train Epoch: 0 [127168/250314 (51%)]\tLoss: 0.746090\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:01 | INFO | Rank 0 | Train Epoch: 0 [127200/250314 (51%)]\tLoss: 0.674643\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:02 | INFO | Rank 0 | Train Epoch: 0 [127232/250314 (51%)]\tLoss: 0.711970\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:02 | INFO | Rank 0 | Train Epoch: 0 [127264/250314 (51%)]\tLoss: 0.636763\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:03 | INFO | Rank 0 | Train Epoch: 0 [127296/250314 (51%)]\tLoss: 0.661915\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:03 | INFO | Rank 0 | Train Epoch: 0 [127328/250314 (51%)]\tLoss: 0.691855\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:04 | INFO | Rank 0 | Train Epoch: 0 [127360/250314 (51%)]\tLoss: 0.721959\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:04 | INFO | Rank 0 | Train Epoch: 0 [127392/250314 (51%)]\tLoss: 0.622001\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:05 | INFO | Rank 0 | Train Epoch: 0 [127424/250314 (51%)]\tLoss: 0.562504\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:05 | INFO | Rank 0 | Train Epoch: 0 [127456/250314 (51%)]\tLoss: 1.077861\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:06 | INFO | Rank 0 | Train Epoch: 0 [127488/250314 (51%)]\tLoss: 0.682658\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:06 | INFO | Rank 0 | Train Epoch: 0 [127520/250314 (51%)]\tLoss: 1.547192\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:07 | INFO | Rank 0 | Train Epoch: 0 [127552/250314 (51%)]\tLoss: 0.665246\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:07 | INFO | Rank 0 | Train Epoch: 0 [127584/250314 (51%)]\tLoss: 0.947318\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:08 | INFO | Rank 0 | Train Epoch: 0 [127616/250314 (51%)]\tLoss: 0.798032\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:08 | INFO | Rank 0 | Train Epoch: 0 [127648/250314 (51%)]\tLoss: 0.968067\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:09 | INFO | Rank 0 | Train Epoch: 0 [127680/250314 (51%)]\tLoss: 0.806962\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:09 | INFO | Rank 0 | Train Epoch: 0 [127712/250314 (51%)]\tLoss: 1.028243\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:10 | INFO | Rank 0 | Train Epoch: 0 [127744/250314 (51%)]\tLoss: 0.586594\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:10 | INFO | Rank 0 | Train Epoch: 0 [127776/250314 (51%)]\tLoss: 0.842972\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:11 | INFO | Rank 0 | Train Epoch: 0 [127808/250314 (51%)]\tLoss: 0.625635\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:11 | INFO | Rank 0 | Train Epoch: 0 [127840/250314 (51%)]\tLoss: 0.418531\tData (t) 0.194\tBatch (t) 0.405\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:11 | INFO | Rank 0 | Train Epoch: 0 [127872/250314 (51%)]\tLoss: 0.774803\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:12 | INFO | Rank 0 | Train Epoch: 0 [127904/250314 (51%)]\tLoss: 0.484648\tData (t) 0.221\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:12 | INFO | Rank 0 | Train Epoch: 0 [127936/250314 (51%)]\tLoss: 0.874059\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:13 | INFO | Rank 0 | Train Epoch: 0 [127968/250314 (51%)]\tLoss: 0.635227\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:13 | INFO | Rank 0 | Train Epoch: 0 [128000/250314 (51%)]\tLoss: 0.837933\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:14 | INFO | Rank 0 | Train Epoch: 0 [128032/250314 (51%)]\tLoss: 0.661645\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:14 | INFO | Rank 0 | Train Epoch: 0 [128064/250314 (51%)]\tLoss: 0.708229\tData (t) 0.318\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:15 | INFO | Rank 0 | Train Epoch: 0 [128096/250314 (51%)]\tLoss: 0.946207\tData (t) 0.220\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:15 | INFO | Rank 0 | Train Epoch: 0 [128128/250314 (51%)]\tLoss: 0.766829\tData (t) 0.339\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:16 | INFO | Rank 0 | Train Epoch: 0 [128160/250314 (51%)]\tLoss: 0.972129\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:16 | INFO | Rank 0 | Train Epoch: 0 [128192/250314 (51%)]\tLoss: 0.702409\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:17 | INFO | Rank 0 | Train Epoch: 0 [128224/250314 (51%)]\tLoss: 0.631897\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:17 | INFO | Rank 0 | Train Epoch: 0 [128256/250314 (51%)]\tLoss: 0.883685\tData (t) 0.296\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:18 | INFO | Rank 0 | Train Epoch: 0 [128288/250314 (51%)]\tLoss: 0.729127\tData (t) 0.332\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:18 | INFO | Rank 0 | Train Epoch: 0 [128320/250314 (51%)]\tLoss: 0.630799\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:19 | INFO | Rank 0 | Train Epoch: 0 [128352/250314 (51%)]\tLoss: 0.309135\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:19 | INFO | Rank 0 | Train Epoch: 0 [128384/250314 (51%)]\tLoss: 0.909738\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:20 | INFO | Rank 0 | Train Epoch: 0 [128416/250314 (51%)]\tLoss: 0.584863\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:20 | INFO | Rank 0 | Train Epoch: 0 [128448/250314 (51%)]\tLoss: 0.938745\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:21 | INFO | Rank 0 | Train Epoch: 0 [128480/250314 (51%)]\tLoss: 0.703073\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:21 | INFO | Rank 0 | Train Epoch: 0 [128512/250314 (51%)]\tLoss: 1.075432\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:22 | INFO | Rank 0 | Train Epoch: 0 [128544/250314 (51%)]\tLoss: 0.858885\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:22 | INFO | Rank 0 | Train Epoch: 0 [128576/250314 (51%)]\tLoss: 0.733952\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:23 | INFO | Rank 0 | Train Epoch: 0 [128608/250314 (51%)]\tLoss: 0.794057\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:23 | INFO | Rank 0 | Train Epoch: 0 [128640/250314 (51%)]\tLoss: 0.661119\tData (t) 0.290\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:24 | INFO | Rank 0 | Train Epoch: 0 [128672/250314 (51%)]\tLoss: 0.636839\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:24 | INFO | Rank 0 | Train Epoch: 0 [128704/250314 (51%)]\tLoss: 0.381383\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:25 | INFO | Rank 0 | Train Epoch: 0 [128736/250314 (51%)]\tLoss: 0.879802\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:25 | INFO | Rank 0 | Train Epoch: 0 [128768/250314 (51%)]\tLoss: 0.624857\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:26 | INFO | Rank 0 | Train Epoch: 0 [128800/250314 (51%)]\tLoss: 0.561020\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:26 | INFO | Rank 0 | Train Epoch: 0 [128832/250314 (51%)]\tLoss: 0.732868\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:27 | INFO | Rank 0 | Train Epoch: 0 [128864/250314 (51%)]\tLoss: 0.596865\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:27 | INFO | Rank 0 | Train Epoch: 0 [128896/250314 (51%)]\tLoss: 0.521488\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:28 | INFO | Rank 0 | Train Epoch: 0 [128928/250314 (52%)]\tLoss: 1.053218\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:28 | INFO | Rank 0 | Train Epoch: 0 [128960/250314 (52%)]\tLoss: 0.472178\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:29 | INFO | Rank 0 | Train Epoch: 0 [128992/250314 (52%)]\tLoss: 0.392805\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:29 | INFO | Rank 0 | Train Epoch: 0 [129024/250314 (52%)]\tLoss: 0.852763\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:30 | INFO | Rank 0 | Train Epoch: 0 [129056/250314 (52%)]\tLoss: 0.830346\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:30 | INFO | Rank 0 | Train Epoch: 0 [129088/250314 (52%)]\tLoss: 0.573858\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:31 | INFO | Rank 0 | Train Epoch: 0 [129120/250314 (52%)]\tLoss: 0.595928\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:31 | INFO | Rank 0 | Train Epoch: 0 [129152/250314 (52%)]\tLoss: 0.583722\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:32 | INFO | Rank 0 | Train Epoch: 0 [129184/250314 (52%)]\tLoss: 0.657212\tData (t) 0.211\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:32 | INFO | Rank 0 | Train Epoch: 0 [129216/250314 (52%)]\tLoss: 0.926498\tData (t) 0.214\tBatch (t) 0.426\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:33 | INFO | Rank 0 | Train Epoch: 0 [129248/250314 (52%)]\tLoss: 0.740127\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:33 | INFO | Rank 0 | Train Epoch: 0 [129280/250314 (52%)]\tLoss: 0.653978\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:34 | INFO | Rank 0 | Train Epoch: 0 [129312/250314 (52%)]\tLoss: 0.636623\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:34 | INFO | Rank 0 | Train Epoch: 0 [129344/250314 (52%)]\tLoss: 0.896173\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:35 | INFO | Rank 0 | Train Epoch: 0 [129376/250314 (52%)]\tLoss: 0.376817\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:35 | INFO | Rank 0 | Train Epoch: 0 [129408/250314 (52%)]\tLoss: 1.264175\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:36 | INFO | Rank 0 | Train Epoch: 0 [129440/250314 (52%)]\tLoss: 0.870833\tData (t) 0.264\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:36 | INFO | Rank 0 | Train Epoch: 0 [129472/250314 (52%)]\tLoss: 0.552675\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:37 | INFO | Rank 0 | Train Epoch: 0 [129504/250314 (52%)]\tLoss: 0.529564\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:37 | INFO | Rank 0 | Train Epoch: 0 [129536/250314 (52%)]\tLoss: 0.959543\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:38 | INFO | Rank 0 | Train Epoch: 0 [129568/250314 (52%)]\tLoss: 0.521482\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:38 | INFO | Rank 0 | Train Epoch: 0 [129600/250314 (52%)]\tLoss: 0.513301\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:39 | INFO | Rank 0 | Train Epoch: 0 [129632/250314 (52%)]\tLoss: 0.652300\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:39 | INFO | Rank 0 | Train Epoch: 0 [129664/250314 (52%)]\tLoss: 0.848241\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:40 | INFO | Rank 0 | Train Epoch: 0 [129696/250314 (52%)]\tLoss: 0.390884\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:40 | INFO | Rank 0 | Train Epoch: 0 [129728/250314 (52%)]\tLoss: 0.476577\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:41 | INFO | Rank 0 | Train Epoch: 0 [129760/250314 (52%)]\tLoss: 0.615083\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:41 | INFO | Rank 0 | Train Epoch: 0 [129792/250314 (52%)]\tLoss: 0.598975\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:42 | INFO | Rank 0 | Train Epoch: 0 [129824/250314 (52%)]\tLoss: 1.360374\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:42 | INFO | Rank 0 | Train Epoch: 0 [129856/250314 (52%)]\tLoss: 0.658460\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:43 | INFO | Rank 0 | Train Epoch: 0 [129888/250314 (52%)]\tLoss: 0.616639\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:43 | INFO | Rank 0 | Train Epoch: 0 [129920/250314 (52%)]\tLoss: 0.885995\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:44 | INFO | Rank 0 | Train Epoch: 0 [129952/250314 (52%)]\tLoss: 0.562545\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:44 | INFO | Rank 0 | Train Epoch: 0 [129984/250314 (52%)]\tLoss: 0.857924\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:45 | INFO | Rank 0 | Train Epoch: 0 [130016/250314 (52%)]\tLoss: 0.709338\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:45 | INFO | Rank 0 | Train Epoch: 0 [130048/250314 (52%)]\tLoss: 0.645688\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:46 | INFO | Rank 0 | Train Epoch: 0 [130080/250314 (52%)]\tLoss: 0.884827\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:46 | INFO | Rank 0 | Train Epoch: 0 [130112/250314 (52%)]\tLoss: 0.411437\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:46 | INFO | Rank 0 | Train Epoch: 0 [130144/250314 (52%)]\tLoss: 0.595897\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:47 | INFO | Rank 0 | Train Epoch: 0 [130176/250314 (52%)]\tLoss: 0.569086\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:47 | INFO | Rank 0 | Train Epoch: 0 [130208/250314 (52%)]\tLoss: 0.575544\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:48 | INFO | Rank 0 | Train Epoch: 0 [130240/250314 (52%)]\tLoss: 1.070059\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:48 | INFO | Rank 0 | Train Epoch: 0 [130272/250314 (52%)]\tLoss: 0.614133\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:49 | INFO | Rank 0 | Train Epoch: 0 [130304/250314 (52%)]\tLoss: 0.763219\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:49 | INFO | Rank 0 | Train Epoch: 0 [130336/250314 (52%)]\tLoss: 0.728851\tData (t) 0.221\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:50 | INFO | Rank 0 | Train Epoch: 0 [130368/250314 (52%)]\tLoss: 0.930588\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:50 | INFO | Rank 0 | Train Epoch: 0 [130400/250314 (52%)]\tLoss: 0.439628\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:51 | INFO | Rank 0 | Train Epoch: 0 [130432/250314 (52%)]\tLoss: 0.636037\tData (t) 0.351\tBatch (t) 0.562\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:51 | INFO | Rank 0 | Train Epoch: 0 [130464/250314 (52%)]\tLoss: 0.423081\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:52 | INFO | Rank 0 | Train Epoch: 0 [130496/250314 (52%)]\tLoss: 0.680282\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:52 | INFO | Rank 0 | Train Epoch: 0 [130528/250314 (52%)]\tLoss: 0.694347\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:53 | INFO | Rank 0 | Train Epoch: 0 [130560/250314 (52%)]\tLoss: 0.898771\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:53 | INFO | Rank 0 | Train Epoch: 0 [130592/250314 (52%)]\tLoss: 0.704101\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:54 | INFO | Rank 0 | Train Epoch: 0 [130624/250314 (52%)]\tLoss: 0.577396\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:54 | INFO | Rank 0 | Train Epoch: 0 [130656/250314 (52%)]\tLoss: 1.040433\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:55 | INFO | Rank 0 | Train Epoch: 0 [130688/250314 (52%)]\tLoss: 0.753874\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:55 | INFO | Rank 0 | Train Epoch: 0 [130720/250314 (52%)]\tLoss: 0.550600\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:56 | INFO | Rank 0 | Train Epoch: 0 [130752/250314 (52%)]\tLoss: 0.776362\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:56 | INFO | Rank 0 | Train Epoch: 0 [130784/250314 (52%)]\tLoss: 1.289162\tData (t) 0.238\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:57 | INFO | Rank 0 | Train Epoch: 0 [130816/250314 (52%)]\tLoss: 0.923743\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:57 | INFO | Rank 0 | Train Epoch: 0 [130848/250314 (52%)]\tLoss: 0.753541\tData (t) 0.342\tBatch (t) 0.553\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:58 | INFO | Rank 0 | Train Epoch: 0 [130880/250314 (52%)]\tLoss: 0.555296\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:58 | INFO | Rank 0 | Train Epoch: 0 [130912/250314 (52%)]\tLoss: 1.142389\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:59 | INFO | Rank 0 | Train Epoch: 0 [130944/250314 (52%)]\tLoss: 0.486204\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:43:59 | INFO | Rank 0 | Train Epoch: 0 [130976/250314 (52%)]\tLoss: 0.701539\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:00 | INFO | Rank 0 | Train Epoch: 0 [131008/250314 (52%)]\tLoss: 0.691641\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:00 | INFO | Rank 0 | Train Epoch: 0 [131040/250314 (52%)]\tLoss: 0.733380\tData (t) 0.299\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:01 | INFO | Rank 0 | Train Epoch: 0 [131072/250314 (52%)]\tLoss: 0.643375\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:01 | INFO | Rank 0 | Train Epoch: 0 [131104/250314 (52%)]\tLoss: 0.719594\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:02 | INFO | Rank 0 | Train Epoch: 0 [131136/250314 (52%)]\tLoss: 0.686244\tData (t) 0.222\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:02 | INFO | Rank 0 | Train Epoch: 0 [131168/250314 (52%)]\tLoss: 0.487387\tData (t) 0.230\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:03 | INFO | Rank 0 | Train Epoch: 0 [131200/250314 (52%)]\tLoss: 0.982711\tData (t) 0.217\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:03 | INFO | Rank 0 | Train Epoch: 0 [131232/250314 (52%)]\tLoss: 0.664422\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:04 | INFO | Rank 0 | Train Epoch: 0 [131264/250314 (52%)]\tLoss: 0.450256\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:04 | INFO | Rank 0 | Train Epoch: 0 [131296/250314 (52%)]\tLoss: 0.946015\tData (t) 0.356\tBatch (t) 0.567\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:05 | INFO | Rank 0 | Train Epoch: 0 [131328/250314 (52%)]\tLoss: 0.452533\tData (t) 0.221\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:05 | INFO | Rank 0 | Train Epoch: 0 [131360/250314 (52%)]\tLoss: 0.516195\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:06 | INFO | Rank 0 | Train Epoch: 0 [131392/250314 (52%)]\tLoss: 0.882997\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:06 | INFO | Rank 0 | Train Epoch: 0 [131424/250314 (53%)]\tLoss: 0.939689\tData (t) 0.316\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:07 | INFO | Rank 0 | Train Epoch: 0 [131456/250314 (53%)]\tLoss: 0.882252\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:07 | INFO | Rank 0 | Train Epoch: 0 [131488/250314 (53%)]\tLoss: 0.888008\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:08 | INFO | Rank 0 | Train Epoch: 0 [131520/250314 (53%)]\tLoss: 0.965539\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:08 | INFO | Rank 0 | Train Epoch: 0 [131552/250314 (53%)]\tLoss: 1.274117\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:09 | INFO | Rank 0 | Train Epoch: 0 [131584/250314 (53%)]\tLoss: 1.044039\tData (t) 0.211\tBatch (t) 0.423\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:09 | INFO | Rank 0 | Train Epoch: 0 [131616/250314 (53%)]\tLoss: 0.794296\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:10 | INFO | Rank 0 | Train Epoch: 0 [131648/250314 (53%)]\tLoss: 0.810532\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:10 | INFO | Rank 0 | Train Epoch: 0 [131680/250314 (53%)]\tLoss: 0.793610\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:11 | INFO | Rank 0 | Train Epoch: 0 [131712/250314 (53%)]\tLoss: 0.798766\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:11 | INFO | Rank 0 | Train Epoch: 0 [131744/250314 (53%)]\tLoss: 0.949568\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:12 | INFO | Rank 0 | Train Epoch: 0 [131776/250314 (53%)]\tLoss: 0.697882\tData (t) 0.338\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:12 | INFO | Rank 0 | Train Epoch: 0 [131808/250314 (53%)]\tLoss: 1.212105\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:12 | INFO | Rank 0 | Train Epoch: 0 [131840/250314 (53%)]\tLoss: 0.834804\tData (t) 0.196\tBatch (t) 0.407\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:13 | INFO | Rank 0 | Train Epoch: 0 [131872/250314 (53%)]\tLoss: 0.670082\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:13 | INFO | Rank 0 | Train Epoch: 0 [131904/250314 (53%)]\tLoss: 1.138504\tData (t) 0.307\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:14 | INFO | Rank 0 | Train Epoch: 0 [131936/250314 (53%)]\tLoss: 0.471710\tData (t) 0.214\tBatch (t) 0.426\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:14 | INFO | Rank 0 | Train Epoch: 0 [131968/250314 (53%)]\tLoss: 0.775494\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:15 | INFO | Rank 0 | Train Epoch: 0 [132000/250314 (53%)]\tLoss: 0.438196\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:15 | INFO | Rank 0 | Train Epoch: 0 [132032/250314 (53%)]\tLoss: 0.637753\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:16 | INFO | Rank 0 | Train Epoch: 0 [132064/250314 (53%)]\tLoss: 0.398686\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:16 | INFO | Rank 0 | Train Epoch: 0 [132096/250314 (53%)]\tLoss: 1.173102\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:17 | INFO | Rank 0 | Train Epoch: 0 [132128/250314 (53%)]\tLoss: 0.803286\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:17 | INFO | Rank 0 | Train Epoch: 0 [132160/250314 (53%)]\tLoss: 0.773964\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:18 | INFO | Rank 0 | Train Epoch: 0 [132192/250314 (53%)]\tLoss: 0.453945\tData (t) 0.216\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:18 | INFO | Rank 0 | Train Epoch: 0 [132224/250314 (53%)]\tLoss: 0.620687\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:19 | INFO | Rank 0 | Train Epoch: 0 [132256/250314 (53%)]\tLoss: 0.677793\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:19 | INFO | Rank 0 | Train Epoch: 0 [132288/250314 (53%)]\tLoss: 0.690106\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:20 | INFO | Rank 0 | Train Epoch: 0 [132320/250314 (53%)]\tLoss: 0.433820\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:20 | INFO | Rank 0 | Train Epoch: 0 [132352/250314 (53%)]\tLoss: 0.666775\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:21 | INFO | Rank 0 | Train Epoch: 0 [132384/250314 (53%)]\tLoss: 0.779225\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:21 | INFO | Rank 0 | Train Epoch: 0 [132416/250314 (53%)]\tLoss: 1.031038\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:22 | INFO | Rank 0 | Train Epoch: 0 [132448/250314 (53%)]\tLoss: 0.435489\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:22 | INFO | Rank 0 | Train Epoch: 0 [132480/250314 (53%)]\tLoss: 0.681564\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:23 | INFO | Rank 0 | Train Epoch: 0 [132512/250314 (53%)]\tLoss: 0.698320\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:23 | INFO | Rank 0 | Train Epoch: 0 [132544/250314 (53%)]\tLoss: 0.874870\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:24 | INFO | Rank 0 | Train Epoch: 0 [132576/250314 (53%)]\tLoss: 0.720420\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:24 | INFO | Rank 0 | Train Epoch: 0 [132608/250314 (53%)]\tLoss: 1.019189\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:25 | INFO | Rank 0 | Train Epoch: 0 [132640/250314 (53%)]\tLoss: 0.526182\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:25 | INFO | Rank 0 | Train Epoch: 0 [132672/250314 (53%)]\tLoss: 0.646177\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:26 | INFO | Rank 0 | Train Epoch: 0 [132704/250314 (53%)]\tLoss: 0.698932\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:26 | INFO | Rank 0 | Train Epoch: 0 [132736/250314 (53%)]\tLoss: 0.479312\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:27 | INFO | Rank 0 | Train Epoch: 0 [132768/250314 (53%)]\tLoss: 1.009765\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:27 | INFO | Rank 0 | Train Epoch: 0 [132800/250314 (53%)]\tLoss: 0.655384\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:27 | INFO | Rank 0 | Train Epoch: 0 [132832/250314 (53%)]\tLoss: 1.013733\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:28 | INFO | Rank 0 | Train Epoch: 0 [132864/250314 (53%)]\tLoss: 0.495668\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:28 | INFO | Rank 0 | Train Epoch: 0 [132896/250314 (53%)]\tLoss: 0.599153\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:29 | INFO | Rank 0 | Train Epoch: 0 [132928/250314 (53%)]\tLoss: 0.627799\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:29 | INFO | Rank 0 | Train Epoch: 0 [132960/250314 (53%)]\tLoss: 0.754914\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:30 | INFO | Rank 0 | Train Epoch: 0 [132992/250314 (53%)]\tLoss: 0.853899\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:30 | INFO | Rank 0 | Train Epoch: 0 [133024/250314 (53%)]\tLoss: 0.764107\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:31 | INFO | Rank 0 | Train Epoch: 0 [133056/250314 (53%)]\tLoss: 0.298301\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:31 | INFO | Rank 0 | Train Epoch: 0 [133088/250314 (53%)]\tLoss: 0.582165\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:32 | INFO | Rank 0 | Train Epoch: 0 [133120/250314 (53%)]\tLoss: 0.622535\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:32 | INFO | Rank 0 | Train Epoch: 0 [133152/250314 (53%)]\tLoss: 0.735294\tData (t) 0.233\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:33 | INFO | Rank 0 | Train Epoch: 0 [133184/250314 (53%)]\tLoss: 0.619163\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:33 | INFO | Rank 0 | Train Epoch: 0 [133216/250314 (53%)]\tLoss: 0.779232\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:34 | INFO | Rank 0 | Train Epoch: 0 [133248/250314 (53%)]\tLoss: 0.720177\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:34 | INFO | Rank 0 | Train Epoch: 0 [133280/250314 (53%)]\tLoss: 0.477303\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:35 | INFO | Rank 0 | Train Epoch: 0 [133312/250314 (53%)]\tLoss: 0.801627\tData (t) 0.257\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:35 | INFO | Rank 0 | Train Epoch: 0 [133344/250314 (53%)]\tLoss: 0.494216\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:36 | INFO | Rank 0 | Train Epoch: 0 [133376/250314 (53%)]\tLoss: 0.833901\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:36 | INFO | Rank 0 | Train Epoch: 0 [133408/250314 (53%)]\tLoss: 0.308755\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:37 | INFO | Rank 0 | Train Epoch: 0 [133440/250314 (53%)]\tLoss: 0.915198\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:37 | INFO | Rank 0 | Train Epoch: 0 [133472/250314 (53%)]\tLoss: 0.625184\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:38 | INFO | Rank 0 | Train Epoch: 0 [133504/250314 (53%)]\tLoss: 0.458719\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:38 | INFO | Rank 0 | Train Epoch: 0 [133536/250314 (53%)]\tLoss: 0.966550\tData (t) 0.209\tBatch (t) 0.421\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:39 | INFO | Rank 0 | Train Epoch: 0 [133568/250314 (53%)]\tLoss: 0.596224\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:39 | INFO | Rank 0 | Train Epoch: 0 [133600/250314 (53%)]\tLoss: 0.873377\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:40 | INFO | Rank 0 | Train Epoch: 0 [133632/250314 (53%)]\tLoss: 1.084113\tData (t) 0.229\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:40 | INFO | Rank 0 | Train Epoch: 0 [133664/250314 (53%)]\tLoss: 0.710331\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:41 | INFO | Rank 0 | Train Epoch: 0 [133696/250314 (53%)]\tLoss: 0.418969\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:41 | INFO | Rank 0 | Train Epoch: 0 [133728/250314 (53%)]\tLoss: 0.921309\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:42 | INFO | Rank 0 | Train Epoch: 0 [133760/250314 (53%)]\tLoss: 0.829894\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:42 | INFO | Rank 0 | Train Epoch: 0 [133792/250314 (53%)]\tLoss: 0.654685\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:43 | INFO | Rank 0 | Train Epoch: 0 [133824/250314 (53%)]\tLoss: 0.637190\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:43 | INFO | Rank 0 | Train Epoch: 0 [133856/250314 (53%)]\tLoss: 0.569188\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:43 | INFO | Rank 0 | Train Epoch: 0 [133888/250314 (53%)]\tLoss: 0.903058\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:44 | INFO | Rank 0 | Train Epoch: 0 [133920/250314 (54%)]\tLoss: 0.705360\tData (t) 0.191\tBatch (t) 0.403\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:44 | INFO | Rank 0 | Train Epoch: 0 [133952/250314 (54%)]\tLoss: 0.588702\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:45 | INFO | Rank 0 | Train Epoch: 0 [133984/250314 (54%)]\tLoss: 0.530972\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:45 | INFO | Rank 0 | Train Epoch: 0 [134016/250314 (54%)]\tLoss: 0.726049\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:46 | INFO | Rank 0 | Train Epoch: 0 [134048/250314 (54%)]\tLoss: 0.646109\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:46 | INFO | Rank 0 | Train Epoch: 0 [134080/250314 (54%)]\tLoss: 0.841537\tData (t) 0.219\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:47 | INFO | Rank 0 | Train Epoch: 0 [134112/250314 (54%)]\tLoss: 1.204420\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:47 | INFO | Rank 0 | Train Epoch: 0 [134144/250314 (54%)]\tLoss: 0.739858\tData (t) 0.322\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:48 | INFO | Rank 0 | Train Epoch: 0 [134176/250314 (54%)]\tLoss: 1.227271\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:48 | INFO | Rank 0 | Train Epoch: 0 [134208/250314 (54%)]\tLoss: 1.058204\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.594\n",
      "2022-11-09,13:44:49 | INFO | Rank 0 | Train Epoch: 0 [134240/250314 (54%)]\tLoss: 1.005059\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:49 | INFO | Rank 0 | Train Epoch: 0 [134272/250314 (54%)]\tLoss: 0.979032\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:50 | INFO | Rank 0 | Train Epoch: 0 [134304/250314 (54%)]\tLoss: 0.545782\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:50 | INFO | Rank 0 | Train Epoch: 0 [134336/250314 (54%)]\tLoss: 0.773703\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:51 | INFO | Rank 0 | Train Epoch: 0 [134368/250314 (54%)]\tLoss: 0.614596\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:51 | INFO | Rank 0 | Train Epoch: 0 [134400/250314 (54%)]\tLoss: 0.774816\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:52 | INFO | Rank 0 | Train Epoch: 0 [134432/250314 (54%)]\tLoss: 0.632633\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:52 | INFO | Rank 0 | Train Epoch: 0 [134464/250314 (54%)]\tLoss: 0.728000\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:53 | INFO | Rank 0 | Train Epoch: 0 [134496/250314 (54%)]\tLoss: 0.651275\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:53 | INFO | Rank 0 | Train Epoch: 0 [134528/250314 (54%)]\tLoss: 1.083636\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:54 | INFO | Rank 0 | Train Epoch: 0 [134560/250314 (54%)]\tLoss: 0.782979\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:54 | INFO | Rank 0 | Train Epoch: 0 [134592/250314 (54%)]\tLoss: 0.745439\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:55 | INFO | Rank 0 | Train Epoch: 0 [134624/250314 (54%)]\tLoss: 1.267552\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:55 | INFO | Rank 0 | Train Epoch: 0 [134656/250314 (54%)]\tLoss: 0.641715\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:55 | INFO | Rank 0 | Train Epoch: 0 [134688/250314 (54%)]\tLoss: 0.735824\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:56 | INFO | Rank 0 | Train Epoch: 0 [134720/250314 (54%)]\tLoss: 0.937790\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:57 | INFO | Rank 0 | Train Epoch: 0 [134752/250314 (54%)]\tLoss: 0.975314\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:57 | INFO | Rank 0 | Train Epoch: 0 [134784/250314 (54%)]\tLoss: 0.858893\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:57 | INFO | Rank 0 | Train Epoch: 0 [134816/250314 (54%)]\tLoss: 0.767216\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:58 | INFO | Rank 0 | Train Epoch: 0 [134848/250314 (54%)]\tLoss: 0.702156\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:58 | INFO | Rank 0 | Train Epoch: 0 [134880/250314 (54%)]\tLoss: 0.922203\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:59 | INFO | Rank 0 | Train Epoch: 0 [134912/250314 (54%)]\tLoss: 0.775972\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:44:59 | INFO | Rank 0 | Train Epoch: 0 [134944/250314 (54%)]\tLoss: 0.664313\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:00 | INFO | Rank 0 | Train Epoch: 0 [134976/250314 (54%)]\tLoss: 0.937128\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:00 | INFO | Rank 0 | Train Epoch: 0 [135008/250314 (54%)]\tLoss: 0.729497\tData (t) 0.204\tBatch (t) 0.416\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:01 | INFO | Rank 0 | Train Epoch: 0 [135040/250314 (54%)]\tLoss: 0.625238\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:01 | INFO | Rank 0 | Train Epoch: 0 [135072/250314 (54%)]\tLoss: 0.619757\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:02 | INFO | Rank 0 | Train Epoch: 0 [135104/250314 (54%)]\tLoss: 0.691245\tData (t) 0.333\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:02 | INFO | Rank 0 | Train Epoch: 0 [135136/250314 (54%)]\tLoss: 0.631179\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:03 | INFO | Rank 0 | Train Epoch: 0 [135168/250314 (54%)]\tLoss: 0.561943\tData (t) 0.226\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:03 | INFO | Rank 0 | Train Epoch: 0 [135200/250314 (54%)]\tLoss: 0.548219\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:04 | INFO | Rank 0 | Train Epoch: 0 [135232/250314 (54%)]\tLoss: 0.456186\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:04 | INFO | Rank 0 | Train Epoch: 0 [135264/250314 (54%)]\tLoss: 0.754649\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:05 | INFO | Rank 0 | Train Epoch: 0 [135296/250314 (54%)]\tLoss: 0.782572\tData (t) 0.205\tBatch (t) 0.416\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:05 | INFO | Rank 0 | Train Epoch: 0 [135328/250314 (54%)]\tLoss: 0.731310\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:06 | INFO | Rank 0 | Train Epoch: 0 [135360/250314 (54%)]\tLoss: 0.671563\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:06 | INFO | Rank 0 | Train Epoch: 0 [135392/250314 (54%)]\tLoss: 0.772192\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:06 | INFO | Rank 0 | Train Epoch: 0 [135424/250314 (54%)]\tLoss: 0.825479\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:07 | INFO | Rank 0 | Train Epoch: 0 [135456/250314 (54%)]\tLoss: 0.916479\tData (t) 0.378\tBatch (t) 0.590\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:08 | INFO | Rank 0 | Train Epoch: 0 [135488/250314 (54%)]\tLoss: 0.608564\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:08 | INFO | Rank 0 | Train Epoch: 0 [135520/250314 (54%)]\tLoss: 0.500611\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:09 | INFO | Rank 0 | Train Epoch: 0 [135552/250314 (54%)]\tLoss: 0.699056\tData (t) 0.330\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:09 | INFO | Rank 0 | Train Epoch: 0 [135584/250314 (54%)]\tLoss: 1.054109\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:09 | INFO | Rank 0 | Train Epoch: 0 [135616/250314 (54%)]\tLoss: 0.789545\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:10 | INFO | Rank 0 | Train Epoch: 0 [135648/250314 (54%)]\tLoss: 0.789635\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:10 | INFO | Rank 0 | Train Epoch: 0 [135680/250314 (54%)]\tLoss: 0.461044\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:11 | INFO | Rank 0 | Train Epoch: 0 [135712/250314 (54%)]\tLoss: 0.959304\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:11 | INFO | Rank 0 | Train Epoch: 0 [135744/250314 (54%)]\tLoss: 0.459811\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:12 | INFO | Rank 0 | Train Epoch: 0 [135776/250314 (54%)]\tLoss: 0.787813\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:12 | INFO | Rank 0 | Train Epoch: 0 [135808/250314 (54%)]\tLoss: 0.622131\tData (t) 0.188\tBatch (t) 0.400\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:13 | INFO | Rank 0 | Train Epoch: 0 [135840/250314 (54%)]\tLoss: 0.486724\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:13 | INFO | Rank 0 | Train Epoch: 0 [135872/250314 (54%)]\tLoss: 0.627318\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:14 | INFO | Rank 0 | Train Epoch: 0 [135904/250314 (54%)]\tLoss: 0.608707\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:14 | INFO | Rank 0 | Train Epoch: 0 [135936/250314 (54%)]\tLoss: 0.897906\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:15 | INFO | Rank 0 | Train Epoch: 0 [135968/250314 (54%)]\tLoss: 0.744044\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:15 | INFO | Rank 0 | Train Epoch: 0 [136000/250314 (54%)]\tLoss: 0.810017\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:16 | INFO | Rank 0 | Train Epoch: 0 [136032/250314 (54%)]\tLoss: 0.559092\tData (t) 0.220\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:16 | INFO | Rank 0 | Train Epoch: 0 [136064/250314 (54%)]\tLoss: 0.482633\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:17 | INFO | Rank 0 | Train Epoch: 0 [136096/250314 (54%)]\tLoss: 0.687559\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:17 | INFO | Rank 0 | Train Epoch: 0 [136128/250314 (54%)]\tLoss: 0.491218\tData (t) 0.224\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:17 | INFO | Rank 0 | Train Epoch: 0 [136160/250314 (54%)]\tLoss: 1.059377\tData (t) 0.178\tBatch (t) 0.390\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:18 | INFO | Rank 0 | Train Epoch: 0 [136192/250314 (54%)]\tLoss: 0.739282\tData (t) 0.350\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:18 | INFO | Rank 0 | Train Epoch: 0 [136224/250314 (54%)]\tLoss: 0.900589\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:19 | INFO | Rank 0 | Train Epoch: 0 [136256/250314 (54%)]\tLoss: 1.386735\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:19 | INFO | Rank 0 | Train Epoch: 0 [136288/250314 (54%)]\tLoss: 0.539825\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:20 | INFO | Rank 0 | Train Epoch: 0 [136320/250314 (54%)]\tLoss: 0.525762\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:20 | INFO | Rank 0 | Train Epoch: 0 [136352/250314 (54%)]\tLoss: 0.521674\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:21 | INFO | Rank 0 | Train Epoch: 0 [136384/250314 (54%)]\tLoss: 0.650455\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:21 | INFO | Rank 0 | Train Epoch: 0 [136416/250314 (55%)]\tLoss: 0.968914\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:22 | INFO | Rank 0 | Train Epoch: 0 [136448/250314 (55%)]\tLoss: 1.009254\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:22 | INFO | Rank 0 | Train Epoch: 0 [136480/250314 (55%)]\tLoss: 0.634914\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:23 | INFO | Rank 0 | Train Epoch: 0 [136512/250314 (55%)]\tLoss: 0.672600\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:23 | INFO | Rank 0 | Train Epoch: 0 [136544/250314 (55%)]\tLoss: 0.707863\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:24 | INFO | Rank 0 | Train Epoch: 0 [136576/250314 (55%)]\tLoss: 0.878614\tData (t) 0.407\tBatch (t) 0.618\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:24 | INFO | Rank 0 | Train Epoch: 0 [136608/250314 (55%)]\tLoss: 0.525116\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:25 | INFO | Rank 0 | Train Epoch: 0 [136640/250314 (55%)]\tLoss: 0.587643\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:25 | INFO | Rank 0 | Train Epoch: 0 [136672/250314 (55%)]\tLoss: 0.737534\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:26 | INFO | Rank 0 | Train Epoch: 0 [136704/250314 (55%)]\tLoss: 0.866684\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:26 | INFO | Rank 0 | Train Epoch: 0 [136736/250314 (55%)]\tLoss: 0.779567\tData (t) 0.221\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:27 | INFO | Rank 0 | Train Epoch: 0 [136768/250314 (55%)]\tLoss: 0.872960\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:27 | INFO | Rank 0 | Train Epoch: 0 [136800/250314 (55%)]\tLoss: 0.683522\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:28 | INFO | Rank 0 | Train Epoch: 0 [136832/250314 (55%)]\tLoss: 0.688322\tData (t) 0.359\tBatch (t) 0.571\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:28 | INFO | Rank 0 | Train Epoch: 0 [136864/250314 (55%)]\tLoss: 0.770084\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:29 | INFO | Rank 0 | Train Epoch: 0 [136896/250314 (55%)]\tLoss: 0.694214\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:29 | INFO | Rank 0 | Train Epoch: 0 [136928/250314 (55%)]\tLoss: 0.764140\tData (t) 0.233\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:30 | INFO | Rank 0 | Train Epoch: 0 [136960/250314 (55%)]\tLoss: 1.058309\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:30 | INFO | Rank 0 | Train Epoch: 0 [136992/250314 (55%)]\tLoss: 0.601932\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:31 | INFO | Rank 0 | Train Epoch: 0 [137024/250314 (55%)]\tLoss: 0.487894\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:31 | INFO | Rank 0 | Train Epoch: 0 [137056/250314 (55%)]\tLoss: 0.672497\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:32 | INFO | Rank 0 | Train Epoch: 0 [137088/250314 (55%)]\tLoss: 0.863057\tData (t) 0.353\tBatch (t) 0.564\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:32 | INFO | Rank 0 | Train Epoch: 0 [137120/250314 (55%)]\tLoss: 0.848697\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:33 | INFO | Rank 0 | Train Epoch: 0 [137152/250314 (55%)]\tLoss: 0.926419\tData (t) 0.222\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:33 | INFO | Rank 0 | Train Epoch: 0 [137184/250314 (55%)]\tLoss: 0.658181\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:34 | INFO | Rank 0 | Train Epoch: 0 [137216/250314 (55%)]\tLoss: 0.687296\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:34 | INFO | Rank 0 | Train Epoch: 0 [137248/250314 (55%)]\tLoss: 0.942175\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:35 | INFO | Rank 0 | Train Epoch: 0 [137280/250314 (55%)]\tLoss: 1.256483\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:35 | INFO | Rank 0 | Train Epoch: 0 [137312/250314 (55%)]\tLoss: 1.016686\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:36 | INFO | Rank 0 | Train Epoch: 0 [137344/250314 (55%)]\tLoss: 0.631693\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:36 | INFO | Rank 0 | Train Epoch: 0 [137376/250314 (55%)]\tLoss: 0.879992\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:37 | INFO | Rank 0 | Train Epoch: 0 [137408/250314 (55%)]\tLoss: 0.929612\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:37 | INFO | Rank 0 | Train Epoch: 0 [137440/250314 (55%)]\tLoss: 0.699189\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:38 | INFO | Rank 0 | Train Epoch: 0 [137472/250314 (55%)]\tLoss: 1.053936\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:38 | INFO | Rank 0 | Train Epoch: 0 [137504/250314 (55%)]\tLoss: 0.522310\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:39 | INFO | Rank 0 | Train Epoch: 0 [137536/250314 (55%)]\tLoss: 0.416638\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:39 | INFO | Rank 0 | Train Epoch: 0 [137568/250314 (55%)]\tLoss: 0.560100\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:40 | INFO | Rank 0 | Train Epoch: 0 [137600/250314 (55%)]\tLoss: 0.540947\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:40 | INFO | Rank 0 | Train Epoch: 0 [137632/250314 (55%)]\tLoss: 0.613234\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:41 | INFO | Rank 0 | Train Epoch: 0 [137664/250314 (55%)]\tLoss: 0.678901\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:41 | INFO | Rank 0 | Train Epoch: 0 [137696/250314 (55%)]\tLoss: 0.747318\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:42 | INFO | Rank 0 | Train Epoch: 0 [137728/250314 (55%)]\tLoss: 0.794737\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:42 | INFO | Rank 0 | Train Epoch: 0 [137760/250314 (55%)]\tLoss: 0.662044\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:43 | INFO | Rank 0 | Train Epoch: 0 [137792/250314 (55%)]\tLoss: 0.589669\tData (t) 0.257\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:43 | INFO | Rank 0 | Train Epoch: 0 [137824/250314 (55%)]\tLoss: 1.090924\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:44 | INFO | Rank 0 | Train Epoch: 0 [137856/250314 (55%)]\tLoss: 0.393110\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:44 | INFO | Rank 0 | Train Epoch: 0 [137888/250314 (55%)]\tLoss: 0.849513\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:45 | INFO | Rank 0 | Train Epoch: 0 [137920/250314 (55%)]\tLoss: 0.632442\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:45 | INFO | Rank 0 | Train Epoch: 0 [137952/250314 (55%)]\tLoss: 0.846655\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:46 | INFO | Rank 0 | Train Epoch: 0 [137984/250314 (55%)]\tLoss: 0.781699\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:46 | INFO | Rank 0 | Train Epoch: 0 [138016/250314 (55%)]\tLoss: 0.219886\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:47 | INFO | Rank 0 | Train Epoch: 0 [138048/250314 (55%)]\tLoss: 0.834592\tData (t) 0.296\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:47 | INFO | Rank 0 | Train Epoch: 0 [138080/250314 (55%)]\tLoss: 0.531960\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:48 | INFO | Rank 0 | Train Epoch: 0 [138112/250314 (55%)]\tLoss: 0.661947\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:48 | INFO | Rank 0 | Train Epoch: 0 [138144/250314 (55%)]\tLoss: 0.840794\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:49 | INFO | Rank 0 | Train Epoch: 0 [138176/250314 (55%)]\tLoss: 0.889276\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:49 | INFO | Rank 0 | Train Epoch: 0 [138208/250314 (55%)]\tLoss: 0.759297\tData (t) 0.326\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:50 | INFO | Rank 0 | Train Epoch: 0 [138240/250314 (55%)]\tLoss: 0.399082\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:50 | INFO | Rank 0 | Train Epoch: 0 [138272/250314 (55%)]\tLoss: 0.685060\tData (t) 0.220\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:50 | INFO | Rank 0 | Train Epoch: 0 [138304/250314 (55%)]\tLoss: 0.562272\tData (t) 0.225\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:51 | INFO | Rank 0 | Train Epoch: 0 [138336/250314 (55%)]\tLoss: 0.743068\tData (t) 0.213\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:51 | INFO | Rank 0 | Train Epoch: 0 [138368/250314 (55%)]\tLoss: 0.657280\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:52 | INFO | Rank 0 | Train Epoch: 0 [138400/250314 (55%)]\tLoss: 0.784415\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:52 | INFO | Rank 0 | Train Epoch: 0 [138432/250314 (55%)]\tLoss: 1.159114\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:53 | INFO | Rank 0 | Train Epoch: 0 [138464/250314 (55%)]\tLoss: 0.684832\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:53 | INFO | Rank 0 | Train Epoch: 0 [138496/250314 (55%)]\tLoss: 0.682135\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:54 | INFO | Rank 0 | Train Epoch: 0 [138528/250314 (55%)]\tLoss: 0.986896\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:54 | INFO | Rank 0 | Train Epoch: 0 [138560/250314 (55%)]\tLoss: 0.685482\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:55 | INFO | Rank 0 | Train Epoch: 0 [138592/250314 (55%)]\tLoss: 0.589772\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:55 | INFO | Rank 0 | Train Epoch: 0 [138624/250314 (55%)]\tLoss: 0.817162\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:56 | INFO | Rank 0 | Train Epoch: 0 [138656/250314 (55%)]\tLoss: 0.523484\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:56 | INFO | Rank 0 | Train Epoch: 0 [138688/250314 (55%)]\tLoss: 0.948450\tData (t) 0.245\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:57 | INFO | Rank 0 | Train Epoch: 0 [138720/250314 (55%)]\tLoss: 0.831195\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:57 | INFO | Rank 0 | Train Epoch: 0 [138752/250314 (55%)]\tLoss: 0.586290\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:58 | INFO | Rank 0 | Train Epoch: 0 [138784/250314 (55%)]\tLoss: 0.345979\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:58 | INFO | Rank 0 | Train Epoch: 0 [138816/250314 (55%)]\tLoss: 0.269453\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:59 | INFO | Rank 0 | Train Epoch: 0 [138848/250314 (55%)]\tLoss: 0.841653\tData (t) 0.229\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:59 | INFO | Rank 0 | Train Epoch: 0 [138880/250314 (55%)]\tLoss: 0.595944\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:45:59 | INFO | Rank 0 | Train Epoch: 0 [138912/250314 (55%)]\tLoss: 0.783481\tData (t) 0.216\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:00 | INFO | Rank 0 | Train Epoch: 0 [138944/250314 (56%)]\tLoss: 0.777854\tData (t) 0.351\tBatch (t) 0.563\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:01 | INFO | Rank 0 | Train Epoch: 0 [138976/250314 (56%)]\tLoss: 0.692713\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:01 | INFO | Rank 0 | Train Epoch: 0 [139008/250314 (56%)]\tLoss: 0.963283\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:02 | INFO | Rank 0 | Train Epoch: 0 [139040/250314 (56%)]\tLoss: 0.829683\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:02 | INFO | Rank 0 | Train Epoch: 0 [139072/250314 (56%)]\tLoss: 0.595897\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:03 | INFO | Rank 0 | Train Epoch: 0 [139104/250314 (56%)]\tLoss: 0.901122\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:03 | INFO | Rank 0 | Train Epoch: 0 [139136/250314 (56%)]\tLoss: 0.547729\tData (t) 0.216\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:03 | INFO | Rank 0 | Train Epoch: 0 [139168/250314 (56%)]\tLoss: 0.995995\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:04 | INFO | Rank 0 | Train Epoch: 0 [139200/250314 (56%)]\tLoss: 0.596558\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:04 | INFO | Rank 0 | Train Epoch: 0 [139232/250314 (56%)]\tLoss: 0.663629\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:05 | INFO | Rank 0 | Train Epoch: 0 [139264/250314 (56%)]\tLoss: 1.331121\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:05 | INFO | Rank 0 | Train Epoch: 0 [139296/250314 (56%)]\tLoss: 0.739482\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:06 | INFO | Rank 0 | Train Epoch: 0 [139328/250314 (56%)]\tLoss: 0.625741\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:06 | INFO | Rank 0 | Train Epoch: 0 [139360/250314 (56%)]\tLoss: 0.859426\tData (t) 0.216\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:07 | INFO | Rank 0 | Train Epoch: 0 [139392/250314 (56%)]\tLoss: 0.622724\tData (t) 0.218\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:07 | INFO | Rank 0 | Train Epoch: 0 [139424/250314 (56%)]\tLoss: 0.647361\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:08 | INFO | Rank 0 | Train Epoch: 0 [139456/250314 (56%)]\tLoss: 0.635381\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:08 | INFO | Rank 0 | Train Epoch: 0 [139488/250314 (56%)]\tLoss: 0.577126\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:09 | INFO | Rank 0 | Train Epoch: 0 [139520/250314 (56%)]\tLoss: 0.583237\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:09 | INFO | Rank 0 | Train Epoch: 0 [139552/250314 (56%)]\tLoss: 1.004700\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:10 | INFO | Rank 0 | Train Epoch: 0 [139584/250314 (56%)]\tLoss: 0.679658\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:10 | INFO | Rank 0 | Train Epoch: 0 [139616/250314 (56%)]\tLoss: 0.477160\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:11 | INFO | Rank 0 | Train Epoch: 0 [139648/250314 (56%)]\tLoss: 0.591185\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:11 | INFO | Rank 0 | Train Epoch: 0 [139680/250314 (56%)]\tLoss: 0.507427\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:12 | INFO | Rank 0 | Train Epoch: 0 [139712/250314 (56%)]\tLoss: 0.620594\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:12 | INFO | Rank 0 | Train Epoch: 0 [139744/250314 (56%)]\tLoss: 0.860597\tData (t) 0.229\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:12 | INFO | Rank 0 | Train Epoch: 0 [139776/250314 (56%)]\tLoss: 0.419567\tData (t) 0.221\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:13 | INFO | Rank 0 | Train Epoch: 0 [139808/250314 (56%)]\tLoss: 0.563064\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:13 | INFO | Rank 0 | Train Epoch: 0 [139840/250314 (56%)]\tLoss: 0.613028\tData (t) 0.307\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:14 | INFO | Rank 0 | Train Epoch: 0 [139872/250314 (56%)]\tLoss: 0.981871\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:14 | INFO | Rank 0 | Train Epoch: 0 [139904/250314 (56%)]\tLoss: 0.258085\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:15 | INFO | Rank 0 | Train Epoch: 0 [139936/250314 (56%)]\tLoss: 0.616489\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:15 | INFO | Rank 0 | Train Epoch: 0 [139968/250314 (56%)]\tLoss: 1.028790\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:16 | INFO | Rank 0 | Train Epoch: 0 [140000/250314 (56%)]\tLoss: 0.873486\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:16 | INFO | Rank 0 | Train Epoch: 0 [140032/250314 (56%)]\tLoss: 1.390061\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:17 | INFO | Rank 0 | Train Epoch: 0 [140064/250314 (56%)]\tLoss: 0.905259\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:17 | INFO | Rank 0 | Train Epoch: 0 [140096/250314 (56%)]\tLoss: 0.649372\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:18 | INFO | Rank 0 | Train Epoch: 0 [140128/250314 (56%)]\tLoss: 0.402670\tData (t) 0.229\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:18 | INFO | Rank 0 | Train Epoch: 0 [140160/250314 (56%)]\tLoss: 1.078102\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:19 | INFO | Rank 0 | Train Epoch: 0 [140192/250314 (56%)]\tLoss: 0.698334\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:19 | INFO | Rank 0 | Train Epoch: 0 [140224/250314 (56%)]\tLoss: 0.724716\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:20 | INFO | Rank 0 | Train Epoch: 0 [140256/250314 (56%)]\tLoss: 0.851153\tData (t) 0.222\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:20 | INFO | Rank 0 | Train Epoch: 0 [140288/250314 (56%)]\tLoss: 0.760026\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:21 | INFO | Rank 0 | Train Epoch: 0 [140320/250314 (56%)]\tLoss: 0.634060\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:21 | INFO | Rank 0 | Train Epoch: 0 [140352/250314 (56%)]\tLoss: 0.610939\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:22 | INFO | Rank 0 | Train Epoch: 0 [140384/250314 (56%)]\tLoss: 0.936811\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:22 | INFO | Rank 0 | Train Epoch: 0 [140416/250314 (56%)]\tLoss: 0.745972\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:23 | INFO | Rank 0 | Train Epoch: 0 [140448/250314 (56%)]\tLoss: 0.731214\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:23 | INFO | Rank 0 | Train Epoch: 0 [140480/250314 (56%)]\tLoss: 0.709938\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:24 | INFO | Rank 0 | Train Epoch: 0 [140512/250314 (56%)]\tLoss: 1.077070\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:24 | INFO | Rank 0 | Train Epoch: 0 [140544/250314 (56%)]\tLoss: 1.326648\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:25 | INFO | Rank 0 | Train Epoch: 0 [140576/250314 (56%)]\tLoss: 0.939783\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:25 | INFO | Rank 0 | Train Epoch: 0 [140608/250314 (56%)]\tLoss: 0.565790\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:26 | INFO | Rank 0 | Train Epoch: 0 [140640/250314 (56%)]\tLoss: 0.691483\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:26 | INFO | Rank 0 | Train Epoch: 0 [140672/250314 (56%)]\tLoss: 0.896959\tData (t) 0.213\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:27 | INFO | Rank 0 | Train Epoch: 0 [140704/250314 (56%)]\tLoss: 0.963903\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:27 | INFO | Rank 0 | Train Epoch: 0 [140736/250314 (56%)]\tLoss: 0.520821\tData (t) 0.307\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:27 | INFO | Rank 0 | Train Epoch: 0 [140768/250314 (56%)]\tLoss: 0.817268\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:28 | INFO | Rank 0 | Train Epoch: 0 [140800/250314 (56%)]\tLoss: 0.579830\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:28 | INFO | Rank 0 | Train Epoch: 0 [140832/250314 (56%)]\tLoss: 0.868374\tData (t) 0.320\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:29 | INFO | Rank 0 | Train Epoch: 0 [140864/250314 (56%)]\tLoss: 1.034096\tData (t) 0.342\tBatch (t) 0.553\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:30 | INFO | Rank 0 | Train Epoch: 0 [140896/250314 (56%)]\tLoss: 0.407934\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:30 | INFO | Rank 0 | Train Epoch: 0 [140928/250314 (56%)]\tLoss: 0.309907\tData (t) 0.204\tBatch (t) 0.416\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:30 | INFO | Rank 0 | Train Epoch: 0 [140960/250314 (56%)]\tLoss: 0.442487\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:31 | INFO | Rank 0 | Train Epoch: 0 [140992/250314 (56%)]\tLoss: 0.814693\tData (t) 0.346\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:31 | INFO | Rank 0 | Train Epoch: 0 [141024/250314 (56%)]\tLoss: 0.795922\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:32 | INFO | Rank 0 | Train Epoch: 0 [141056/250314 (56%)]\tLoss: 0.756763\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:32 | INFO | Rank 0 | Train Epoch: 0 [141088/250314 (56%)]\tLoss: 0.367444\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:33 | INFO | Rank 0 | Train Epoch: 0 [141120/250314 (56%)]\tLoss: 0.593707\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:33 | INFO | Rank 0 | Train Epoch: 0 [141152/250314 (56%)]\tLoss: 0.701990\tData (t) 0.289\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:34 | INFO | Rank 0 | Train Epoch: 0 [141184/250314 (56%)]\tLoss: 0.824801\tData (t) 0.228\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:34 | INFO | Rank 0 | Train Epoch: 0 [141216/250314 (56%)]\tLoss: 0.504533\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:35 | INFO | Rank 0 | Train Epoch: 0 [141248/250314 (56%)]\tLoss: 0.661920\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:35 | INFO | Rank 0 | Train Epoch: 0 [141280/250314 (56%)]\tLoss: 1.113845\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:36 | INFO | Rank 0 | Train Epoch: 0 [141312/250314 (56%)]\tLoss: 1.192053\tData (t) 0.347\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:37 | INFO | Rank 0 | Train Epoch: 0 [141344/250314 (56%)]\tLoss: 0.275499\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:37 | INFO | Rank 0 | Train Epoch: 0 [141376/250314 (56%)]\tLoss: 0.797187\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:38 | INFO | Rank 0 | Train Epoch: 0 [141408/250314 (56%)]\tLoss: 0.724184\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:38 | INFO | Rank 0 | Train Epoch: 0 [141440/250314 (57%)]\tLoss: 0.832870\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:39 | INFO | Rank 0 | Train Epoch: 0 [141472/250314 (57%)]\tLoss: 0.567360\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:39 | INFO | Rank 0 | Train Epoch: 0 [141504/250314 (57%)]\tLoss: 1.026917\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:40 | INFO | Rank 0 | Train Epoch: 0 [141536/250314 (57%)]\tLoss: 0.690878\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:40 | INFO | Rank 0 | Train Epoch: 0 [141568/250314 (57%)]\tLoss: 0.654559\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:40 | INFO | Rank 0 | Train Epoch: 0 [141600/250314 (57%)]\tLoss: 0.743725\tData (t) 0.217\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:41 | INFO | Rank 0 | Train Epoch: 0 [141632/250314 (57%)]\tLoss: 0.713173\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:41 | INFO | Rank 0 | Train Epoch: 0 [141664/250314 (57%)]\tLoss: 0.772629\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:42 | INFO | Rank 0 | Train Epoch: 0 [141696/250314 (57%)]\tLoss: 0.923385\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:42 | INFO | Rank 0 | Train Epoch: 0 [141728/250314 (57%)]\tLoss: 0.401178\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:43 | INFO | Rank 0 | Train Epoch: 0 [141760/250314 (57%)]\tLoss: 0.541055\tData (t) 0.199\tBatch (t) 0.410\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:43 | INFO | Rank 0 | Train Epoch: 0 [141792/250314 (57%)]\tLoss: 0.452368\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:44 | INFO | Rank 0 | Train Epoch: 0 [141824/250314 (57%)]\tLoss: 0.394361\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:44 | INFO | Rank 0 | Train Epoch: 0 [141856/250314 (57%)]\tLoss: 0.661891\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:45 | INFO | Rank 0 | Train Epoch: 0 [141888/250314 (57%)]\tLoss: 0.826572\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:45 | INFO | Rank 0 | Train Epoch: 0 [141920/250314 (57%)]\tLoss: 0.874479\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:46 | INFO | Rank 0 | Train Epoch: 0 [141952/250314 (57%)]\tLoss: 0.508951\tData (t) 0.223\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:46 | INFO | Rank 0 | Train Epoch: 0 [141984/250314 (57%)]\tLoss: 1.115884\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:47 | INFO | Rank 0 | Train Epoch: 0 [142016/250314 (57%)]\tLoss: 0.407360\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:47 | INFO | Rank 0 | Train Epoch: 0 [142048/250314 (57%)]\tLoss: 0.357220\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:47 | INFO | Rank 0 | Train Epoch: 0 [142080/250314 (57%)]\tLoss: 0.645504\tData (t) 0.192\tBatch (t) 0.403\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:48 | INFO | Rank 0 | Train Epoch: 0 [142112/250314 (57%)]\tLoss: 0.506219\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:48 | INFO | Rank 0 | Train Epoch: 0 [142144/250314 (57%)]\tLoss: 0.446746\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:49 | INFO | Rank 0 | Train Epoch: 0 [142176/250314 (57%)]\tLoss: 1.225761\tData (t) 0.282\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:49 | INFO | Rank 0 | Train Epoch: 0 [142208/250314 (57%)]\tLoss: 0.780335\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:50 | INFO | Rank 0 | Train Epoch: 0 [142240/250314 (57%)]\tLoss: 0.545877\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:50 | INFO | Rank 0 | Train Epoch: 0 [142272/250314 (57%)]\tLoss: 0.723699\tData (t) 0.328\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:51 | INFO | Rank 0 | Train Epoch: 0 [142304/250314 (57%)]\tLoss: 0.328773\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:51 | INFO | Rank 0 | Train Epoch: 0 [142336/250314 (57%)]\tLoss: 1.092671\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:52 | INFO | Rank 0 | Train Epoch: 0 [142368/250314 (57%)]\tLoss: 0.535330\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:52 | INFO | Rank 0 | Train Epoch: 0 [142400/250314 (57%)]\tLoss: 0.804955\tData (t) 0.250\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:53 | INFO | Rank 0 | Train Epoch: 0 [142432/250314 (57%)]\tLoss: 0.846363\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:53 | INFO | Rank 0 | Train Epoch: 0 [142464/250314 (57%)]\tLoss: 0.731001\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:54 | INFO | Rank 0 | Train Epoch: 0 [142496/250314 (57%)]\tLoss: 1.208991\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:54 | INFO | Rank 0 | Train Epoch: 0 [142528/250314 (57%)]\tLoss: 0.622026\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:55 | INFO | Rank 0 | Train Epoch: 0 [142560/250314 (57%)]\tLoss: 0.770786\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:55 | INFO | Rank 0 | Train Epoch: 0 [142592/250314 (57%)]\tLoss: 0.442400\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:56 | INFO | Rank 0 | Train Epoch: 0 [142624/250314 (57%)]\tLoss: 0.697441\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:56 | INFO | Rank 0 | Train Epoch: 0 [142656/250314 (57%)]\tLoss: 0.672193\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:57 | INFO | Rank 0 | Train Epoch: 0 [142688/250314 (57%)]\tLoss: 0.739521\tData (t) 0.353\tBatch (t) 0.565\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:57 | INFO | Rank 0 | Train Epoch: 0 [142720/250314 (57%)]\tLoss: 0.769515\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:58 | INFO | Rank 0 | Train Epoch: 0 [142752/250314 (57%)]\tLoss: 0.933490\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:58 | INFO | Rank 0 | Train Epoch: 0 [142784/250314 (57%)]\tLoss: 0.451221\tData (t) 0.215\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:59 | INFO | Rank 0 | Train Epoch: 0 [142816/250314 (57%)]\tLoss: 0.604510\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:46:59 | INFO | Rank 0 | Train Epoch: 0 [142848/250314 (57%)]\tLoss: 0.777314\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:00 | INFO | Rank 0 | Train Epoch: 0 [142880/250314 (57%)]\tLoss: 0.659969\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:00 | INFO | Rank 0 | Train Epoch: 0 [142912/250314 (57%)]\tLoss: 0.440546\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:01 | INFO | Rank 0 | Train Epoch: 0 [142944/250314 (57%)]\tLoss: 0.537703\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:01 | INFO | Rank 0 | Train Epoch: 0 [142976/250314 (57%)]\tLoss: 0.715497\tData (t) 0.332\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:02 | INFO | Rank 0 | Train Epoch: 0 [143008/250314 (57%)]\tLoss: 0.949248\tData (t) 0.233\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:02 | INFO | Rank 0 | Train Epoch: 0 [143040/250314 (57%)]\tLoss: 0.474134\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:03 | INFO | Rank 0 | Train Epoch: 0 [143072/250314 (57%)]\tLoss: 0.982131\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:03 | INFO | Rank 0 | Train Epoch: 0 [143104/250314 (57%)]\tLoss: 0.441293\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:03 | INFO | Rank 0 | Train Epoch: 0 [143136/250314 (57%)]\tLoss: 0.785020\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:04 | INFO | Rank 0 | Train Epoch: 0 [143168/250314 (57%)]\tLoss: 0.764366\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:04 | INFO | Rank 0 | Train Epoch: 0 [143200/250314 (57%)]\tLoss: 0.403480\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:05 | INFO | Rank 0 | Train Epoch: 0 [143232/250314 (57%)]\tLoss: 0.440799\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:05 | INFO | Rank 0 | Train Epoch: 0 [143264/250314 (57%)]\tLoss: 0.409446\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:06 | INFO | Rank 0 | Train Epoch: 0 [143296/250314 (57%)]\tLoss: 0.527825\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:07 | INFO | Rank 0 | Train Epoch: 0 [143328/250314 (57%)]\tLoss: 0.599864\tData (t) 0.457\tBatch (t) 0.669\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:07 | INFO | Rank 0 | Train Epoch: 0 [143360/250314 (57%)]\tLoss: 0.616642\tData (t) 0.427\tBatch (t) 0.640\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:08 | INFO | Rank 0 | Train Epoch: 0 [143392/250314 (57%)]\tLoss: 1.070505\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:08 | INFO | Rank 0 | Train Epoch: 0 [143424/250314 (57%)]\tLoss: 0.572728\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:09 | INFO | Rank 0 | Train Epoch: 0 [143456/250314 (57%)]\tLoss: 0.809915\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:09 | INFO | Rank 0 | Train Epoch: 0 [143488/250314 (57%)]\tLoss: 0.820387\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:10 | INFO | Rank 0 | Train Epoch: 0 [143520/250314 (57%)]\tLoss: 0.395489\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:10 | INFO | Rank 0 | Train Epoch: 0 [143552/250314 (57%)]\tLoss: 1.099802\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:11 | INFO | Rank 0 | Train Epoch: 0 [143584/250314 (57%)]\tLoss: 0.529210\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:11 | INFO | Rank 0 | Train Epoch: 0 [143616/250314 (57%)]\tLoss: 0.488690\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:12 | INFO | Rank 0 | Train Epoch: 0 [143648/250314 (57%)]\tLoss: 0.691684\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:12 | INFO | Rank 0 | Train Epoch: 0 [143680/250314 (57%)]\tLoss: 0.676808\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:13 | INFO | Rank 0 | Train Epoch: 0 [143712/250314 (57%)]\tLoss: 0.558277\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:13 | INFO | Rank 0 | Train Epoch: 0 [143744/250314 (57%)]\tLoss: 0.615121\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:14 | INFO | Rank 0 | Train Epoch: 0 [143776/250314 (57%)]\tLoss: 0.328563\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:14 | INFO | Rank 0 | Train Epoch: 0 [143808/250314 (57%)]\tLoss: 0.928298\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:15 | INFO | Rank 0 | Train Epoch: 0 [143840/250314 (57%)]\tLoss: 0.603064\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:15 | INFO | Rank 0 | Train Epoch: 0 [143872/250314 (57%)]\tLoss: 0.519438\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:16 | INFO | Rank 0 | Train Epoch: 0 [143904/250314 (57%)]\tLoss: 0.536995\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:16 | INFO | Rank 0 | Train Epoch: 0 [143936/250314 (58%)]\tLoss: 0.726136\tData (t) 0.215\tBatch (t) 0.426\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:17 | INFO | Rank 0 | Train Epoch: 0 [143968/250314 (58%)]\tLoss: 0.215201\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:17 | INFO | Rank 0 | Train Epoch: 0 [144000/250314 (58%)]\tLoss: 0.783940\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:18 | INFO | Rank 0 | Train Epoch: 0 [144032/250314 (58%)]\tLoss: 0.620487\tData (t) 0.391\tBatch (t) 0.603\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:18 | INFO | Rank 0 | Train Epoch: 0 [144064/250314 (58%)]\tLoss: 0.838087\tData (t) 0.228\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:19 | INFO | Rank 0 | Train Epoch: 0 [144096/250314 (58%)]\tLoss: 0.399173\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:19 | INFO | Rank 0 | Train Epoch: 0 [144128/250314 (58%)]\tLoss: 0.704661\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:20 | INFO | Rank 0 | Train Epoch: 0 [144160/250314 (58%)]\tLoss: 0.919762\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:20 | INFO | Rank 0 | Train Epoch: 0 [144192/250314 (58%)]\tLoss: 0.666661\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:21 | INFO | Rank 0 | Train Epoch: 0 [144224/250314 (58%)]\tLoss: 0.546295\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:21 | INFO | Rank 0 | Train Epoch: 0 [144256/250314 (58%)]\tLoss: 0.754779\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:22 | INFO | Rank 0 | Train Epoch: 0 [144288/250314 (58%)]\tLoss: 0.632469\tData (t) 0.220\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:22 | INFO | Rank 0 | Train Epoch: 0 [144320/250314 (58%)]\tLoss: 0.965661\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:23 | INFO | Rank 0 | Train Epoch: 0 [144352/250314 (58%)]\tLoss: 0.630021\tData (t) 0.340\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:23 | INFO | Rank 0 | Train Epoch: 0 [144384/250314 (58%)]\tLoss: 0.529179\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:24 | INFO | Rank 0 | Train Epoch: 0 [144416/250314 (58%)]\tLoss: 0.751671\tData (t) 0.216\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:24 | INFO | Rank 0 | Train Epoch: 0 [144448/250314 (58%)]\tLoss: 0.755489\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:25 | INFO | Rank 0 | Train Epoch: 0 [144480/250314 (58%)]\tLoss: 0.511844\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:25 | INFO | Rank 0 | Train Epoch: 0 [144512/250314 (58%)]\tLoss: 0.644349\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:26 | INFO | Rank 0 | Train Epoch: 0 [144544/250314 (58%)]\tLoss: 0.697432\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:26 | INFO | Rank 0 | Train Epoch: 0 [144576/250314 (58%)]\tLoss: 0.452826\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:27 | INFO | Rank 0 | Train Epoch: 0 [144608/250314 (58%)]\tLoss: 0.904243\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:27 | INFO | Rank 0 | Train Epoch: 0 [144640/250314 (58%)]\tLoss: 0.810946\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:28 | INFO | Rank 0 | Train Epoch: 0 [144672/250314 (58%)]\tLoss: 0.905218\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:28 | INFO | Rank 0 | Train Epoch: 0 [144704/250314 (58%)]\tLoss: 0.608710\tData (t) 0.404\tBatch (t) 0.615\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:29 | INFO | Rank 0 | Train Epoch: 0 [144736/250314 (58%)]\tLoss: 0.426111\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:29 | INFO | Rank 0 | Train Epoch: 0 [144768/250314 (58%)]\tLoss: 0.650850\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:30 | INFO | Rank 0 | Train Epoch: 0 [144800/250314 (58%)]\tLoss: 0.828396\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:30 | INFO | Rank 0 | Train Epoch: 0 [144832/250314 (58%)]\tLoss: 0.571250\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:31 | INFO | Rank 0 | Train Epoch: 0 [144864/250314 (58%)]\tLoss: 0.587718\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:31 | INFO | Rank 0 | Train Epoch: 0 [144896/250314 (58%)]\tLoss: 0.702727\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:32 | INFO | Rank 0 | Train Epoch: 0 [144928/250314 (58%)]\tLoss: 0.854694\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:32 | INFO | Rank 0 | Train Epoch: 0 [144960/250314 (58%)]\tLoss: 0.572005\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:33 | INFO | Rank 0 | Train Epoch: 0 [144992/250314 (58%)]\tLoss: 0.967891\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:33 | INFO | Rank 0 | Train Epoch: 0 [145024/250314 (58%)]\tLoss: 1.010857\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:34 | INFO | Rank 0 | Train Epoch: 0 [145056/250314 (58%)]\tLoss: 0.412861\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:34 | INFO | Rank 0 | Train Epoch: 0 [145088/250314 (58%)]\tLoss: 1.071910\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:35 | INFO | Rank 0 | Train Epoch: 0 [145120/250314 (58%)]\tLoss: 1.156960\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:35 | INFO | Rank 0 | Train Epoch: 0 [145152/250314 (58%)]\tLoss: 0.682727\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:35 | INFO | Rank 0 | Train Epoch: 0 [145184/250314 (58%)]\tLoss: 0.497904\tData (t) 0.176\tBatch (t) 0.388\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:36 | INFO | Rank 0 | Train Epoch: 0 [145216/250314 (58%)]\tLoss: 0.551274\tData (t) 0.308\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:36 | INFO | Rank 0 | Train Epoch: 0 [145248/250314 (58%)]\tLoss: 0.605469\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:37 | INFO | Rank 0 | Train Epoch: 0 [145280/250314 (58%)]\tLoss: 1.467257\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:37 | INFO | Rank 0 | Train Epoch: 0 [145312/250314 (58%)]\tLoss: 0.750969\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:38 | INFO | Rank 0 | Train Epoch: 0 [145344/250314 (58%)]\tLoss: 0.966582\tData (t) 0.332\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:38 | INFO | Rank 0 | Train Epoch: 0 [145376/250314 (58%)]\tLoss: 0.773087\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:39 | INFO | Rank 0 | Train Epoch: 0 [145408/250314 (58%)]\tLoss: 0.925089\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:39 | INFO | Rank 0 | Train Epoch: 0 [145440/250314 (58%)]\tLoss: 0.738669\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:40 | INFO | Rank 0 | Train Epoch: 0 [145472/250314 (58%)]\tLoss: 0.713349\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:40 | INFO | Rank 0 | Train Epoch: 0 [145504/250314 (58%)]\tLoss: 1.035470\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:41 | INFO | Rank 0 | Train Epoch: 0 [145536/250314 (58%)]\tLoss: 1.057457\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:41 | INFO | Rank 0 | Train Epoch: 0 [145568/250314 (58%)]\tLoss: 0.594997\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:42 | INFO | Rank 0 | Train Epoch: 0 [145600/250314 (58%)]\tLoss: 0.722503\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:42 | INFO | Rank 0 | Train Epoch: 0 [145632/250314 (58%)]\tLoss: 0.425734\tData (t) 0.474\tBatch (t) 0.686\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:43 | INFO | Rank 0 | Train Epoch: 0 [145664/250314 (58%)]\tLoss: 0.532380\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:43 | INFO | Rank 0 | Train Epoch: 0 [145696/250314 (58%)]\tLoss: 0.744933\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:44 | INFO | Rank 0 | Train Epoch: 0 [145728/250314 (58%)]\tLoss: 0.863684\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:44 | INFO | Rank 0 | Train Epoch: 0 [145760/250314 (58%)]\tLoss: 0.709816\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:45 | INFO | Rank 0 | Train Epoch: 0 [145792/250314 (58%)]\tLoss: 0.961757\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:45 | INFO | Rank 0 | Train Epoch: 0 [145824/250314 (58%)]\tLoss: 0.637766\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:46 | INFO | Rank 0 | Train Epoch: 0 [145856/250314 (58%)]\tLoss: 0.635290\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:46 | INFO | Rank 0 | Train Epoch: 0 [145888/250314 (58%)]\tLoss: 0.570573\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:47 | INFO | Rank 0 | Train Epoch: 0 [145920/250314 (58%)]\tLoss: 0.810727\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:47 | INFO | Rank 0 | Train Epoch: 0 [145952/250314 (58%)]\tLoss: 0.570317\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:48 | INFO | Rank 0 | Train Epoch: 0 [145984/250314 (58%)]\tLoss: 0.787916\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:48 | INFO | Rank 0 | Train Epoch: 0 [146016/250314 (58%)]\tLoss: 0.666751\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:49 | INFO | Rank 0 | Train Epoch: 0 [146048/250314 (58%)]\tLoss: 0.689519\tData (t) 0.362\tBatch (t) 0.573\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:49 | INFO | Rank 0 | Train Epoch: 0 [146080/250314 (58%)]\tLoss: 0.361521\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:50 | INFO | Rank 0 | Train Epoch: 0 [146112/250314 (58%)]\tLoss: 0.659541\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:50 | INFO | Rank 0 | Train Epoch: 0 [146144/250314 (58%)]\tLoss: 0.734049\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:51 | INFO | Rank 0 | Train Epoch: 0 [146176/250314 (58%)]\tLoss: 0.747638\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:51 | INFO | Rank 0 | Train Epoch: 0 [146208/250314 (58%)]\tLoss: 0.836856\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:52 | INFO | Rank 0 | Train Epoch: 0 [146240/250314 (58%)]\tLoss: 0.719501\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:52 | INFO | Rank 0 | Train Epoch: 0 [146272/250314 (58%)]\tLoss: 0.817843\tData (t) 0.255\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:53 | INFO | Rank 0 | Train Epoch: 0 [146304/250314 (58%)]\tLoss: 0.546914\tData (t) 0.208\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:53 | INFO | Rank 0 | Train Epoch: 0 [146336/250314 (58%)]\tLoss: 0.833255\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:54 | INFO | Rank 0 | Train Epoch: 0 [146368/250314 (58%)]\tLoss: 0.661771\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:54 | INFO | Rank 0 | Train Epoch: 0 [146400/250314 (58%)]\tLoss: 0.824058\tData (t) 0.366\tBatch (t) 0.577\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:55 | INFO | Rank 0 | Train Epoch: 0 [146432/250314 (59%)]\tLoss: 1.173968\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:55 | INFO | Rank 0 | Train Epoch: 0 [146464/250314 (59%)]\tLoss: 0.488584\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:56 | INFO | Rank 0 | Train Epoch: 0 [146496/250314 (59%)]\tLoss: 0.710840\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:56 | INFO | Rank 0 | Train Epoch: 0 [146528/250314 (59%)]\tLoss: 0.681908\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:57 | INFO | Rank 0 | Train Epoch: 0 [146560/250314 (59%)]\tLoss: 0.570534\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:57 | INFO | Rank 0 | Train Epoch: 0 [146592/250314 (59%)]\tLoss: 0.708288\tData (t) 0.219\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:58 | INFO | Rank 0 | Train Epoch: 0 [146624/250314 (59%)]\tLoss: 0.617027\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:58 | INFO | Rank 0 | Train Epoch: 0 [146656/250314 (59%)]\tLoss: 0.728452\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:59 | INFO | Rank 0 | Train Epoch: 0 [146688/250314 (59%)]\tLoss: 0.762085\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:47:59 | INFO | Rank 0 | Train Epoch: 0 [146720/250314 (59%)]\tLoss: 0.603211\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:00 | INFO | Rank 0 | Train Epoch: 0 [146752/250314 (59%)]\tLoss: 0.576766\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:00 | INFO | Rank 0 | Train Epoch: 0 [146784/250314 (59%)]\tLoss: 0.879371\tData (t) 0.319\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:01 | INFO | Rank 0 | Train Epoch: 0 [146816/250314 (59%)]\tLoss: 0.951576\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:01 | INFO | Rank 0 | Train Epoch: 0 [146848/250314 (59%)]\tLoss: 1.031553\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:02 | INFO | Rank 0 | Train Epoch: 0 [146880/250314 (59%)]\tLoss: 0.471218\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:02 | INFO | Rank 0 | Train Epoch: 0 [146912/250314 (59%)]\tLoss: 0.896525\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:03 | INFO | Rank 0 | Train Epoch: 0 [146944/250314 (59%)]\tLoss: 1.143332\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:03 | INFO | Rank 0 | Train Epoch: 0 [146976/250314 (59%)]\tLoss: 0.454563\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:04 | INFO | Rank 0 | Train Epoch: 0 [147008/250314 (59%)]\tLoss: 0.621070\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:04 | INFO | Rank 0 | Train Epoch: 0 [147040/250314 (59%)]\tLoss: 1.113705\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:05 | INFO | Rank 0 | Train Epoch: 0 [147072/250314 (59%)]\tLoss: 0.810307\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:05 | INFO | Rank 0 | Train Epoch: 0 [147104/250314 (59%)]\tLoss: 0.666870\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:06 | INFO | Rank 0 | Train Epoch: 0 [147136/250314 (59%)]\tLoss: 0.585189\tData (t) 0.320\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:06 | INFO | Rank 0 | Train Epoch: 0 [147168/250314 (59%)]\tLoss: 0.727387\tData (t) 0.218\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:06 | INFO | Rank 0 | Train Epoch: 0 [147200/250314 (59%)]\tLoss: 0.644810\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:07 | INFO | Rank 0 | Train Epoch: 0 [147232/250314 (59%)]\tLoss: 0.632008\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:07 | INFO | Rank 0 | Train Epoch: 0 [147264/250314 (59%)]\tLoss: 0.794321\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:08 | INFO | Rank 0 | Train Epoch: 0 [147296/250314 (59%)]\tLoss: 0.723350\tData (t) 0.229\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:08 | INFO | Rank 0 | Train Epoch: 0 [147328/250314 (59%)]\tLoss: 0.681846\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:09 | INFO | Rank 0 | Train Epoch: 0 [147360/250314 (59%)]\tLoss: 0.560813\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:09 | INFO | Rank 0 | Train Epoch: 0 [147392/250314 (59%)]\tLoss: 0.776044\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:10 | INFO | Rank 0 | Train Epoch: 0 [147424/250314 (59%)]\tLoss: 0.997857\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:10 | INFO | Rank 0 | Train Epoch: 0 [147456/250314 (59%)]\tLoss: 0.382729\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:11 | INFO | Rank 0 | Train Epoch: 0 [147488/250314 (59%)]\tLoss: 0.662650\tData (t) 0.192\tBatch (t) 0.403\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:11 | INFO | Rank 0 | Train Epoch: 0 [147520/250314 (59%)]\tLoss: 0.661378\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:12 | INFO | Rank 0 | Train Epoch: 0 [147552/250314 (59%)]\tLoss: 0.670472\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:12 | INFO | Rank 0 | Train Epoch: 0 [147584/250314 (59%)]\tLoss: 0.778260\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:13 | INFO | Rank 0 | Train Epoch: 0 [147616/250314 (59%)]\tLoss: 0.548132\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:13 | INFO | Rank 0 | Train Epoch: 0 [147648/250314 (59%)]\tLoss: 0.768620\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:14 | INFO | Rank 0 | Train Epoch: 0 [147680/250314 (59%)]\tLoss: 1.188335\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:14 | INFO | Rank 0 | Train Epoch: 0 [147712/250314 (59%)]\tLoss: 1.021052\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:15 | INFO | Rank 0 | Train Epoch: 0 [147744/250314 (59%)]\tLoss: 0.596410\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:15 | INFO | Rank 0 | Train Epoch: 0 [147776/250314 (59%)]\tLoss: 0.655752\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:15 | INFO | Rank 0 | Train Epoch: 0 [147808/250314 (59%)]\tLoss: 0.638862\tData (t) 0.277\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:16 | INFO | Rank 0 | Train Epoch: 0 [147840/250314 (59%)]\tLoss: 0.411505\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:17 | INFO | Rank 0 | Train Epoch: 0 [147872/250314 (59%)]\tLoss: 0.822755\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:17 | INFO | Rank 0 | Train Epoch: 0 [147904/250314 (59%)]\tLoss: 0.934255\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:18 | INFO | Rank 0 | Train Epoch: 0 [147936/250314 (59%)]\tLoss: 0.582775\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:18 | INFO | Rank 0 | Train Epoch: 0 [147968/250314 (59%)]\tLoss: 0.829998\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:19 | INFO | Rank 0 | Train Epoch: 0 [148000/250314 (59%)]\tLoss: 0.421370\tData (t) 0.385\tBatch (t) 0.596\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:19 | INFO | Rank 0 | Train Epoch: 0 [148032/250314 (59%)]\tLoss: 1.069179\tData (t) 0.364\tBatch (t) 0.576\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:20 | INFO | Rank 0 | Train Epoch: 0 [148064/250314 (59%)]\tLoss: 0.481447\tData (t) 0.325\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:20 | INFO | Rank 0 | Train Epoch: 0 [148096/250314 (59%)]\tLoss: 1.067209\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:21 | INFO | Rank 0 | Train Epoch: 0 [148128/250314 (59%)]\tLoss: 1.085278\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:21 | INFO | Rank 0 | Train Epoch: 0 [148160/250314 (59%)]\tLoss: 0.621984\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:22 | INFO | Rank 0 | Train Epoch: 0 [148192/250314 (59%)]\tLoss: 0.933489\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:22 | INFO | Rank 0 | Train Epoch: 0 [148224/250314 (59%)]\tLoss: 0.594776\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:23 | INFO | Rank 0 | Train Epoch: 0 [148256/250314 (59%)]\tLoss: 0.705530\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:23 | INFO | Rank 0 | Train Epoch: 0 [148288/250314 (59%)]\tLoss: 0.713861\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:24 | INFO | Rank 0 | Train Epoch: 0 [148320/250314 (59%)]\tLoss: 0.837633\tData (t) 0.266\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:24 | INFO | Rank 0 | Train Epoch: 0 [148352/250314 (59%)]\tLoss: 0.529048\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:25 | INFO | Rank 0 | Train Epoch: 0 [148384/250314 (59%)]\tLoss: 1.059624\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:25 | INFO | Rank 0 | Train Epoch: 0 [148416/250314 (59%)]\tLoss: 0.812575\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:26 | INFO | Rank 0 | Train Epoch: 0 [148448/250314 (59%)]\tLoss: 0.804484\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:26 | INFO | Rank 0 | Train Epoch: 0 [148480/250314 (59%)]\tLoss: 0.446214\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:26 | INFO | Rank 0 | Train Epoch: 0 [148512/250314 (59%)]\tLoss: 0.463626\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:27 | INFO | Rank 0 | Train Epoch: 0 [148544/250314 (59%)]\tLoss: 0.723426\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:27 | INFO | Rank 0 | Train Epoch: 0 [148576/250314 (59%)]\tLoss: 0.541252\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:28 | INFO | Rank 0 | Train Epoch: 0 [148608/250314 (59%)]\tLoss: 0.687872\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:28 | INFO | Rank 0 | Train Epoch: 0 [148640/250314 (59%)]\tLoss: 0.505402\tData (t) 0.231\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:29 | INFO | Rank 0 | Train Epoch: 0 [148672/250314 (59%)]\tLoss: 0.630965\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:29 | INFO | Rank 0 | Train Epoch: 0 [148704/250314 (59%)]\tLoss: 1.031093\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:30 | INFO | Rank 0 | Train Epoch: 0 [148736/250314 (59%)]\tLoss: 0.869482\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:30 | INFO | Rank 0 | Train Epoch: 0 [148768/250314 (59%)]\tLoss: 0.554376\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:31 | INFO | Rank 0 | Train Epoch: 0 [148800/250314 (59%)]\tLoss: 0.680112\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:31 | INFO | Rank 0 | Train Epoch: 0 [148832/250314 (59%)]\tLoss: 0.636932\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:32 | INFO | Rank 0 | Train Epoch: 0 [148864/250314 (59%)]\tLoss: 0.409958\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:32 | INFO | Rank 0 | Train Epoch: 0 [148896/250314 (59%)]\tLoss: 0.619496\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:33 | INFO | Rank 0 | Train Epoch: 0 [148928/250314 (59%)]\tLoss: 0.492741\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:33 | INFO | Rank 0 | Train Epoch: 0 [148960/250314 (60%)]\tLoss: 0.500560\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:34 | INFO | Rank 0 | Train Epoch: 0 [148992/250314 (60%)]\tLoss: 0.939143\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:34 | INFO | Rank 0 | Train Epoch: 0 [149024/250314 (60%)]\tLoss: 1.015382\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:35 | INFO | Rank 0 | Train Epoch: 0 [149056/250314 (60%)]\tLoss: 0.737112\tData (t) 0.208\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:35 | INFO | Rank 0 | Train Epoch: 0 [149088/250314 (60%)]\tLoss: 1.086487\tData (t) 0.339\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:36 | INFO | Rank 0 | Train Epoch: 0 [149120/250314 (60%)]\tLoss: 0.470959\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:36 | INFO | Rank 0 | Train Epoch: 0 [149152/250314 (60%)]\tLoss: 0.981353\tData (t) 0.447\tBatch (t) 0.662\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:37 | INFO | Rank 0 | Train Epoch: 0 [149184/250314 (60%)]\tLoss: 0.889654\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:37 | INFO | Rank 0 | Train Epoch: 0 [149216/250314 (60%)]\tLoss: 0.955841\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:38 | INFO | Rank 0 | Train Epoch: 0 [149248/250314 (60%)]\tLoss: 0.816713\tData (t) 0.247\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:38 | INFO | Rank 0 | Train Epoch: 0 [149280/250314 (60%)]\tLoss: 0.360427\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:39 | INFO | Rank 0 | Train Epoch: 0 [149312/250314 (60%)]\tLoss: 0.584284\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:39 | INFO | Rank 0 | Train Epoch: 0 [149344/250314 (60%)]\tLoss: 0.236327\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:40 | INFO | Rank 0 | Train Epoch: 0 [149376/250314 (60%)]\tLoss: 0.799582\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:40 | INFO | Rank 0 | Train Epoch: 0 [149408/250314 (60%)]\tLoss: 0.346147\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:41 | INFO | Rank 0 | Train Epoch: 0 [149440/250314 (60%)]\tLoss: 0.715973\tData (t) 0.357\tBatch (t) 0.569\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:41 | INFO | Rank 0 | Train Epoch: 0 [149472/250314 (60%)]\tLoss: 0.544047\tData (t) 0.246\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:42 | INFO | Rank 0 | Train Epoch: 0 [149504/250314 (60%)]\tLoss: 0.826059\tData (t) 0.194\tBatch (t) 0.406\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:42 | INFO | Rank 0 | Train Epoch: 0 [149536/250314 (60%)]\tLoss: 0.955006\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:42 | INFO | Rank 0 | Train Epoch: 0 [149568/250314 (60%)]\tLoss: 0.824455\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:43 | INFO | Rank 0 | Train Epoch: 0 [149600/250314 (60%)]\tLoss: 0.610298\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:43 | INFO | Rank 0 | Train Epoch: 0 [149632/250314 (60%)]\tLoss: 0.702498\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:44 | INFO | Rank 0 | Train Epoch: 0 [149664/250314 (60%)]\tLoss: 0.591335\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:44 | INFO | Rank 0 | Train Epoch: 0 [149696/250314 (60%)]\tLoss: 0.618578\tData (t) 0.316\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:45 | INFO | Rank 0 | Train Epoch: 0 [149728/250314 (60%)]\tLoss: 0.876074\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:45 | INFO | Rank 0 | Train Epoch: 0 [149760/250314 (60%)]\tLoss: 0.381165\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:46 | INFO | Rank 0 | Train Epoch: 0 [149792/250314 (60%)]\tLoss: 0.860180\tData (t) 0.365\tBatch (t) 0.577\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:47 | INFO | Rank 0 | Train Epoch: 0 [149824/250314 (60%)]\tLoss: 0.603028\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:47 | INFO | Rank 0 | Train Epoch: 0 [149856/250314 (60%)]\tLoss: 0.559724\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:47 | INFO | Rank 0 | Train Epoch: 0 [149888/250314 (60%)]\tLoss: 0.526382\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:48 | INFO | Rank 0 | Train Epoch: 0 [149920/250314 (60%)]\tLoss: 0.630233\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:48 | INFO | Rank 0 | Train Epoch: 0 [149952/250314 (60%)]\tLoss: 0.918246\tData (t) 0.302\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:49 | INFO | Rank 0 | Train Epoch: 0 [149984/250314 (60%)]\tLoss: 0.388271\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:49 | INFO | Rank 0 | Train Epoch: 0 [150016/250314 (60%)]\tLoss: 0.746118\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:50 | INFO | Rank 0 | Train Epoch: 0 [150048/250314 (60%)]\tLoss: 0.442964\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:50 | INFO | Rank 0 | Train Epoch: 0 [150080/250314 (60%)]\tLoss: 0.681551\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:51 | INFO | Rank 0 | Train Epoch: 0 [150112/250314 (60%)]\tLoss: 0.669548\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:51 | INFO | Rank 0 | Train Epoch: 0 [150144/250314 (60%)]\tLoss: 0.815553\tData (t) 0.354\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:52 | INFO | Rank 0 | Train Epoch: 0 [150176/250314 (60%)]\tLoss: 0.785847\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:52 | INFO | Rank 0 | Train Epoch: 0 [150208/250314 (60%)]\tLoss: 0.718955\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:53 | INFO | Rank 0 | Train Epoch: 0 [150240/250314 (60%)]\tLoss: 0.683599\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:53 | INFO | Rank 0 | Train Epoch: 0 [150272/250314 (60%)]\tLoss: 0.409229\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:54 | INFO | Rank 0 | Train Epoch: 0 [150304/250314 (60%)]\tLoss: 0.412162\tData (t) 0.213\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:54 | INFO | Rank 0 | Train Epoch: 0 [150336/250314 (60%)]\tLoss: 0.529322\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:55 | INFO | Rank 0 | Train Epoch: 0 [150368/250314 (60%)]\tLoss: 0.704856\tData (t) 0.284\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:55 | INFO | Rank 0 | Train Epoch: 0 [150400/250314 (60%)]\tLoss: 0.551872\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:56 | INFO | Rank 0 | Train Epoch: 0 [150432/250314 (60%)]\tLoss: 1.014821\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:56 | INFO | Rank 0 | Train Epoch: 0 [150464/250314 (60%)]\tLoss: 0.549404\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:57 | INFO | Rank 0 | Train Epoch: 0 [150496/250314 (60%)]\tLoss: 0.808645\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:57 | INFO | Rank 0 | Train Epoch: 0 [150528/250314 (60%)]\tLoss: 0.920246\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:58 | INFO | Rank 0 | Train Epoch: 0 [150560/250314 (60%)]\tLoss: 0.661981\tData (t) 0.326\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:58 | INFO | Rank 0 | Train Epoch: 0 [150592/250314 (60%)]\tLoss: 0.737536\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:59 | INFO | Rank 0 | Train Epoch: 0 [150624/250314 (60%)]\tLoss: 0.701342\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:48:59 | INFO | Rank 0 | Train Epoch: 0 [150656/250314 (60%)]\tLoss: 0.769012\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:00 | INFO | Rank 0 | Train Epoch: 0 [150688/250314 (60%)]\tLoss: 0.413808\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:00 | INFO | Rank 0 | Train Epoch: 0 [150720/250314 (60%)]\tLoss: 0.513709\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:01 | INFO | Rank 0 | Train Epoch: 0 [150752/250314 (60%)]\tLoss: 0.607571\tData (t) 0.219\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:01 | INFO | Rank 0 | Train Epoch: 0 [150784/250314 (60%)]\tLoss: 0.873467\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:02 | INFO | Rank 0 | Train Epoch: 0 [150816/250314 (60%)]\tLoss: 0.798686\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:02 | INFO | Rank 0 | Train Epoch: 0 [150848/250314 (60%)]\tLoss: 0.721448\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:03 | INFO | Rank 0 | Train Epoch: 0 [150880/250314 (60%)]\tLoss: 0.718241\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:03 | INFO | Rank 0 | Train Epoch: 0 [150912/250314 (60%)]\tLoss: 1.184977\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:03 | INFO | Rank 0 | Train Epoch: 0 [150944/250314 (60%)]\tLoss: 0.822603\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:04 | INFO | Rank 0 | Train Epoch: 0 [150976/250314 (60%)]\tLoss: 1.103500\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:04 | INFO | Rank 0 | Train Epoch: 0 [151008/250314 (60%)]\tLoss: 0.860661\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:05 | INFO | Rank 0 | Train Epoch: 0 [151040/250314 (60%)]\tLoss: 0.699122\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:05 | INFO | Rank 0 | Train Epoch: 0 [151072/250314 (60%)]\tLoss: 0.466045\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:06 | INFO | Rank 0 | Train Epoch: 0 [151104/250314 (60%)]\tLoss: 0.593758\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:06 | INFO | Rank 0 | Train Epoch: 0 [151136/250314 (60%)]\tLoss: 0.661733\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:07 | INFO | Rank 0 | Train Epoch: 0 [151168/250314 (60%)]\tLoss: 0.513356\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:07 | INFO | Rank 0 | Train Epoch: 0 [151200/250314 (60%)]\tLoss: 0.682100\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:08 | INFO | Rank 0 | Train Epoch: 0 [151232/250314 (60%)]\tLoss: 1.001736\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:08 | INFO | Rank 0 | Train Epoch: 0 [151264/250314 (60%)]\tLoss: 0.816354\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:09 | INFO | Rank 0 | Train Epoch: 0 [151296/250314 (60%)]\tLoss: 0.886063\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:09 | INFO | Rank 0 | Train Epoch: 0 [151328/250314 (60%)]\tLoss: 0.861522\tData (t) 0.292\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:10 | INFO | Rank 0 | Train Epoch: 0 [151360/250314 (60%)]\tLoss: 1.134592\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:10 | INFO | Rank 0 | Train Epoch: 0 [151392/250314 (60%)]\tLoss: 0.945549\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:11 | INFO | Rank 0 | Train Epoch: 0 [151424/250314 (60%)]\tLoss: 0.430307\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:11 | INFO | Rank 0 | Train Epoch: 0 [151456/250314 (61%)]\tLoss: 1.012212\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:12 | INFO | Rank 0 | Train Epoch: 0 [151488/250314 (61%)]\tLoss: 0.417215\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:12 | INFO | Rank 0 | Train Epoch: 0 [151520/250314 (61%)]\tLoss: 0.605308\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:13 | INFO | Rank 0 | Train Epoch: 0 [151552/250314 (61%)]\tLoss: 0.559960\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:13 | INFO | Rank 0 | Train Epoch: 0 [151584/250314 (61%)]\tLoss: 0.930876\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:14 | INFO | Rank 0 | Train Epoch: 0 [151616/250314 (61%)]\tLoss: 0.975768\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:14 | INFO | Rank 0 | Train Epoch: 0 [151648/250314 (61%)]\tLoss: 0.570536\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:15 | INFO | Rank 0 | Train Epoch: 0 [151680/250314 (61%)]\tLoss: 1.177387\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:15 | INFO | Rank 0 | Train Epoch: 0 [151712/250314 (61%)]\tLoss: 0.770777\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:16 | INFO | Rank 0 | Train Epoch: 0 [151744/250314 (61%)]\tLoss: 0.728430\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:16 | INFO | Rank 0 | Train Epoch: 0 [151776/250314 (61%)]\tLoss: 0.664555\tData (t) 0.219\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:17 | INFO | Rank 0 | Train Epoch: 0 [151808/250314 (61%)]\tLoss: 0.711959\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:17 | INFO | Rank 0 | Train Epoch: 0 [151840/250314 (61%)]\tLoss: 0.490761\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:18 | INFO | Rank 0 | Train Epoch: 0 [151872/250314 (61%)]\tLoss: 0.810223\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:18 | INFO | Rank 0 | Train Epoch: 0 [151904/250314 (61%)]\tLoss: 0.651476\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:18 | INFO | Rank 0 | Train Epoch: 0 [151936/250314 (61%)]\tLoss: 0.624768\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:19 | INFO | Rank 0 | Train Epoch: 0 [151968/250314 (61%)]\tLoss: 0.465400\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:19 | INFO | Rank 0 | Train Epoch: 0 [152000/250314 (61%)]\tLoss: 0.632126\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:20 | INFO | Rank 0 | Train Epoch: 0 [152032/250314 (61%)]\tLoss: 0.669586\tData (t) 0.233\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:20 | INFO | Rank 0 | Train Epoch: 0 [152064/250314 (61%)]\tLoss: 0.713108\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:21 | INFO | Rank 0 | Train Epoch: 0 [152096/250314 (61%)]\tLoss: 0.855780\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:21 | INFO | Rank 0 | Train Epoch: 0 [152128/250314 (61%)]\tLoss: 0.727558\tData (t) 0.321\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:22 | INFO | Rank 0 | Train Epoch: 0 [152160/250314 (61%)]\tLoss: 0.671962\tData (t) 0.355\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:22 | INFO | Rank 0 | Train Epoch: 0 [152192/250314 (61%)]\tLoss: 0.430593\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:23 | INFO | Rank 0 | Train Epoch: 0 [152224/250314 (61%)]\tLoss: 0.527944\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:23 | INFO | Rank 0 | Train Epoch: 0 [152256/250314 (61%)]\tLoss: 0.912945\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:24 | INFO | Rank 0 | Train Epoch: 0 [152288/250314 (61%)]\tLoss: 0.821628\tData (t) 0.209\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:24 | INFO | Rank 0 | Train Epoch: 0 [152320/250314 (61%)]\tLoss: 0.767235\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:25 | INFO | Rank 0 | Train Epoch: 0 [152352/250314 (61%)]\tLoss: 0.879642\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:25 | INFO | Rank 0 | Train Epoch: 0 [152384/250314 (61%)]\tLoss: 0.635963\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:26 | INFO | Rank 0 | Train Epoch: 0 [152416/250314 (61%)]\tLoss: 0.934877\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:26 | INFO | Rank 0 | Train Epoch: 0 [152448/250314 (61%)]\tLoss: 0.595807\tData (t) 0.242\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:27 | INFO | Rank 0 | Train Epoch: 0 [152480/250314 (61%)]\tLoss: 0.711714\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:27 | INFO | Rank 0 | Train Epoch: 0 [152512/250314 (61%)]\tLoss: 0.294964\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:28 | INFO | Rank 0 | Train Epoch: 0 [152544/250314 (61%)]\tLoss: 0.450205\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.593\n",
      "2022-11-09,13:49:28 | INFO | Rank 0 | Train Epoch: 0 [152576/250314 (61%)]\tLoss: 0.561052\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:29 | INFO | Rank 0 | Train Epoch: 0 [152608/250314 (61%)]\tLoss: 0.497470\tData (t) 0.225\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:29 | INFO | Rank 0 | Train Epoch: 0 [152640/250314 (61%)]\tLoss: 0.798497\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:30 | INFO | Rank 0 | Train Epoch: 0 [152672/250314 (61%)]\tLoss: 1.041334\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:30 | INFO | Rank 0 | Train Epoch: 0 [152704/250314 (61%)]\tLoss: 0.234133\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:31 | INFO | Rank 0 | Train Epoch: 0 [152736/250314 (61%)]\tLoss: 0.517203\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:31 | INFO | Rank 0 | Train Epoch: 0 [152768/250314 (61%)]\tLoss: 0.384105\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:32 | INFO | Rank 0 | Train Epoch: 0 [152800/250314 (61%)]\tLoss: 0.530339\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:32 | INFO | Rank 0 | Train Epoch: 0 [152832/250314 (61%)]\tLoss: 0.906436\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:33 | INFO | Rank 0 | Train Epoch: 0 [152864/250314 (61%)]\tLoss: 0.620052\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:33 | INFO | Rank 0 | Train Epoch: 0 [152896/250314 (61%)]\tLoss: 0.995837\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:34 | INFO | Rank 0 | Train Epoch: 0 [152928/250314 (61%)]\tLoss: 0.426053\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:34 | INFO | Rank 0 | Train Epoch: 0 [152960/250314 (61%)]\tLoss: 0.524955\tData (t) 0.345\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:35 | INFO | Rank 0 | Train Epoch: 0 [152992/250314 (61%)]\tLoss: 0.800808\tData (t) 0.228\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:35 | INFO | Rank 0 | Train Epoch: 0 [153024/250314 (61%)]\tLoss: 1.331910\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:36 | INFO | Rank 0 | Train Epoch: 0 [153056/250314 (61%)]\tLoss: 0.712132\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:36 | INFO | Rank 0 | Train Epoch: 0 [153088/250314 (61%)]\tLoss: 0.749041\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:37 | INFO | Rank 0 | Train Epoch: 0 [153120/250314 (61%)]\tLoss: 1.026864\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:37 | INFO | Rank 0 | Train Epoch: 0 [153152/250314 (61%)]\tLoss: 0.650307\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:38 | INFO | Rank 0 | Train Epoch: 0 [153184/250314 (61%)]\tLoss: 0.502192\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:38 | INFO | Rank 0 | Train Epoch: 0 [153216/250314 (61%)]\tLoss: 0.617434\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:38 | INFO | Rank 0 | Train Epoch: 0 [153248/250314 (61%)]\tLoss: 0.884431\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:39 | INFO | Rank 0 | Train Epoch: 0 [153280/250314 (61%)]\tLoss: 0.368856\tData (t) 0.211\tBatch (t) 0.423\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:39 | INFO | Rank 0 | Train Epoch: 0 [153312/250314 (61%)]\tLoss: 0.574330\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:40 | INFO | Rank 0 | Train Epoch: 0 [153344/250314 (61%)]\tLoss: 0.794227\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:40 | INFO | Rank 0 | Train Epoch: 0 [153376/250314 (61%)]\tLoss: 0.618883\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:41 | INFO | Rank 0 | Train Epoch: 0 [153408/250314 (61%)]\tLoss: 0.784782\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:41 | INFO | Rank 0 | Train Epoch: 0 [153440/250314 (61%)]\tLoss: 0.607511\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:42 | INFO | Rank 0 | Train Epoch: 0 [153472/250314 (61%)]\tLoss: 0.772855\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:42 | INFO | Rank 0 | Train Epoch: 0 [153504/250314 (61%)]\tLoss: 0.986731\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:43 | INFO | Rank 0 | Train Epoch: 0 [153536/250314 (61%)]\tLoss: 0.959051\tData (t) 0.283\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:43 | INFO | Rank 0 | Train Epoch: 0 [153568/250314 (61%)]\tLoss: 0.624969\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:44 | INFO | Rank 0 | Train Epoch: 0 [153600/250314 (61%)]\tLoss: 0.763327\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:44 | INFO | Rank 0 | Train Epoch: 0 [153632/250314 (61%)]\tLoss: 0.618236\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:45 | INFO | Rank 0 | Train Epoch: 0 [153664/250314 (61%)]\tLoss: 0.554590\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:45 | INFO | Rank 0 | Train Epoch: 0 [153696/250314 (61%)]\tLoss: 0.386878\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:46 | INFO | Rank 0 | Train Epoch: 0 [153728/250314 (61%)]\tLoss: 0.446308\tData (t) 0.211\tBatch (t) 0.423\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:46 | INFO | Rank 0 | Train Epoch: 0 [153760/250314 (61%)]\tLoss: 0.649661\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:46 | INFO | Rank 0 | Train Epoch: 0 [153792/250314 (61%)]\tLoss: 0.795213\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:47 | INFO | Rank 0 | Train Epoch: 0 [153824/250314 (61%)]\tLoss: 0.509432\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:47 | INFO | Rank 0 | Train Epoch: 0 [153856/250314 (61%)]\tLoss: 0.598285\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:48 | INFO | Rank 0 | Train Epoch: 0 [153888/250314 (61%)]\tLoss: 0.596863\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:48 | INFO | Rank 0 | Train Epoch: 0 [153920/250314 (61%)]\tLoss: 0.577110\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:49 | INFO | Rank 0 | Train Epoch: 0 [153952/250314 (62%)]\tLoss: 0.365362\tData (t) 0.229\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:49 | INFO | Rank 0 | Train Epoch: 0 [153984/250314 (62%)]\tLoss: 0.776489\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:50 | INFO | Rank 0 | Train Epoch: 0 [154016/250314 (62%)]\tLoss: 0.756193\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:50 | INFO | Rank 0 | Train Epoch: 0 [154048/250314 (62%)]\tLoss: 0.540027\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:51 | INFO | Rank 0 | Train Epoch: 0 [154080/250314 (62%)]\tLoss: 0.456104\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:51 | INFO | Rank 0 | Train Epoch: 0 [154112/250314 (62%)]\tLoss: 0.580570\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:52 | INFO | Rank 0 | Train Epoch: 0 [154144/250314 (62%)]\tLoss: 0.460963\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:52 | INFO | Rank 0 | Train Epoch: 0 [154176/250314 (62%)]\tLoss: 0.623511\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:53 | INFO | Rank 0 | Train Epoch: 0 [154208/250314 (62%)]\tLoss: 0.925066\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:54 | INFO | Rank 0 | Train Epoch: 0 [154240/250314 (62%)]\tLoss: 0.933087\tData (t) 0.350\tBatch (t) 0.562\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:54 | INFO | Rank 0 | Train Epoch: 0 [154272/250314 (62%)]\tLoss: 0.462079\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:54 | INFO | Rank 0 | Train Epoch: 0 [154304/250314 (62%)]\tLoss: 0.881414\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:55 | INFO | Rank 0 | Train Epoch: 0 [154336/250314 (62%)]\tLoss: 0.807069\tData (t) 0.402\tBatch (t) 0.613\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:56 | INFO | Rank 0 | Train Epoch: 0 [154368/250314 (62%)]\tLoss: 0.198188\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:56 | INFO | Rank 0 | Train Epoch: 0 [154400/250314 (62%)]\tLoss: 1.031897\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:57 | INFO | Rank 0 | Train Epoch: 0 [154432/250314 (62%)]\tLoss: 0.670720\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:57 | INFO | Rank 0 | Train Epoch: 0 [154464/250314 (62%)]\tLoss: 0.686900\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:58 | INFO | Rank 0 | Train Epoch: 0 [154496/250314 (62%)]\tLoss: 0.393659\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:58 | INFO | Rank 0 | Train Epoch: 0 [154528/250314 (62%)]\tLoss: 0.888736\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:59 | INFO | Rank 0 | Train Epoch: 0 [154560/250314 (62%)]\tLoss: 1.056143\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:49:59 | INFO | Rank 0 | Train Epoch: 0 [154592/250314 (62%)]\tLoss: 0.875013\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:00 | INFO | Rank 0 | Train Epoch: 0 [154624/250314 (62%)]\tLoss: 0.474119\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:00 | INFO | Rank 0 | Train Epoch: 0 [154656/250314 (62%)]\tLoss: 0.937010\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:01 | INFO | Rank 0 | Train Epoch: 0 [154688/250314 (62%)]\tLoss: 0.648791\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:01 | INFO | Rank 0 | Train Epoch: 0 [154720/250314 (62%)]\tLoss: 0.852959\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:01 | INFO | Rank 0 | Train Epoch: 0 [154752/250314 (62%)]\tLoss: 0.527599\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:02 | INFO | Rank 0 | Train Epoch: 0 [154784/250314 (62%)]\tLoss: 0.776840\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:02 | INFO | Rank 0 | Train Epoch: 0 [154816/250314 (62%)]\tLoss: 0.604178\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:03 | INFO | Rank 0 | Train Epoch: 0 [154848/250314 (62%)]\tLoss: 0.374052\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:03 | INFO | Rank 0 | Train Epoch: 0 [154880/250314 (62%)]\tLoss: 0.517328\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:04 | INFO | Rank 0 | Train Epoch: 0 [154912/250314 (62%)]\tLoss: 0.627411\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:04 | INFO | Rank 0 | Train Epoch: 0 [154944/250314 (62%)]\tLoss: 0.734125\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:05 | INFO | Rank 0 | Train Epoch: 0 [154976/250314 (62%)]\tLoss: 0.540905\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:05 | INFO | Rank 0 | Train Epoch: 0 [155008/250314 (62%)]\tLoss: 0.461772\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:06 | INFO | Rank 0 | Train Epoch: 0 [155040/250314 (62%)]\tLoss: 0.324181\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:06 | INFO | Rank 0 | Train Epoch: 0 [155072/250314 (62%)]\tLoss: 0.460089\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:07 | INFO | Rank 0 | Train Epoch: 0 [155104/250314 (62%)]\tLoss: 0.290913\tData (t) 0.218\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:07 | INFO | Rank 0 | Train Epoch: 0 [155136/250314 (62%)]\tLoss: 0.706118\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:08 | INFO | Rank 0 | Train Epoch: 0 [155168/250314 (62%)]\tLoss: 0.869241\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:08 | INFO | Rank 0 | Train Epoch: 0 [155200/250314 (62%)]\tLoss: 1.182451\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:09 | INFO | Rank 0 | Train Epoch: 0 [155232/250314 (62%)]\tLoss: 0.569571\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:09 | INFO | Rank 0 | Train Epoch: 0 [155264/250314 (62%)]\tLoss: 0.684136\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:10 | INFO | Rank 0 | Train Epoch: 0 [155296/250314 (62%)]\tLoss: 0.957486\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:10 | INFO | Rank 0 | Train Epoch: 0 [155328/250314 (62%)]\tLoss: 0.619126\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:11 | INFO | Rank 0 | Train Epoch: 0 [155360/250314 (62%)]\tLoss: 0.819342\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:11 | INFO | Rank 0 | Train Epoch: 0 [155392/250314 (62%)]\tLoss: 0.594994\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:12 | INFO | Rank 0 | Train Epoch: 0 [155424/250314 (62%)]\tLoss: 0.552557\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:12 | INFO | Rank 0 | Train Epoch: 0 [155456/250314 (62%)]\tLoss: 0.900176\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:13 | INFO | Rank 0 | Train Epoch: 0 [155488/250314 (62%)]\tLoss: 0.968919\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:13 | INFO | Rank 0 | Train Epoch: 0 [155520/250314 (62%)]\tLoss: 0.648530\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:14 | INFO | Rank 0 | Train Epoch: 0 [155552/250314 (62%)]\tLoss: 0.699350\tData (t) 0.219\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:14 | INFO | Rank 0 | Train Epoch: 0 [155584/250314 (62%)]\tLoss: 0.799084\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:14 | INFO | Rank 0 | Train Epoch: 0 [155616/250314 (62%)]\tLoss: 0.871947\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:15 | INFO | Rank 0 | Train Epoch: 0 [155648/250314 (62%)]\tLoss: 0.734932\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:15 | INFO | Rank 0 | Train Epoch: 0 [155680/250314 (62%)]\tLoss: 0.734073\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:16 | INFO | Rank 0 | Train Epoch: 0 [155712/250314 (62%)]\tLoss: 0.517497\tData (t) 0.195\tBatch (t) 0.408\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:16 | INFO | Rank 0 | Train Epoch: 0 [155744/250314 (62%)]\tLoss: 0.813533\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:17 | INFO | Rank 0 | Train Epoch: 0 [155776/250314 (62%)]\tLoss: 0.932371\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:17 | INFO | Rank 0 | Train Epoch: 0 [155808/250314 (62%)]\tLoss: 0.681953\tData (t) 0.233\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:18 | INFO | Rank 0 | Train Epoch: 0 [155840/250314 (62%)]\tLoss: 0.973746\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:18 | INFO | Rank 0 | Train Epoch: 0 [155872/250314 (62%)]\tLoss: 0.394204\tData (t) 0.198\tBatch (t) 0.410\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:19 | INFO | Rank 0 | Train Epoch: 0 [155904/250314 (62%)]\tLoss: 0.500305\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:19 | INFO | Rank 0 | Train Epoch: 0 [155936/250314 (62%)]\tLoss: 0.568447\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:20 | INFO | Rank 0 | Train Epoch: 0 [155968/250314 (62%)]\tLoss: 0.629712\tData (t) 0.223\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:20 | INFO | Rank 0 | Train Epoch: 0 [156000/250314 (62%)]\tLoss: 1.005261\tData (t) 0.227\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:20 | INFO | Rank 0 | Train Epoch: 0 [156032/250314 (62%)]\tLoss: 0.603588\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:21 | INFO | Rank 0 | Train Epoch: 0 [156064/250314 (62%)]\tLoss: 0.622012\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:21 | INFO | Rank 0 | Train Epoch: 0 [156096/250314 (62%)]\tLoss: 0.922268\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:22 | INFO | Rank 0 | Train Epoch: 0 [156128/250314 (62%)]\tLoss: 0.874098\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:22 | INFO | Rank 0 | Train Epoch: 0 [156160/250314 (62%)]\tLoss: 0.641837\tData (t) 0.318\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:23 | INFO | Rank 0 | Train Epoch: 0 [156192/250314 (62%)]\tLoss: 0.592439\tData (t) 0.261\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:23 | INFO | Rank 0 | Train Epoch: 0 [156224/250314 (62%)]\tLoss: 0.478024\tData (t) 0.283\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:24 | INFO | Rank 0 | Train Epoch: 0 [156256/250314 (62%)]\tLoss: 1.362619\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:24 | INFO | Rank 0 | Train Epoch: 0 [156288/250314 (62%)]\tLoss: 0.869673\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:25 | INFO | Rank 0 | Train Epoch: 0 [156320/250314 (62%)]\tLoss: 0.787627\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:25 | INFO | Rank 0 | Train Epoch: 0 [156352/250314 (62%)]\tLoss: 0.799317\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:26 | INFO | Rank 0 | Train Epoch: 0 [156384/250314 (62%)]\tLoss: 0.440354\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:26 | INFO | Rank 0 | Train Epoch: 0 [156416/250314 (62%)]\tLoss: 0.818631\tData (t) 0.321\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:27 | INFO | Rank 0 | Train Epoch: 0 [156448/250314 (63%)]\tLoss: 0.574903\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:27 | INFO | Rank 0 | Train Epoch: 0 [156480/250314 (63%)]\tLoss: 0.519389\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:28 | INFO | Rank 0 | Train Epoch: 0 [156512/250314 (63%)]\tLoss: 0.349245\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:28 | INFO | Rank 0 | Train Epoch: 0 [156544/250314 (63%)]\tLoss: 0.547847\tData (t) 0.416\tBatch (t) 0.628\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:29 | INFO | Rank 0 | Train Epoch: 0 [156576/250314 (63%)]\tLoss: 0.485473\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:30 | INFO | Rank 0 | Train Epoch: 0 [156608/250314 (63%)]\tLoss: 0.922130\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:30 | INFO | Rank 0 | Train Epoch: 0 [156640/250314 (63%)]\tLoss: 0.603290\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:31 | INFO | Rank 0 | Train Epoch: 0 [156672/250314 (63%)]\tLoss: 0.538130\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:31 | INFO | Rank 0 | Train Epoch: 0 [156704/250314 (63%)]\tLoss: 0.383168\tData (t) 0.425\tBatch (t) 0.637\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:32 | INFO | Rank 0 | Train Epoch: 0 [156736/250314 (63%)]\tLoss: 0.629017\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:32 | INFO | Rank 0 | Train Epoch: 0 [156768/250314 (63%)]\tLoss: 0.897704\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:33 | INFO | Rank 0 | Train Epoch: 0 [156800/250314 (63%)]\tLoss: 0.404635\tData (t) 0.215\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:33 | INFO | Rank 0 | Train Epoch: 0 [156832/250314 (63%)]\tLoss: 1.144130\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:34 | INFO | Rank 0 | Train Epoch: 0 [156864/250314 (63%)]\tLoss: 1.079304\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:34 | INFO | Rank 0 | Train Epoch: 0 [156896/250314 (63%)]\tLoss: 0.921230\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:35 | INFO | Rank 0 | Train Epoch: 0 [156928/250314 (63%)]\tLoss: 0.408250\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:35 | INFO | Rank 0 | Train Epoch: 0 [156960/250314 (63%)]\tLoss: 0.782584\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:35 | INFO | Rank 0 | Train Epoch: 0 [156992/250314 (63%)]\tLoss: 0.666913\tData (t) 0.225\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:36 | INFO | Rank 0 | Train Epoch: 0 [157024/250314 (63%)]\tLoss: 0.754984\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:36 | INFO | Rank 0 | Train Epoch: 0 [157056/250314 (63%)]\tLoss: 1.201767\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:37 | INFO | Rank 0 | Train Epoch: 0 [157088/250314 (63%)]\tLoss: 0.672328\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:37 | INFO | Rank 0 | Train Epoch: 0 [157120/250314 (63%)]\tLoss: 0.671355\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:38 | INFO | Rank 0 | Train Epoch: 0 [157152/250314 (63%)]\tLoss: 0.788388\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:38 | INFO | Rank 0 | Train Epoch: 0 [157184/250314 (63%)]\tLoss: 0.631269\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:39 | INFO | Rank 0 | Train Epoch: 0 [157216/250314 (63%)]\tLoss: 0.651291\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:39 | INFO | Rank 0 | Train Epoch: 0 [157248/250314 (63%)]\tLoss: 0.683442\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:40 | INFO | Rank 0 | Train Epoch: 0 [157280/250314 (63%)]\tLoss: 0.759738\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:40 | INFO | Rank 0 | Train Epoch: 0 [157312/250314 (63%)]\tLoss: 1.138138\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:41 | INFO | Rank 0 | Train Epoch: 0 [157344/250314 (63%)]\tLoss: 0.706746\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:41 | INFO | Rank 0 | Train Epoch: 0 [157376/250314 (63%)]\tLoss: 0.860236\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:42 | INFO | Rank 0 | Train Epoch: 0 [157408/250314 (63%)]\tLoss: 1.127596\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:42 | INFO | Rank 0 | Train Epoch: 0 [157440/250314 (63%)]\tLoss: 0.534556\tData (t) 0.208\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:43 | INFO | Rank 0 | Train Epoch: 0 [157472/250314 (63%)]\tLoss: 0.813704\tData (t) 0.229\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:43 | INFO | Rank 0 | Train Epoch: 0 [157504/250314 (63%)]\tLoss: 1.108567\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:44 | INFO | Rank 0 | Train Epoch: 0 [157536/250314 (63%)]\tLoss: 0.596455\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:44 | INFO | Rank 0 | Train Epoch: 0 [157568/250314 (63%)]\tLoss: 0.708575\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:44 | INFO | Rank 0 | Train Epoch: 0 [157600/250314 (63%)]\tLoss: 0.997723\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:45 | INFO | Rank 0 | Train Epoch: 0 [157632/250314 (63%)]\tLoss: 0.671152\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:45 | INFO | Rank 0 | Train Epoch: 0 [157664/250314 (63%)]\tLoss: 0.800975\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:46 | INFO | Rank 0 | Train Epoch: 0 [157696/250314 (63%)]\tLoss: 0.701380\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:46 | INFO | Rank 0 | Train Epoch: 0 [157728/250314 (63%)]\tLoss: 0.503720\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:47 | INFO | Rank 0 | Train Epoch: 0 [157760/250314 (63%)]\tLoss: 0.586916\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:47 | INFO | Rank 0 | Train Epoch: 0 [157792/250314 (63%)]\tLoss: 0.682130\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:48 | INFO | Rank 0 | Train Epoch: 0 [157824/250314 (63%)]\tLoss: 0.757545\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:48 | INFO | Rank 0 | Train Epoch: 0 [157856/250314 (63%)]\tLoss: 0.839168\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:49 | INFO | Rank 0 | Train Epoch: 0 [157888/250314 (63%)]\tLoss: 0.723433\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:49 | INFO | Rank 0 | Train Epoch: 0 [157920/250314 (63%)]\tLoss: 0.783560\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:50 | INFO | Rank 0 | Train Epoch: 0 [157952/250314 (63%)]\tLoss: 0.381189\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:50 | INFO | Rank 0 | Train Epoch: 0 [157984/250314 (63%)]\tLoss: 0.665097\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:51 | INFO | Rank 0 | Train Epoch: 0 [158016/250314 (63%)]\tLoss: 0.544719\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:51 | INFO | Rank 0 | Train Epoch: 0 [158048/250314 (63%)]\tLoss: 1.096811\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:52 | INFO | Rank 0 | Train Epoch: 0 [158080/250314 (63%)]\tLoss: 0.850586\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:52 | INFO | Rank 0 | Train Epoch: 0 [158112/250314 (63%)]\tLoss: 0.398307\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:53 | INFO | Rank 0 | Train Epoch: 0 [158144/250314 (63%)]\tLoss: 0.510312\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:53 | INFO | Rank 0 | Train Epoch: 0 [158176/250314 (63%)]\tLoss: 0.544065\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:54 | INFO | Rank 0 | Train Epoch: 0 [158208/250314 (63%)]\tLoss: 0.464795\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:54 | INFO | Rank 0 | Train Epoch: 0 [158240/250314 (63%)]\tLoss: 0.653997\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:55 | INFO | Rank 0 | Train Epoch: 0 [158272/250314 (63%)]\tLoss: 0.441517\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:55 | INFO | Rank 0 | Train Epoch: 0 [158304/250314 (63%)]\tLoss: 1.293402\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:55 | INFO | Rank 0 | Train Epoch: 0 [158336/250314 (63%)]\tLoss: 0.433726\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:56 | INFO | Rank 0 | Train Epoch: 0 [158368/250314 (63%)]\tLoss: 0.692996\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:56 | INFO | Rank 0 | Train Epoch: 0 [158400/250314 (63%)]\tLoss: 1.083702\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:57 | INFO | Rank 0 | Train Epoch: 0 [158432/250314 (63%)]\tLoss: 0.821000\tData (t) 0.221\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:57 | INFO | Rank 0 | Train Epoch: 0 [158464/250314 (63%)]\tLoss: 0.627203\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:58 | INFO | Rank 0 | Train Epoch: 0 [158496/250314 (63%)]\tLoss: 1.298316\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:58 | INFO | Rank 0 | Train Epoch: 0 [158528/250314 (63%)]\tLoss: 0.526875\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:59 | INFO | Rank 0 | Train Epoch: 0 [158560/250314 (63%)]\tLoss: 0.488238\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:50:59 | INFO | Rank 0 | Train Epoch: 0 [158592/250314 (63%)]\tLoss: 0.716933\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:00 | INFO | Rank 0 | Train Epoch: 0 [158624/250314 (63%)]\tLoss: 0.477346\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:00 | INFO | Rank 0 | Train Epoch: 0 [158656/250314 (63%)]\tLoss: 0.694151\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:01 | INFO | Rank 0 | Train Epoch: 0 [158688/250314 (63%)]\tLoss: 0.470862\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:01 | INFO | Rank 0 | Train Epoch: 0 [158720/250314 (63%)]\tLoss: 0.694201\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:02 | INFO | Rank 0 | Train Epoch: 0 [158752/250314 (63%)]\tLoss: 0.549400\tData (t) 0.225\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:02 | INFO | Rank 0 | Train Epoch: 0 [158784/250314 (63%)]\tLoss: 0.785506\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:03 | INFO | Rank 0 | Train Epoch: 0 [158816/250314 (63%)]\tLoss: 0.772220\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:03 | INFO | Rank 0 | Train Epoch: 0 [158848/250314 (63%)]\tLoss: 1.308206\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:04 | INFO | Rank 0 | Train Epoch: 0 [158880/250314 (63%)]\tLoss: 0.576494\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:04 | INFO | Rank 0 | Train Epoch: 0 [158912/250314 (63%)]\tLoss: 0.640080\tData (t) 0.259\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:05 | INFO | Rank 0 | Train Epoch: 0 [158944/250314 (64%)]\tLoss: 0.789218\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:05 | INFO | Rank 0 | Train Epoch: 0 [158976/250314 (64%)]\tLoss: 1.097848\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:06 | INFO | Rank 0 | Train Epoch: 0 [159008/250314 (64%)]\tLoss: 0.570998\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:06 | INFO | Rank 0 | Train Epoch: 0 [159040/250314 (64%)]\tLoss: 0.787582\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:07 | INFO | Rank 0 | Train Epoch: 0 [159072/250314 (64%)]\tLoss: 0.663938\tData (t) 0.183\tBatch (t) 0.395\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:07 | INFO | Rank 0 | Train Epoch: 0 [159104/250314 (64%)]\tLoss: 0.747096\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:08 | INFO | Rank 0 | Train Epoch: 0 [159136/250314 (64%)]\tLoss: 0.454418\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:08 | INFO | Rank 0 | Train Epoch: 0 [159168/250314 (64%)]\tLoss: 0.924654\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:09 | INFO | Rank 0 | Train Epoch: 0 [159200/250314 (64%)]\tLoss: 0.701468\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:09 | INFO | Rank 0 | Train Epoch: 0 [159232/250314 (64%)]\tLoss: 1.305435\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:10 | INFO | Rank 0 | Train Epoch: 0 [159264/250314 (64%)]\tLoss: 0.609008\tData (t) 0.224\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:10 | INFO | Rank 0 | Train Epoch: 0 [159296/250314 (64%)]\tLoss: 0.264997\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:11 | INFO | Rank 0 | Train Epoch: 0 [159328/250314 (64%)]\tLoss: 0.392862\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:11 | INFO | Rank 0 | Train Epoch: 0 [159360/250314 (64%)]\tLoss: 1.177848\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:12 | INFO | Rank 0 | Train Epoch: 0 [159392/250314 (64%)]\tLoss: 0.531802\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:12 | INFO | Rank 0 | Train Epoch: 0 [159424/250314 (64%)]\tLoss: 0.706502\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:12 | INFO | Rank 0 | Train Epoch: 0 [159456/250314 (64%)]\tLoss: 0.722884\tData (t) 0.227\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:13 | INFO | Rank 0 | Train Epoch: 0 [159488/250314 (64%)]\tLoss: 0.892194\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:13 | INFO | Rank 0 | Train Epoch: 0 [159520/250314 (64%)]\tLoss: 0.669716\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:14 | INFO | Rank 0 | Train Epoch: 0 [159552/250314 (64%)]\tLoss: 0.935130\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:14 | INFO | Rank 0 | Train Epoch: 0 [159584/250314 (64%)]\tLoss: 1.000788\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:15 | INFO | Rank 0 | Train Epoch: 0 [159616/250314 (64%)]\tLoss: 0.452711\tData (t) 0.321\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:15 | INFO | Rank 0 | Train Epoch: 0 [159648/250314 (64%)]\tLoss: 0.452379\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:16 | INFO | Rank 0 | Train Epoch: 0 [159680/250314 (64%)]\tLoss: 0.483749\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:17 | INFO | Rank 0 | Train Epoch: 0 [159712/250314 (64%)]\tLoss: 0.646553\tData (t) 0.349\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:17 | INFO | Rank 0 | Train Epoch: 0 [159744/250314 (64%)]\tLoss: 1.003668\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:18 | INFO | Rank 0 | Train Epoch: 0 [159776/250314 (64%)]\tLoss: 0.799058\tData (t) 0.243\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:18 | INFO | Rank 0 | Train Epoch: 0 [159808/250314 (64%)]\tLoss: 0.510942\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:18 | INFO | Rank 0 | Train Epoch: 0 [159840/250314 (64%)]\tLoss: 0.663098\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:19 | INFO | Rank 0 | Train Epoch: 0 [159872/250314 (64%)]\tLoss: 1.081801\tData (t) 0.217\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:19 | INFO | Rank 0 | Train Epoch: 0 [159904/250314 (64%)]\tLoss: 0.689932\tData (t) 0.204\tBatch (t) 0.415\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:20 | INFO | Rank 0 | Train Epoch: 0 [159936/250314 (64%)]\tLoss: 0.418275\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:20 | INFO | Rank 0 | Train Epoch: 0 [159968/250314 (64%)]\tLoss: 0.710520\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:21 | INFO | Rank 0 | Train Epoch: 0 [160000/250314 (64%)]\tLoss: 0.671278\tData (t) 0.208\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:21 | INFO | Rank 0 | Train Epoch: 0 [160032/250314 (64%)]\tLoss: 0.728847\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:22 | INFO | Rank 0 | Train Epoch: 0 [160064/250314 (64%)]\tLoss: 0.817785\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:22 | INFO | Rank 0 | Train Epoch: 0 [160096/250314 (64%)]\tLoss: 0.522127\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:23 | INFO | Rank 0 | Train Epoch: 0 [160128/250314 (64%)]\tLoss: 1.026824\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:23 | INFO | Rank 0 | Train Epoch: 0 [160160/250314 (64%)]\tLoss: 0.295332\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:24 | INFO | Rank 0 | Train Epoch: 0 [160192/250314 (64%)]\tLoss: 0.706868\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:24 | INFO | Rank 0 | Train Epoch: 0 [160224/250314 (64%)]\tLoss: 0.690834\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:25 | INFO | Rank 0 | Train Epoch: 0 [160256/250314 (64%)]\tLoss: 0.398635\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:25 | INFO | Rank 0 | Train Epoch: 0 [160288/250314 (64%)]\tLoss: 0.867454\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:26 | INFO | Rank 0 | Train Epoch: 0 [160320/250314 (64%)]\tLoss: 0.735448\tData (t) 0.231\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:26 | INFO | Rank 0 | Train Epoch: 0 [160352/250314 (64%)]\tLoss: 0.578579\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:27 | INFO | Rank 0 | Train Epoch: 0 [160384/250314 (64%)]\tLoss: 0.953827\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:27 | INFO | Rank 0 | Train Epoch: 0 [160416/250314 (64%)]\tLoss: 0.285897\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:28 | INFO | Rank 0 | Train Epoch: 0 [160448/250314 (64%)]\tLoss: 0.991034\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:28 | INFO | Rank 0 | Train Epoch: 0 [160480/250314 (64%)]\tLoss: 0.781790\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:29 | INFO | Rank 0 | Train Epoch: 0 [160512/250314 (64%)]\tLoss: 1.268647\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:29 | INFO | Rank 0 | Train Epoch: 0 [160544/250314 (64%)]\tLoss: 0.588396\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:30 | INFO | Rank 0 | Train Epoch: 0 [160576/250314 (64%)]\tLoss: 0.853266\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:30 | INFO | Rank 0 | Train Epoch: 0 [160608/250314 (64%)]\tLoss: 0.629517\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:31 | INFO | Rank 0 | Train Epoch: 0 [160640/250314 (64%)]\tLoss: 0.440102\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:31 | INFO | Rank 0 | Train Epoch: 0 [160672/250314 (64%)]\tLoss: 0.593982\tData (t) 0.222\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:31 | INFO | Rank 0 | Train Epoch: 0 [160704/250314 (64%)]\tLoss: 0.557520\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:32 | INFO | Rank 0 | Train Epoch: 0 [160736/250314 (64%)]\tLoss: 0.617868\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:32 | INFO | Rank 0 | Train Epoch: 0 [160768/250314 (64%)]\tLoss: 0.553726\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:33 | INFO | Rank 0 | Train Epoch: 0 [160800/250314 (64%)]\tLoss: 0.469060\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:33 | INFO | Rank 0 | Train Epoch: 0 [160832/250314 (64%)]\tLoss: 1.227791\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:34 | INFO | Rank 0 | Train Epoch: 0 [160864/250314 (64%)]\tLoss: 0.427903\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:34 | INFO | Rank 0 | Train Epoch: 0 [160896/250314 (64%)]\tLoss: 0.415118\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:35 | INFO | Rank 0 | Train Epoch: 0 [160928/250314 (64%)]\tLoss: 0.842518\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:35 | INFO | Rank 0 | Train Epoch: 0 [160960/250314 (64%)]\tLoss: 0.722403\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:36 | INFO | Rank 0 | Train Epoch: 0 [160992/250314 (64%)]\tLoss: 0.543915\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:36 | INFO | Rank 0 | Train Epoch: 0 [161024/250314 (64%)]\tLoss: 0.781047\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:37 | INFO | Rank 0 | Train Epoch: 0 [161056/250314 (64%)]\tLoss: 0.577705\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:37 | INFO | Rank 0 | Train Epoch: 0 [161088/250314 (64%)]\tLoss: 1.047161\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:38 | INFO | Rank 0 | Train Epoch: 0 [161120/250314 (64%)]\tLoss: 0.444517\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:38 | INFO | Rank 0 | Train Epoch: 0 [161152/250314 (64%)]\tLoss: 0.528208\tData (t) 0.180\tBatch (t) 0.392\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:39 | INFO | Rank 0 | Train Epoch: 0 [161184/250314 (64%)]\tLoss: 0.819101\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:39 | INFO | Rank 0 | Train Epoch: 0 [161216/250314 (64%)]\tLoss: 1.009659\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:40 | INFO | Rank 0 | Train Epoch: 0 [161248/250314 (64%)]\tLoss: 0.767793\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:40 | INFO | Rank 0 | Train Epoch: 0 [161280/250314 (64%)]\tLoss: 0.740147\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:41 | INFO | Rank 0 | Train Epoch: 0 [161312/250314 (64%)]\tLoss: 0.707451\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:41 | INFO | Rank 0 | Train Epoch: 0 [161344/250314 (64%)]\tLoss: 0.743997\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:42 | INFO | Rank 0 | Train Epoch: 0 [161376/250314 (64%)]\tLoss: 0.648390\tData (t) 0.344\tBatch (t) 0.555\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:42 | INFO | Rank 0 | Train Epoch: 0 [161408/250314 (64%)]\tLoss: 0.550154\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:43 | INFO | Rank 0 | Train Epoch: 0 [161440/250314 (64%)]\tLoss: 0.580656\tData (t) 0.292\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:43 | INFO | Rank 0 | Train Epoch: 0 [161472/250314 (65%)]\tLoss: 0.333843\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:44 | INFO | Rank 0 | Train Epoch: 0 [161504/250314 (65%)]\tLoss: 0.657580\tData (t) 0.317\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:44 | INFO | Rank 0 | Train Epoch: 0 [161536/250314 (65%)]\tLoss: 0.583866\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:45 | INFO | Rank 0 | Train Epoch: 0 [161568/250314 (65%)]\tLoss: 0.481974\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:45 | INFO | Rank 0 | Train Epoch: 0 [161600/250314 (65%)]\tLoss: 0.824312\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:46 | INFO | Rank 0 | Train Epoch: 0 [161632/250314 (65%)]\tLoss: 0.687730\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:46 | INFO | Rank 0 | Train Epoch: 0 [161664/250314 (65%)]\tLoss: 0.457992\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:47 | INFO | Rank 0 | Train Epoch: 0 [161696/250314 (65%)]\tLoss: 0.451301\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:47 | INFO | Rank 0 | Train Epoch: 0 [161728/250314 (65%)]\tLoss: 0.501828\tData (t) 0.384\tBatch (t) 0.595\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:48 | INFO | Rank 0 | Train Epoch: 0 [161760/250314 (65%)]\tLoss: 0.744913\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:48 | INFO | Rank 0 | Train Epoch: 0 [161792/250314 (65%)]\tLoss: 1.143192\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:49 | INFO | Rank 0 | Train Epoch: 0 [161824/250314 (65%)]\tLoss: 0.883216\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:49 | INFO | Rank 0 | Train Epoch: 0 [161856/250314 (65%)]\tLoss: 0.720670\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:50 | INFO | Rank 0 | Train Epoch: 0 [161888/250314 (65%)]\tLoss: 0.572611\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:50 | INFO | Rank 0 | Train Epoch: 0 [161920/250314 (65%)]\tLoss: 0.621871\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:50 | INFO | Rank 0 | Train Epoch: 0 [161952/250314 (65%)]\tLoss: 0.540789\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:51 | INFO | Rank 0 | Train Epoch: 0 [161984/250314 (65%)]\tLoss: 0.522447\tData (t) 0.268\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:51 | INFO | Rank 0 | Train Epoch: 0 [162016/250314 (65%)]\tLoss: 0.667155\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:52 | INFO | Rank 0 | Train Epoch: 0 [162048/250314 (65%)]\tLoss: 0.705021\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:52 | INFO | Rank 0 | Train Epoch: 0 [162080/250314 (65%)]\tLoss: 0.571604\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:53 | INFO | Rank 0 | Train Epoch: 0 [162112/250314 (65%)]\tLoss: 0.569042\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:53 | INFO | Rank 0 | Train Epoch: 0 [162144/250314 (65%)]\tLoss: 0.438892\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:54 | INFO | Rank 0 | Train Epoch: 0 [162176/250314 (65%)]\tLoss: 0.617034\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:54 | INFO | Rank 0 | Train Epoch: 0 [162208/250314 (65%)]\tLoss: 0.407970\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:55 | INFO | Rank 0 | Train Epoch: 0 [162240/250314 (65%)]\tLoss: 1.052888\tData (t) 0.245\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:55 | INFO | Rank 0 | Train Epoch: 0 [162272/250314 (65%)]\tLoss: 0.465663\tData (t) 0.266\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:56 | INFO | Rank 0 | Train Epoch: 0 [162304/250314 (65%)]\tLoss: 0.597213\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:56 | INFO | Rank 0 | Train Epoch: 0 [162336/250314 (65%)]\tLoss: 0.760923\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:57 | INFO | Rank 0 | Train Epoch: 0 [162368/250314 (65%)]\tLoss: 0.577913\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:57 | INFO | Rank 0 | Train Epoch: 0 [162400/250314 (65%)]\tLoss: 0.650095\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:58 | INFO | Rank 0 | Train Epoch: 0 [162432/250314 (65%)]\tLoss: 0.463245\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:58 | INFO | Rank 0 | Train Epoch: 0 [162464/250314 (65%)]\tLoss: 0.593211\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:59 | INFO | Rank 0 | Train Epoch: 0 [162496/250314 (65%)]\tLoss: 0.769611\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:51:59 | INFO | Rank 0 | Train Epoch: 0 [162528/250314 (65%)]\tLoss: 0.488968\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:00 | INFO | Rank 0 | Train Epoch: 0 [162560/250314 (65%)]\tLoss: 0.712591\tData (t) 0.233\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:00 | INFO | Rank 0 | Train Epoch: 0 [162592/250314 (65%)]\tLoss: 0.603850\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:01 | INFO | Rank 0 | Train Epoch: 0 [162624/250314 (65%)]\tLoss: 0.613000\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:01 | INFO | Rank 0 | Train Epoch: 0 [162656/250314 (65%)]\tLoss: 0.636713\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:02 | INFO | Rank 0 | Train Epoch: 0 [162688/250314 (65%)]\tLoss: 1.107747\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:02 | INFO | Rank 0 | Train Epoch: 0 [162720/250314 (65%)]\tLoss: 0.497781\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:03 | INFO | Rank 0 | Train Epoch: 0 [162752/250314 (65%)]\tLoss: 0.479895\tData (t) 0.458\tBatch (t) 0.670\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:03 | INFO | Rank 0 | Train Epoch: 0 [162784/250314 (65%)]\tLoss: 0.772399\tData (t) 0.207\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:04 | INFO | Rank 0 | Train Epoch: 0 [162816/250314 (65%)]\tLoss: 0.717995\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:04 | INFO | Rank 0 | Train Epoch: 0 [162848/250314 (65%)]\tLoss: 0.759904\tData (t) 0.225\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:05 | INFO | Rank 0 | Train Epoch: 0 [162880/250314 (65%)]\tLoss: 0.534541\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:05 | INFO | Rank 0 | Train Epoch: 0 [162912/250314 (65%)]\tLoss: 0.449815\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:06 | INFO | Rank 0 | Train Epoch: 0 [162944/250314 (65%)]\tLoss: 0.830324\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:06 | INFO | Rank 0 | Train Epoch: 0 [162976/250314 (65%)]\tLoss: 0.393045\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:06 | INFO | Rank 0 | Train Epoch: 0 [163008/250314 (65%)]\tLoss: 0.661396\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:07 | INFO | Rank 0 | Train Epoch: 0 [163040/250314 (65%)]\tLoss: 0.168200\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:08 | INFO | Rank 0 | Train Epoch: 0 [163072/250314 (65%)]\tLoss: 0.724823\tData (t) 0.371\tBatch (t) 0.583\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:08 | INFO | Rank 0 | Train Epoch: 0 [163104/250314 (65%)]\tLoss: 0.376866\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:08 | INFO | Rank 0 | Train Epoch: 0 [163136/250314 (65%)]\tLoss: 0.698560\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:09 | INFO | Rank 0 | Train Epoch: 0 [163168/250314 (65%)]\tLoss: 0.753636\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:09 | INFO | Rank 0 | Train Epoch: 0 [163200/250314 (65%)]\tLoss: 0.669986\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:10 | INFO | Rank 0 | Train Epoch: 0 [163232/250314 (65%)]\tLoss: 0.292750\tData (t) 0.204\tBatch (t) 0.416\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:10 | INFO | Rank 0 | Train Epoch: 0 [163264/250314 (65%)]\tLoss: 0.604077\tData (t) 0.267\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:11 | INFO | Rank 0 | Train Epoch: 0 [163296/250314 (65%)]\tLoss: 0.671053\tData (t) 0.292\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:11 | INFO | Rank 0 | Train Epoch: 0 [163328/250314 (65%)]\tLoss: 0.820541\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:12 | INFO | Rank 0 | Train Epoch: 0 [163360/250314 (65%)]\tLoss: 0.782197\tData (t) 0.281\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:12 | INFO | Rank 0 | Train Epoch: 0 [163392/250314 (65%)]\tLoss: 1.083184\tData (t) 0.272\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:13 | INFO | Rank 0 | Train Epoch: 0 [163424/250314 (65%)]\tLoss: 0.798505\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:13 | INFO | Rank 0 | Train Epoch: 0 [163456/250314 (65%)]\tLoss: 0.843974\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:14 | INFO | Rank 0 | Train Epoch: 0 [163488/250314 (65%)]\tLoss: 0.467495\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:14 | INFO | Rank 0 | Train Epoch: 0 [163520/250314 (65%)]\tLoss: 0.884573\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:15 | INFO | Rank 0 | Train Epoch: 0 [163552/250314 (65%)]\tLoss: 0.291991\tData (t) 0.206\tBatch (t) 0.418\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:15 | INFO | Rank 0 | Train Epoch: 0 [163584/250314 (65%)]\tLoss: 0.528392\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:16 | INFO | Rank 0 | Train Epoch: 0 [163616/250314 (65%)]\tLoss: 0.790780\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:16 | INFO | Rank 0 | Train Epoch: 0 [163648/250314 (65%)]\tLoss: 0.524274\tData (t) 0.267\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:17 | INFO | Rank 0 | Train Epoch: 0 [163680/250314 (65%)]\tLoss: 0.813138\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:17 | INFO | Rank 0 | Train Epoch: 0 [163712/250314 (65%)]\tLoss: 0.493545\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:18 | INFO | Rank 0 | Train Epoch: 0 [163744/250314 (65%)]\tLoss: 0.711515\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:18 | INFO | Rank 0 | Train Epoch: 0 [163776/250314 (65%)]\tLoss: 0.771563\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:19 | INFO | Rank 0 | Train Epoch: 0 [163808/250314 (65%)]\tLoss: 1.015392\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:19 | INFO | Rank 0 | Train Epoch: 0 [163840/250314 (65%)]\tLoss: 0.598476\tData (t) 0.186\tBatch (t) 0.397\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:19 | INFO | Rank 0 | Train Epoch: 0 [163872/250314 (65%)]\tLoss: 0.989042\tData (t) 0.306\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:20 | INFO | Rank 0 | Train Epoch: 0 [163904/250314 (65%)]\tLoss: 0.885505\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:20 | INFO | Rank 0 | Train Epoch: 0 [163936/250314 (65%)]\tLoss: 1.093066\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:21 | INFO | Rank 0 | Train Epoch: 0 [163968/250314 (66%)]\tLoss: 0.879475\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:21 | INFO | Rank 0 | Train Epoch: 0 [164000/250314 (66%)]\tLoss: 0.533164\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:22 | INFO | Rank 0 | Train Epoch: 0 [164032/250314 (66%)]\tLoss: 0.675474\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:22 | INFO | Rank 0 | Train Epoch: 0 [164064/250314 (66%)]\tLoss: 0.955969\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:23 | INFO | Rank 0 | Train Epoch: 0 [164096/250314 (66%)]\tLoss: 0.524282\tData (t) 0.222\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:23 | INFO | Rank 0 | Train Epoch: 0 [164128/250314 (66%)]\tLoss: 0.664062\tData (t) 0.359\tBatch (t) 0.571\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:24 | INFO | Rank 0 | Train Epoch: 0 [164160/250314 (66%)]\tLoss: 0.579328\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:24 | INFO | Rank 0 | Train Epoch: 0 [164192/250314 (66%)]\tLoss: 0.455286\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:25 | INFO | Rank 0 | Train Epoch: 0 [164224/250314 (66%)]\tLoss: 0.599779\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:25 | INFO | Rank 0 | Train Epoch: 0 [164256/250314 (66%)]\tLoss: 0.582000\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:26 | INFO | Rank 0 | Train Epoch: 0 [164288/250314 (66%)]\tLoss: 0.716536\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:26 | INFO | Rank 0 | Train Epoch: 0 [164320/250314 (66%)]\tLoss: 0.800183\tData (t) 0.331\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:27 | INFO | Rank 0 | Train Epoch: 0 [164352/250314 (66%)]\tLoss: 0.488090\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:27 | INFO | Rank 0 | Train Epoch: 0 [164384/250314 (66%)]\tLoss: 0.519259\tData (t) 0.318\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:28 | INFO | Rank 0 | Train Epoch: 0 [164416/250314 (66%)]\tLoss: 0.965083\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:28 | INFO | Rank 0 | Train Epoch: 0 [164448/250314 (66%)]\tLoss: 0.564673\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:29 | INFO | Rank 0 | Train Epoch: 0 [164480/250314 (66%)]\tLoss: 0.835694\tData (t) 0.376\tBatch (t) 0.588\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:29 | INFO | Rank 0 | Train Epoch: 0 [164512/250314 (66%)]\tLoss: 0.645555\tData (t) 0.208\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:30 | INFO | Rank 0 | Train Epoch: 0 [164544/250314 (66%)]\tLoss: 0.607071\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:30 | INFO | Rank 0 | Train Epoch: 0 [164576/250314 (66%)]\tLoss: 1.011552\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:31 | INFO | Rank 0 | Train Epoch: 0 [164608/250314 (66%)]\tLoss: 0.265914\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:31 | INFO | Rank 0 | Train Epoch: 0 [164640/250314 (66%)]\tLoss: 0.813324\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:32 | INFO | Rank 0 | Train Epoch: 0 [164672/250314 (66%)]\tLoss: 0.628241\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:32 | INFO | Rank 0 | Train Epoch: 0 [164704/250314 (66%)]\tLoss: 0.412979\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:33 | INFO | Rank 0 | Train Epoch: 0 [164736/250314 (66%)]\tLoss: 0.552891\tData (t) 0.338\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:33 | INFO | Rank 0 | Train Epoch: 0 [164768/250314 (66%)]\tLoss: 0.333363\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:34 | INFO | Rank 0 | Train Epoch: 0 [164800/250314 (66%)]\tLoss: 0.675994\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:34 | INFO | Rank 0 | Train Epoch: 0 [164832/250314 (66%)]\tLoss: 0.935138\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:35 | INFO | Rank 0 | Train Epoch: 0 [164864/250314 (66%)]\tLoss: 0.588088\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:36 | INFO | Rank 0 | Train Epoch: 0 [164896/250314 (66%)]\tLoss: 0.745475\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:36 | INFO | Rank 0 | Train Epoch: 0 [164928/250314 (66%)]\tLoss: 0.738656\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:36 | INFO | Rank 0 | Train Epoch: 0 [164960/250314 (66%)]\tLoss: 0.585079\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:37 | INFO | Rank 0 | Train Epoch: 0 [164992/250314 (66%)]\tLoss: 0.750439\tData (t) 0.294\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:37 | INFO | Rank 0 | Train Epoch: 0 [165024/250314 (66%)]\tLoss: 0.711817\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:38 | INFO | Rank 0 | Train Epoch: 0 [165056/250314 (66%)]\tLoss: 0.890341\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:38 | INFO | Rank 0 | Train Epoch: 0 [165088/250314 (66%)]\tLoss: 0.656369\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:39 | INFO | Rank 0 | Train Epoch: 0 [165120/250314 (66%)]\tLoss: 0.605727\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:39 | INFO | Rank 0 | Train Epoch: 0 [165152/250314 (66%)]\tLoss: 0.869591\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:40 | INFO | Rank 0 | Train Epoch: 0 [165184/250314 (66%)]\tLoss: 0.666468\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:40 | INFO | Rank 0 | Train Epoch: 0 [165216/250314 (66%)]\tLoss: 0.527863\tData (t) 0.306\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:41 | INFO | Rank 0 | Train Epoch: 0 [165248/250314 (66%)]\tLoss: 0.527093\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:41 | INFO | Rank 0 | Train Epoch: 0 [165280/250314 (66%)]\tLoss: 0.586186\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:42 | INFO | Rank 0 | Train Epoch: 0 [165312/250314 (66%)]\tLoss: 0.416487\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:42 | INFO | Rank 0 | Train Epoch: 0 [165344/250314 (66%)]\tLoss: 0.891469\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:43 | INFO | Rank 0 | Train Epoch: 0 [165376/250314 (66%)]\tLoss: 0.799749\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:43 | INFO | Rank 0 | Train Epoch: 0 [165408/250314 (66%)]\tLoss: 0.542593\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:44 | INFO | Rank 0 | Train Epoch: 0 [165440/250314 (66%)]\tLoss: 0.437952\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:44 | INFO | Rank 0 | Train Epoch: 0 [165472/250314 (66%)]\tLoss: 0.329874\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:45 | INFO | Rank 0 | Train Epoch: 0 [165504/250314 (66%)]\tLoss: 1.236705\tData (t) 0.341\tBatch (t) 0.553\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:45 | INFO | Rank 0 | Train Epoch: 0 [165536/250314 (66%)]\tLoss: 0.816722\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:46 | INFO | Rank 0 | Train Epoch: 0 [165568/250314 (66%)]\tLoss: 1.095445\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:46 | INFO | Rank 0 | Train Epoch: 0 [165600/250314 (66%)]\tLoss: 0.493764\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:47 | INFO | Rank 0 | Train Epoch: 0 [165632/250314 (66%)]\tLoss: 0.604625\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:47 | INFO | Rank 0 | Train Epoch: 0 [165664/250314 (66%)]\tLoss: 0.606588\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:48 | INFO | Rank 0 | Train Epoch: 0 [165696/250314 (66%)]\tLoss: 0.391147\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:48 | INFO | Rank 0 | Train Epoch: 0 [165728/250314 (66%)]\tLoss: 0.783039\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:49 | INFO | Rank 0 | Train Epoch: 0 [165760/250314 (66%)]\tLoss: 0.459136\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:49 | INFO | Rank 0 | Train Epoch: 0 [165792/250314 (66%)]\tLoss: 0.912783\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:50 | INFO | Rank 0 | Train Epoch: 0 [165824/250314 (66%)]\tLoss: 0.327500\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:50 | INFO | Rank 0 | Train Epoch: 0 [165856/250314 (66%)]\tLoss: 0.959420\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:51 | INFO | Rank 0 | Train Epoch: 0 [165888/250314 (66%)]\tLoss: 0.701516\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:51 | INFO | Rank 0 | Train Epoch: 0 [165920/250314 (66%)]\tLoss: 0.888252\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:52 | INFO | Rank 0 | Train Epoch: 0 [165952/250314 (66%)]\tLoss: 0.325875\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:52 | INFO | Rank 0 | Train Epoch: 0 [165984/250314 (66%)]\tLoss: 0.999694\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:53 | INFO | Rank 0 | Train Epoch: 0 [166016/250314 (66%)]\tLoss: 0.907301\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:53 | INFO | Rank 0 | Train Epoch: 0 [166048/250314 (66%)]\tLoss: 0.885226\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:54 | INFO | Rank 0 | Train Epoch: 0 [166080/250314 (66%)]\tLoss: 0.599504\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:54 | INFO | Rank 0 | Train Epoch: 0 [166112/250314 (66%)]\tLoss: 0.854261\tData (t) 0.220\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:55 | INFO | Rank 0 | Train Epoch: 0 [166144/250314 (66%)]\tLoss: 0.830499\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:55 | INFO | Rank 0 | Train Epoch: 0 [166176/250314 (66%)]\tLoss: 0.735337\tData (t) 0.652\tBatch (t) 0.864\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:56 | INFO | Rank 0 | Train Epoch: 0 [166208/250314 (66%)]\tLoss: 0.940689\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:56 | INFO | Rank 0 | Train Epoch: 0 [166240/250314 (66%)]\tLoss: 0.885995\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:57 | INFO | Rank 0 | Train Epoch: 0 [166272/250314 (66%)]\tLoss: 0.444532\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:57 | INFO | Rank 0 | Train Epoch: 0 [166304/250314 (66%)]\tLoss: 0.633524\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:58 | INFO | Rank 0 | Train Epoch: 0 [166336/250314 (66%)]\tLoss: 0.912142\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:58 | INFO | Rank 0 | Train Epoch: 0 [166368/250314 (66%)]\tLoss: 0.607596\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:59 | INFO | Rank 0 | Train Epoch: 0 [166400/250314 (66%)]\tLoss: 0.733019\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:52:59 | INFO | Rank 0 | Train Epoch: 0 [166432/250314 (66%)]\tLoss: 0.715461\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:00 | INFO | Rank 0 | Train Epoch: 0 [166464/250314 (67%)]\tLoss: 0.422334\tData (t) 0.175\tBatch (t) 0.387\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:00 | INFO | Rank 0 | Train Epoch: 0 [166496/250314 (67%)]\tLoss: 0.547443\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:01 | INFO | Rank 0 | Train Epoch: 0 [166528/250314 (67%)]\tLoss: 1.003867\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:01 | INFO | Rank 0 | Train Epoch: 0 [166560/250314 (67%)]\tLoss: 0.279509\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:02 | INFO | Rank 0 | Train Epoch: 0 [166592/250314 (67%)]\tLoss: 0.807912\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:02 | INFO | Rank 0 | Train Epoch: 0 [166624/250314 (67%)]\tLoss: 0.592517\tData (t) 0.304\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:03 | INFO | Rank 0 | Train Epoch: 0 [166656/250314 (67%)]\tLoss: 0.571397\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:03 | INFO | Rank 0 | Train Epoch: 0 [166688/250314 (67%)]\tLoss: 0.542788\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:04 | INFO | Rank 0 | Train Epoch: 0 [166720/250314 (67%)]\tLoss: 0.739025\tData (t) 0.239\tBatch (t) 0.406\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:04 | INFO | Rank 0 | Train Epoch: 0 [166752/250314 (67%)]\tLoss: 0.606656\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:05 | INFO | Rank 0 | Train Epoch: 0 [166784/250314 (67%)]\tLoss: 0.616895\tData (t) 0.328\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:05 | INFO | Rank 0 | Train Epoch: 0 [166816/250314 (67%)]\tLoss: 0.750834\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:06 | INFO | Rank 0 | Train Epoch: 0 [166848/250314 (67%)]\tLoss: 0.686205\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:06 | INFO | Rank 0 | Train Epoch: 0 [166880/250314 (67%)]\tLoss: 0.762770\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:07 | INFO | Rank 0 | Train Epoch: 0 [166912/250314 (67%)]\tLoss: 0.818755\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:07 | INFO | Rank 0 | Train Epoch: 0 [166944/250314 (67%)]\tLoss: 0.448850\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:07 | INFO | Rank 0 | Train Epoch: 0 [166976/250314 (67%)]\tLoss: 0.614908\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:08 | INFO | Rank 0 | Train Epoch: 0 [167008/250314 (67%)]\tLoss: 1.005202\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:08 | INFO | Rank 0 | Train Epoch: 0 [167040/250314 (67%)]\tLoss: 0.671701\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:09 | INFO | Rank 0 | Train Epoch: 0 [167072/250314 (67%)]\tLoss: 0.882584\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:09 | INFO | Rank 0 | Train Epoch: 0 [167104/250314 (67%)]\tLoss: 0.756233\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:10 | INFO | Rank 0 | Train Epoch: 0 [167136/250314 (67%)]\tLoss: 0.472893\tData (t) 0.355\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:10 | INFO | Rank 0 | Train Epoch: 0 [167168/250314 (67%)]\tLoss: 0.769786\tData (t) 0.213\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:11 | INFO | Rank 0 | Train Epoch: 0 [167200/250314 (67%)]\tLoss: 0.371299\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:11 | INFO | Rank 0 | Train Epoch: 0 [167232/250314 (67%)]\tLoss: 0.780849\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:12 | INFO | Rank 0 | Train Epoch: 0 [167264/250314 (67%)]\tLoss: 0.489719\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:12 | INFO | Rank 0 | Train Epoch: 0 [167296/250314 (67%)]\tLoss: 0.926745\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:13 | INFO | Rank 0 | Train Epoch: 0 [167328/250314 (67%)]\tLoss: 0.754734\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:13 | INFO | Rank 0 | Train Epoch: 0 [167360/250314 (67%)]\tLoss: 0.925364\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:14 | INFO | Rank 0 | Train Epoch: 0 [167392/250314 (67%)]\tLoss: 0.737593\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:14 | INFO | Rank 0 | Train Epoch: 0 [167424/250314 (67%)]\tLoss: 1.025656\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:15 | INFO | Rank 0 | Train Epoch: 0 [167456/250314 (67%)]\tLoss: 0.733447\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:15 | INFO | Rank 0 | Train Epoch: 0 [167488/250314 (67%)]\tLoss: 1.032013\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:16 | INFO | Rank 0 | Train Epoch: 0 [167520/250314 (67%)]\tLoss: 1.020414\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:16 | INFO | Rank 0 | Train Epoch: 0 [167552/250314 (67%)]\tLoss: 0.677983\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:17 | INFO | Rank 0 | Train Epoch: 0 [167584/250314 (67%)]\tLoss: 0.605809\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:17 | INFO | Rank 0 | Train Epoch: 0 [167616/250314 (67%)]\tLoss: 0.526582\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:18 | INFO | Rank 0 | Train Epoch: 0 [167648/250314 (67%)]\tLoss: 0.630864\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:18 | INFO | Rank 0 | Train Epoch: 0 [167680/250314 (67%)]\tLoss: 0.394791\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:19 | INFO | Rank 0 | Train Epoch: 0 [167712/250314 (67%)]\tLoss: 0.477874\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:19 | INFO | Rank 0 | Train Epoch: 0 [167744/250314 (67%)]\tLoss: 0.857031\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:20 | INFO | Rank 0 | Train Epoch: 0 [167776/250314 (67%)]\tLoss: 0.626488\tData (t) 0.343\tBatch (t) 0.555\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:20 | INFO | Rank 0 | Train Epoch: 0 [167808/250314 (67%)]\tLoss: 0.499091\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:21 | INFO | Rank 0 | Train Epoch: 0 [167840/250314 (67%)]\tLoss: 0.746143\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:21 | INFO | Rank 0 | Train Epoch: 0 [167872/250314 (67%)]\tLoss: 0.803173\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:22 | INFO | Rank 0 | Train Epoch: 0 [167904/250314 (67%)]\tLoss: 0.342917\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:22 | INFO | Rank 0 | Train Epoch: 0 [167936/250314 (67%)]\tLoss: 0.679498\tData (t) 0.277\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:23 | INFO | Rank 0 | Train Epoch: 0 [167968/250314 (67%)]\tLoss: 1.163884\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:23 | INFO | Rank 0 | Train Epoch: 0 [168000/250314 (67%)]\tLoss: 1.009321\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:24 | INFO | Rank 0 | Train Epoch: 0 [168032/250314 (67%)]\tLoss: 0.514274\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:24 | INFO | Rank 0 | Train Epoch: 0 [168064/250314 (67%)]\tLoss: 0.491212\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:24 | INFO | Rank 0 | Train Epoch: 0 [168096/250314 (67%)]\tLoss: 0.813081\tData (t) 0.279\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:25 | INFO | Rank 0 | Train Epoch: 0 [168128/250314 (67%)]\tLoss: 0.579175\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:25 | INFO | Rank 0 | Train Epoch: 0 [168160/250314 (67%)]\tLoss: 0.757902\tData (t) 0.185\tBatch (t) 0.397\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:26 | INFO | Rank 0 | Train Epoch: 0 [168192/250314 (67%)]\tLoss: 0.647659\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:26 | INFO | Rank 0 | Train Epoch: 0 [168224/250314 (67%)]\tLoss: 1.064970\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:27 | INFO | Rank 0 | Train Epoch: 0 [168256/250314 (67%)]\tLoss: 0.556851\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:27 | INFO | Rank 0 | Train Epoch: 0 [168288/250314 (67%)]\tLoss: 1.027921\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:28 | INFO | Rank 0 | Train Epoch: 0 [168320/250314 (67%)]\tLoss: 1.010909\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:28 | INFO | Rank 0 | Train Epoch: 0 [168352/250314 (67%)]\tLoss: 0.377675\tData (t) 0.274\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:29 | INFO | Rank 0 | Train Epoch: 0 [168384/250314 (67%)]\tLoss: 0.872874\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:29 | INFO | Rank 0 | Train Epoch: 0 [168416/250314 (67%)]\tLoss: 0.978379\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:30 | INFO | Rank 0 | Train Epoch: 0 [168448/250314 (67%)]\tLoss: 0.623179\tData (t) 0.246\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:30 | INFO | Rank 0 | Train Epoch: 0 [168480/250314 (67%)]\tLoss: 0.402825\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:31 | INFO | Rank 0 | Train Epoch: 0 [168512/250314 (67%)]\tLoss: 0.698631\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:31 | INFO | Rank 0 | Train Epoch: 0 [168544/250314 (67%)]\tLoss: 0.742375\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:32 | INFO | Rank 0 | Train Epoch: 0 [168576/250314 (67%)]\tLoss: 0.983712\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:32 | INFO | Rank 0 | Train Epoch: 0 [168608/250314 (67%)]\tLoss: 0.747279\tData (t) 0.201\tBatch (t) 0.413\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:33 | INFO | Rank 0 | Train Epoch: 0 [168640/250314 (67%)]\tLoss: 0.520145\tData (t) 0.200\tBatch (t) 0.412\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:33 | INFO | Rank 0 | Train Epoch: 0 [168672/250314 (67%)]\tLoss: 0.405131\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:34 | INFO | Rank 0 | Train Epoch: 0 [168704/250314 (67%)]\tLoss: 0.683596\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:34 | INFO | Rank 0 | Train Epoch: 0 [168736/250314 (67%)]\tLoss: 0.879493\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:35 | INFO | Rank 0 | Train Epoch: 0 [168768/250314 (67%)]\tLoss: 1.062298\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:35 | INFO | Rank 0 | Train Epoch: 0 [168800/250314 (67%)]\tLoss: 0.458492\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:36 | INFO | Rank 0 | Train Epoch: 0 [168832/250314 (67%)]\tLoss: 0.559220\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:36 | INFO | Rank 0 | Train Epoch: 0 [168864/250314 (67%)]\tLoss: 0.639603\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:37 | INFO | Rank 0 | Train Epoch: 0 [168896/250314 (67%)]\tLoss: 1.007837\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:37 | INFO | Rank 0 | Train Epoch: 0 [168928/250314 (67%)]\tLoss: 0.684713\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:38 | INFO | Rank 0 | Train Epoch: 0 [168960/250314 (68%)]\tLoss: 0.637770\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:38 | INFO | Rank 0 | Train Epoch: 0 [168992/250314 (68%)]\tLoss: 0.758235\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:38 | INFO | Rank 0 | Train Epoch: 0 [169024/250314 (68%)]\tLoss: 0.855368\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:39 | INFO | Rank 0 | Train Epoch: 0 [169056/250314 (68%)]\tLoss: 0.689982\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:39 | INFO | Rank 0 | Train Epoch: 0 [169088/250314 (68%)]\tLoss: 0.798814\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:40 | INFO | Rank 0 | Train Epoch: 0 [169120/250314 (68%)]\tLoss: 0.734338\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:40 | INFO | Rank 0 | Train Epoch: 0 [169152/250314 (68%)]\tLoss: 0.693005\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:41 | INFO | Rank 0 | Train Epoch: 0 [169184/250314 (68%)]\tLoss: 0.637036\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:41 | INFO | Rank 0 | Train Epoch: 0 [169216/250314 (68%)]\tLoss: 0.408510\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:42 | INFO | Rank 0 | Train Epoch: 0 [169248/250314 (68%)]\tLoss: 0.519894\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:42 | INFO | Rank 0 | Train Epoch: 0 [169280/250314 (68%)]\tLoss: 0.747344\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:43 | INFO | Rank 0 | Train Epoch: 0 [169312/250314 (68%)]\tLoss: 0.732508\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:43 | INFO | Rank 0 | Train Epoch: 0 [169344/250314 (68%)]\tLoss: 0.681167\tData (t) 0.204\tBatch (t) 0.416\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:44 | INFO | Rank 0 | Train Epoch: 0 [169376/250314 (68%)]\tLoss: 0.665399\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:44 | INFO | Rank 0 | Train Epoch: 0 [169408/250314 (68%)]\tLoss: 0.602923\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:45 | INFO | Rank 0 | Train Epoch: 0 [169440/250314 (68%)]\tLoss: 0.729064\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:45 | INFO | Rank 0 | Train Epoch: 0 [169472/250314 (68%)]\tLoss: 0.569661\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:46 | INFO | Rank 0 | Train Epoch: 0 [169504/250314 (68%)]\tLoss: 0.653742\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:46 | INFO | Rank 0 | Train Epoch: 0 [169536/250314 (68%)]\tLoss: 0.585079\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:47 | INFO | Rank 0 | Train Epoch: 0 [169568/250314 (68%)]\tLoss: 0.538377\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:47 | INFO | Rank 0 | Train Epoch: 0 [169600/250314 (68%)]\tLoss: 0.667549\tData (t) 0.208\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:47 | INFO | Rank 0 | Train Epoch: 0 [169632/250314 (68%)]\tLoss: 0.843231\tData (t) 0.292\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:48 | INFO | Rank 0 | Train Epoch: 0 [169664/250314 (68%)]\tLoss: 0.628472\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:49 | INFO | Rank 0 | Train Epoch: 0 [169696/250314 (68%)]\tLoss: 0.822073\tData (t) 0.359\tBatch (t) 0.571\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:49 | INFO | Rank 0 | Train Epoch: 0 [169728/250314 (68%)]\tLoss: 0.550897\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:49 | INFO | Rank 0 | Train Epoch: 0 [169760/250314 (68%)]\tLoss: 0.704152\tData (t) 0.214\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:50 | INFO | Rank 0 | Train Epoch: 0 [169792/250314 (68%)]\tLoss: 0.469671\tData (t) 0.225\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:50 | INFO | Rank 0 | Train Epoch: 0 [169824/250314 (68%)]\tLoss: 0.724705\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:51 | INFO | Rank 0 | Train Epoch: 0 [169856/250314 (68%)]\tLoss: 0.881967\tData (t) 0.314\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:51 | INFO | Rank 0 | Train Epoch: 0 [169888/250314 (68%)]\tLoss: 0.617704\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:52 | INFO | Rank 0 | Train Epoch: 0 [169920/250314 (68%)]\tLoss: 0.319056\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:52 | INFO | Rank 0 | Train Epoch: 0 [169952/250314 (68%)]\tLoss: 0.658094\tData (t) 0.219\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:53 | INFO | Rank 0 | Train Epoch: 0 [169984/250314 (68%)]\tLoss: 0.527197\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:53 | INFO | Rank 0 | Train Epoch: 0 [170016/250314 (68%)]\tLoss: 0.555058\tData (t) 0.221\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:54 | INFO | Rank 0 | Train Epoch: 0 [170048/250314 (68%)]\tLoss: 0.877498\tData (t) 0.307\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:54 | INFO | Rank 0 | Train Epoch: 0 [170080/250314 (68%)]\tLoss: 0.696239\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:55 | INFO | Rank 0 | Train Epoch: 0 [170112/250314 (68%)]\tLoss: 0.900480\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:55 | INFO | Rank 0 | Train Epoch: 0 [170144/250314 (68%)]\tLoss: 0.965165\tData (t) 0.275\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:56 | INFO | Rank 0 | Train Epoch: 0 [170176/250314 (68%)]\tLoss: 0.918368\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:56 | INFO | Rank 0 | Train Epoch: 0 [170208/250314 (68%)]\tLoss: 0.985883\tData (t) 0.200\tBatch (t) 0.412\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:57 | INFO | Rank 0 | Train Epoch: 0 [170240/250314 (68%)]\tLoss: 0.611682\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:57 | INFO | Rank 0 | Train Epoch: 0 [170272/250314 (68%)]\tLoss: 0.695901\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:58 | INFO | Rank 0 | Train Epoch: 0 [170304/250314 (68%)]\tLoss: 0.820407\tData (t) 0.320\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:58 | INFO | Rank 0 | Train Epoch: 0 [170336/250314 (68%)]\tLoss: 0.872120\tData (t) 0.294\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:59 | INFO | Rank 0 | Train Epoch: 0 [170368/250314 (68%)]\tLoss: 0.429603\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:53:59 | INFO | Rank 0 | Train Epoch: 0 [170400/250314 (68%)]\tLoss: 0.410881\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:00 | INFO | Rank 0 | Train Epoch: 0 [170432/250314 (68%)]\tLoss: 0.437915\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:00 | INFO | Rank 0 | Train Epoch: 0 [170464/250314 (68%)]\tLoss: 0.651082\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:00 | INFO | Rank 0 | Train Epoch: 0 [170496/250314 (68%)]\tLoss: 0.503632\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:01 | INFO | Rank 0 | Train Epoch: 0 [170528/250314 (68%)]\tLoss: 0.486843\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:01 | INFO | Rank 0 | Train Epoch: 0 [170560/250314 (68%)]\tLoss: 0.412352\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:02 | INFO | Rank 0 | Train Epoch: 0 [170592/250314 (68%)]\tLoss: 0.566247\tData (t) 0.314\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:02 | INFO | Rank 0 | Train Epoch: 0 [170624/250314 (68%)]\tLoss: 1.121141\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:03 | INFO | Rank 0 | Train Epoch: 0 [170656/250314 (68%)]\tLoss: 0.940958\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:03 | INFO | Rank 0 | Train Epoch: 0 [170688/250314 (68%)]\tLoss: 0.621446\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:04 | INFO | Rank 0 | Train Epoch: 0 [170720/250314 (68%)]\tLoss: 0.620575\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:04 | INFO | Rank 0 | Train Epoch: 0 [170752/250314 (68%)]\tLoss: 0.888911\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:05 | INFO | Rank 0 | Train Epoch: 0 [170784/250314 (68%)]\tLoss: 0.759838\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:05 | INFO | Rank 0 | Train Epoch: 0 [170816/250314 (68%)]\tLoss: 0.933503\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:06 | INFO | Rank 0 | Train Epoch: 0 [170848/250314 (68%)]\tLoss: 0.850045\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:06 | INFO | Rank 0 | Train Epoch: 0 [170880/250314 (68%)]\tLoss: 0.475933\tData (t) 0.221\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:07 | INFO | Rank 0 | Train Epoch: 0 [170912/250314 (68%)]\tLoss: 0.481585\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:07 | INFO | Rank 0 | Train Epoch: 0 [170944/250314 (68%)]\tLoss: 0.611628\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:08 | INFO | Rank 0 | Train Epoch: 0 [170976/250314 (68%)]\tLoss: 0.599280\tData (t) 0.274\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:08 | INFO | Rank 0 | Train Epoch: 0 [171008/250314 (68%)]\tLoss: 0.727633\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:09 | INFO | Rank 0 | Train Epoch: 0 [171040/250314 (68%)]\tLoss: 0.604994\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:09 | INFO | Rank 0 | Train Epoch: 0 [171072/250314 (68%)]\tLoss: 0.791337\tData (t) 0.215\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:10 | INFO | Rank 0 | Train Epoch: 0 [171104/250314 (68%)]\tLoss: 0.481263\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:10 | INFO | Rank 0 | Train Epoch: 0 [171136/250314 (68%)]\tLoss: 0.466148\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:11 | INFO | Rank 0 | Train Epoch: 0 [171168/250314 (68%)]\tLoss: 0.826242\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:11 | INFO | Rank 0 | Train Epoch: 0 [171200/250314 (68%)]\tLoss: 0.554111\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:12 | INFO | Rank 0 | Train Epoch: 0 [171232/250314 (68%)]\tLoss: 0.673842\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:12 | INFO | Rank 0 | Train Epoch: 0 [171264/250314 (68%)]\tLoss: 0.558922\tData (t) 0.233\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:13 | INFO | Rank 0 | Train Epoch: 0 [171296/250314 (68%)]\tLoss: 0.277379\tData (t) 0.204\tBatch (t) 0.416\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:13 | INFO | Rank 0 | Train Epoch: 0 [171328/250314 (68%)]\tLoss: 1.046107\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:14 | INFO | Rank 0 | Train Epoch: 0 [171360/250314 (68%)]\tLoss: 0.491201\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:14 | INFO | Rank 0 | Train Epoch: 0 [171392/250314 (68%)]\tLoss: 0.579428\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:15 | INFO | Rank 0 | Train Epoch: 0 [171424/250314 (68%)]\tLoss: 0.608329\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:15 | INFO | Rank 0 | Train Epoch: 0 [171456/250314 (68%)]\tLoss: 1.080920\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:16 | INFO | Rank 0 | Train Epoch: 0 [171488/250314 (69%)]\tLoss: 0.575562\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:16 | INFO | Rank 0 | Train Epoch: 0 [171520/250314 (69%)]\tLoss: 0.849415\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:16 | INFO | Rank 0 | Train Epoch: 0 [171552/250314 (69%)]\tLoss: 0.755788\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:17 | INFO | Rank 0 | Train Epoch: 0 [171584/250314 (69%)]\tLoss: 0.403368\tData (t) 0.276\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:17 | INFO | Rank 0 | Train Epoch: 0 [171616/250314 (69%)]\tLoss: 1.011421\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:18 | INFO | Rank 0 | Train Epoch: 0 [171648/250314 (69%)]\tLoss: 0.701319\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:18 | INFO | Rank 0 | Train Epoch: 0 [171680/250314 (69%)]\tLoss: 0.638070\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:19 | INFO | Rank 0 | Train Epoch: 0 [171712/250314 (69%)]\tLoss: 0.407234\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:19 | INFO | Rank 0 | Train Epoch: 0 [171744/250314 (69%)]\tLoss: 0.878942\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:20 | INFO | Rank 0 | Train Epoch: 0 [171776/250314 (69%)]\tLoss: 0.774906\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:21 | INFO | Rank 0 | Train Epoch: 0 [171808/250314 (69%)]\tLoss: 0.524256\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:21 | INFO | Rank 0 | Train Epoch: 0 [171840/250314 (69%)]\tLoss: 0.409966\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:21 | INFO | Rank 0 | Train Epoch: 0 [171872/250314 (69%)]\tLoss: 0.537306\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:22 | INFO | Rank 0 | Train Epoch: 0 [171904/250314 (69%)]\tLoss: 0.754304\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:23 | INFO | Rank 0 | Train Epoch: 0 [171936/250314 (69%)]\tLoss: 0.676529\tData (t) 0.411\tBatch (t) 0.623\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:23 | INFO | Rank 0 | Train Epoch: 0 [171968/250314 (69%)]\tLoss: 0.510633\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:23 | INFO | Rank 0 | Train Epoch: 0 [172000/250314 (69%)]\tLoss: 0.647093\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:24 | INFO | Rank 0 | Train Epoch: 0 [172032/250314 (69%)]\tLoss: 0.653108\tData (t) 0.223\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:24 | INFO | Rank 0 | Train Epoch: 0 [172064/250314 (69%)]\tLoss: 0.556280\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:25 | INFO | Rank 0 | Train Epoch: 0 [172096/250314 (69%)]\tLoss: 0.450509\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:25 | INFO | Rank 0 | Train Epoch: 0 [172128/250314 (69%)]\tLoss: 0.890649\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:26 | INFO | Rank 0 | Train Epoch: 0 [172160/250314 (69%)]\tLoss: 0.720982\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:26 | INFO | Rank 0 | Train Epoch: 0 [172192/250314 (69%)]\tLoss: 0.703746\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:27 | INFO | Rank 0 | Train Epoch: 0 [172224/250314 (69%)]\tLoss: 0.525446\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:27 | INFO | Rank 0 | Train Epoch: 0 [172256/250314 (69%)]\tLoss: 0.497784\tData (t) 0.216\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:28 | INFO | Rank 0 | Train Epoch: 0 [172288/250314 (69%)]\tLoss: 1.080719\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:28 | INFO | Rank 0 | Train Epoch: 0 [172320/250314 (69%)]\tLoss: 0.785567\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:29 | INFO | Rank 0 | Train Epoch: 0 [172352/250314 (69%)]\tLoss: 0.263893\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:29 | INFO | Rank 0 | Train Epoch: 0 [172384/250314 (69%)]\tLoss: 0.427197\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:30 | INFO | Rank 0 | Train Epoch: 0 [172416/250314 (69%)]\tLoss: 0.604925\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:30 | INFO | Rank 0 | Train Epoch: 0 [172448/250314 (69%)]\tLoss: 0.447107\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:31 | INFO | Rank 0 | Train Epoch: 0 [172480/250314 (69%)]\tLoss: 0.736617\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:31 | INFO | Rank 0 | Train Epoch: 0 [172512/250314 (69%)]\tLoss: 0.839823\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:32 | INFO | Rank 0 | Train Epoch: 0 [172544/250314 (69%)]\tLoss: 0.642890\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:32 | INFO | Rank 0 | Train Epoch: 0 [172576/250314 (69%)]\tLoss: 0.555554\tData (t) 0.213\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:33 | INFO | Rank 0 | Train Epoch: 0 [172608/250314 (69%)]\tLoss: 0.936539\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:33 | INFO | Rank 0 | Train Epoch: 0 [172640/250314 (69%)]\tLoss: 0.880107\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:34 | INFO | Rank 0 | Train Epoch: 0 [172672/250314 (69%)]\tLoss: 0.989195\tData (t) 0.303\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:34 | INFO | Rank 0 | Train Epoch: 0 [172704/250314 (69%)]\tLoss: 0.531668\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:34 | INFO | Rank 0 | Train Epoch: 0 [172736/250314 (69%)]\tLoss: 0.537954\tData (t) 0.222\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:35 | INFO | Rank 0 | Train Epoch: 0 [172768/250314 (69%)]\tLoss: 0.475764\tData (t) 0.217\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:35 | INFO | Rank 0 | Train Epoch: 0 [172800/250314 (69%)]\tLoss: 0.884420\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:36 | INFO | Rank 0 | Train Epoch: 0 [172832/250314 (69%)]\tLoss: 0.983233\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:36 | INFO | Rank 0 | Train Epoch: 0 [172864/250314 (69%)]\tLoss: 0.670511\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:37 | INFO | Rank 0 | Train Epoch: 0 [172896/250314 (69%)]\tLoss: 0.940554\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:37 | INFO | Rank 0 | Train Epoch: 0 [172928/250314 (69%)]\tLoss: 0.737488\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:38 | INFO | Rank 0 | Train Epoch: 0 [172960/250314 (69%)]\tLoss: 0.738533\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:38 | INFO | Rank 0 | Train Epoch: 0 [172992/250314 (69%)]\tLoss: 0.812937\tData (t) 0.282\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:39 | INFO | Rank 0 | Train Epoch: 0 [173024/250314 (69%)]\tLoss: 0.729256\tData (t) 0.213\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:39 | INFO | Rank 0 | Train Epoch: 0 [173056/250314 (69%)]\tLoss: 0.410171\tData (t) 0.282\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:40 | INFO | Rank 0 | Train Epoch: 0 [173088/250314 (69%)]\tLoss: 0.679433\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:40 | INFO | Rank 0 | Train Epoch: 0 [173120/250314 (69%)]\tLoss: 0.594820\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:41 | INFO | Rank 0 | Train Epoch: 0 [173152/250314 (69%)]\tLoss: 0.832089\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:41 | INFO | Rank 0 | Train Epoch: 0 [173184/250314 (69%)]\tLoss: 0.507905\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:42 | INFO | Rank 0 | Train Epoch: 0 [173216/250314 (69%)]\tLoss: 0.643130\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:42 | INFO | Rank 0 | Train Epoch: 0 [173248/250314 (69%)]\tLoss: 0.552328\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:43 | INFO | Rank 0 | Train Epoch: 0 [173280/250314 (69%)]\tLoss: 0.701471\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:43 | INFO | Rank 0 | Train Epoch: 0 [173312/250314 (69%)]\tLoss: 0.776231\tData (t) 0.310\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:44 | INFO | Rank 0 | Train Epoch: 0 [173344/250314 (69%)]\tLoss: 0.687707\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:44 | INFO | Rank 0 | Train Epoch: 0 [173376/250314 (69%)]\tLoss: 0.546875\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:45 | INFO | Rank 0 | Train Epoch: 0 [173408/250314 (69%)]\tLoss: 0.645132\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:45 | INFO | Rank 0 | Train Epoch: 0 [173440/250314 (69%)]\tLoss: 0.584320\tData (t) 0.223\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:46 | INFO | Rank 0 | Train Epoch: 0 [173472/250314 (69%)]\tLoss: 0.656330\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:46 | INFO | Rank 0 | Train Epoch: 0 [173504/250314 (69%)]\tLoss: 0.804932\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:47 | INFO | Rank 0 | Train Epoch: 0 [173536/250314 (69%)]\tLoss: 0.546025\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:47 | INFO | Rank 0 | Train Epoch: 0 [173568/250314 (69%)]\tLoss: 0.922075\tData (t) 0.185\tBatch (t) 0.397\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:47 | INFO | Rank 0 | Train Epoch: 0 [173600/250314 (69%)]\tLoss: 0.776945\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:48 | INFO | Rank 0 | Train Epoch: 0 [173632/250314 (69%)]\tLoss: 0.450267\tData (t) 0.200\tBatch (t) 0.412\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:48 | INFO | Rank 0 | Train Epoch: 0 [173664/250314 (69%)]\tLoss: 0.956064\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:49 | INFO | Rank 0 | Train Epoch: 0 [173696/250314 (69%)]\tLoss: 0.600791\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:49 | INFO | Rank 0 | Train Epoch: 0 [173728/250314 (69%)]\tLoss: 0.437906\tData (t) 0.275\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:50 | INFO | Rank 0 | Train Epoch: 0 [173760/250314 (69%)]\tLoss: 0.663357\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:50 | INFO | Rank 0 | Train Epoch: 0 [173792/250314 (69%)]\tLoss: 0.532901\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:51 | INFO | Rank 0 | Train Epoch: 0 [173824/250314 (69%)]\tLoss: 0.638823\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:51 | INFO | Rank 0 | Train Epoch: 0 [173856/250314 (69%)]\tLoss: 1.055173\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:52 | INFO | Rank 0 | Train Epoch: 0 [173888/250314 (69%)]\tLoss: 0.567897\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:52 | INFO | Rank 0 | Train Epoch: 0 [173920/250314 (69%)]\tLoss: 0.842147\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:53 | INFO | Rank 0 | Train Epoch: 0 [173952/250314 (69%)]\tLoss: 0.405339\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:53 | INFO | Rank 0 | Train Epoch: 0 [173984/250314 (70%)]\tLoss: 0.513056\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:54 | INFO | Rank 0 | Train Epoch: 0 [174016/250314 (70%)]\tLoss: 0.498246\tData (t) 0.355\tBatch (t) 0.568\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:54 | INFO | Rank 0 | Train Epoch: 0 [174048/250314 (70%)]\tLoss: 0.938060\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:55 | INFO | Rank 0 | Train Epoch: 0 [174080/250314 (70%)]\tLoss: 0.731913\tData (t) 0.218\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:55 | INFO | Rank 0 | Train Epoch: 0 [174112/250314 (70%)]\tLoss: 0.771926\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:56 | INFO | Rank 0 | Train Epoch: 0 [174144/250314 (70%)]\tLoss: 1.175816\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.592\n",
      "2022-11-09,13:54:56 | INFO | Rank 0 | Train Epoch: 0 [174176/250314 (70%)]\tLoss: 0.850903\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:54:57 | INFO | Rank 0 | Train Epoch: 0 [174208/250314 (70%)]\tLoss: 0.757522\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:54:57 | INFO | Rank 0 | Train Epoch: 0 [174240/250314 (70%)]\tLoss: 0.862182\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:54:58 | INFO | Rank 0 | Train Epoch: 0 [174272/250314 (70%)]\tLoss: 0.521443\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:54:58 | INFO | Rank 0 | Train Epoch: 0 [174304/250314 (70%)]\tLoss: 0.707547\tData (t) 0.293\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:54:58 | INFO | Rank 0 | Train Epoch: 0 [174336/250314 (70%)]\tLoss: 0.444693\tData (t) 0.183\tBatch (t) 0.394\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:54:59 | INFO | Rank 0 | Train Epoch: 0 [174368/250314 (70%)]\tLoss: 0.661113\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:54:59 | INFO | Rank 0 | Train Epoch: 0 [174400/250314 (70%)]\tLoss: 0.573528\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:00 | INFO | Rank 0 | Train Epoch: 0 [174432/250314 (70%)]\tLoss: 0.776106\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:00 | INFO | Rank 0 | Train Epoch: 0 [174464/250314 (70%)]\tLoss: 0.576259\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:01 | INFO | Rank 0 | Train Epoch: 0 [174496/250314 (70%)]\tLoss: 0.897361\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:01 | INFO | Rank 0 | Train Epoch: 0 [174528/250314 (70%)]\tLoss: 0.692321\tData (t) 0.272\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:02 | INFO | Rank 0 | Train Epoch: 0 [174560/250314 (70%)]\tLoss: 0.564744\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:02 | INFO | Rank 0 | Train Epoch: 0 [174592/250314 (70%)]\tLoss: 0.469323\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:03 | INFO | Rank 0 | Train Epoch: 0 [174624/250314 (70%)]\tLoss: 0.736032\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:03 | INFO | Rank 0 | Train Epoch: 0 [174656/250314 (70%)]\tLoss: 0.796825\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:04 | INFO | Rank 0 | Train Epoch: 0 [174688/250314 (70%)]\tLoss: 1.006629\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:04 | INFO | Rank 0 | Train Epoch: 0 [174720/250314 (70%)]\tLoss: 0.632650\tData (t) 0.362\tBatch (t) 0.574\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:05 | INFO | Rank 0 | Train Epoch: 0 [174752/250314 (70%)]\tLoss: 0.821166\tData (t) 0.274\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:05 | INFO | Rank 0 | Train Epoch: 0 [174784/250314 (70%)]\tLoss: 0.753752\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:06 | INFO | Rank 0 | Train Epoch: 0 [174816/250314 (70%)]\tLoss: 0.455689\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:06 | INFO | Rank 0 | Train Epoch: 0 [174848/250314 (70%)]\tLoss: 0.558904\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:07 | INFO | Rank 0 | Train Epoch: 0 [174880/250314 (70%)]\tLoss: 0.619981\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:07 | INFO | Rank 0 | Train Epoch: 0 [174912/250314 (70%)]\tLoss: 0.730338\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:08 | INFO | Rank 0 | Train Epoch: 0 [174944/250314 (70%)]\tLoss: 0.290101\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:08 | INFO | Rank 0 | Train Epoch: 0 [174976/250314 (70%)]\tLoss: 0.602653\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:09 | INFO | Rank 0 | Train Epoch: 0 [175008/250314 (70%)]\tLoss: 0.572065\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:09 | INFO | Rank 0 | Train Epoch: 0 [175040/250314 (70%)]\tLoss: 0.459896\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:10 | INFO | Rank 0 | Train Epoch: 0 [175072/250314 (70%)]\tLoss: 0.658560\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:10 | INFO | Rank 0 | Train Epoch: 0 [175104/250314 (70%)]\tLoss: 0.666928\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:11 | INFO | Rank 0 | Train Epoch: 0 [175136/250314 (70%)]\tLoss: 0.725379\tData (t) 0.371\tBatch (t) 0.583\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:11 | INFO | Rank 0 | Train Epoch: 0 [175168/250314 (70%)]\tLoss: 0.715494\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:12 | INFO | Rank 0 | Train Epoch: 0 [175200/250314 (70%)]\tLoss: 0.826117\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:12 | INFO | Rank 0 | Train Epoch: 0 [175232/250314 (70%)]\tLoss: 0.600036\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:13 | INFO | Rank 0 | Train Epoch: 0 [175264/250314 (70%)]\tLoss: 0.936815\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:13 | INFO | Rank 0 | Train Epoch: 0 [175296/250314 (70%)]\tLoss: 0.544824\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:14 | INFO | Rank 0 | Train Epoch: 0 [175328/250314 (70%)]\tLoss: 0.778193\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:14 | INFO | Rank 0 | Train Epoch: 0 [175360/250314 (70%)]\tLoss: 0.507728\tData (t) 0.211\tBatch (t) 0.422\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:15 | INFO | Rank 0 | Train Epoch: 0 [175392/250314 (70%)]\tLoss: 0.806167\tData (t) 0.336\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:15 | INFO | Rank 0 | Train Epoch: 0 [175424/250314 (70%)]\tLoss: 0.587563\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:16 | INFO | Rank 0 | Train Epoch: 0 [175456/250314 (70%)]\tLoss: 0.429636\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:16 | INFO | Rank 0 | Train Epoch: 0 [175488/250314 (70%)]\tLoss: 0.435114\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:17 | INFO | Rank 0 | Train Epoch: 0 [175520/250314 (70%)]\tLoss: 0.586077\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:17 | INFO | Rank 0 | Train Epoch: 0 [175552/250314 (70%)]\tLoss: 0.494812\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:18 | INFO | Rank 0 | Train Epoch: 0 [175584/250314 (70%)]\tLoss: 0.664732\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:18 | INFO | Rank 0 | Train Epoch: 0 [175616/250314 (70%)]\tLoss: 0.910241\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:19 | INFO | Rank 0 | Train Epoch: 0 [175648/250314 (70%)]\tLoss: 0.603603\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:19 | INFO | Rank 0 | Train Epoch: 0 [175680/250314 (70%)]\tLoss: 0.736549\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:20 | INFO | Rank 0 | Train Epoch: 0 [175712/250314 (70%)]\tLoss: 0.513110\tData (t) 0.371\tBatch (t) 0.583\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:20 | INFO | Rank 0 | Train Epoch: 0 [175744/250314 (70%)]\tLoss: 0.869502\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:21 | INFO | Rank 0 | Train Epoch: 0 [175776/250314 (70%)]\tLoss: 0.825239\tData (t) 0.341\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:21 | INFO | Rank 0 | Train Epoch: 0 [175808/250314 (70%)]\tLoss: 0.696314\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:22 | INFO | Rank 0 | Train Epoch: 0 [175840/250314 (70%)]\tLoss: 0.404482\tData (t) 0.231\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:22 | INFO | Rank 0 | Train Epoch: 0 [175872/250314 (70%)]\tLoss: 0.416464\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:23 | INFO | Rank 0 | Train Epoch: 0 [175904/250314 (70%)]\tLoss: 0.600762\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:23 | INFO | Rank 0 | Train Epoch: 0 [175936/250314 (70%)]\tLoss: 0.609638\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:24 | INFO | Rank 0 | Train Epoch: 0 [175968/250314 (70%)]\tLoss: 0.571588\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:24 | INFO | Rank 0 | Train Epoch: 0 [176000/250314 (70%)]\tLoss: 0.529273\tData (t) 0.198\tBatch (t) 0.410\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:24 | INFO | Rank 0 | Train Epoch: 0 [176032/250314 (70%)]\tLoss: 0.460983\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:25 | INFO | Rank 0 | Train Epoch: 0 [176064/250314 (70%)]\tLoss: 0.706984\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:25 | INFO | Rank 0 | Train Epoch: 0 [176096/250314 (70%)]\tLoss: 0.531314\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:26 | INFO | Rank 0 | Train Epoch: 0 [176128/250314 (70%)]\tLoss: 0.885594\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:26 | INFO | Rank 0 | Train Epoch: 0 [176160/250314 (70%)]\tLoss: 0.939028\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:27 | INFO | Rank 0 | Train Epoch: 0 [176192/250314 (70%)]\tLoss: 0.892677\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:27 | INFO | Rank 0 | Train Epoch: 0 [176224/250314 (70%)]\tLoss: 0.734518\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:28 | INFO | Rank 0 | Train Epoch: 0 [176256/250314 (70%)]\tLoss: 0.691096\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:28 | INFO | Rank 0 | Train Epoch: 0 [176288/250314 (70%)]\tLoss: 0.767480\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:29 | INFO | Rank 0 | Train Epoch: 0 [176320/250314 (70%)]\tLoss: 1.081820\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:29 | INFO | Rank 0 | Train Epoch: 0 [176352/250314 (70%)]\tLoss: 0.368980\tData (t) 0.273\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:30 | INFO | Rank 0 | Train Epoch: 0 [176384/250314 (70%)]\tLoss: 0.761410\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:30 | INFO | Rank 0 | Train Epoch: 0 [176416/250314 (70%)]\tLoss: 0.589193\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:31 | INFO | Rank 0 | Train Epoch: 0 [176448/250314 (70%)]\tLoss: 0.824883\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:31 | INFO | Rank 0 | Train Epoch: 0 [176480/250314 (71%)]\tLoss: 0.669952\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:32 | INFO | Rank 0 | Train Epoch: 0 [176512/250314 (71%)]\tLoss: 0.944608\tData (t) 0.331\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:32 | INFO | Rank 0 | Train Epoch: 0 [176544/250314 (71%)]\tLoss: 0.564518\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:33 | INFO | Rank 0 | Train Epoch: 0 [176576/250314 (71%)]\tLoss: 0.478380\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:33 | INFO | Rank 0 | Train Epoch: 0 [176608/250314 (71%)]\tLoss: 0.460117\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:34 | INFO | Rank 0 | Train Epoch: 0 [176640/250314 (71%)]\tLoss: 0.522629\tData (t) 0.214\tBatch (t) 0.426\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:34 | INFO | Rank 0 | Train Epoch: 0 [176672/250314 (71%)]\tLoss: 0.328617\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:35 | INFO | Rank 0 | Train Epoch: 0 [176704/250314 (71%)]\tLoss: 0.479135\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:35 | INFO | Rank 0 | Train Epoch: 0 [176736/250314 (71%)]\tLoss: 1.038290\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:36 | INFO | Rank 0 | Train Epoch: 0 [176768/250314 (71%)]\tLoss: 0.663683\tData (t) 0.229\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:36 | INFO | Rank 0 | Train Epoch: 0 [176800/250314 (71%)]\tLoss: 0.867786\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:37 | INFO | Rank 0 | Train Epoch: 0 [176832/250314 (71%)]\tLoss: 0.631892\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:37 | INFO | Rank 0 | Train Epoch: 0 [176864/250314 (71%)]\tLoss: 0.561597\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:37 | INFO | Rank 0 | Train Epoch: 0 [176896/250314 (71%)]\tLoss: 0.551652\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:38 | INFO | Rank 0 | Train Epoch: 0 [176928/250314 (71%)]\tLoss: 0.639317\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:38 | INFO | Rank 0 | Train Epoch: 0 [176960/250314 (71%)]\tLoss: 0.606623\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:39 | INFO | Rank 0 | Train Epoch: 0 [176992/250314 (71%)]\tLoss: 0.549302\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:39 | INFO | Rank 0 | Train Epoch: 0 [177024/250314 (71%)]\tLoss: 0.589688\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:40 | INFO | Rank 0 | Train Epoch: 0 [177056/250314 (71%)]\tLoss: 0.576055\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:40 | INFO | Rank 0 | Train Epoch: 0 [177088/250314 (71%)]\tLoss: 0.473563\tData (t) 0.343\tBatch (t) 0.555\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:41 | INFO | Rank 0 | Train Epoch: 0 [177120/250314 (71%)]\tLoss: 0.718671\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:41 | INFO | Rank 0 | Train Epoch: 0 [177152/250314 (71%)]\tLoss: 0.714318\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:42 | INFO | Rank 0 | Train Epoch: 0 [177184/250314 (71%)]\tLoss: 0.481425\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:42 | INFO | Rank 0 | Train Epoch: 0 [177216/250314 (71%)]\tLoss: 0.694406\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:43 | INFO | Rank 0 | Train Epoch: 0 [177248/250314 (71%)]\tLoss: 0.593460\tData (t) 0.201\tBatch (t) 0.413\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:43 | INFO | Rank 0 | Train Epoch: 0 [177280/250314 (71%)]\tLoss: 0.662009\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:44 | INFO | Rank 0 | Train Epoch: 0 [177312/250314 (71%)]\tLoss: 0.643879\tData (t) 0.186\tBatch (t) 0.398\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:44 | INFO | Rank 0 | Train Epoch: 0 [177344/250314 (71%)]\tLoss: 0.466693\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:45 | INFO | Rank 0 | Train Epoch: 0 [177376/250314 (71%)]\tLoss: 0.579369\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:45 | INFO | Rank 0 | Train Epoch: 0 [177408/250314 (71%)]\tLoss: 0.616567\tData (t) 0.330\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:46 | INFO | Rank 0 | Train Epoch: 0 [177440/250314 (71%)]\tLoss: 0.774411\tData (t) 0.331\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:46 | INFO | Rank 0 | Train Epoch: 0 [177472/250314 (71%)]\tLoss: 0.941589\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:47 | INFO | Rank 0 | Train Epoch: 0 [177504/250314 (71%)]\tLoss: 0.499347\tData (t) 0.281\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:47 | INFO | Rank 0 | Train Epoch: 0 [177536/250314 (71%)]\tLoss: 0.506117\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:48 | INFO | Rank 0 | Train Epoch: 0 [177568/250314 (71%)]\tLoss: 0.492791\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:48 | INFO | Rank 0 | Train Epoch: 0 [177600/250314 (71%)]\tLoss: 0.448178\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:49 | INFO | Rank 0 | Train Epoch: 0 [177632/250314 (71%)]\tLoss: 1.163000\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:49 | INFO | Rank 0 | Train Epoch: 0 [177664/250314 (71%)]\tLoss: 0.866859\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:50 | INFO | Rank 0 | Train Epoch: 0 [177696/250314 (71%)]\tLoss: 0.470786\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:50 | INFO | Rank 0 | Train Epoch: 0 [177728/250314 (71%)]\tLoss: 0.356881\tData (t) 0.423\tBatch (t) 0.635\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:51 | INFO | Rank 0 | Train Epoch: 0 [177760/250314 (71%)]\tLoss: 0.615453\tData (t) 0.385\tBatch (t) 0.597\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:51 | INFO | Rank 0 | Train Epoch: 0 [177792/250314 (71%)]\tLoss: 0.448578\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:52 | INFO | Rank 0 | Train Epoch: 0 [177824/250314 (71%)]\tLoss: 0.834807\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:52 | INFO | Rank 0 | Train Epoch: 0 [177856/250314 (71%)]\tLoss: 0.566954\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:53 | INFO | Rank 0 | Train Epoch: 0 [177888/250314 (71%)]\tLoss: 0.420457\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:53 | INFO | Rank 0 | Train Epoch: 0 [177920/250314 (71%)]\tLoss: 0.657194\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:54 | INFO | Rank 0 | Train Epoch: 0 [177952/250314 (71%)]\tLoss: 0.766275\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:54 | INFO | Rank 0 | Train Epoch: 0 [177984/250314 (71%)]\tLoss: 0.420296\tData (t) 0.265\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:55 | INFO | Rank 0 | Train Epoch: 0 [178016/250314 (71%)]\tLoss: 0.609561\tData (t) 0.201\tBatch (t) 0.413\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:55 | INFO | Rank 0 | Train Epoch: 0 [178048/250314 (71%)]\tLoss: 0.673732\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:56 | INFO | Rank 0 | Train Epoch: 0 [178080/250314 (71%)]\tLoss: 0.532364\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:56 | INFO | Rank 0 | Train Epoch: 0 [178112/250314 (71%)]\tLoss: 0.467254\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:57 | INFO | Rank 0 | Train Epoch: 0 [178144/250314 (71%)]\tLoss: 0.473638\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:57 | INFO | Rank 0 | Train Epoch: 0 [178176/250314 (71%)]\tLoss: 0.674067\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:58 | INFO | Rank 0 | Train Epoch: 0 [178208/250314 (71%)]\tLoss: 0.556348\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:58 | INFO | Rank 0 | Train Epoch: 0 [178240/250314 (71%)]\tLoss: 0.580523\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:59 | INFO | Rank 0 | Train Epoch: 0 [178272/250314 (71%)]\tLoss: 0.979996\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:59 | INFO | Rank 0 | Train Epoch: 0 [178304/250314 (71%)]\tLoss: 0.650054\tData (t) 0.212\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:55:59 | INFO | Rank 0 | Train Epoch: 0 [178336/250314 (71%)]\tLoss: 0.566398\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:00 | INFO | Rank 0 | Train Epoch: 0 [178368/250314 (71%)]\tLoss: 0.531708\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:00 | INFO | Rank 0 | Train Epoch: 0 [178400/250314 (71%)]\tLoss: 1.026537\tData (t) 0.200\tBatch (t) 0.412\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:01 | INFO | Rank 0 | Train Epoch: 0 [178432/250314 (71%)]\tLoss: 1.234598\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:01 | INFO | Rank 0 | Train Epoch: 0 [178464/250314 (71%)]\tLoss: 0.501185\tData (t) 0.354\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:02 | INFO | Rank 0 | Train Epoch: 0 [178496/250314 (71%)]\tLoss: 0.709787\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:02 | INFO | Rank 0 | Train Epoch: 0 [178528/250314 (71%)]\tLoss: 0.994271\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:03 | INFO | Rank 0 | Train Epoch: 0 [178560/250314 (71%)]\tLoss: 0.667535\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:04 | INFO | Rank 0 | Train Epoch: 0 [178592/250314 (71%)]\tLoss: 0.412132\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:04 | INFO | Rank 0 | Train Epoch: 0 [178624/250314 (71%)]\tLoss: 0.701089\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:05 | INFO | Rank 0 | Train Epoch: 0 [178656/250314 (71%)]\tLoss: 0.412525\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:05 | INFO | Rank 0 | Train Epoch: 0 [178688/250314 (71%)]\tLoss: 0.755024\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:06 | INFO | Rank 0 | Train Epoch: 0 [178720/250314 (71%)]\tLoss: 0.618725\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:06 | INFO | Rank 0 | Train Epoch: 0 [178752/250314 (71%)]\tLoss: 0.657824\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:07 | INFO | Rank 0 | Train Epoch: 0 [178784/250314 (71%)]\tLoss: 0.785628\tData (t) 0.372\tBatch (t) 0.584\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:07 | INFO | Rank 0 | Train Epoch: 0 [178816/250314 (71%)]\tLoss: 0.709846\tData (t) 0.223\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:08 | INFO | Rank 0 | Train Epoch: 0 [178848/250314 (71%)]\tLoss: 0.601793\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:08 | INFO | Rank 0 | Train Epoch: 0 [178880/250314 (71%)]\tLoss: 0.564478\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:08 | INFO | Rank 0 | Train Epoch: 0 [178912/250314 (71%)]\tLoss: 0.503565\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:09 | INFO | Rank 0 | Train Epoch: 0 [178944/250314 (71%)]\tLoss: 0.867815\tData (t) 0.195\tBatch (t) 0.406\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:09 | INFO | Rank 0 | Train Epoch: 0 [178976/250314 (72%)]\tLoss: 1.191930\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:10 | INFO | Rank 0 | Train Epoch: 0 [179008/250314 (72%)]\tLoss: 0.476400\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:10 | INFO | Rank 0 | Train Epoch: 0 [179040/250314 (72%)]\tLoss: 0.745940\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:11 | INFO | Rank 0 | Train Epoch: 0 [179072/250314 (72%)]\tLoss: 0.647511\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:11 | INFO | Rank 0 | Train Epoch: 0 [179104/250314 (72%)]\tLoss: 0.381084\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:12 | INFO | Rank 0 | Train Epoch: 0 [179136/250314 (72%)]\tLoss: 0.772156\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:12 | INFO | Rank 0 | Train Epoch: 0 [179168/250314 (72%)]\tLoss: 0.560098\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:13 | INFO | Rank 0 | Train Epoch: 0 [179200/250314 (72%)]\tLoss: 0.779822\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:13 | INFO | Rank 0 | Train Epoch: 0 [179232/250314 (72%)]\tLoss: 0.554939\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:14 | INFO | Rank 0 | Train Epoch: 0 [179264/250314 (72%)]\tLoss: 0.436940\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:14 | INFO | Rank 0 | Train Epoch: 0 [179296/250314 (72%)]\tLoss: 0.813760\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:15 | INFO | Rank 0 | Train Epoch: 0 [179328/250314 (72%)]\tLoss: 0.982292\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:15 | INFO | Rank 0 | Train Epoch: 0 [179360/250314 (72%)]\tLoss: 0.593015\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:16 | INFO | Rank 0 | Train Epoch: 0 [179392/250314 (72%)]\tLoss: 0.870332\tData (t) 0.251\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:16 | INFO | Rank 0 | Train Epoch: 0 [179424/250314 (72%)]\tLoss: 0.503977\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:16 | INFO | Rank 0 | Train Epoch: 0 [179456/250314 (72%)]\tLoss: 0.864974\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:17 | INFO | Rank 0 | Train Epoch: 0 [179488/250314 (72%)]\tLoss: 0.751728\tData (t) 0.420\tBatch (t) 0.632\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:18 | INFO | Rank 0 | Train Epoch: 0 [179520/250314 (72%)]\tLoss: 0.642188\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:18 | INFO | Rank 0 | Train Epoch: 0 [179552/250314 (72%)]\tLoss: 0.659178\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:19 | INFO | Rank 0 | Train Epoch: 0 [179584/250314 (72%)]\tLoss: 0.627811\tData (t) 0.274\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:19 | INFO | Rank 0 | Train Epoch: 0 [179616/250314 (72%)]\tLoss: 0.380040\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:20 | INFO | Rank 0 | Train Epoch: 0 [179648/250314 (72%)]\tLoss: 0.760838\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:20 | INFO | Rank 0 | Train Epoch: 0 [179680/250314 (72%)]\tLoss: 0.493882\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:21 | INFO | Rank 0 | Train Epoch: 0 [179712/250314 (72%)]\tLoss: 0.437921\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:21 | INFO | Rank 0 | Train Epoch: 0 [179744/250314 (72%)]\tLoss: 0.719906\tData (t) 0.479\tBatch (t) 0.691\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:22 | INFO | Rank 0 | Train Epoch: 0 [179776/250314 (72%)]\tLoss: 0.640619\tData (t) 0.430\tBatch (t) 0.641\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:22 | INFO | Rank 0 | Train Epoch: 0 [179808/250314 (72%)]\tLoss: 0.629650\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:23 | INFO | Rank 0 | Train Epoch: 0 [179840/250314 (72%)]\tLoss: 0.751917\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:23 | INFO | Rank 0 | Train Epoch: 0 [179872/250314 (72%)]\tLoss: 0.762889\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:24 | INFO | Rank 0 | Train Epoch: 0 [179904/250314 (72%)]\tLoss: 0.313700\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:24 | INFO | Rank 0 | Train Epoch: 0 [179936/250314 (72%)]\tLoss: 0.919707\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:25 | INFO | Rank 0 | Train Epoch: 0 [179968/250314 (72%)]\tLoss: 0.874135\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:25 | INFO | Rank 0 | Train Epoch: 0 [180000/250314 (72%)]\tLoss: 0.762103\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:26 | INFO | Rank 0 | Train Epoch: 0 [180032/250314 (72%)]\tLoss: 1.285737\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:26 | INFO | Rank 0 | Train Epoch: 0 [180064/250314 (72%)]\tLoss: 0.434932\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:27 | INFO | Rank 0 | Train Epoch: 0 [180096/250314 (72%)]\tLoss: 0.692272\tData (t) 0.363\tBatch (t) 0.575\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:27 | INFO | Rank 0 | Train Epoch: 0 [180128/250314 (72%)]\tLoss: 0.869891\tData (t) 0.321\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:28 | INFO | Rank 0 | Train Epoch: 0 [180160/250314 (72%)]\tLoss: 0.681571\tData (t) 0.210\tBatch (t) 0.422\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:28 | INFO | Rank 0 | Train Epoch: 0 [180192/250314 (72%)]\tLoss: 1.303262\tData (t) 0.332\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:29 | INFO | Rank 0 | Train Epoch: 0 [180224/250314 (72%)]\tLoss: 0.703524\tData (t) 0.197\tBatch (t) 0.408\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:29 | INFO | Rank 0 | Train Epoch: 0 [180256/250314 (72%)]\tLoss: 0.773228\tData (t) 0.228\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:30 | INFO | Rank 0 | Train Epoch: 0 [180288/250314 (72%)]\tLoss: 0.467375\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:30 | INFO | Rank 0 | Train Epoch: 0 [180320/250314 (72%)]\tLoss: 0.642691\tData (t) 0.208\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:31 | INFO | Rank 0 | Train Epoch: 0 [180352/250314 (72%)]\tLoss: 0.845788\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:31 | INFO | Rank 0 | Train Epoch: 0 [180384/250314 (72%)]\tLoss: 0.630923\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:32 | INFO | Rank 0 | Train Epoch: 0 [180416/250314 (72%)]\tLoss: 0.575327\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:32 | INFO | Rank 0 | Train Epoch: 0 [180448/250314 (72%)]\tLoss: 0.698989\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:33 | INFO | Rank 0 | Train Epoch: 0 [180480/250314 (72%)]\tLoss: 0.302623\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:33 | INFO | Rank 0 | Train Epoch: 0 [180512/250314 (72%)]\tLoss: 0.443647\tData (t) 0.192\tBatch (t) 0.404\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:33 | INFO | Rank 0 | Train Epoch: 0 [180544/250314 (72%)]\tLoss: 0.655631\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:34 | INFO | Rank 0 | Train Epoch: 0 [180576/250314 (72%)]\tLoss: 0.609994\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:34 | INFO | Rank 0 | Train Epoch: 0 [180608/250314 (72%)]\tLoss: 0.970134\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:35 | INFO | Rank 0 | Train Epoch: 0 [180640/250314 (72%)]\tLoss: 0.576194\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:35 | INFO | Rank 0 | Train Epoch: 0 [180672/250314 (72%)]\tLoss: 0.616313\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:36 | INFO | Rank 0 | Train Epoch: 0 [180704/250314 (72%)]\tLoss: 0.443741\tData (t) 0.182\tBatch (t) 0.394\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:36 | INFO | Rank 0 | Train Epoch: 0 [180736/250314 (72%)]\tLoss: 0.253444\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:37 | INFO | Rank 0 | Train Epoch: 0 [180768/250314 (72%)]\tLoss: 0.572006\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:37 | INFO | Rank 0 | Train Epoch: 0 [180800/250314 (72%)]\tLoss: 0.540177\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:38 | INFO | Rank 0 | Train Epoch: 0 [180832/250314 (72%)]\tLoss: 0.586518\tData (t) 0.203\tBatch (t) 0.414\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:38 | INFO | Rank 0 | Train Epoch: 0 [180864/250314 (72%)]\tLoss: 0.642074\tData (t) 0.307\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:39 | INFO | Rank 0 | Train Epoch: 0 [180896/250314 (72%)]\tLoss: 0.976066\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:39 | INFO | Rank 0 | Train Epoch: 0 [180928/250314 (72%)]\tLoss: 1.199454\tData (t) 0.225\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:40 | INFO | Rank 0 | Train Epoch: 0 [180960/250314 (72%)]\tLoss: 0.914116\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:40 | INFO | Rank 0 | Train Epoch: 0 [180992/250314 (72%)]\tLoss: 0.752471\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:40 | INFO | Rank 0 | Train Epoch: 0 [181024/250314 (72%)]\tLoss: 0.663335\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:41 | INFO | Rank 0 | Train Epoch: 0 [181056/250314 (72%)]\tLoss: 0.909108\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:41 | INFO | Rank 0 | Train Epoch: 0 [181088/250314 (72%)]\tLoss: 0.663720\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:42 | INFO | Rank 0 | Train Epoch: 0 [181120/250314 (72%)]\tLoss: 0.832473\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:42 | INFO | Rank 0 | Train Epoch: 0 [181152/250314 (72%)]\tLoss: 0.780728\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:43 | INFO | Rank 0 | Train Epoch: 0 [181184/250314 (72%)]\tLoss: 0.448459\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:43 | INFO | Rank 0 | Train Epoch: 0 [181216/250314 (72%)]\tLoss: 0.246687\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:44 | INFO | Rank 0 | Train Epoch: 0 [181248/250314 (72%)]\tLoss: 1.030093\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:45 | INFO | Rank 0 | Train Epoch: 0 [181280/250314 (72%)]\tLoss: 0.919747\tData (t) 0.301\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:45 | INFO | Rank 0 | Train Epoch: 0 [181312/250314 (72%)]\tLoss: 0.744519\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:45 | INFO | Rank 0 | Train Epoch: 0 [181344/250314 (72%)]\tLoss: 0.538520\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:46 | INFO | Rank 0 | Train Epoch: 0 [181376/250314 (72%)]\tLoss: 0.986597\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:46 | INFO | Rank 0 | Train Epoch: 0 [181408/250314 (72%)]\tLoss: 0.469912\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:47 | INFO | Rank 0 | Train Epoch: 0 [181440/250314 (72%)]\tLoss: 0.510280\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:47 | INFO | Rank 0 | Train Epoch: 0 [181472/250314 (73%)]\tLoss: 0.410913\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:48 | INFO | Rank 0 | Train Epoch: 0 [181504/250314 (73%)]\tLoss: 0.332831\tData (t) 0.203\tBatch (t) 0.415\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:48 | INFO | Rank 0 | Train Epoch: 0 [181536/250314 (73%)]\tLoss: 0.821761\tData (t) 0.291\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:49 | INFO | Rank 0 | Train Epoch: 0 [181568/250314 (73%)]\tLoss: 0.689050\tData (t) 0.189\tBatch (t) 0.401\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:49 | INFO | Rank 0 | Train Epoch: 0 [181600/250314 (73%)]\tLoss: 1.139499\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:50 | INFO | Rank 0 | Train Epoch: 0 [181632/250314 (73%)]\tLoss: 0.915741\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:50 | INFO | Rank 0 | Train Epoch: 0 [181664/250314 (73%)]\tLoss: 0.795437\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:51 | INFO | Rank 0 | Train Epoch: 0 [181696/250314 (73%)]\tLoss: 1.014711\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:51 | INFO | Rank 0 | Train Epoch: 0 [181728/250314 (73%)]\tLoss: 0.709734\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:52 | INFO | Rank 0 | Train Epoch: 0 [181760/250314 (73%)]\tLoss: 0.550677\tData (t) 0.217\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:52 | INFO | Rank 0 | Train Epoch: 0 [181792/250314 (73%)]\tLoss: 0.808285\tData (t) 0.498\tBatch (t) 0.710\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:53 | INFO | Rank 0 | Train Epoch: 0 [181824/250314 (73%)]\tLoss: 0.653642\tData (t) 0.341\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:53 | INFO | Rank 0 | Train Epoch: 0 [181856/250314 (73%)]\tLoss: 0.815702\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:54 | INFO | Rank 0 | Train Epoch: 0 [181888/250314 (73%)]\tLoss: 0.768091\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:54 | INFO | Rank 0 | Train Epoch: 0 [181920/250314 (73%)]\tLoss: 0.642009\tData (t) 0.194\tBatch (t) 0.405\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:55 | INFO | Rank 0 | Train Epoch: 0 [181952/250314 (73%)]\tLoss: 0.739874\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:55 | INFO | Rank 0 | Train Epoch: 0 [181984/250314 (73%)]\tLoss: 1.001359\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:56 | INFO | Rank 0 | Train Epoch: 0 [182016/250314 (73%)]\tLoss: 0.652189\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:56 | INFO | Rank 0 | Train Epoch: 0 [182048/250314 (73%)]\tLoss: 0.898439\tData (t) 0.359\tBatch (t) 0.571\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:57 | INFO | Rank 0 | Train Epoch: 0 [182080/250314 (73%)]\tLoss: 0.377229\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:57 | INFO | Rank 0 | Train Epoch: 0 [182112/250314 (73%)]\tLoss: 0.567425\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:58 | INFO | Rank 0 | Train Epoch: 0 [182144/250314 (73%)]\tLoss: 0.775527\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:58 | INFO | Rank 0 | Train Epoch: 0 [182176/250314 (73%)]\tLoss: 0.693964\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:59 | INFO | Rank 0 | Train Epoch: 0 [182208/250314 (73%)]\tLoss: 0.836064\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:56:59 | INFO | Rank 0 | Train Epoch: 0 [182240/250314 (73%)]\tLoss: 0.773375\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:00 | INFO | Rank 0 | Train Epoch: 0 [182272/250314 (73%)]\tLoss: 0.611095\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:00 | INFO | Rank 0 | Train Epoch: 0 [182304/250314 (73%)]\tLoss: 0.479583\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:01 | INFO | Rank 0 | Train Epoch: 0 [182336/250314 (73%)]\tLoss: 0.454928\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:01 | INFO | Rank 0 | Train Epoch: 0 [182368/250314 (73%)]\tLoss: 0.775262\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:02 | INFO | Rank 0 | Train Epoch: 0 [182400/250314 (73%)]\tLoss: 0.593974\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:02 | INFO | Rank 0 | Train Epoch: 0 [182432/250314 (73%)]\tLoss: 1.019169\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:03 | INFO | Rank 0 | Train Epoch: 0 [182464/250314 (73%)]\tLoss: 0.745675\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:03 | INFO | Rank 0 | Train Epoch: 0 [182496/250314 (73%)]\tLoss: 0.636790\tData (t) 0.233\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:04 | INFO | Rank 0 | Train Epoch: 0 [182528/250314 (73%)]\tLoss: 0.769069\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:04 | INFO | Rank 0 | Train Epoch: 0 [182560/250314 (73%)]\tLoss: 0.681296\tData (t) 0.223\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:05 | INFO | Rank 0 | Train Epoch: 0 [182592/250314 (73%)]\tLoss: 0.450729\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:05 | INFO | Rank 0 | Train Epoch: 0 [182624/250314 (73%)]\tLoss: 0.501392\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:06 | INFO | Rank 0 | Train Epoch: 0 [182656/250314 (73%)]\tLoss: 0.499203\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:06 | INFO | Rank 0 | Train Epoch: 0 [182688/250314 (73%)]\tLoss: 0.747038\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:07 | INFO | Rank 0 | Train Epoch: 0 [182720/250314 (73%)]\tLoss: 0.473065\tData (t) 0.332\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:07 | INFO | Rank 0 | Train Epoch: 0 [182752/250314 (73%)]\tLoss: 0.725205\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:08 | INFO | Rank 0 | Train Epoch: 0 [182784/250314 (73%)]\tLoss: 0.363911\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:08 | INFO | Rank 0 | Train Epoch: 0 [182816/250314 (73%)]\tLoss: 1.268083\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:08 | INFO | Rank 0 | Train Epoch: 0 [182848/250314 (73%)]\tLoss: 0.404503\tData (t) 0.205\tBatch (t) 0.416\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:09 | INFO | Rank 0 | Train Epoch: 0 [182880/250314 (73%)]\tLoss: 0.949277\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:09 | INFO | Rank 0 | Train Epoch: 0 [182912/250314 (73%)]\tLoss: 0.273459\tData (t) 0.318\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:10 | INFO | Rank 0 | Train Epoch: 0 [182944/250314 (73%)]\tLoss: 0.472486\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:10 | INFO | Rank 0 | Train Epoch: 0 [182976/250314 (73%)]\tLoss: 0.427452\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:11 | INFO | Rank 0 | Train Epoch: 0 [183008/250314 (73%)]\tLoss: 0.699926\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:11 | INFO | Rank 0 | Train Epoch: 0 [183040/250314 (73%)]\tLoss: 0.606315\tData (t) 0.343\tBatch (t) 0.555\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:12 | INFO | Rank 0 | Train Epoch: 0 [183072/250314 (73%)]\tLoss: 0.799511\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:12 | INFO | Rank 0 | Train Epoch: 0 [183104/250314 (73%)]\tLoss: 0.447157\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:13 | INFO | Rank 0 | Train Epoch: 0 [183136/250314 (73%)]\tLoss: 0.983969\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:13 | INFO | Rank 0 | Train Epoch: 0 [183168/250314 (73%)]\tLoss: 0.446847\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:14 | INFO | Rank 0 | Train Epoch: 0 [183200/250314 (73%)]\tLoss: 0.572050\tData (t) 0.269\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:14 | INFO | Rank 0 | Train Epoch: 0 [183232/250314 (73%)]\tLoss: 0.699661\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:15 | INFO | Rank 0 | Train Epoch: 0 [183264/250314 (73%)]\tLoss: 1.152476\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:15 | INFO | Rank 0 | Train Epoch: 0 [183296/250314 (73%)]\tLoss: 0.674769\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:16 | INFO | Rank 0 | Train Epoch: 0 [183328/250314 (73%)]\tLoss: 0.855864\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:16 | INFO | Rank 0 | Train Epoch: 0 [183360/250314 (73%)]\tLoss: 0.474179\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:17 | INFO | Rank 0 | Train Epoch: 0 [183392/250314 (73%)]\tLoss: 0.455906\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:17 | INFO | Rank 0 | Train Epoch: 0 [183424/250314 (73%)]\tLoss: 0.442797\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:18 | INFO | Rank 0 | Train Epoch: 0 [183456/250314 (73%)]\tLoss: 0.304238\tData (t) 0.233\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:18 | INFO | Rank 0 | Train Epoch: 0 [183488/250314 (73%)]\tLoss: 0.768311\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:19 | INFO | Rank 0 | Train Epoch: 0 [183520/250314 (73%)]\tLoss: 0.687251\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:19 | INFO | Rank 0 | Train Epoch: 0 [183552/250314 (73%)]\tLoss: 0.670363\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:20 | INFO | Rank 0 | Train Epoch: 0 [183584/250314 (73%)]\tLoss: 0.510521\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:20 | INFO | Rank 0 | Train Epoch: 0 [183616/250314 (73%)]\tLoss: 0.833986\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:21 | INFO | Rank 0 | Train Epoch: 0 [183648/250314 (73%)]\tLoss: 0.483557\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:21 | INFO | Rank 0 | Train Epoch: 0 [183680/250314 (73%)]\tLoss: 0.642899\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:21 | INFO | Rank 0 | Train Epoch: 0 [183712/250314 (73%)]\tLoss: 0.736229\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:22 | INFO | Rank 0 | Train Epoch: 0 [183744/250314 (73%)]\tLoss: 0.425825\tData (t) 0.305\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:22 | INFO | Rank 0 | Train Epoch: 0 [183776/250314 (73%)]\tLoss: 0.617826\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:23 | INFO | Rank 0 | Train Epoch: 0 [183808/250314 (73%)]\tLoss: 0.535150\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:23 | INFO | Rank 0 | Train Epoch: 0 [183840/250314 (73%)]\tLoss: 1.245994\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:24 | INFO | Rank 0 | Train Epoch: 0 [183872/250314 (73%)]\tLoss: 0.729789\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:24 | INFO | Rank 0 | Train Epoch: 0 [183904/250314 (73%)]\tLoss: 0.764985\tData (t) 0.229\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:25 | INFO | Rank 0 | Train Epoch: 0 [183936/250314 (73%)]\tLoss: 0.752669\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:25 | INFO | Rank 0 | Train Epoch: 0 [183968/250314 (73%)]\tLoss: 0.423677\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:26 | INFO | Rank 0 | Train Epoch: 0 [184000/250314 (74%)]\tLoss: 1.022906\tData (t) 0.233\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:26 | INFO | Rank 0 | Train Epoch: 0 [184032/250314 (74%)]\tLoss: 0.842077\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:27 | INFO | Rank 0 | Train Epoch: 0 [184064/250314 (74%)]\tLoss: 0.497742\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:27 | INFO | Rank 0 | Train Epoch: 0 [184096/250314 (74%)]\tLoss: 0.626972\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:28 | INFO | Rank 0 | Train Epoch: 0 [184128/250314 (74%)]\tLoss: 0.524998\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:28 | INFO | Rank 0 | Train Epoch: 0 [184160/250314 (74%)]\tLoss: 0.650668\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:29 | INFO | Rank 0 | Train Epoch: 0 [184192/250314 (74%)]\tLoss: 0.672947\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:29 | INFO | Rank 0 | Train Epoch: 0 [184224/250314 (74%)]\tLoss: 1.161728\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:30 | INFO | Rank 0 | Train Epoch: 0 [184256/250314 (74%)]\tLoss: 0.965696\tData (t) 0.225\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:30 | INFO | Rank 0 | Train Epoch: 0 [184288/250314 (74%)]\tLoss: 0.668799\tData (t) 0.210\tBatch (t) 0.421\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:31 | INFO | Rank 0 | Train Epoch: 0 [184320/250314 (74%)]\tLoss: 0.816839\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:31 | INFO | Rank 0 | Train Epoch: 0 [184352/250314 (74%)]\tLoss: 0.535771\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:32 | INFO | Rank 0 | Train Epoch: 0 [184384/250314 (74%)]\tLoss: 0.367254\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:32 | INFO | Rank 0 | Train Epoch: 0 [184416/250314 (74%)]\tLoss: 0.826891\tData (t) 0.269\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:33 | INFO | Rank 0 | Train Epoch: 0 [184448/250314 (74%)]\tLoss: 0.282834\tData (t) 0.256\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:33 | INFO | Rank 0 | Train Epoch: 0 [184480/250314 (74%)]\tLoss: 0.590060\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:34 | INFO | Rank 0 | Train Epoch: 0 [184512/250314 (74%)]\tLoss: 0.885579\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:34 | INFO | Rank 0 | Train Epoch: 0 [184544/250314 (74%)]\tLoss: 1.070244\tData (t) 0.222\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:35 | INFO | Rank 0 | Train Epoch: 0 [184576/250314 (74%)]\tLoss: 0.976957\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:35 | INFO | Rank 0 | Train Epoch: 0 [184608/250314 (74%)]\tLoss: 0.598944\tData (t) 0.313\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:36 | INFO | Rank 0 | Train Epoch: 0 [184640/250314 (74%)]\tLoss: 0.994841\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:36 | INFO | Rank 0 | Train Epoch: 0 [184672/250314 (74%)]\tLoss: 0.787739\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:36 | INFO | Rank 0 | Train Epoch: 0 [184704/250314 (74%)]\tLoss: 0.728854\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:37 | INFO | Rank 0 | Train Epoch: 0 [184736/250314 (74%)]\tLoss: 0.668273\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:38 | INFO | Rank 0 | Train Epoch: 0 [184768/250314 (74%)]\tLoss: 0.690642\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:38 | INFO | Rank 0 | Train Epoch: 0 [184800/250314 (74%)]\tLoss: 0.627673\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:39 | INFO | Rank 0 | Train Epoch: 0 [184832/250314 (74%)]\tLoss: 0.687364\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:39 | INFO | Rank 0 | Train Epoch: 0 [184864/250314 (74%)]\tLoss: 0.413243\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:40 | INFO | Rank 0 | Train Epoch: 0 [184896/250314 (74%)]\tLoss: 0.496129\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:40 | INFO | Rank 0 | Train Epoch: 0 [184928/250314 (74%)]\tLoss: 0.581281\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:41 | INFO | Rank 0 | Train Epoch: 0 [184960/250314 (74%)]\tLoss: 0.722801\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:41 | INFO | Rank 0 | Train Epoch: 0 [184992/250314 (74%)]\tLoss: 0.673851\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:42 | INFO | Rank 0 | Train Epoch: 0 [185024/250314 (74%)]\tLoss: 1.068693\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:42 | INFO | Rank 0 | Train Epoch: 0 [185056/250314 (74%)]\tLoss: 0.513879\tData (t) 0.175\tBatch (t) 0.387\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:42 | INFO | Rank 0 | Train Epoch: 0 [185088/250314 (74%)]\tLoss: 0.984857\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:43 | INFO | Rank 0 | Train Epoch: 0 [185120/250314 (74%)]\tLoss: 0.896107\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:43 | INFO | Rank 0 | Train Epoch: 0 [185152/250314 (74%)]\tLoss: 0.728384\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:44 | INFO | Rank 0 | Train Epoch: 0 [185184/250314 (74%)]\tLoss: 0.458685\tData (t) 0.341\tBatch (t) 0.553\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:44 | INFO | Rank 0 | Train Epoch: 0 [185216/250314 (74%)]\tLoss: 0.558526\tData (t) 0.253\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:45 | INFO | Rank 0 | Train Epoch: 0 [185248/250314 (74%)]\tLoss: 0.698625\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:45 | INFO | Rank 0 | Train Epoch: 0 [185280/250314 (74%)]\tLoss: 0.705799\tData (t) 0.205\tBatch (t) 0.416\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:46 | INFO | Rank 0 | Train Epoch: 0 [185312/250314 (74%)]\tLoss: 0.683768\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:46 | INFO | Rank 0 | Train Epoch: 0 [185344/250314 (74%)]\tLoss: 0.615393\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:47 | INFO | Rank 0 | Train Epoch: 0 [185376/250314 (74%)]\tLoss: 0.664432\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:47 | INFO | Rank 0 | Train Epoch: 0 [185408/250314 (74%)]\tLoss: 0.912183\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:48 | INFO | Rank 0 | Train Epoch: 0 [185440/250314 (74%)]\tLoss: 0.623926\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:48 | INFO | Rank 0 | Train Epoch: 0 [185472/250314 (74%)]\tLoss: 0.910591\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:49 | INFO | Rank 0 | Train Epoch: 0 [185504/250314 (74%)]\tLoss: 0.678195\tData (t) 0.287\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:49 | INFO | Rank 0 | Train Epoch: 0 [185536/250314 (74%)]\tLoss: 0.531182\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:50 | INFO | Rank 0 | Train Epoch: 0 [185568/250314 (74%)]\tLoss: 0.419749\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:50 | INFO | Rank 0 | Train Epoch: 0 [185600/250314 (74%)]\tLoss: 0.532180\tData (t) 0.219\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:50 | INFO | Rank 0 | Train Epoch: 0 [185632/250314 (74%)]\tLoss: 0.777086\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:51 | INFO | Rank 0 | Train Epoch: 0 [185664/250314 (74%)]\tLoss: 0.679677\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:51 | INFO | Rank 0 | Train Epoch: 0 [185696/250314 (74%)]\tLoss: 0.393330\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:52 | INFO | Rank 0 | Train Epoch: 0 [185728/250314 (74%)]\tLoss: 0.619772\tData (t) 0.187\tBatch (t) 0.399\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:52 | INFO | Rank 0 | Train Epoch: 0 [185760/250314 (74%)]\tLoss: 0.488328\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:53 | INFO | Rank 0 | Train Epoch: 0 [185792/250314 (74%)]\tLoss: 0.942783\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:53 | INFO | Rank 0 | Train Epoch: 0 [185824/250314 (74%)]\tLoss: 0.633904\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:54 | INFO | Rank 0 | Train Epoch: 0 [185856/250314 (74%)]\tLoss: 0.535412\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:54 | INFO | Rank 0 | Train Epoch: 0 [185888/250314 (74%)]\tLoss: 0.889953\tData (t) 0.296\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:55 | INFO | Rank 0 | Train Epoch: 0 [185920/250314 (74%)]\tLoss: 0.795099\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:55 | INFO | Rank 0 | Train Epoch: 0 [185952/250314 (74%)]\tLoss: 1.428340\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:56 | INFO | Rank 0 | Train Epoch: 0 [185984/250314 (74%)]\tLoss: 0.858624\tData (t) 0.293\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:56 | INFO | Rank 0 | Train Epoch: 0 [186016/250314 (74%)]\tLoss: 0.495171\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:57 | INFO | Rank 0 | Train Epoch: 0 [186048/250314 (74%)]\tLoss: 0.701872\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:57 | INFO | Rank 0 | Train Epoch: 0 [186080/250314 (74%)]\tLoss: 0.264272\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:58 | INFO | Rank 0 | Train Epoch: 0 [186112/250314 (74%)]\tLoss: 1.013014\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:58 | INFO | Rank 0 | Train Epoch: 0 [186144/250314 (74%)]\tLoss: 0.528478\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:59 | INFO | Rank 0 | Train Epoch: 0 [186176/250314 (74%)]\tLoss: 0.325379\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:57:59 | INFO | Rank 0 | Train Epoch: 0 [186208/250314 (74%)]\tLoss: 0.428444\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:00 | INFO | Rank 0 | Train Epoch: 0 [186240/250314 (74%)]\tLoss: 0.741346\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:00 | INFO | Rank 0 | Train Epoch: 0 [186272/250314 (74%)]\tLoss: 0.703147\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:01 | INFO | Rank 0 | Train Epoch: 0 [186304/250314 (74%)]\tLoss: 0.767912\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:01 | INFO | Rank 0 | Train Epoch: 0 [186336/250314 (74%)]\tLoss: 0.992591\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:02 | INFO | Rank 0 | Train Epoch: 0 [186368/250314 (74%)]\tLoss: 0.591416\tData (t) 0.284\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:02 | INFO | Rank 0 | Train Epoch: 0 [186400/250314 (74%)]\tLoss: 0.584151\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:03 | INFO | Rank 0 | Train Epoch: 0 [186432/250314 (74%)]\tLoss: 0.349574\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:03 | INFO | Rank 0 | Train Epoch: 0 [186464/250314 (74%)]\tLoss: 0.907624\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:04 | INFO | Rank 0 | Train Epoch: 0 [186496/250314 (75%)]\tLoss: 0.761003\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:04 | INFO | Rank 0 | Train Epoch: 0 [186528/250314 (75%)]\tLoss: 0.392703\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:05 | INFO | Rank 0 | Train Epoch: 0 [186560/250314 (75%)]\tLoss: 0.553421\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:05 | INFO | Rank 0 | Train Epoch: 0 [186592/250314 (75%)]\tLoss: 0.557731\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:06 | INFO | Rank 0 | Train Epoch: 0 [186624/250314 (75%)]\tLoss: 0.588100\tData (t) 0.356\tBatch (t) 0.568\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:06 | INFO | Rank 0 | Train Epoch: 0 [186656/250314 (75%)]\tLoss: 0.903949\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:07 | INFO | Rank 0 | Train Epoch: 0 [186688/250314 (75%)]\tLoss: 0.406642\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:07 | INFO | Rank 0 | Train Epoch: 0 [186720/250314 (75%)]\tLoss: 0.793769\tData (t) 0.349\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:08 | INFO | Rank 0 | Train Epoch: 0 [186752/250314 (75%)]\tLoss: 0.776261\tData (t) 0.225\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:08 | INFO | Rank 0 | Train Epoch: 0 [186784/250314 (75%)]\tLoss: 0.856961\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:09 | INFO | Rank 0 | Train Epoch: 0 [186816/250314 (75%)]\tLoss: 0.636441\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:09 | INFO | Rank 0 | Train Epoch: 0 [186848/250314 (75%)]\tLoss: 0.676738\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:10 | INFO | Rank 0 | Train Epoch: 0 [186880/250314 (75%)]\tLoss: 0.625774\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:10 | INFO | Rank 0 | Train Epoch: 0 [186912/250314 (75%)]\tLoss: 0.549421\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:11 | INFO | Rank 0 | Train Epoch: 0 [186944/250314 (75%)]\tLoss: 0.734382\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:11 | INFO | Rank 0 | Train Epoch: 0 [186976/250314 (75%)]\tLoss: 0.856016\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:12 | INFO | Rank 0 | Train Epoch: 0 [187008/250314 (75%)]\tLoss: 0.661913\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:12 | INFO | Rank 0 | Train Epoch: 0 [187040/250314 (75%)]\tLoss: 1.153126\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:13 | INFO | Rank 0 | Train Epoch: 0 [187072/250314 (75%)]\tLoss: 0.473065\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:13 | INFO | Rank 0 | Train Epoch: 0 [187104/250314 (75%)]\tLoss: 0.726837\tData (t) 0.219\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:13 | INFO | Rank 0 | Train Epoch: 0 [187136/250314 (75%)]\tLoss: 0.464404\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:14 | INFO | Rank 0 | Train Epoch: 0 [187168/250314 (75%)]\tLoss: 0.417029\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:14 | INFO | Rank 0 | Train Epoch: 0 [187200/250314 (75%)]\tLoss: 0.536265\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:15 | INFO | Rank 0 | Train Epoch: 0 [187232/250314 (75%)]\tLoss: 0.595506\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:15 | INFO | Rank 0 | Train Epoch: 0 [187264/250314 (75%)]\tLoss: 0.329504\tData (t) 0.226\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:16 | INFO | Rank 0 | Train Epoch: 0 [187296/250314 (75%)]\tLoss: 0.607852\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:16 | INFO | Rank 0 | Train Epoch: 0 [187328/250314 (75%)]\tLoss: 0.629021\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:17 | INFO | Rank 0 | Train Epoch: 0 [187360/250314 (75%)]\tLoss: 0.916915\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:17 | INFO | Rank 0 | Train Epoch: 0 [187392/250314 (75%)]\tLoss: 0.719284\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:18 | INFO | Rank 0 | Train Epoch: 0 [187424/250314 (75%)]\tLoss: 0.854985\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:18 | INFO | Rank 0 | Train Epoch: 0 [187456/250314 (75%)]\tLoss: 1.202404\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:19 | INFO | Rank 0 | Train Epoch: 0 [187488/250314 (75%)]\tLoss: 0.646847\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:19 | INFO | Rank 0 | Train Epoch: 0 [187520/250314 (75%)]\tLoss: 0.865352\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:20 | INFO | Rank 0 | Train Epoch: 0 [187552/250314 (75%)]\tLoss: 0.424118\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:20 | INFO | Rank 0 | Train Epoch: 0 [187584/250314 (75%)]\tLoss: 0.685985\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:21 | INFO | Rank 0 | Train Epoch: 0 [187616/250314 (75%)]\tLoss: 0.456416\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:21 | INFO | Rank 0 | Train Epoch: 0 [187648/250314 (75%)]\tLoss: 0.684420\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:22 | INFO | Rank 0 | Train Epoch: 0 [187680/250314 (75%)]\tLoss: 0.819855\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:22 | INFO | Rank 0 | Train Epoch: 0 [187712/250314 (75%)]\tLoss: 0.635630\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:23 | INFO | Rank 0 | Train Epoch: 0 [187744/250314 (75%)]\tLoss: 0.299310\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:23 | INFO | Rank 0 | Train Epoch: 0 [187776/250314 (75%)]\tLoss: 0.365061\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:24 | INFO | Rank 0 | Train Epoch: 0 [187808/250314 (75%)]\tLoss: 0.892216\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:24 | INFO | Rank 0 | Train Epoch: 0 [187840/250314 (75%)]\tLoss: 0.512311\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:25 | INFO | Rank 0 | Train Epoch: 0 [187872/250314 (75%)]\tLoss: 0.656164\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:25 | INFO | Rank 0 | Train Epoch: 0 [187904/250314 (75%)]\tLoss: 0.518941\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:26 | INFO | Rank 0 | Train Epoch: 0 [187936/250314 (75%)]\tLoss: 0.724583\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:26 | INFO | Rank 0 | Train Epoch: 0 [187968/250314 (75%)]\tLoss: 0.535314\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:27 | INFO | Rank 0 | Train Epoch: 0 [188000/250314 (75%)]\tLoss: 0.873575\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:27 | INFO | Rank 0 | Train Epoch: 0 [188032/250314 (75%)]\tLoss: 0.861374\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:28 | INFO | Rank 0 | Train Epoch: 0 [188064/250314 (75%)]\tLoss: 0.797963\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:28 | INFO | Rank 0 | Train Epoch: 0 [188096/250314 (75%)]\tLoss: 0.948732\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:29 | INFO | Rank 0 | Train Epoch: 0 [188128/250314 (75%)]\tLoss: 0.709034\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:29 | INFO | Rank 0 | Train Epoch: 0 [188160/250314 (75%)]\tLoss: 0.524639\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:29 | INFO | Rank 0 | Train Epoch: 0 [188192/250314 (75%)]\tLoss: 0.490059\tData (t) 0.233\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:30 | INFO | Rank 0 | Train Epoch: 0 [188224/250314 (75%)]\tLoss: 0.701750\tData (t) 0.475\tBatch (t) 0.687\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:31 | INFO | Rank 0 | Train Epoch: 0 [188256/250314 (75%)]\tLoss: 0.909057\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:31 | INFO | Rank 0 | Train Epoch: 0 [188288/250314 (75%)]\tLoss: 0.623582\tData (t) 0.399\tBatch (t) 0.611\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:32 | INFO | Rank 0 | Train Epoch: 0 [188320/250314 (75%)]\tLoss: 0.576540\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:32 | INFO | Rank 0 | Train Epoch: 0 [188352/250314 (75%)]\tLoss: 0.880716\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:33 | INFO | Rank 0 | Train Epoch: 0 [188384/250314 (75%)]\tLoss: 0.721243\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:33 | INFO | Rank 0 | Train Epoch: 0 [188416/250314 (75%)]\tLoss: 0.718664\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:34 | INFO | Rank 0 | Train Epoch: 0 [188448/250314 (75%)]\tLoss: 0.727439\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:34 | INFO | Rank 0 | Train Epoch: 0 [188480/250314 (75%)]\tLoss: 0.652720\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:35 | INFO | Rank 0 | Train Epoch: 0 [188512/250314 (75%)]\tLoss: 0.653512\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:35 | INFO | Rank 0 | Train Epoch: 0 [188544/250314 (75%)]\tLoss: 0.609934\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:36 | INFO | Rank 0 | Train Epoch: 0 [188576/250314 (75%)]\tLoss: 0.501216\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:36 | INFO | Rank 0 | Train Epoch: 0 [188608/250314 (75%)]\tLoss: 0.511412\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:37 | INFO | Rank 0 | Train Epoch: 0 [188640/250314 (75%)]\tLoss: 0.331374\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:37 | INFO | Rank 0 | Train Epoch: 0 [188672/250314 (75%)]\tLoss: 0.547127\tData (t) 0.231\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:38 | INFO | Rank 0 | Train Epoch: 0 [188704/250314 (75%)]\tLoss: 0.661536\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:38 | INFO | Rank 0 | Train Epoch: 0 [188736/250314 (75%)]\tLoss: 1.042527\tData (t) 0.330\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:39 | INFO | Rank 0 | Train Epoch: 0 [188768/250314 (75%)]\tLoss: 0.543207\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:39 | INFO | Rank 0 | Train Epoch: 0 [188800/250314 (75%)]\tLoss: 0.533672\tData (t) 0.222\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:40 | INFO | Rank 0 | Train Epoch: 0 [188832/250314 (75%)]\tLoss: 0.607949\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:40 | INFO | Rank 0 | Train Epoch: 0 [188864/250314 (75%)]\tLoss: 0.862520\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:41 | INFO | Rank 0 | Train Epoch: 0 [188896/250314 (75%)]\tLoss: 0.554511\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:41 | INFO | Rank 0 | Train Epoch: 0 [188928/250314 (75%)]\tLoss: 1.085275\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:42 | INFO | Rank 0 | Train Epoch: 0 [188960/250314 (75%)]\tLoss: 0.636685\tData (t) 0.423\tBatch (t) 0.634\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:42 | INFO | Rank 0 | Train Epoch: 0 [188992/250314 (76%)]\tLoss: 0.631779\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:43 | INFO | Rank 0 | Train Epoch: 0 [189024/250314 (76%)]\tLoss: 0.377248\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:43 | INFO | Rank 0 | Train Epoch: 0 [189056/250314 (76%)]\tLoss: 0.692266\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:44 | INFO | Rank 0 | Train Epoch: 0 [189088/250314 (76%)]\tLoss: 0.810374\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:44 | INFO | Rank 0 | Train Epoch: 0 [189120/250314 (76%)]\tLoss: 0.727673\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:45 | INFO | Rank 0 | Train Epoch: 0 [189152/250314 (76%)]\tLoss: 0.561226\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:45 | INFO | Rank 0 | Train Epoch: 0 [189184/250314 (76%)]\tLoss: 0.598073\tData (t) 0.286\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:46 | INFO | Rank 0 | Train Epoch: 0 [189216/250314 (76%)]\tLoss: 0.521104\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:46 | INFO | Rank 0 | Train Epoch: 0 [189248/250314 (76%)]\tLoss: 0.719227\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:47 | INFO | Rank 0 | Train Epoch: 0 [189280/250314 (76%)]\tLoss: 0.562972\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:47 | INFO | Rank 0 | Train Epoch: 0 [189312/250314 (76%)]\tLoss: 0.712652\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:48 | INFO | Rank 0 | Train Epoch: 0 [189344/250314 (76%)]\tLoss: 0.880998\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:48 | INFO | Rank 0 | Train Epoch: 0 [189376/250314 (76%)]\tLoss: 0.552858\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:49 | INFO | Rank 0 | Train Epoch: 0 [189408/250314 (76%)]\tLoss: 0.765538\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:49 | INFO | Rank 0 | Train Epoch: 0 [189440/250314 (76%)]\tLoss: 0.336111\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:50 | INFO | Rank 0 | Train Epoch: 0 [189472/250314 (76%)]\tLoss: 0.264064\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:50 | INFO | Rank 0 | Train Epoch: 0 [189504/250314 (76%)]\tLoss: 0.941124\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:50 | INFO | Rank 0 | Train Epoch: 0 [189536/250314 (76%)]\tLoss: 0.540717\tData (t) 0.208\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:51 | INFO | Rank 0 | Train Epoch: 0 [189568/250314 (76%)]\tLoss: 0.651671\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:51 | INFO | Rank 0 | Train Epoch: 0 [189600/250314 (76%)]\tLoss: 0.391726\tData (t) 0.341\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:52 | INFO | Rank 0 | Train Epoch: 0 [189632/250314 (76%)]\tLoss: 1.021562\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:53 | INFO | Rank 0 | Train Epoch: 0 [189664/250314 (76%)]\tLoss: 0.591711\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:53 | INFO | Rank 0 | Train Epoch: 0 [189696/250314 (76%)]\tLoss: 0.630428\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:53 | INFO | Rank 0 | Train Epoch: 0 [189728/250314 (76%)]\tLoss: 0.507829\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:54 | INFO | Rank 0 | Train Epoch: 0 [189760/250314 (76%)]\tLoss: 0.722866\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:54 | INFO | Rank 0 | Train Epoch: 0 [189792/250314 (76%)]\tLoss: 0.715156\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:55 | INFO | Rank 0 | Train Epoch: 0 [189824/250314 (76%)]\tLoss: 0.631246\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:55 | INFO | Rank 0 | Train Epoch: 0 [189856/250314 (76%)]\tLoss: 0.582489\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:56 | INFO | Rank 0 | Train Epoch: 0 [189888/250314 (76%)]\tLoss: 0.688147\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:56 | INFO | Rank 0 | Train Epoch: 0 [189920/250314 (76%)]\tLoss: 0.584595\tData (t) 0.253\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:57 | INFO | Rank 0 | Train Epoch: 0 [189952/250314 (76%)]\tLoss: 0.974360\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:57 | INFO | Rank 0 | Train Epoch: 0 [189984/250314 (76%)]\tLoss: 0.623884\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:58 | INFO | Rank 0 | Train Epoch: 0 [190016/250314 (76%)]\tLoss: 0.726547\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:58 | INFO | Rank 0 | Train Epoch: 0 [190048/250314 (76%)]\tLoss: 0.499357\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:59 | INFO | Rank 0 | Train Epoch: 0 [190080/250314 (76%)]\tLoss: 0.847126\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:58:59 | INFO | Rank 0 | Train Epoch: 0 [190112/250314 (76%)]\tLoss: 0.325381\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:00 | INFO | Rank 0 | Train Epoch: 0 [190144/250314 (76%)]\tLoss: 0.776282\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:00 | INFO | Rank 0 | Train Epoch: 0 [190176/250314 (76%)]\tLoss: 0.794316\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:01 | INFO | Rank 0 | Train Epoch: 0 [190208/250314 (76%)]\tLoss: 0.450089\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:01 | INFO | Rank 0 | Train Epoch: 0 [190240/250314 (76%)]\tLoss: 0.469038\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:02 | INFO | Rank 0 | Train Epoch: 0 [190272/250314 (76%)]\tLoss: 0.768224\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:02 | INFO | Rank 0 | Train Epoch: 0 [190304/250314 (76%)]\tLoss: 0.613998\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:03 | INFO | Rank 0 | Train Epoch: 0 [190336/250314 (76%)]\tLoss: 0.882214\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:03 | INFO | Rank 0 | Train Epoch: 0 [190368/250314 (76%)]\tLoss: 0.562008\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:04 | INFO | Rank 0 | Train Epoch: 0 [190400/250314 (76%)]\tLoss: 0.574625\tData (t) 0.220\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:04 | INFO | Rank 0 | Train Epoch: 0 [190432/250314 (76%)]\tLoss: 0.605286\tData (t) 0.260\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:05 | INFO | Rank 0 | Train Epoch: 0 [190464/250314 (76%)]\tLoss: 0.345789\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:05 | INFO | Rank 0 | Train Epoch: 0 [190496/250314 (76%)]\tLoss: 0.265077\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:06 | INFO | Rank 0 | Train Epoch: 0 [190528/250314 (76%)]\tLoss: 0.506177\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:06 | INFO | Rank 0 | Train Epoch: 0 [190560/250314 (76%)]\tLoss: 0.734040\tData (t) 0.447\tBatch (t) 0.659\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:07 | INFO | Rank 0 | Train Epoch: 0 [190592/250314 (76%)]\tLoss: 0.454173\tData (t) 0.364\tBatch (t) 0.576\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:07 | INFO | Rank 0 | Train Epoch: 0 [190624/250314 (76%)]\tLoss: 0.821674\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:08 | INFO | Rank 0 | Train Epoch: 0 [190656/250314 (76%)]\tLoss: 0.530597\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:08 | INFO | Rank 0 | Train Epoch: 0 [190688/250314 (76%)]\tLoss: 0.562033\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:09 | INFO | Rank 0 | Train Epoch: 0 [190720/250314 (76%)]\tLoss: 0.730506\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:09 | INFO | Rank 0 | Train Epoch: 0 [190752/250314 (76%)]\tLoss: 0.698031\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:10 | INFO | Rank 0 | Train Epoch: 0 [190784/250314 (76%)]\tLoss: 0.412863\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:10 | INFO | Rank 0 | Train Epoch: 0 [190816/250314 (76%)]\tLoss: 1.176927\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:11 | INFO | Rank 0 | Train Epoch: 0 [190848/250314 (76%)]\tLoss: 0.719296\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:11 | INFO | Rank 0 | Train Epoch: 0 [190880/250314 (76%)]\tLoss: 0.791213\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:12 | INFO | Rank 0 | Train Epoch: 0 [190912/250314 (76%)]\tLoss: 0.656754\tData (t) 0.229\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:12 | INFO | Rank 0 | Train Epoch: 0 [190944/250314 (76%)]\tLoss: 0.306090\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:13 | INFO | Rank 0 | Train Epoch: 0 [190976/250314 (76%)]\tLoss: 0.585089\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:13 | INFO | Rank 0 | Train Epoch: 0 [191008/250314 (76%)]\tLoss: 0.579568\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:14 | INFO | Rank 0 | Train Epoch: 0 [191040/250314 (76%)]\tLoss: 0.490263\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:14 | INFO | Rank 0 | Train Epoch: 0 [191072/250314 (76%)]\tLoss: 0.561090\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:15 | INFO | Rank 0 | Train Epoch: 0 [191104/250314 (76%)]\tLoss: 0.917565\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:15 | INFO | Rank 0 | Train Epoch: 0 [191136/250314 (76%)]\tLoss: 0.663031\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:15 | INFO | Rank 0 | Train Epoch: 0 [191168/250314 (76%)]\tLoss: 0.255315\tData (t) 0.222\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:16 | INFO | Rank 0 | Train Epoch: 0 [191200/250314 (76%)]\tLoss: 0.539030\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:16 | INFO | Rank 0 | Train Epoch: 0 [191232/250314 (76%)]\tLoss: 0.769188\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:17 | INFO | Rank 0 | Train Epoch: 0 [191264/250314 (76%)]\tLoss: 0.694540\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:17 | INFO | Rank 0 | Train Epoch: 0 [191296/250314 (76%)]\tLoss: 0.691650\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:18 | INFO | Rank 0 | Train Epoch: 0 [191328/250314 (76%)]\tLoss: 0.559376\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:18 | INFO | Rank 0 | Train Epoch: 0 [191360/250314 (76%)]\tLoss: 0.375715\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:19 | INFO | Rank 0 | Train Epoch: 0 [191392/250314 (76%)]\tLoss: 0.471207\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:19 | INFO | Rank 0 | Train Epoch: 0 [191424/250314 (76%)]\tLoss: 0.718364\tData (t) 0.272\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:20 | INFO | Rank 0 | Train Epoch: 0 [191456/250314 (76%)]\tLoss: 0.419477\tData (t) 0.262\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:20 | INFO | Rank 0 | Train Epoch: 0 [191488/250314 (77%)]\tLoss: 0.515731\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:21 | INFO | Rank 0 | Train Epoch: 0 [191520/250314 (77%)]\tLoss: 0.751821\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:21 | INFO | Rank 0 | Train Epoch: 0 [191552/250314 (77%)]\tLoss: 0.580664\tData (t) 0.281\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:22 | INFO | Rank 0 | Train Epoch: 0 [191584/250314 (77%)]\tLoss: 0.361674\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:22 | INFO | Rank 0 | Train Epoch: 0 [191616/250314 (77%)]\tLoss: 0.683718\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:23 | INFO | Rank 0 | Train Epoch: 0 [191648/250314 (77%)]\tLoss: 0.869693\tData (t) 0.356\tBatch (t) 0.568\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:23 | INFO | Rank 0 | Train Epoch: 0 [191680/250314 (77%)]\tLoss: 0.902317\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:24 | INFO | Rank 0 | Train Epoch: 0 [191712/250314 (77%)]\tLoss: 0.339580\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:24 | INFO | Rank 0 | Train Epoch: 0 [191744/250314 (77%)]\tLoss: 0.832986\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:25 | INFO | Rank 0 | Train Epoch: 0 [191776/250314 (77%)]\tLoss: 0.683227\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:25 | INFO | Rank 0 | Train Epoch: 0 [191808/250314 (77%)]\tLoss: 0.501310\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:26 | INFO | Rank 0 | Train Epoch: 0 [191840/250314 (77%)]\tLoss: 0.918005\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:26 | INFO | Rank 0 | Train Epoch: 0 [191872/250314 (77%)]\tLoss: 0.457382\tData (t) 0.279\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:27 | INFO | Rank 0 | Train Epoch: 0 [191904/250314 (77%)]\tLoss: 0.980726\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:27 | INFO | Rank 0 | Train Epoch: 0 [191936/250314 (77%)]\tLoss: 1.199896\tData (t) 0.206\tBatch (t) 0.418\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:28 | INFO | Rank 0 | Train Epoch: 0 [191968/250314 (77%)]\tLoss: 0.487123\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:28 | INFO | Rank 0 | Train Epoch: 0 [192000/250314 (77%)]\tLoss: 0.481223\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:29 | INFO | Rank 0 | Train Epoch: 0 [192032/250314 (77%)]\tLoss: 0.816965\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:29 | INFO | Rank 0 | Train Epoch: 0 [192064/250314 (77%)]\tLoss: 0.636064\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:30 | INFO | Rank 0 | Train Epoch: 0 [192096/250314 (77%)]\tLoss: 0.548374\tData (t) 0.197\tBatch (t) 0.409\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:30 | INFO | Rank 0 | Train Epoch: 0 [192128/250314 (77%)]\tLoss: 0.934485\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:31 | INFO | Rank 0 | Train Epoch: 0 [192160/250314 (77%)]\tLoss: 0.622474\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:31 | INFO | Rank 0 | Train Epoch: 0 [192192/250314 (77%)]\tLoss: 0.410018\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:32 | INFO | Rank 0 | Train Epoch: 0 [192224/250314 (77%)]\tLoss: 0.660890\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:32 | INFO | Rank 0 | Train Epoch: 0 [192256/250314 (77%)]\tLoss: 0.578701\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:32 | INFO | Rank 0 | Train Epoch: 0 [192288/250314 (77%)]\tLoss: 0.533246\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:33 | INFO | Rank 0 | Train Epoch: 0 [192320/250314 (77%)]\tLoss: 0.815232\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:33 | INFO | Rank 0 | Train Epoch: 0 [192352/250314 (77%)]\tLoss: 0.596214\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:34 | INFO | Rank 0 | Train Epoch: 0 [192384/250314 (77%)]\tLoss: 0.581965\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:34 | INFO | Rank 0 | Train Epoch: 0 [192416/250314 (77%)]\tLoss: 0.786968\tData (t) 0.207\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:35 | INFO | Rank 0 | Train Epoch: 0 [192448/250314 (77%)]\tLoss: 0.767671\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:35 | INFO | Rank 0 | Train Epoch: 0 [192480/250314 (77%)]\tLoss: 0.568386\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:36 | INFO | Rank 0 | Train Epoch: 0 [192512/250314 (77%)]\tLoss: 1.211618\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:36 | INFO | Rank 0 | Train Epoch: 0 [192544/250314 (77%)]\tLoss: 0.336310\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:37 | INFO | Rank 0 | Train Epoch: 0 [192576/250314 (77%)]\tLoss: 0.565893\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:37 | INFO | Rank 0 | Train Epoch: 0 [192608/250314 (77%)]\tLoss: 0.943175\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:38 | INFO | Rank 0 | Train Epoch: 0 [192640/250314 (77%)]\tLoss: 0.848898\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:38 | INFO | Rank 0 | Train Epoch: 0 [192672/250314 (77%)]\tLoss: 0.587482\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:39 | INFO | Rank 0 | Train Epoch: 0 [192704/250314 (77%)]\tLoss: 0.605919\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:39 | INFO | Rank 0 | Train Epoch: 0 [192736/250314 (77%)]\tLoss: 0.422501\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:40 | INFO | Rank 0 | Train Epoch: 0 [192768/250314 (77%)]\tLoss: 0.783571\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:40 | INFO | Rank 0 | Train Epoch: 0 [192800/250314 (77%)]\tLoss: 0.464566\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:41 | INFO | Rank 0 | Train Epoch: 0 [192832/250314 (77%)]\tLoss: 0.325771\tData (t) 0.220\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:41 | INFO | Rank 0 | Train Epoch: 0 [192864/250314 (77%)]\tLoss: 0.420349\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:42 | INFO | Rank 0 | Train Epoch: 0 [192896/250314 (77%)]\tLoss: 0.296365\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:42 | INFO | Rank 0 | Train Epoch: 0 [192928/250314 (77%)]\tLoss: 0.889349\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:43 | INFO | Rank 0 | Train Epoch: 0 [192960/250314 (77%)]\tLoss: 0.606187\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:43 | INFO | Rank 0 | Train Epoch: 0 [192992/250314 (77%)]\tLoss: 0.991233\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:44 | INFO | Rank 0 | Train Epoch: 0 [193024/250314 (77%)]\tLoss: 0.491209\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:44 | INFO | Rank 0 | Train Epoch: 0 [193056/250314 (77%)]\tLoss: 0.828074\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:45 | INFO | Rank 0 | Train Epoch: 0 [193088/250314 (77%)]\tLoss: 0.416216\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:45 | INFO | Rank 0 | Train Epoch: 0 [193120/250314 (77%)]\tLoss: 0.516994\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:46 | INFO | Rank 0 | Train Epoch: 0 [193152/250314 (77%)]\tLoss: 0.931619\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:46 | INFO | Rank 0 | Train Epoch: 0 [193184/250314 (77%)]\tLoss: 0.382731\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:47 | INFO | Rank 0 | Train Epoch: 0 [193216/250314 (77%)]\tLoss: 0.655407\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:47 | INFO | Rank 0 | Train Epoch: 0 [193248/250314 (77%)]\tLoss: 0.694348\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:48 | INFO | Rank 0 | Train Epoch: 0 [193280/250314 (77%)]\tLoss: 0.558757\tData (t) 0.220\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:48 | INFO | Rank 0 | Train Epoch: 0 [193312/250314 (77%)]\tLoss: 0.555621\tData (t) 0.323\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:49 | INFO | Rank 0 | Train Epoch: 0 [193344/250314 (77%)]\tLoss: 0.648137\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:49 | INFO | Rank 0 | Train Epoch: 0 [193376/250314 (77%)]\tLoss: 1.083709\tData (t) 0.372\tBatch (t) 0.583\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:50 | INFO | Rank 0 | Train Epoch: 0 [193408/250314 (77%)]\tLoss: 0.720338\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:50 | INFO | Rank 0 | Train Epoch: 0 [193440/250314 (77%)]\tLoss: 0.594179\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:51 | INFO | Rank 0 | Train Epoch: 0 [193472/250314 (77%)]\tLoss: 0.417451\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:51 | INFO | Rank 0 | Train Epoch: 0 [193504/250314 (77%)]\tLoss: 0.506433\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:52 | INFO | Rank 0 | Train Epoch: 0 [193536/250314 (77%)]\tLoss: 0.381650\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:52 | INFO | Rank 0 | Train Epoch: 0 [193568/250314 (77%)]\tLoss: 0.392659\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:53 | INFO | Rank 0 | Train Epoch: 0 [193600/250314 (77%)]\tLoss: 0.526215\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:53 | INFO | Rank 0 | Train Epoch: 0 [193632/250314 (77%)]\tLoss: 0.565751\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:54 | INFO | Rank 0 | Train Epoch: 0 [193664/250314 (77%)]\tLoss: 0.924539\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:54 | INFO | Rank 0 | Train Epoch: 0 [193696/250314 (77%)]\tLoss: 0.770695\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:55 | INFO | Rank 0 | Train Epoch: 0 [193728/250314 (77%)]\tLoss: 0.505925\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:55 | INFO | Rank 0 | Train Epoch: 0 [193760/250314 (77%)]\tLoss: 0.762295\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:56 | INFO | Rank 0 | Train Epoch: 0 [193792/250314 (77%)]\tLoss: 0.667338\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:56 | INFO | Rank 0 | Train Epoch: 0 [193824/250314 (77%)]\tLoss: 0.523872\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:57 | INFO | Rank 0 | Train Epoch: 0 [193856/250314 (77%)]\tLoss: 0.326817\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:57 | INFO | Rank 0 | Train Epoch: 0 [193888/250314 (77%)]\tLoss: 0.845214\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:58 | INFO | Rank 0 | Train Epoch: 0 [193920/250314 (77%)]\tLoss: 0.522378\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:58 | INFO | Rank 0 | Train Epoch: 0 [193952/250314 (77%)]\tLoss: 0.506513\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:58 | INFO | Rank 0 | Train Epoch: 0 [193984/250314 (77%)]\tLoss: 0.890566\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:59 | INFO | Rank 0 | Train Epoch: 0 [194016/250314 (78%)]\tLoss: 0.700158\tData (t) 0.211\tBatch (t) 0.423\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,13:59:59 | INFO | Rank 0 | Train Epoch: 0 [194048/250314 (78%)]\tLoss: 0.510278\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:00 | INFO | Rank 0 | Train Epoch: 0 [194080/250314 (78%)]\tLoss: 0.751981\tData (t) 0.278\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:00 | INFO | Rank 0 | Train Epoch: 0 [194112/250314 (78%)]\tLoss: 0.746030\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:01 | INFO | Rank 0 | Train Epoch: 0 [194144/250314 (78%)]\tLoss: 0.214950\tData (t) 0.208\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:01 | INFO | Rank 0 | Train Epoch: 0 [194176/250314 (78%)]\tLoss: 0.962879\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:02 | INFO | Rank 0 | Train Epoch: 0 [194208/250314 (78%)]\tLoss: 0.465575\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:02 | INFO | Rank 0 | Train Epoch: 0 [194240/250314 (78%)]\tLoss: 0.293417\tData (t) 0.194\tBatch (t) 0.405\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:03 | INFO | Rank 0 | Train Epoch: 0 [194272/250314 (78%)]\tLoss: 0.446588\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:03 | INFO | Rank 0 | Train Epoch: 0 [194304/250314 (78%)]\tLoss: 0.697566\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:04 | INFO | Rank 0 | Train Epoch: 0 [194336/250314 (78%)]\tLoss: 0.321777\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:04 | INFO | Rank 0 | Train Epoch: 0 [194368/250314 (78%)]\tLoss: 0.566049\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:04 | INFO | Rank 0 | Train Epoch: 0 [194400/250314 (78%)]\tLoss: 0.828713\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:05 | INFO | Rank 0 | Train Epoch: 0 [194432/250314 (78%)]\tLoss: 0.567641\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:06 | INFO | Rank 0 | Train Epoch: 0 [194464/250314 (78%)]\tLoss: 0.459343\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:06 | INFO | Rank 0 | Train Epoch: 0 [194496/250314 (78%)]\tLoss: 0.538832\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:07 | INFO | Rank 0 | Train Epoch: 0 [194528/250314 (78%)]\tLoss: 0.665422\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:07 | INFO | Rank 0 | Train Epoch: 0 [194560/250314 (78%)]\tLoss: 0.411262\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:07 | INFO | Rank 0 | Train Epoch: 0 [194592/250314 (78%)]\tLoss: 0.896013\tData (t) 0.204\tBatch (t) 0.416\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:08 | INFO | Rank 0 | Train Epoch: 0 [194624/250314 (78%)]\tLoss: 0.646360\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:08 | INFO | Rank 0 | Train Epoch: 0 [194656/250314 (78%)]\tLoss: 0.807281\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:09 | INFO | Rank 0 | Train Epoch: 0 [194688/250314 (78%)]\tLoss: 0.925333\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:09 | INFO | Rank 0 | Train Epoch: 0 [194720/250314 (78%)]\tLoss: 0.817016\tData (t) 0.194\tBatch (t) 0.406\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:10 | INFO | Rank 0 | Train Epoch: 0 [194752/250314 (78%)]\tLoss: 0.608079\tData (t) 0.321\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:10 | INFO | Rank 0 | Train Epoch: 0 [194784/250314 (78%)]\tLoss: 0.793398\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:11 | INFO | Rank 0 | Train Epoch: 0 [194816/250314 (78%)]\tLoss: 0.736596\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:11 | INFO | Rank 0 | Train Epoch: 0 [194848/250314 (78%)]\tLoss: 0.720992\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:12 | INFO | Rank 0 | Train Epoch: 0 [194880/250314 (78%)]\tLoss: 0.628186\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:12 | INFO | Rank 0 | Train Epoch: 0 [194912/250314 (78%)]\tLoss: 0.290754\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:13 | INFO | Rank 0 | Train Epoch: 0 [194944/250314 (78%)]\tLoss: 0.684341\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.591\n",
      "2022-11-09,14:00:13 | INFO | Rank 0 | Train Epoch: 0 [194976/250314 (78%)]\tLoss: 0.999689\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:14 | INFO | Rank 0 | Train Epoch: 0 [195008/250314 (78%)]\tLoss: 0.798056\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:14 | INFO | Rank 0 | Train Epoch: 0 [195040/250314 (78%)]\tLoss: 0.798190\tData (t) 0.216\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:15 | INFO | Rank 0 | Train Epoch: 0 [195072/250314 (78%)]\tLoss: 0.785763\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:15 | INFO | Rank 0 | Train Epoch: 0 [195104/250314 (78%)]\tLoss: 0.805657\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:16 | INFO | Rank 0 | Train Epoch: 0 [195136/250314 (78%)]\tLoss: 1.144864\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:16 | INFO | Rank 0 | Train Epoch: 0 [195168/250314 (78%)]\tLoss: 0.511410\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:17 | INFO | Rank 0 | Train Epoch: 0 [195200/250314 (78%)]\tLoss: 0.544131\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:17 | INFO | Rank 0 | Train Epoch: 0 [195232/250314 (78%)]\tLoss: 0.677583\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:17 | INFO | Rank 0 | Train Epoch: 0 [195264/250314 (78%)]\tLoss: 0.496570\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:18 | INFO | Rank 0 | Train Epoch: 0 [195296/250314 (78%)]\tLoss: 0.578605\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:19 | INFO | Rank 0 | Train Epoch: 0 [195328/250314 (78%)]\tLoss: 0.805058\tData (t) 0.668\tBatch (t) 0.879\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:19 | INFO | Rank 0 | Train Epoch: 0 [195360/250314 (78%)]\tLoss: 0.568313\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:20 | INFO | Rank 0 | Train Epoch: 0 [195392/250314 (78%)]\tLoss: 0.808153\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:20 | INFO | Rank 0 | Train Epoch: 0 [195424/250314 (78%)]\tLoss: 0.212872\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:21 | INFO | Rank 0 | Train Epoch: 0 [195456/250314 (78%)]\tLoss: 0.804808\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:21 | INFO | Rank 0 | Train Epoch: 0 [195488/250314 (78%)]\tLoss: 0.563576\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:22 | INFO | Rank 0 | Train Epoch: 0 [195520/250314 (78%)]\tLoss: 0.927124\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:22 | INFO | Rank 0 | Train Epoch: 0 [195552/250314 (78%)]\tLoss: 0.510253\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:23 | INFO | Rank 0 | Train Epoch: 0 [195584/250314 (78%)]\tLoss: 0.514874\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:23 | INFO | Rank 0 | Train Epoch: 0 [195616/250314 (78%)]\tLoss: 0.861825\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:24 | INFO | Rank 0 | Train Epoch: 0 [195648/250314 (78%)]\tLoss: 0.638778\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:24 | INFO | Rank 0 | Train Epoch: 0 [195680/250314 (78%)]\tLoss: 0.820134\tData (t) 0.263\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:25 | INFO | Rank 0 | Train Epoch: 0 [195712/250314 (78%)]\tLoss: 0.583012\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:25 | INFO | Rank 0 | Train Epoch: 0 [195744/250314 (78%)]\tLoss: 0.242380\tData (t) 0.355\tBatch (t) 0.568\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:26 | INFO | Rank 0 | Train Epoch: 0 [195776/250314 (78%)]\tLoss: 1.096986\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:26 | INFO | Rank 0 | Train Epoch: 0 [195808/250314 (78%)]\tLoss: 0.606359\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:27 | INFO | Rank 0 | Train Epoch: 0 [195840/250314 (78%)]\tLoss: 0.616577\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:27 | INFO | Rank 0 | Train Epoch: 0 [195872/250314 (78%)]\tLoss: 0.607641\tData (t) 0.291\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:28 | INFO | Rank 0 | Train Epoch: 0 [195904/250314 (78%)]\tLoss: 0.761114\tData (t) 0.318\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:28 | INFO | Rank 0 | Train Epoch: 0 [195936/250314 (78%)]\tLoss: 0.829543\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:29 | INFO | Rank 0 | Train Epoch: 0 [195968/250314 (78%)]\tLoss: 0.427673\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:29 | INFO | Rank 0 | Train Epoch: 0 [196000/250314 (78%)]\tLoss: 0.452558\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:30 | INFO | Rank 0 | Train Epoch: 0 [196032/250314 (78%)]\tLoss: 0.581595\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:30 | INFO | Rank 0 | Train Epoch: 0 [196064/250314 (78%)]\tLoss: 0.446404\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:31 | INFO | Rank 0 | Train Epoch: 0 [196096/250314 (78%)]\tLoss: 0.990686\tData (t) 0.338\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:31 | INFO | Rank 0 | Train Epoch: 0 [196128/250314 (78%)]\tLoss: 0.878972\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:32 | INFO | Rank 0 | Train Epoch: 0 [196160/250314 (78%)]\tLoss: 0.611704\tData (t) 0.309\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:32 | INFO | Rank 0 | Train Epoch: 0 [196192/250314 (78%)]\tLoss: 0.884183\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:33 | INFO | Rank 0 | Train Epoch: 0 [196224/250314 (78%)]\tLoss: 0.471657\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:33 | INFO | Rank 0 | Train Epoch: 0 [196256/250314 (78%)]\tLoss: 0.767078\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:34 | INFO | Rank 0 | Train Epoch: 0 [196288/250314 (78%)]\tLoss: 0.651373\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:34 | INFO | Rank 0 | Train Epoch: 0 [196320/250314 (78%)]\tLoss: 0.698678\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:35 | INFO | Rank 0 | Train Epoch: 0 [196352/250314 (78%)]\tLoss: 0.764880\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:35 | INFO | Rank 0 | Train Epoch: 0 [196384/250314 (78%)]\tLoss: 0.626460\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:36 | INFO | Rank 0 | Train Epoch: 0 [196416/250314 (78%)]\tLoss: 0.657216\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:36 | INFO | Rank 0 | Train Epoch: 0 [196448/250314 (78%)]\tLoss: 0.700500\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:37 | INFO | Rank 0 | Train Epoch: 0 [196480/250314 (78%)]\tLoss: 0.444962\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:37 | INFO | Rank 0 | Train Epoch: 0 [196512/250314 (79%)]\tLoss: 0.551363\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:38 | INFO | Rank 0 | Train Epoch: 0 [196544/250314 (79%)]\tLoss: 0.434896\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:38 | INFO | Rank 0 | Train Epoch: 0 [196576/250314 (79%)]\tLoss: 0.477196\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:39 | INFO | Rank 0 | Train Epoch: 0 [196608/250314 (79%)]\tLoss: 0.599285\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:39 | INFO | Rank 0 | Train Epoch: 0 [196640/250314 (79%)]\tLoss: 0.656945\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:39 | INFO | Rank 0 | Train Epoch: 0 [196672/250314 (79%)]\tLoss: 0.401258\tData (t) 0.228\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:40 | INFO | Rank 0 | Train Epoch: 0 [196704/250314 (79%)]\tLoss: 0.667108\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:40 | INFO | Rank 0 | Train Epoch: 0 [196736/250314 (79%)]\tLoss: 0.455481\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:41 | INFO | Rank 0 | Train Epoch: 0 [196768/250314 (79%)]\tLoss: 0.789776\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:41 | INFO | Rank 0 | Train Epoch: 0 [196800/250314 (79%)]\tLoss: 0.906985\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:42 | INFO | Rank 0 | Train Epoch: 0 [196832/250314 (79%)]\tLoss: 0.615189\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:42 | INFO | Rank 0 | Train Epoch: 0 [196864/250314 (79%)]\tLoss: 0.601583\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:43 | INFO | Rank 0 | Train Epoch: 0 [196896/250314 (79%)]\tLoss: 0.259976\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:43 | INFO | Rank 0 | Train Epoch: 0 [196928/250314 (79%)]\tLoss: 0.394669\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:44 | INFO | Rank 0 | Train Epoch: 0 [196960/250314 (79%)]\tLoss: 0.655277\tData (t) 0.229\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:44 | INFO | Rank 0 | Train Epoch: 0 [196992/250314 (79%)]\tLoss: 0.514871\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:45 | INFO | Rank 0 | Train Epoch: 0 [197024/250314 (79%)]\tLoss: 0.962441\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:45 | INFO | Rank 0 | Train Epoch: 0 [197056/250314 (79%)]\tLoss: 0.324455\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:46 | INFO | Rank 0 | Train Epoch: 0 [197088/250314 (79%)]\tLoss: 0.489596\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:46 | INFO | Rank 0 | Train Epoch: 0 [197120/250314 (79%)]\tLoss: 0.623733\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:47 | INFO | Rank 0 | Train Epoch: 0 [197152/250314 (79%)]\tLoss: 0.493524\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:47 | INFO | Rank 0 | Train Epoch: 0 [197184/250314 (79%)]\tLoss: 0.574679\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:48 | INFO | Rank 0 | Train Epoch: 0 [197216/250314 (79%)]\tLoss: 0.611483\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:48 | INFO | Rank 0 | Train Epoch: 0 [197248/250314 (79%)]\tLoss: 0.844861\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:49 | INFO | Rank 0 | Train Epoch: 0 [197280/250314 (79%)]\tLoss: 0.959136\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:49 | INFO | Rank 0 | Train Epoch: 0 [197312/250314 (79%)]\tLoss: 0.904642\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:50 | INFO | Rank 0 | Train Epoch: 0 [197344/250314 (79%)]\tLoss: 0.336710\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:50 | INFO | Rank 0 | Train Epoch: 0 [197376/250314 (79%)]\tLoss: 0.954716\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:51 | INFO | Rank 0 | Train Epoch: 0 [197408/250314 (79%)]\tLoss: 0.700882\tData (t) 0.295\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:51 | INFO | Rank 0 | Train Epoch: 0 [197440/250314 (79%)]\tLoss: 0.663774\tData (t) 0.344\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:52 | INFO | Rank 0 | Train Epoch: 0 [197472/250314 (79%)]\tLoss: 0.965226\tData (t) 0.264\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:52 | INFO | Rank 0 | Train Epoch: 0 [197504/250314 (79%)]\tLoss: 0.604073\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:53 | INFO | Rank 0 | Train Epoch: 0 [197536/250314 (79%)]\tLoss: 0.344260\tData (t) 0.229\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:53 | INFO | Rank 0 | Train Epoch: 0 [197568/250314 (79%)]\tLoss: 0.484691\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:54 | INFO | Rank 0 | Train Epoch: 0 [197600/250314 (79%)]\tLoss: 0.643013\tData (t) 0.229\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:54 | INFO | Rank 0 | Train Epoch: 0 [197632/250314 (79%)]\tLoss: 1.132288\tData (t) 0.225\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:55 | INFO | Rank 0 | Train Epoch: 0 [197664/250314 (79%)]\tLoss: 0.253129\tData (t) 0.214\tBatch (t) 0.426\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:55 | INFO | Rank 0 | Train Epoch: 0 [197696/250314 (79%)]\tLoss: 0.690120\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:55 | INFO | Rank 0 | Train Epoch: 0 [197728/250314 (79%)]\tLoss: 0.658659\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:56 | INFO | Rank 0 | Train Epoch: 0 [197760/250314 (79%)]\tLoss: 0.681973\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:56 | INFO | Rank 0 | Train Epoch: 0 [197792/250314 (79%)]\tLoss: 0.864192\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:57 | INFO | Rank 0 | Train Epoch: 0 [197824/250314 (79%)]\tLoss: 0.501400\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:57 | INFO | Rank 0 | Train Epoch: 0 [197856/250314 (79%)]\tLoss: 0.689766\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:58 | INFO | Rank 0 | Train Epoch: 0 [197888/250314 (79%)]\tLoss: 0.467366\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:58 | INFO | Rank 0 | Train Epoch: 0 [197920/250314 (79%)]\tLoss: 0.523799\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:59 | INFO | Rank 0 | Train Epoch: 0 [197952/250314 (79%)]\tLoss: 0.549905\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:00:59 | INFO | Rank 0 | Train Epoch: 0 [197984/250314 (79%)]\tLoss: 0.761405\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:00 | INFO | Rank 0 | Train Epoch: 0 [198016/250314 (79%)]\tLoss: 0.739018\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:00 | INFO | Rank 0 | Train Epoch: 0 [198048/250314 (79%)]\tLoss: 0.679822\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:01 | INFO | Rank 0 | Train Epoch: 0 [198080/250314 (79%)]\tLoss: 0.454024\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:01 | INFO | Rank 0 | Train Epoch: 0 [198112/250314 (79%)]\tLoss: 0.787078\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:02 | INFO | Rank 0 | Train Epoch: 0 [198144/250314 (79%)]\tLoss: 0.480161\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:02 | INFO | Rank 0 | Train Epoch: 0 [198176/250314 (79%)]\tLoss: 0.745958\tData (t) 0.331\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:03 | INFO | Rank 0 | Train Epoch: 0 [198208/250314 (79%)]\tLoss: 0.770075\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:03 | INFO | Rank 0 | Train Epoch: 0 [198240/250314 (79%)]\tLoss: 0.487591\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:04 | INFO | Rank 0 | Train Epoch: 0 [198272/250314 (79%)]\tLoss: 0.495010\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:04 | INFO | Rank 0 | Train Epoch: 0 [198304/250314 (79%)]\tLoss: 0.592530\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:05 | INFO | Rank 0 | Train Epoch: 0 [198336/250314 (79%)]\tLoss: 0.515402\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:05 | INFO | Rank 0 | Train Epoch: 0 [198368/250314 (79%)]\tLoss: 0.401485\tData (t) 0.231\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:06 | INFO | Rank 0 | Train Epoch: 0 [198400/250314 (79%)]\tLoss: 0.455818\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:06 | INFO | Rank 0 | Train Epoch: 0 [198432/250314 (79%)]\tLoss: 0.552538\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:06 | INFO | Rank 0 | Train Epoch: 0 [198464/250314 (79%)]\tLoss: 0.720261\tData (t) 0.249\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:07 | INFO | Rank 0 | Train Epoch: 0 [198496/250314 (79%)]\tLoss: 0.455999\tData (t) 0.420\tBatch (t) 0.634\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:08 | INFO | Rank 0 | Train Epoch: 0 [198528/250314 (79%)]\tLoss: 0.892678\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:08 | INFO | Rank 0 | Train Epoch: 0 [198560/250314 (79%)]\tLoss: 0.900161\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:09 | INFO | Rank 0 | Train Epoch: 0 [198592/250314 (79%)]\tLoss: 0.558787\tData (t) 0.406\tBatch (t) 0.618\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:09 | INFO | Rank 0 | Train Epoch: 0 [198624/250314 (79%)]\tLoss: 0.229583\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:10 | INFO | Rank 0 | Train Epoch: 0 [198656/250314 (79%)]\tLoss: 1.084512\tData (t) 0.269\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:10 | INFO | Rank 0 | Train Epoch: 0 [198688/250314 (79%)]\tLoss: 0.412295\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:11 | INFO | Rank 0 | Train Epoch: 0 [198720/250314 (79%)]\tLoss: 0.558394\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:11 | INFO | Rank 0 | Train Epoch: 0 [198752/250314 (79%)]\tLoss: 0.655199\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:12 | INFO | Rank 0 | Train Epoch: 0 [198784/250314 (79%)]\tLoss: 0.563910\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:12 | INFO | Rank 0 | Train Epoch: 0 [198816/250314 (79%)]\tLoss: 0.924650\tData (t) 0.379\tBatch (t) 0.591\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:13 | INFO | Rank 0 | Train Epoch: 0 [198848/250314 (79%)]\tLoss: 0.502978\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:13 | INFO | Rank 0 | Train Epoch: 0 [198880/250314 (79%)]\tLoss: 0.512279\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:14 | INFO | Rank 0 | Train Epoch: 0 [198912/250314 (79%)]\tLoss: 0.697248\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:14 | INFO | Rank 0 | Train Epoch: 0 [198944/250314 (79%)]\tLoss: 0.696204\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:15 | INFO | Rank 0 | Train Epoch: 0 [198976/250314 (79%)]\tLoss: 0.777434\tData (t) 0.263\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:15 | INFO | Rank 0 | Train Epoch: 0 [199008/250314 (80%)]\tLoss: 0.371333\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:16 | INFO | Rank 0 | Train Epoch: 0 [199040/250314 (80%)]\tLoss: 0.626868\tData (t) 0.251\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:16 | INFO | Rank 0 | Train Epoch: 0 [199072/250314 (80%)]\tLoss: 0.669699\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:17 | INFO | Rank 0 | Train Epoch: 0 [199104/250314 (80%)]\tLoss: 0.425050\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:17 | INFO | Rank 0 | Train Epoch: 0 [199136/250314 (80%)]\tLoss: 0.484189\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:18 | INFO | Rank 0 | Train Epoch: 0 [199168/250314 (80%)]\tLoss: 0.631091\tData (t) 0.411\tBatch (t) 0.623\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:18 | INFO | Rank 0 | Train Epoch: 0 [199200/250314 (80%)]\tLoss: 0.861140\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:19 | INFO | Rank 0 | Train Epoch: 0 [199232/250314 (80%)]\tLoss: 0.797285\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:19 | INFO | Rank 0 | Train Epoch: 0 [199264/250314 (80%)]\tLoss: 0.413199\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:20 | INFO | Rank 0 | Train Epoch: 0 [199296/250314 (80%)]\tLoss: 0.528803\tData (t) 0.219\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:20 | INFO | Rank 0 | Train Epoch: 0 [199328/250314 (80%)]\tLoss: 0.652291\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:20 | INFO | Rank 0 | Train Epoch: 0 [199360/250314 (80%)]\tLoss: 0.837991\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:21 | INFO | Rank 0 | Train Epoch: 0 [199392/250314 (80%)]\tLoss: 0.303646\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:21 | INFO | Rank 0 | Train Epoch: 0 [199424/250314 (80%)]\tLoss: 0.361133\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:22 | INFO | Rank 0 | Train Epoch: 0 [199456/250314 (80%)]\tLoss: 0.708708\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:22 | INFO | Rank 0 | Train Epoch: 0 [199488/250314 (80%)]\tLoss: 0.599476\tData (t) 0.193\tBatch (t) 0.405\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:23 | INFO | Rank 0 | Train Epoch: 0 [199520/250314 (80%)]\tLoss: 0.742142\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:23 | INFO | Rank 0 | Train Epoch: 0 [199552/250314 (80%)]\tLoss: 0.705263\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:24 | INFO | Rank 0 | Train Epoch: 0 [199584/250314 (80%)]\tLoss: 0.755970\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:24 | INFO | Rank 0 | Train Epoch: 0 [199616/250314 (80%)]\tLoss: 1.054078\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:25 | INFO | Rank 0 | Train Epoch: 0 [199648/250314 (80%)]\tLoss: 0.441581\tData (t) 0.287\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:25 | INFO | Rank 0 | Train Epoch: 0 [199680/250314 (80%)]\tLoss: 0.655849\tData (t) 0.197\tBatch (t) 0.408\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:26 | INFO | Rank 0 | Train Epoch: 0 [199712/250314 (80%)]\tLoss: 1.070887\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:26 | INFO | Rank 0 | Train Epoch: 0 [199744/250314 (80%)]\tLoss: 0.759593\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:27 | INFO | Rank 0 | Train Epoch: 0 [199776/250314 (80%)]\tLoss: 0.618403\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:27 | INFO | Rank 0 | Train Epoch: 0 [199808/250314 (80%)]\tLoss: 0.908451\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:28 | INFO | Rank 0 | Train Epoch: 0 [199840/250314 (80%)]\tLoss: 0.878897\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:28 | INFO | Rank 0 | Train Epoch: 0 [199872/250314 (80%)]\tLoss: 0.408047\tData (t) 0.394\tBatch (t) 0.605\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:29 | INFO | Rank 0 | Train Epoch: 0 [199904/250314 (80%)]\tLoss: 0.488609\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:29 | INFO | Rank 0 | Train Epoch: 0 [199936/250314 (80%)]\tLoss: 0.553264\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:30 | INFO | Rank 0 | Train Epoch: 0 [199968/250314 (80%)]\tLoss: 0.581847\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:30 | INFO | Rank 0 | Train Epoch: 0 [200000/250314 (80%)]\tLoss: 0.712500\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:31 | INFO | Rank 0 | Train Epoch: 0 [200032/250314 (80%)]\tLoss: 0.827805\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:31 | INFO | Rank 0 | Train Epoch: 0 [200064/250314 (80%)]\tLoss: 0.989779\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:32 | INFO | Rank 0 | Train Epoch: 0 [200096/250314 (80%)]\tLoss: 0.661204\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:32 | INFO | Rank 0 | Train Epoch: 0 [200128/250314 (80%)]\tLoss: 0.770326\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:33 | INFO | Rank 0 | Train Epoch: 0 [200160/250314 (80%)]\tLoss: 0.900124\tData (t) 0.218\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:33 | INFO | Rank 0 | Train Epoch: 0 [200192/250314 (80%)]\tLoss: 0.747103\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:34 | INFO | Rank 0 | Train Epoch: 0 [200224/250314 (80%)]\tLoss: 0.903818\tData (t) 0.228\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:34 | INFO | Rank 0 | Train Epoch: 0 [200256/250314 (80%)]\tLoss: 0.699111\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:35 | INFO | Rank 0 | Train Epoch: 0 [200288/250314 (80%)]\tLoss: 0.296320\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:35 | INFO | Rank 0 | Train Epoch: 0 [200320/250314 (80%)]\tLoss: 0.612427\tData (t) 0.219\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:35 | INFO | Rank 0 | Train Epoch: 0 [200352/250314 (80%)]\tLoss: 0.313964\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:36 | INFO | Rank 0 | Train Epoch: 0 [200384/250314 (80%)]\tLoss: 0.543395\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:36 | INFO | Rank 0 | Train Epoch: 0 [200416/250314 (80%)]\tLoss: 0.936304\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:37 | INFO | Rank 0 | Train Epoch: 0 [200448/250314 (80%)]\tLoss: 0.547251\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:37 | INFO | Rank 0 | Train Epoch: 0 [200480/250314 (80%)]\tLoss: 0.964854\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:38 | INFO | Rank 0 | Train Epoch: 0 [200512/250314 (80%)]\tLoss: 0.937775\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:38 | INFO | Rank 0 | Train Epoch: 0 [200544/250314 (80%)]\tLoss: 0.495888\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:39 | INFO | Rank 0 | Train Epoch: 0 [200576/250314 (80%)]\tLoss: 0.432138\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:39 | INFO | Rank 0 | Train Epoch: 0 [200608/250314 (80%)]\tLoss: 0.641907\tData (t) 0.221\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:40 | INFO | Rank 0 | Train Epoch: 0 [200640/250314 (80%)]\tLoss: 0.587380\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:40 | INFO | Rank 0 | Train Epoch: 0 [200672/250314 (80%)]\tLoss: 0.645878\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:41 | INFO | Rank 0 | Train Epoch: 0 [200704/250314 (80%)]\tLoss: 0.681763\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:41 | INFO | Rank 0 | Train Epoch: 0 [200736/250314 (80%)]\tLoss: 0.818494\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:42 | INFO | Rank 0 | Train Epoch: 0 [200768/250314 (80%)]\tLoss: 0.419113\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:42 | INFO | Rank 0 | Train Epoch: 0 [200800/250314 (80%)]\tLoss: 0.417886\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:43 | INFO | Rank 0 | Train Epoch: 0 [200832/250314 (80%)]\tLoss: 0.608771\tData (t) 0.362\tBatch (t) 0.573\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:43 | INFO | Rank 0 | Train Epoch: 0 [200864/250314 (80%)]\tLoss: 0.434039\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:44 | INFO | Rank 0 | Train Epoch: 0 [200896/250314 (80%)]\tLoss: 0.392493\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:45 | INFO | Rank 0 | Train Epoch: 0 [200928/250314 (80%)]\tLoss: 0.449722\tData (t) 0.426\tBatch (t) 0.638\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:45 | INFO | Rank 0 | Train Epoch: 0 [200960/250314 (80%)]\tLoss: 0.571625\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:46 | INFO | Rank 0 | Train Epoch: 0 [200992/250314 (80%)]\tLoss: 0.636139\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:46 | INFO | Rank 0 | Train Epoch: 0 [201024/250314 (80%)]\tLoss: 0.495045\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:46 | INFO | Rank 0 | Train Epoch: 0 [201056/250314 (80%)]\tLoss: 0.549856\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:47 | INFO | Rank 0 | Train Epoch: 0 [201088/250314 (80%)]\tLoss: 0.370107\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:47 | INFO | Rank 0 | Train Epoch: 0 [201120/250314 (80%)]\tLoss: 1.005756\tData (t) 0.309\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:48 | INFO | Rank 0 | Train Epoch: 0 [201152/250314 (80%)]\tLoss: 0.744854\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:48 | INFO | Rank 0 | Train Epoch: 0 [201184/250314 (80%)]\tLoss: 0.630485\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:49 | INFO | Rank 0 | Train Epoch: 0 [201216/250314 (80%)]\tLoss: 1.033696\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:49 | INFO | Rank 0 | Train Epoch: 0 [201248/250314 (80%)]\tLoss: 0.422201\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:50 | INFO | Rank 0 | Train Epoch: 0 [201280/250314 (80%)]\tLoss: 0.463209\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:50 | INFO | Rank 0 | Train Epoch: 0 [201312/250314 (80%)]\tLoss: 0.321908\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:51 | INFO | Rank 0 | Train Epoch: 0 [201344/250314 (80%)]\tLoss: 0.548218\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:51 | INFO | Rank 0 | Train Epoch: 0 [201376/250314 (80%)]\tLoss: 0.577906\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:52 | INFO | Rank 0 | Train Epoch: 0 [201408/250314 (80%)]\tLoss: 0.627182\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:52 | INFO | Rank 0 | Train Epoch: 0 [201440/250314 (80%)]\tLoss: 0.554957\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:53 | INFO | Rank 0 | Train Epoch: 0 [201472/250314 (80%)]\tLoss: 0.880070\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:53 | INFO | Rank 0 | Train Epoch: 0 [201504/250314 (81%)]\tLoss: 0.650768\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:54 | INFO | Rank 0 | Train Epoch: 0 [201536/250314 (81%)]\tLoss: 0.346188\tData (t) 0.225\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:54 | INFO | Rank 0 | Train Epoch: 0 [201568/250314 (81%)]\tLoss: 0.490466\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:55 | INFO | Rank 0 | Train Epoch: 0 [201600/250314 (81%)]\tLoss: 0.778238\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:55 | INFO | Rank 0 | Train Epoch: 0 [201632/250314 (81%)]\tLoss: 0.494007\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:56 | INFO | Rank 0 | Train Epoch: 0 [201664/250314 (81%)]\tLoss: 0.717826\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:56 | INFO | Rank 0 | Train Epoch: 0 [201696/250314 (81%)]\tLoss: 0.478992\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:57 | INFO | Rank 0 | Train Epoch: 0 [201728/250314 (81%)]\tLoss: 0.896756\tData (t) 0.272\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:57 | INFO | Rank 0 | Train Epoch: 0 [201760/250314 (81%)]\tLoss: 0.525503\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:58 | INFO | Rank 0 | Train Epoch: 0 [201792/250314 (81%)]\tLoss: 0.688005\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:58 | INFO | Rank 0 | Train Epoch: 0 [201824/250314 (81%)]\tLoss: 0.530661\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:58 | INFO | Rank 0 | Train Epoch: 0 [201856/250314 (81%)]\tLoss: 0.997141\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:01:59 | INFO | Rank 0 | Train Epoch: 0 [201888/250314 (81%)]\tLoss: 0.535035\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:00 | INFO | Rank 0 | Train Epoch: 0 [201920/250314 (81%)]\tLoss: 0.557081\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:00 | INFO | Rank 0 | Train Epoch: 0 [201952/250314 (81%)]\tLoss: 0.693027\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:00 | INFO | Rank 0 | Train Epoch: 0 [201984/250314 (81%)]\tLoss: 0.677339\tData (t) 0.217\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:01 | INFO | Rank 0 | Train Epoch: 0 [202016/250314 (81%)]\tLoss: 0.599972\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:01 | INFO | Rank 0 | Train Epoch: 0 [202048/250314 (81%)]\tLoss: 0.938792\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:02 | INFO | Rank 0 | Train Epoch: 0 [202080/250314 (81%)]\tLoss: 0.997775\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:02 | INFO | Rank 0 | Train Epoch: 0 [202112/250314 (81%)]\tLoss: 0.671727\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:03 | INFO | Rank 0 | Train Epoch: 0 [202144/250314 (81%)]\tLoss: 0.827581\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:03 | INFO | Rank 0 | Train Epoch: 0 [202176/250314 (81%)]\tLoss: 0.412735\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:04 | INFO | Rank 0 | Train Epoch: 0 [202208/250314 (81%)]\tLoss: 0.666645\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:04 | INFO | Rank 0 | Train Epoch: 0 [202240/250314 (81%)]\tLoss: 0.683389\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:05 | INFO | Rank 0 | Train Epoch: 0 [202272/250314 (81%)]\tLoss: 0.625378\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:05 | INFO | Rank 0 | Train Epoch: 0 [202304/250314 (81%)]\tLoss: 0.365395\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:06 | INFO | Rank 0 | Train Epoch: 0 [202336/250314 (81%)]\tLoss: 0.410239\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:06 | INFO | Rank 0 | Train Epoch: 0 [202368/250314 (81%)]\tLoss: 0.499837\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:07 | INFO | Rank 0 | Train Epoch: 0 [202400/250314 (81%)]\tLoss: 0.569978\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:07 | INFO | Rank 0 | Train Epoch: 0 [202432/250314 (81%)]\tLoss: 0.423133\tData (t) 0.195\tBatch (t) 0.406\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:08 | INFO | Rank 0 | Train Epoch: 0 [202464/250314 (81%)]\tLoss: 0.491662\tData (t) 0.211\tBatch (t) 0.423\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:08 | INFO | Rank 0 | Train Epoch: 0 [202496/250314 (81%)]\tLoss: 0.620226\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:08 | INFO | Rank 0 | Train Epoch: 0 [202528/250314 (81%)]\tLoss: 0.633387\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:09 | INFO | Rank 0 | Train Epoch: 0 [202560/250314 (81%)]\tLoss: 1.211524\tData (t) 0.206\tBatch (t) 0.418\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:09 | INFO | Rank 0 | Train Epoch: 0 [202592/250314 (81%)]\tLoss: 0.576438\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:10 | INFO | Rank 0 | Train Epoch: 0 [202624/250314 (81%)]\tLoss: 0.403881\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:10 | INFO | Rank 0 | Train Epoch: 0 [202656/250314 (81%)]\tLoss: 0.537110\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:11 | INFO | Rank 0 | Train Epoch: 0 [202688/250314 (81%)]\tLoss: 0.681527\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:11 | INFO | Rank 0 | Train Epoch: 0 [202720/250314 (81%)]\tLoss: 0.832891\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:12 | INFO | Rank 0 | Train Epoch: 0 [202752/250314 (81%)]\tLoss: 0.825795\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:12 | INFO | Rank 0 | Train Epoch: 0 [202784/250314 (81%)]\tLoss: 0.678564\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:13 | INFO | Rank 0 | Train Epoch: 0 [202816/250314 (81%)]\tLoss: 0.381236\tData (t) 0.200\tBatch (t) 0.411\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:13 | INFO | Rank 0 | Train Epoch: 0 [202848/250314 (81%)]\tLoss: 0.513401\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:14 | INFO | Rank 0 | Train Epoch: 0 [202880/250314 (81%)]\tLoss: 0.529176\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:14 | INFO | Rank 0 | Train Epoch: 0 [202912/250314 (81%)]\tLoss: 0.603499\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:15 | INFO | Rank 0 | Train Epoch: 0 [202944/250314 (81%)]\tLoss: 0.819034\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:15 | INFO | Rank 0 | Train Epoch: 0 [202976/250314 (81%)]\tLoss: 0.608485\tData (t) 0.342\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:16 | INFO | Rank 0 | Train Epoch: 0 [203008/250314 (81%)]\tLoss: 0.685616\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:16 | INFO | Rank 0 | Train Epoch: 0 [203040/250314 (81%)]\tLoss: 0.822132\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:16 | INFO | Rank 0 | Train Epoch: 0 [203072/250314 (81%)]\tLoss: 0.621906\tData (t) 0.185\tBatch (t) 0.397\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:17 | INFO | Rank 0 | Train Epoch: 0 [203104/250314 (81%)]\tLoss: 0.647301\tData (t) 0.230\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:17 | INFO | Rank 0 | Train Epoch: 0 [203136/250314 (81%)]\tLoss: 0.574235\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:18 | INFO | Rank 0 | Train Epoch: 0 [203168/250314 (81%)]\tLoss: 0.601586\tData (t) 0.352\tBatch (t) 0.562\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:18 | INFO | Rank 0 | Train Epoch: 0 [203200/250314 (81%)]\tLoss: 0.727039\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:19 | INFO | Rank 0 | Train Epoch: 0 [203232/250314 (81%)]\tLoss: 0.421356\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:19 | INFO | Rank 0 | Train Epoch: 0 [203264/250314 (81%)]\tLoss: 1.128419\tData (t) 0.350\tBatch (t) 0.562\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:20 | INFO | Rank 0 | Train Epoch: 0 [203296/250314 (81%)]\tLoss: 0.740981\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:20 | INFO | Rank 0 | Train Epoch: 0 [203328/250314 (81%)]\tLoss: 0.712798\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:21 | INFO | Rank 0 | Train Epoch: 0 [203360/250314 (81%)]\tLoss: 0.773482\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:21 | INFO | Rank 0 | Train Epoch: 0 [203392/250314 (81%)]\tLoss: 0.624285\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:22 | INFO | Rank 0 | Train Epoch: 0 [203424/250314 (81%)]\tLoss: 0.583874\tData (t) 0.219\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:22 | INFO | Rank 0 | Train Epoch: 0 [203456/250314 (81%)]\tLoss: 0.632439\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:23 | INFO | Rank 0 | Train Epoch: 0 [203488/250314 (81%)]\tLoss: 0.452600\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:23 | INFO | Rank 0 | Train Epoch: 0 [203520/250314 (81%)]\tLoss: 0.798028\tData (t) 0.310\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:24 | INFO | Rank 0 | Train Epoch: 0 [203552/250314 (81%)]\tLoss: 0.837585\tData (t) 0.242\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:24 | INFO | Rank 0 | Train Epoch: 0 [203584/250314 (81%)]\tLoss: 0.741906\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:25 | INFO | Rank 0 | Train Epoch: 0 [203616/250314 (81%)]\tLoss: 0.480644\tData (t) 0.338\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:25 | INFO | Rank 0 | Train Epoch: 0 [203648/250314 (81%)]\tLoss: 0.503407\tData (t) 0.214\tBatch (t) 0.426\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:26 | INFO | Rank 0 | Train Epoch: 0 [203680/250314 (81%)]\tLoss: 0.947839\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:26 | INFO | Rank 0 | Train Epoch: 0 [203712/250314 (81%)]\tLoss: 0.481683\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:27 | INFO | Rank 0 | Train Epoch: 0 [203744/250314 (81%)]\tLoss: 0.497217\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:27 | INFO | Rank 0 | Train Epoch: 0 [203776/250314 (81%)]\tLoss: 0.534881\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:28 | INFO | Rank 0 | Train Epoch: 0 [203808/250314 (81%)]\tLoss: 0.332821\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:28 | INFO | Rank 0 | Train Epoch: 0 [203840/250314 (81%)]\tLoss: 0.730880\tData (t) 0.285\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:29 | INFO | Rank 0 | Train Epoch: 0 [203872/250314 (81%)]\tLoss: 0.534239\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:29 | INFO | Rank 0 | Train Epoch: 0 [203904/250314 (81%)]\tLoss: 1.783927\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:30 | INFO | Rank 0 | Train Epoch: 0 [203936/250314 (81%)]\tLoss: 0.644987\tData (t) 0.314\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:30 | INFO | Rank 0 | Train Epoch: 0 [203968/250314 (81%)]\tLoss: 0.573012\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:31 | INFO | Rank 0 | Train Epoch: 0 [204000/250314 (82%)]\tLoss: 0.545959\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:31 | INFO | Rank 0 | Train Epoch: 0 [204032/250314 (82%)]\tLoss: 0.563530\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:32 | INFO | Rank 0 | Train Epoch: 0 [204064/250314 (82%)]\tLoss: 0.707582\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:32 | INFO | Rank 0 | Train Epoch: 0 [204096/250314 (82%)]\tLoss: 0.670673\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:33 | INFO | Rank 0 | Train Epoch: 0 [204128/250314 (82%)]\tLoss: 0.493542\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:33 | INFO | Rank 0 | Train Epoch: 0 [204160/250314 (82%)]\tLoss: 0.514894\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:34 | INFO | Rank 0 | Train Epoch: 0 [204192/250314 (82%)]\tLoss: 0.598832\tData (t) 0.199\tBatch (t) 0.411\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:34 | INFO | Rank 0 | Train Epoch: 0 [204224/250314 (82%)]\tLoss: 1.141851\tData (t) 0.217\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:34 | INFO | Rank 0 | Train Epoch: 0 [204256/250314 (82%)]\tLoss: 0.408477\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:35 | INFO | Rank 0 | Train Epoch: 0 [204288/250314 (82%)]\tLoss: 0.597366\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:35 | INFO | Rank 0 | Train Epoch: 0 [204320/250314 (82%)]\tLoss: 0.536368\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:36 | INFO | Rank 0 | Train Epoch: 0 [204352/250314 (82%)]\tLoss: 0.592723\tData (t) 0.218\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:36 | INFO | Rank 0 | Train Epoch: 0 [204384/250314 (82%)]\tLoss: 0.465960\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:37 | INFO | Rank 0 | Train Epoch: 0 [204416/250314 (82%)]\tLoss: 0.337507\tData (t) 0.198\tBatch (t) 0.409\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:37 | INFO | Rank 0 | Train Epoch: 0 [204448/250314 (82%)]\tLoss: 0.631039\tData (t) 0.307\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:38 | INFO | Rank 0 | Train Epoch: 0 [204480/250314 (82%)]\tLoss: 0.388847\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:38 | INFO | Rank 0 | Train Epoch: 0 [204512/250314 (82%)]\tLoss: 0.780894\tData (t) 0.275\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:39 | INFO | Rank 0 | Train Epoch: 0 [204544/250314 (82%)]\tLoss: 0.314492\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:39 | INFO | Rank 0 | Train Epoch: 0 [204576/250314 (82%)]\tLoss: 0.575940\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:40 | INFO | Rank 0 | Train Epoch: 0 [204608/250314 (82%)]\tLoss: 0.696165\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:40 | INFO | Rank 0 | Train Epoch: 0 [204640/250314 (82%)]\tLoss: 0.716032\tData (t) 0.209\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:41 | INFO | Rank 0 | Train Epoch: 0 [204672/250314 (82%)]\tLoss: 0.868685\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:41 | INFO | Rank 0 | Train Epoch: 0 [204704/250314 (82%)]\tLoss: 0.552229\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:42 | INFO | Rank 0 | Train Epoch: 0 [204736/250314 (82%)]\tLoss: 0.405076\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:42 | INFO | Rank 0 | Train Epoch: 0 [204768/250314 (82%)]\tLoss: 0.256647\tData (t) 0.229\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:43 | INFO | Rank 0 | Train Epoch: 0 [204800/250314 (82%)]\tLoss: 0.779937\tData (t) 0.262\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:43 | INFO | Rank 0 | Train Epoch: 0 [204832/250314 (82%)]\tLoss: 0.578882\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:44 | INFO | Rank 0 | Train Epoch: 0 [204864/250314 (82%)]\tLoss: 0.454764\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:44 | INFO | Rank 0 | Train Epoch: 0 [204896/250314 (82%)]\tLoss: 0.604317\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:45 | INFO | Rank 0 | Train Epoch: 0 [204928/250314 (82%)]\tLoss: 0.553740\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:45 | INFO | Rank 0 | Train Epoch: 0 [204960/250314 (82%)]\tLoss: 0.332579\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:46 | INFO | Rank 0 | Train Epoch: 0 [204992/250314 (82%)]\tLoss: 0.849143\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:46 | INFO | Rank 0 | Train Epoch: 0 [205024/250314 (82%)]\tLoss: 0.644818\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:47 | INFO | Rank 0 | Train Epoch: 0 [205056/250314 (82%)]\tLoss: 0.650610\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:47 | INFO | Rank 0 | Train Epoch: 0 [205088/250314 (82%)]\tLoss: 0.465495\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:47 | INFO | Rank 0 | Train Epoch: 0 [205120/250314 (82%)]\tLoss: 0.539941\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:48 | INFO | Rank 0 | Train Epoch: 0 [205152/250314 (82%)]\tLoss: 0.407477\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:48 | INFO | Rank 0 | Train Epoch: 0 [205184/250314 (82%)]\tLoss: 0.566921\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:49 | INFO | Rank 0 | Train Epoch: 0 [205216/250314 (82%)]\tLoss: 0.651614\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:49 | INFO | Rank 0 | Train Epoch: 0 [205248/250314 (82%)]\tLoss: 0.395712\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:50 | INFO | Rank 0 | Train Epoch: 0 [205280/250314 (82%)]\tLoss: 0.833295\tData (t) 0.217\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:50 | INFO | Rank 0 | Train Epoch: 0 [205312/250314 (82%)]\tLoss: 0.495690\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:51 | INFO | Rank 0 | Train Epoch: 0 [205344/250314 (82%)]\tLoss: 0.674319\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:51 | INFO | Rank 0 | Train Epoch: 0 [205376/250314 (82%)]\tLoss: 0.490609\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:52 | INFO | Rank 0 | Train Epoch: 0 [205408/250314 (82%)]\tLoss: 0.546163\tData (t) 0.225\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:52 | INFO | Rank 0 | Train Epoch: 0 [205440/250314 (82%)]\tLoss: 0.699762\tData (t) 0.204\tBatch (t) 0.416\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:53 | INFO | Rank 0 | Train Epoch: 0 [205472/250314 (82%)]\tLoss: 0.782783\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:53 | INFO | Rank 0 | Train Epoch: 0 [205504/250314 (82%)]\tLoss: 0.494197\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:54 | INFO | Rank 0 | Train Epoch: 0 [205536/250314 (82%)]\tLoss: 0.460477\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:54 | INFO | Rank 0 | Train Epoch: 0 [205568/250314 (82%)]\tLoss: 0.824677\tData (t) 0.252\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:55 | INFO | Rank 0 | Train Epoch: 0 [205600/250314 (82%)]\tLoss: 0.498364\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:55 | INFO | Rank 0 | Train Epoch: 0 [205632/250314 (82%)]\tLoss: 0.456605\tData (t) 0.249\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:56 | INFO | Rank 0 | Train Epoch: 0 [205664/250314 (82%)]\tLoss: 0.654675\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:56 | INFO | Rank 0 | Train Epoch: 0 [205696/250314 (82%)]\tLoss: 0.586159\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:57 | INFO | Rank 0 | Train Epoch: 0 [205728/250314 (82%)]\tLoss: 0.345017\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:57 | INFO | Rank 0 | Train Epoch: 0 [205760/250314 (82%)]\tLoss: 0.608500\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:58 | INFO | Rank 0 | Train Epoch: 0 [205792/250314 (82%)]\tLoss: 0.555117\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:58 | INFO | Rank 0 | Train Epoch: 0 [205824/250314 (82%)]\tLoss: 0.323319\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:59 | INFO | Rank 0 | Train Epoch: 0 [205856/250314 (82%)]\tLoss: 0.585853\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:02:59 | INFO | Rank 0 | Train Epoch: 0 [205888/250314 (82%)]\tLoss: 0.854816\tData (t) 0.258\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:00 | INFO | Rank 0 | Train Epoch: 0 [205920/250314 (82%)]\tLoss: 0.366326\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:00 | INFO | Rank 0 | Train Epoch: 0 [205952/250314 (82%)]\tLoss: 0.365271\tData (t) 0.295\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:01 | INFO | Rank 0 | Train Epoch: 0 [205984/250314 (82%)]\tLoss: 0.834169\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:01 | INFO | Rank 0 | Train Epoch: 0 [206016/250314 (82%)]\tLoss: 0.827887\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:02 | INFO | Rank 0 | Train Epoch: 0 [206048/250314 (82%)]\tLoss: 0.451807\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:02 | INFO | Rank 0 | Train Epoch: 0 [206080/250314 (82%)]\tLoss: 0.847189\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:02 | INFO | Rank 0 | Train Epoch: 0 [206112/250314 (82%)]\tLoss: 0.484591\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:03 | INFO | Rank 0 | Train Epoch: 0 [206144/250314 (82%)]\tLoss: 0.887028\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:03 | INFO | Rank 0 | Train Epoch: 0 [206176/250314 (82%)]\tLoss: 0.630849\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:04 | INFO | Rank 0 | Train Epoch: 0 [206208/250314 (82%)]\tLoss: 0.612392\tData (t) 0.226\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:04 | INFO | Rank 0 | Train Epoch: 0 [206240/250314 (82%)]\tLoss: 0.816705\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:05 | INFO | Rank 0 | Train Epoch: 0 [206272/250314 (82%)]\tLoss: 0.784438\tData (t) 0.231\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:05 | INFO | Rank 0 | Train Epoch: 0 [206304/250314 (82%)]\tLoss: 0.521100\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:06 | INFO | Rank 0 | Train Epoch: 0 [206336/250314 (82%)]\tLoss: 0.637657\tData (t) 0.215\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:06 | INFO | Rank 0 | Train Epoch: 0 [206368/250314 (82%)]\tLoss: 0.427443\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:07 | INFO | Rank 0 | Train Epoch: 0 [206400/250314 (82%)]\tLoss: 0.801446\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:07 | INFO | Rank 0 | Train Epoch: 0 [206432/250314 (82%)]\tLoss: 0.641245\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:08 | INFO | Rank 0 | Train Epoch: 0 [206464/250314 (82%)]\tLoss: 0.741037\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:08 | INFO | Rank 0 | Train Epoch: 0 [206496/250314 (82%)]\tLoss: 0.492344\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:09 | INFO | Rank 0 | Train Epoch: 0 [206528/250314 (83%)]\tLoss: 0.825218\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:09 | INFO | Rank 0 | Train Epoch: 0 [206560/250314 (83%)]\tLoss: 0.656963\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:10 | INFO | Rank 0 | Train Epoch: 0 [206592/250314 (83%)]\tLoss: 0.400166\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:10 | INFO | Rank 0 | Train Epoch: 0 [206624/250314 (83%)]\tLoss: 0.225246\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:10 | INFO | Rank 0 | Train Epoch: 0 [206656/250314 (83%)]\tLoss: 0.537359\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:11 | INFO | Rank 0 | Train Epoch: 0 [206688/250314 (83%)]\tLoss: 0.752431\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:12 | INFO | Rank 0 | Train Epoch: 0 [206720/250314 (83%)]\tLoss: 0.634897\tData (t) 0.363\tBatch (t) 0.575\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:12 | INFO | Rank 0 | Train Epoch: 0 [206752/250314 (83%)]\tLoss: 0.501324\tData (t) 0.318\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:13 | INFO | Rank 0 | Train Epoch: 0 [206784/250314 (83%)]\tLoss: 0.695692\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:13 | INFO | Rank 0 | Train Epoch: 0 [206816/250314 (83%)]\tLoss: 0.622341\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:14 | INFO | Rank 0 | Train Epoch: 0 [206848/250314 (83%)]\tLoss: 0.869144\tData (t) 0.240\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:14 | INFO | Rank 0 | Train Epoch: 0 [206880/250314 (83%)]\tLoss: 0.556625\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:15 | INFO | Rank 0 | Train Epoch: 0 [206912/250314 (83%)]\tLoss: 0.931984\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:15 | INFO | Rank 0 | Train Epoch: 0 [206944/250314 (83%)]\tLoss: 0.849065\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:16 | INFO | Rank 0 | Train Epoch: 0 [206976/250314 (83%)]\tLoss: 0.279883\tData (t) 0.308\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:16 | INFO | Rank 0 | Train Epoch: 0 [207008/250314 (83%)]\tLoss: 0.827315\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:16 | INFO | Rank 0 | Train Epoch: 0 [207040/250314 (83%)]\tLoss: 0.651103\tData (t) 0.229\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:17 | INFO | Rank 0 | Train Epoch: 0 [207072/250314 (83%)]\tLoss: 0.838003\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:17 | INFO | Rank 0 | Train Epoch: 0 [207104/250314 (83%)]\tLoss: 0.528994\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:18 | INFO | Rank 0 | Train Epoch: 0 [207136/250314 (83%)]\tLoss: 0.545486\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:19 | INFO | Rank 0 | Train Epoch: 0 [207168/250314 (83%)]\tLoss: 0.529572\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:19 | INFO | Rank 0 | Train Epoch: 0 [207200/250314 (83%)]\tLoss: 1.008953\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:20 | INFO | Rank 0 | Train Epoch: 0 [207232/250314 (83%)]\tLoss: 0.512833\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:20 | INFO | Rank 0 | Train Epoch: 0 [207264/250314 (83%)]\tLoss: 0.751718\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:21 | INFO | Rank 0 | Train Epoch: 0 [207296/250314 (83%)]\tLoss: 0.600638\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:21 | INFO | Rank 0 | Train Epoch: 0 [207328/250314 (83%)]\tLoss: 0.548339\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:22 | INFO | Rank 0 | Train Epoch: 0 [207360/250314 (83%)]\tLoss: 0.462185\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:22 | INFO | Rank 0 | Train Epoch: 0 [207392/250314 (83%)]\tLoss: 0.678713\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:23 | INFO | Rank 0 | Train Epoch: 0 [207424/250314 (83%)]\tLoss: 1.001559\tData (t) 0.340\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:23 | INFO | Rank 0 | Train Epoch: 0 [207456/250314 (83%)]\tLoss: 0.512328\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:24 | INFO | Rank 0 | Train Epoch: 0 [207488/250314 (83%)]\tLoss: 1.000174\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:24 | INFO | Rank 0 | Train Epoch: 0 [207520/250314 (83%)]\tLoss: 1.017412\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:25 | INFO | Rank 0 | Train Epoch: 0 [207552/250314 (83%)]\tLoss: 0.925748\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:25 | INFO | Rank 0 | Train Epoch: 0 [207584/250314 (83%)]\tLoss: 0.857591\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:25 | INFO | Rank 0 | Train Epoch: 0 [207616/250314 (83%)]\tLoss: 0.587592\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:26 | INFO | Rank 0 | Train Epoch: 0 [207648/250314 (83%)]\tLoss: 0.464432\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:26 | INFO | Rank 0 | Train Epoch: 0 [207680/250314 (83%)]\tLoss: 0.733209\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:27 | INFO | Rank 0 | Train Epoch: 0 [207712/250314 (83%)]\tLoss: 0.984006\tData (t) 0.263\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:27 | INFO | Rank 0 | Train Epoch: 0 [207744/250314 (83%)]\tLoss: 0.825275\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:28 | INFO | Rank 0 | Train Epoch: 0 [207776/250314 (83%)]\tLoss: 0.514590\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:28 | INFO | Rank 0 | Train Epoch: 0 [207808/250314 (83%)]\tLoss: 0.714812\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:29 | INFO | Rank 0 | Train Epoch: 0 [207840/250314 (83%)]\tLoss: 0.539408\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:29 | INFO | Rank 0 | Train Epoch: 0 [207872/250314 (83%)]\tLoss: 0.922461\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:30 | INFO | Rank 0 | Train Epoch: 0 [207904/250314 (83%)]\tLoss: 0.734695\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:30 | INFO | Rank 0 | Train Epoch: 0 [207936/250314 (83%)]\tLoss: 0.615006\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:31 | INFO | Rank 0 | Train Epoch: 0 [207968/250314 (83%)]\tLoss: 0.570767\tData (t) 0.257\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:31 | INFO | Rank 0 | Train Epoch: 0 [208000/250314 (83%)]\tLoss: 0.564126\tData (t) 0.233\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:32 | INFO | Rank 0 | Train Epoch: 0 [208032/250314 (83%)]\tLoss: 0.588619\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:32 | INFO | Rank 0 | Train Epoch: 0 [208064/250314 (83%)]\tLoss: 0.777123\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:33 | INFO | Rank 0 | Train Epoch: 0 [208096/250314 (83%)]\tLoss: 0.552426\tData (t) 0.435\tBatch (t) 0.646\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:33 | INFO | Rank 0 | Train Epoch: 0 [208128/250314 (83%)]\tLoss: 0.492585\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:34 | INFO | Rank 0 | Train Epoch: 0 [208160/250314 (83%)]\tLoss: 1.083148\tData (t) 0.280\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:34 | INFO | Rank 0 | Train Epoch: 0 [208192/250314 (83%)]\tLoss: 0.959446\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:35 | INFO | Rank 0 | Train Epoch: 0 [208224/250314 (83%)]\tLoss: 0.883842\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:35 | INFO | Rank 0 | Train Epoch: 0 [208256/250314 (83%)]\tLoss: 0.509991\tData (t) 0.226\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:36 | INFO | Rank 0 | Train Epoch: 0 [208288/250314 (83%)]\tLoss: 0.976233\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:36 | INFO | Rank 0 | Train Epoch: 0 [208320/250314 (83%)]\tLoss: 0.455982\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:37 | INFO | Rank 0 | Train Epoch: 0 [208352/250314 (83%)]\tLoss: 0.792831\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:37 | INFO | Rank 0 | Train Epoch: 0 [208384/250314 (83%)]\tLoss: 0.549201\tData (t) 0.309\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:38 | INFO | Rank 0 | Train Epoch: 0 [208416/250314 (83%)]\tLoss: 0.661618\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:38 | INFO | Rank 0 | Train Epoch: 0 [208448/250314 (83%)]\tLoss: 0.542470\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:39 | INFO | Rank 0 | Train Epoch: 0 [208480/250314 (83%)]\tLoss: 0.722482\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:39 | INFO | Rank 0 | Train Epoch: 0 [208512/250314 (83%)]\tLoss: 0.765162\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:39 | INFO | Rank 0 | Train Epoch: 0 [208544/250314 (83%)]\tLoss: 0.571733\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:40 | INFO | Rank 0 | Train Epoch: 0 [208576/250314 (83%)]\tLoss: 0.639657\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:40 | INFO | Rank 0 | Train Epoch: 0 [208608/250314 (83%)]\tLoss: 0.417607\tData (t) 0.180\tBatch (t) 0.392\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:41 | INFO | Rank 0 | Train Epoch: 0 [208640/250314 (83%)]\tLoss: 0.393740\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:41 | INFO | Rank 0 | Train Epoch: 0 [208672/250314 (83%)]\tLoss: 0.910000\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:42 | INFO | Rank 0 | Train Epoch: 0 [208704/250314 (83%)]\tLoss: 0.936073\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:42 | INFO | Rank 0 | Train Epoch: 0 [208736/250314 (83%)]\tLoss: 0.547755\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:43 | INFO | Rank 0 | Train Epoch: 0 [208768/250314 (83%)]\tLoss: 0.488940\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:43 | INFO | Rank 0 | Train Epoch: 0 [208800/250314 (83%)]\tLoss: 0.443498\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:44 | INFO | Rank 0 | Train Epoch: 0 [208832/250314 (83%)]\tLoss: 0.561136\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:44 | INFO | Rank 0 | Train Epoch: 0 [208864/250314 (83%)]\tLoss: 0.935475\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:45 | INFO | Rank 0 | Train Epoch: 0 [208896/250314 (83%)]\tLoss: 0.766108\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:45 | INFO | Rank 0 | Train Epoch: 0 [208928/250314 (83%)]\tLoss: 0.480174\tData (t) 0.221\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:46 | INFO | Rank 0 | Train Epoch: 0 [208960/250314 (83%)]\tLoss: 0.805259\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:46 | INFO | Rank 0 | Train Epoch: 0 [208992/250314 (83%)]\tLoss: 0.616789\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:46 | INFO | Rank 0 | Train Epoch: 0 [209024/250314 (84%)]\tLoss: 0.787248\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:47 | INFO | Rank 0 | Train Epoch: 0 [209056/250314 (84%)]\tLoss: 0.364513\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:47 | INFO | Rank 0 | Train Epoch: 0 [209088/250314 (84%)]\tLoss: 0.633368\tData (t) 0.285\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:48 | INFO | Rank 0 | Train Epoch: 0 [209120/250314 (84%)]\tLoss: 0.387467\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:48 | INFO | Rank 0 | Train Epoch: 0 [209152/250314 (84%)]\tLoss: 1.077021\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:49 | INFO | Rank 0 | Train Epoch: 0 [209184/250314 (84%)]\tLoss: 0.829330\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:49 | INFO | Rank 0 | Train Epoch: 0 [209216/250314 (84%)]\tLoss: 0.889060\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:50 | INFO | Rank 0 | Train Epoch: 0 [209248/250314 (84%)]\tLoss: 0.662339\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:50 | INFO | Rank 0 | Train Epoch: 0 [209280/250314 (84%)]\tLoss: 0.572910\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:51 | INFO | Rank 0 | Train Epoch: 0 [209312/250314 (84%)]\tLoss: 0.517537\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:51 | INFO | Rank 0 | Train Epoch: 0 [209344/250314 (84%)]\tLoss: 0.535195\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:52 | INFO | Rank 0 | Train Epoch: 0 [209376/250314 (84%)]\tLoss: 0.954080\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:52 | INFO | Rank 0 | Train Epoch: 0 [209408/250314 (84%)]\tLoss: 0.645209\tData (t) 0.238\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:53 | INFO | Rank 0 | Train Epoch: 0 [209440/250314 (84%)]\tLoss: 1.055166\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:53 | INFO | Rank 0 | Train Epoch: 0 [209472/250314 (84%)]\tLoss: 0.484149\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:54 | INFO | Rank 0 | Train Epoch: 0 [209504/250314 (84%)]\tLoss: 0.728043\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:54 | INFO | Rank 0 | Train Epoch: 0 [209536/250314 (84%)]\tLoss: 0.701570\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:55 | INFO | Rank 0 | Train Epoch: 0 [209568/250314 (84%)]\tLoss: 0.603987\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:55 | INFO | Rank 0 | Train Epoch: 0 [209600/250314 (84%)]\tLoss: 0.589832\tData (t) 0.207\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:56 | INFO | Rank 0 | Train Epoch: 0 [209632/250314 (84%)]\tLoss: 0.900225\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:56 | INFO | Rank 0 | Train Epoch: 0 [209664/250314 (84%)]\tLoss: 0.709314\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:57 | INFO | Rank 0 | Train Epoch: 0 [209696/250314 (84%)]\tLoss: 0.545369\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:57 | INFO | Rank 0 | Train Epoch: 0 [209728/250314 (84%)]\tLoss: 0.590423\tData (t) 0.184\tBatch (t) 0.396\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:58 | INFO | Rank 0 | Train Epoch: 0 [209760/250314 (84%)]\tLoss: 0.360890\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:58 | INFO | Rank 0 | Train Epoch: 0 [209792/250314 (84%)]\tLoss: 0.468717\tData (t) 0.224\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:59 | INFO | Rank 0 | Train Epoch: 0 [209824/250314 (84%)]\tLoss: 0.537818\tData (t) 0.216\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:59 | INFO | Rank 0 | Train Epoch: 0 [209856/250314 (84%)]\tLoss: 0.492198\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:03:59 | INFO | Rank 0 | Train Epoch: 0 [209888/250314 (84%)]\tLoss: 0.883536\tData (t) 0.208\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:00 | INFO | Rank 0 | Train Epoch: 0 [209920/250314 (84%)]\tLoss: 0.597599\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:00 | INFO | Rank 0 | Train Epoch: 0 [209952/250314 (84%)]\tLoss: 0.515403\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:01 | INFO | Rank 0 | Train Epoch: 0 [209984/250314 (84%)]\tLoss: 0.521761\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:01 | INFO | Rank 0 | Train Epoch: 0 [210016/250314 (84%)]\tLoss: 0.580927\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:02 | INFO | Rank 0 | Train Epoch: 0 [210048/250314 (84%)]\tLoss: 0.479226\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:02 | INFO | Rank 0 | Train Epoch: 0 [210080/250314 (84%)]\tLoss: 0.620453\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:03 | INFO | Rank 0 | Train Epoch: 0 [210112/250314 (84%)]\tLoss: 0.684511\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:03 | INFO | Rank 0 | Train Epoch: 0 [210144/250314 (84%)]\tLoss: 0.753043\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:04 | INFO | Rank 0 | Train Epoch: 0 [210176/250314 (84%)]\tLoss: 0.652668\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:04 | INFO | Rank 0 | Train Epoch: 0 [210208/250314 (84%)]\tLoss: 0.361464\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:05 | INFO | Rank 0 | Train Epoch: 0 [210240/250314 (84%)]\tLoss: 0.558758\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:05 | INFO | Rank 0 | Train Epoch: 0 [210272/250314 (84%)]\tLoss: 0.225842\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:06 | INFO | Rank 0 | Train Epoch: 0 [210304/250314 (84%)]\tLoss: 0.891453\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:06 | INFO | Rank 0 | Train Epoch: 0 [210336/250314 (84%)]\tLoss: 0.740757\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:07 | INFO | Rank 0 | Train Epoch: 0 [210368/250314 (84%)]\tLoss: 0.984618\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:07 | INFO | Rank 0 | Train Epoch: 0 [210400/250314 (84%)]\tLoss: 0.592783\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:08 | INFO | Rank 0 | Train Epoch: 0 [210432/250314 (84%)]\tLoss: 0.377733\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:08 | INFO | Rank 0 | Train Epoch: 0 [210464/250314 (84%)]\tLoss: 0.831168\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:09 | INFO | Rank 0 | Train Epoch: 0 [210496/250314 (84%)]\tLoss: 0.506392\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:09 | INFO | Rank 0 | Train Epoch: 0 [210528/250314 (84%)]\tLoss: 0.465701\tData (t) 0.336\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:10 | INFO | Rank 0 | Train Epoch: 0 [210560/250314 (84%)]\tLoss: 0.519194\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:10 | INFO | Rank 0 | Train Epoch: 0 [210592/250314 (84%)]\tLoss: 0.760267\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:11 | INFO | Rank 0 | Train Epoch: 0 [210624/250314 (84%)]\tLoss: 0.526152\tData (t) 0.211\tBatch (t) 0.422\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:11 | INFO | Rank 0 | Train Epoch: 0 [210656/250314 (84%)]\tLoss: 0.815730\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:12 | INFO | Rank 0 | Train Epoch: 0 [210688/250314 (84%)]\tLoss: 0.665246\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:12 | INFO | Rank 0 | Train Epoch: 0 [210720/250314 (84%)]\tLoss: 0.503407\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:13 | INFO | Rank 0 | Train Epoch: 0 [210752/250314 (84%)]\tLoss: 0.533066\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:13 | INFO | Rank 0 | Train Epoch: 0 [210784/250314 (84%)]\tLoss: 0.741843\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:14 | INFO | Rank 0 | Train Epoch: 0 [210816/250314 (84%)]\tLoss: 1.059917\tData (t) 0.345\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:14 | INFO | Rank 0 | Train Epoch: 0 [210848/250314 (84%)]\tLoss: 0.656929\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:15 | INFO | Rank 0 | Train Epoch: 0 [210880/250314 (84%)]\tLoss: 0.495193\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:15 | INFO | Rank 0 | Train Epoch: 0 [210912/250314 (84%)]\tLoss: 0.459057\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:15 | INFO | Rank 0 | Train Epoch: 0 [210944/250314 (84%)]\tLoss: 0.720642\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:16 | INFO | Rank 0 | Train Epoch: 0 [210976/250314 (84%)]\tLoss: 0.641831\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:16 | INFO | Rank 0 | Train Epoch: 0 [211008/250314 (84%)]\tLoss: 0.945612\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:17 | INFO | Rank 0 | Train Epoch: 0 [211040/250314 (84%)]\tLoss: 0.338404\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:17 | INFO | Rank 0 | Train Epoch: 0 [211072/250314 (84%)]\tLoss: 0.542626\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:18 | INFO | Rank 0 | Train Epoch: 0 [211104/250314 (84%)]\tLoss: 0.644849\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:18 | INFO | Rank 0 | Train Epoch: 0 [211136/250314 (84%)]\tLoss: 0.572331\tData (t) 0.348\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:19 | INFO | Rank 0 | Train Epoch: 0 [211168/250314 (84%)]\tLoss: 0.729634\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:20 | INFO | Rank 0 | Train Epoch: 0 [211200/250314 (84%)]\tLoss: 0.429001\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:20 | INFO | Rank 0 | Train Epoch: 0 [211232/250314 (84%)]\tLoss: 0.688683\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:20 | INFO | Rank 0 | Train Epoch: 0 [211264/250314 (84%)]\tLoss: 0.532322\tData (t) 0.204\tBatch (t) 0.415\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:21 | INFO | Rank 0 | Train Epoch: 0 [211296/250314 (84%)]\tLoss: 0.716760\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:21 | INFO | Rank 0 | Train Epoch: 0 [211328/250314 (84%)]\tLoss: 0.448891\tData (t) 0.324\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:22 | INFO | Rank 0 | Train Epoch: 0 [211360/250314 (84%)]\tLoss: 0.874106\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:22 | INFO | Rank 0 | Train Epoch: 0 [211392/250314 (84%)]\tLoss: 0.926846\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:23 | INFO | Rank 0 | Train Epoch: 0 [211424/250314 (84%)]\tLoss: 0.693927\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:23 | INFO | Rank 0 | Train Epoch: 0 [211456/250314 (84%)]\tLoss: 0.239979\tData (t) 0.349\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:24 | INFO | Rank 0 | Train Epoch: 0 [211488/250314 (84%)]\tLoss: 0.790526\tData (t) 0.450\tBatch (t) 0.661\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:25 | INFO | Rank 0 | Train Epoch: 0 [211520/250314 (85%)]\tLoss: 0.843952\tData (t) 0.206\tBatch (t) 0.418\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:25 | INFO | Rank 0 | Train Epoch: 0 [211552/250314 (85%)]\tLoss: 0.413832\tData (t) 0.231\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:25 | INFO | Rank 0 | Train Epoch: 0 [211584/250314 (85%)]\tLoss: 0.674340\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:26 | INFO | Rank 0 | Train Epoch: 0 [211616/250314 (85%)]\tLoss: 0.887272\tData (t) 0.219\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:26 | INFO | Rank 0 | Train Epoch: 0 [211648/250314 (85%)]\tLoss: 0.713395\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:27 | INFO | Rank 0 | Train Epoch: 0 [211680/250314 (85%)]\tLoss: 0.745531\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:27 | INFO | Rank 0 | Train Epoch: 0 [211712/250314 (85%)]\tLoss: 0.480921\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:28 | INFO | Rank 0 | Train Epoch: 0 [211744/250314 (85%)]\tLoss: 0.753117\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:28 | INFO | Rank 0 | Train Epoch: 0 [211776/250314 (85%)]\tLoss: 0.451668\tData (t) 0.346\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:29 | INFO | Rank 0 | Train Epoch: 0 [211808/250314 (85%)]\tLoss: 0.560506\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:29 | INFO | Rank 0 | Train Epoch: 0 [211840/250314 (85%)]\tLoss: 0.435764\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:30 | INFO | Rank 0 | Train Epoch: 0 [211872/250314 (85%)]\tLoss: 0.523072\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:30 | INFO | Rank 0 | Train Epoch: 0 [211904/250314 (85%)]\tLoss: 1.002015\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:31 | INFO | Rank 0 | Train Epoch: 0 [211936/250314 (85%)]\tLoss: 0.533813\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:31 | INFO | Rank 0 | Train Epoch: 0 [211968/250314 (85%)]\tLoss: 0.391970\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:32 | INFO | Rank 0 | Train Epoch: 0 [212000/250314 (85%)]\tLoss: 0.753825\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:32 | INFO | Rank 0 | Train Epoch: 0 [212032/250314 (85%)]\tLoss: 0.981524\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:33 | INFO | Rank 0 | Train Epoch: 0 [212064/250314 (85%)]\tLoss: 0.385933\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:33 | INFO | Rank 0 | Train Epoch: 0 [212096/250314 (85%)]\tLoss: 0.303034\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:34 | INFO | Rank 0 | Train Epoch: 0 [212128/250314 (85%)]\tLoss: 0.355434\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:34 | INFO | Rank 0 | Train Epoch: 0 [212160/250314 (85%)]\tLoss: 0.429995\tData (t) 0.331\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:35 | INFO | Rank 0 | Train Epoch: 0 [212192/250314 (85%)]\tLoss: 0.368099\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:35 | INFO | Rank 0 | Train Epoch: 0 [212224/250314 (85%)]\tLoss: 0.620892\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:36 | INFO | Rank 0 | Train Epoch: 0 [212256/250314 (85%)]\tLoss: 0.955688\tData (t) 0.216\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:36 | INFO | Rank 0 | Train Epoch: 0 [212288/250314 (85%)]\tLoss: 0.653030\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:37 | INFO | Rank 0 | Train Epoch: 0 [212320/250314 (85%)]\tLoss: 0.365906\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:37 | INFO | Rank 0 | Train Epoch: 0 [212352/250314 (85%)]\tLoss: 0.723530\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:38 | INFO | Rank 0 | Train Epoch: 0 [212384/250314 (85%)]\tLoss: 0.846568\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:38 | INFO | Rank 0 | Train Epoch: 0 [212416/250314 (85%)]\tLoss: 0.976030\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:38 | INFO | Rank 0 | Train Epoch: 0 [212448/250314 (85%)]\tLoss: 0.653440\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:39 | INFO | Rank 0 | Train Epoch: 0 [212480/250314 (85%)]\tLoss: 0.923591\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:39 | INFO | Rank 0 | Train Epoch: 0 [212512/250314 (85%)]\tLoss: 0.433013\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:40 | INFO | Rank 0 | Train Epoch: 0 [212544/250314 (85%)]\tLoss: 0.417216\tData (t) 0.198\tBatch (t) 0.410\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:40 | INFO | Rank 0 | Train Epoch: 0 [212576/250314 (85%)]\tLoss: 0.762570\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:41 | INFO | Rank 0 | Train Epoch: 0 [212608/250314 (85%)]\tLoss: 0.601362\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:41 | INFO | Rank 0 | Train Epoch: 0 [212640/250314 (85%)]\tLoss: 0.506457\tData (t) 0.345\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:42 | INFO | Rank 0 | Train Epoch: 0 [212672/250314 (85%)]\tLoss: 0.945134\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:42 | INFO | Rank 0 | Train Epoch: 0 [212704/250314 (85%)]\tLoss: 0.571260\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:43 | INFO | Rank 0 | Train Epoch: 0 [212736/250314 (85%)]\tLoss: 0.686117\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:43 | INFO | Rank 0 | Train Epoch: 0 [212768/250314 (85%)]\tLoss: 0.617476\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:44 | INFO | Rank 0 | Train Epoch: 0 [212800/250314 (85%)]\tLoss: 0.348803\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:44 | INFO | Rank 0 | Train Epoch: 0 [212832/250314 (85%)]\tLoss: 0.580397\tData (t) 0.440\tBatch (t) 0.652\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:45 | INFO | Rank 0 | Train Epoch: 0 [212864/250314 (85%)]\tLoss: 0.394601\tData (t) 0.503\tBatch (t) 0.714\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:46 | INFO | Rank 0 | Train Epoch: 0 [212896/250314 (85%)]\tLoss: 0.616963\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:46 | INFO | Rank 0 | Train Epoch: 0 [212928/250314 (85%)]\tLoss: 0.586266\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:47 | INFO | Rank 0 | Train Epoch: 0 [212960/250314 (85%)]\tLoss: 0.511966\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:47 | INFO | Rank 0 | Train Epoch: 0 [212992/250314 (85%)]\tLoss: 1.143629\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:48 | INFO | Rank 0 | Train Epoch: 0 [213024/250314 (85%)]\tLoss: 0.428144\tData (t) 0.289\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:48 | INFO | Rank 0 | Train Epoch: 0 [213056/250314 (85%)]\tLoss: 0.975292\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:48 | INFO | Rank 0 | Train Epoch: 0 [213088/250314 (85%)]\tLoss: 0.273496\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:49 | INFO | Rank 0 | Train Epoch: 0 [213120/250314 (85%)]\tLoss: 0.703106\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:50 | INFO | Rank 0 | Train Epoch: 0 [213152/250314 (85%)]\tLoss: 0.568109\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:50 | INFO | Rank 0 | Train Epoch: 0 [213184/250314 (85%)]\tLoss: 0.513240\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:50 | INFO | Rank 0 | Train Epoch: 0 [213216/250314 (85%)]\tLoss: 0.302050\tData (t) 0.184\tBatch (t) 0.395\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:51 | INFO | Rank 0 | Train Epoch: 0 [213248/250314 (85%)]\tLoss: 0.738852\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:51 | INFO | Rank 0 | Train Epoch: 0 [213280/250314 (85%)]\tLoss: 0.375732\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:52 | INFO | Rank 0 | Train Epoch: 0 [213312/250314 (85%)]\tLoss: 0.788646\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:52 | INFO | Rank 0 | Train Epoch: 0 [213344/250314 (85%)]\tLoss: 0.779749\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:53 | INFO | Rank 0 | Train Epoch: 0 [213376/250314 (85%)]\tLoss: 0.528598\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:53 | INFO | Rank 0 | Train Epoch: 0 [213408/250314 (85%)]\tLoss: 0.827176\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:54 | INFO | Rank 0 | Train Epoch: 0 [213440/250314 (85%)]\tLoss: 0.609491\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:54 | INFO | Rank 0 | Train Epoch: 0 [213472/250314 (85%)]\tLoss: 0.545513\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:55 | INFO | Rank 0 | Train Epoch: 0 [213504/250314 (85%)]\tLoss: 0.704045\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:55 | INFO | Rank 0 | Train Epoch: 0 [213536/250314 (85%)]\tLoss: 0.776133\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:56 | INFO | Rank 0 | Train Epoch: 0 [213568/250314 (85%)]\tLoss: 0.551748\tData (t) 0.349\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:56 | INFO | Rank 0 | Train Epoch: 0 [213600/250314 (85%)]\tLoss: 0.801045\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:57 | INFO | Rank 0 | Train Epoch: 0 [213632/250314 (85%)]\tLoss: 0.603252\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:57 | INFO | Rank 0 | Train Epoch: 0 [213664/250314 (85%)]\tLoss: 0.317624\tData (t) 0.289\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:58 | INFO | Rank 0 | Train Epoch: 0 [213696/250314 (85%)]\tLoss: 1.059675\tData (t) 0.257\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:58 | INFO | Rank 0 | Train Epoch: 0 [213728/250314 (85%)]\tLoss: 0.525487\tData (t) 0.329\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:59 | INFO | Rank 0 | Train Epoch: 0 [213760/250314 (85%)]\tLoss: 0.499008\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:04:59 | INFO | Rank 0 | Train Epoch: 0 [213792/250314 (85%)]\tLoss: 0.373960\tData (t) 0.342\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:05:00 | INFO | Rank 0 | Train Epoch: 0 [213824/250314 (85%)]\tLoss: 0.649252\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:05:00 | INFO | Rank 0 | Train Epoch: 0 [213856/250314 (85%)]\tLoss: 0.646336\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:05:01 | INFO | Rank 0 | Train Epoch: 0 [213888/250314 (85%)]\tLoss: 1.062726\tData (t) 0.271\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:05:01 | INFO | Rank 0 | Train Epoch: 0 [213920/250314 (85%)]\tLoss: 0.908316\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.590\n",
      "2022-11-09,14:05:02 | INFO | Rank 0 | Train Epoch: 0 [213952/250314 (85%)]\tLoss: 0.643851\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:03 | INFO | Rank 0 | Train Epoch: 0 [213984/250314 (85%)]\tLoss: 0.691395\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:03 | INFO | Rank 0 | Train Epoch: 0 [214016/250314 (86%)]\tLoss: 0.378557\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:04 | INFO | Rank 0 | Train Epoch: 0 [214048/250314 (86%)]\tLoss: 0.845211\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:04 | INFO | Rank 0 | Train Epoch: 0 [214080/250314 (86%)]\tLoss: 0.528319\tData (t) 0.229\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:04 | INFO | Rank 0 | Train Epoch: 0 [214112/250314 (86%)]\tLoss: 0.821533\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:05 | INFO | Rank 0 | Train Epoch: 0 [214144/250314 (86%)]\tLoss: 0.942038\tData (t) 0.326\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:06 | INFO | Rank 0 | Train Epoch: 0 [214176/250314 (86%)]\tLoss: 0.787904\tData (t) 0.332\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:06 | INFO | Rank 0 | Train Epoch: 0 [214208/250314 (86%)]\tLoss: 0.692931\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:06 | INFO | Rank 0 | Train Epoch: 0 [214240/250314 (86%)]\tLoss: 0.728500\tData (t) 0.219\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:07 | INFO | Rank 0 | Train Epoch: 0 [214272/250314 (86%)]\tLoss: 0.269857\tData (t) 0.222\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:07 | INFO | Rank 0 | Train Epoch: 0 [214304/250314 (86%)]\tLoss: 0.646661\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:08 | INFO | Rank 0 | Train Epoch: 0 [214336/250314 (86%)]\tLoss: 0.820064\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:08 | INFO | Rank 0 | Train Epoch: 0 [214368/250314 (86%)]\tLoss: 0.561491\tData (t) 0.343\tBatch (t) 0.555\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:09 | INFO | Rank 0 | Train Epoch: 0 [214400/250314 (86%)]\tLoss: 0.672571\tData (t) 0.195\tBatch (t) 0.406\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:09 | INFO | Rank 0 | Train Epoch: 0 [214432/250314 (86%)]\tLoss: 0.897857\tData (t) 0.307\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:10 | INFO | Rank 0 | Train Epoch: 0 [214464/250314 (86%)]\tLoss: 0.655155\tData (t) 0.217\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:10 | INFO | Rank 0 | Train Epoch: 0 [214496/250314 (86%)]\tLoss: 0.556012\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:11 | INFO | Rank 0 | Train Epoch: 0 [214528/250314 (86%)]\tLoss: 0.596791\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:11 | INFO | Rank 0 | Train Epoch: 0 [214560/250314 (86%)]\tLoss: 0.708549\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:12 | INFO | Rank 0 | Train Epoch: 0 [214592/250314 (86%)]\tLoss: 0.728837\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:12 | INFO | Rank 0 | Train Epoch: 0 [214624/250314 (86%)]\tLoss: 0.483580\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:13 | INFO | Rank 0 | Train Epoch: 0 [214656/250314 (86%)]\tLoss: 0.553134\tData (t) 0.208\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:13 | INFO | Rank 0 | Train Epoch: 0 [214688/250314 (86%)]\tLoss: 0.614121\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:14 | INFO | Rank 0 | Train Epoch: 0 [214720/250314 (86%)]\tLoss: 0.473517\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:14 | INFO | Rank 0 | Train Epoch: 0 [214752/250314 (86%)]\tLoss: 0.752961\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:14 | INFO | Rank 0 | Train Epoch: 0 [214784/250314 (86%)]\tLoss: 0.429500\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:15 | INFO | Rank 0 | Train Epoch: 0 [214816/250314 (86%)]\tLoss: 0.660063\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:15 | INFO | Rank 0 | Train Epoch: 0 [214848/250314 (86%)]\tLoss: 0.603389\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:16 | INFO | Rank 0 | Train Epoch: 0 [214880/250314 (86%)]\tLoss: 0.271822\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:16 | INFO | Rank 0 | Train Epoch: 0 [214912/250314 (86%)]\tLoss: 0.573273\tData (t) 0.233\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:17 | INFO | Rank 0 | Train Epoch: 0 [214944/250314 (86%)]\tLoss: 0.407451\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:17 | INFO | Rank 0 | Train Epoch: 0 [214976/250314 (86%)]\tLoss: 0.702764\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:18 | INFO | Rank 0 | Train Epoch: 0 [215008/250314 (86%)]\tLoss: 0.567023\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:18 | INFO | Rank 0 | Train Epoch: 0 [215040/250314 (86%)]\tLoss: 1.043130\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:19 | INFO | Rank 0 | Train Epoch: 0 [215072/250314 (86%)]\tLoss: 0.766609\tData (t) 0.326\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:19 | INFO | Rank 0 | Train Epoch: 0 [215104/250314 (86%)]\tLoss: 0.519107\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:20 | INFO | Rank 0 | Train Epoch: 0 [215136/250314 (86%)]\tLoss: 0.775501\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:20 | INFO | Rank 0 | Train Epoch: 0 [215168/250314 (86%)]\tLoss: 0.553220\tData (t) 0.298\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:21 | INFO | Rank 0 | Train Epoch: 0 [215200/250314 (86%)]\tLoss: 0.462107\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:21 | INFO | Rank 0 | Train Epoch: 0 [215232/250314 (86%)]\tLoss: 0.609903\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:22 | INFO | Rank 0 | Train Epoch: 0 [215264/250314 (86%)]\tLoss: 0.696458\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:22 | INFO | Rank 0 | Train Epoch: 0 [215296/250314 (86%)]\tLoss: 0.761729\tData (t) 0.208\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:23 | INFO | Rank 0 | Train Epoch: 0 [215328/250314 (86%)]\tLoss: 0.634512\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:23 | INFO | Rank 0 | Train Epoch: 0 [215360/250314 (86%)]\tLoss: 0.815825\tData (t) 0.336\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:24 | INFO | Rank 0 | Train Epoch: 0 [215392/250314 (86%)]\tLoss: 0.670408\tData (t) 0.307\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:24 | INFO | Rank 0 | Train Epoch: 0 [215424/250314 (86%)]\tLoss: 0.514023\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:25 | INFO | Rank 0 | Train Epoch: 0 [215456/250314 (86%)]\tLoss: 0.518561\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:25 | INFO | Rank 0 | Train Epoch: 0 [215488/250314 (86%)]\tLoss: 0.665467\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:26 | INFO | Rank 0 | Train Epoch: 0 [215520/250314 (86%)]\tLoss: 0.862179\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:26 | INFO | Rank 0 | Train Epoch: 0 [215552/250314 (86%)]\tLoss: 0.572317\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:27 | INFO | Rank 0 | Train Epoch: 0 [215584/250314 (86%)]\tLoss: 0.566103\tData (t) 0.176\tBatch (t) 0.387\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:27 | INFO | Rank 0 | Train Epoch: 0 [215616/250314 (86%)]\tLoss: 0.501770\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:28 | INFO | Rank 0 | Train Epoch: 0 [215648/250314 (86%)]\tLoss: 0.941862\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:28 | INFO | Rank 0 | Train Epoch: 0 [215680/250314 (86%)]\tLoss: 0.736404\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:28 | INFO | Rank 0 | Train Epoch: 0 [215712/250314 (86%)]\tLoss: 0.386527\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:29 | INFO | Rank 0 | Train Epoch: 0 [215744/250314 (86%)]\tLoss: 0.431365\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:29 | INFO | Rank 0 | Train Epoch: 0 [215776/250314 (86%)]\tLoss: 0.649204\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:30 | INFO | Rank 0 | Train Epoch: 0 [215808/250314 (86%)]\tLoss: 0.436524\tData (t) 0.222\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:30 | INFO | Rank 0 | Train Epoch: 0 [215840/250314 (86%)]\tLoss: 0.909053\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:31 | INFO | Rank 0 | Train Epoch: 0 [215872/250314 (86%)]\tLoss: 0.670905\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:31 | INFO | Rank 0 | Train Epoch: 0 [215904/250314 (86%)]\tLoss: 0.854691\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:32 | INFO | Rank 0 | Train Epoch: 0 [215936/250314 (86%)]\tLoss: 0.539508\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:32 | INFO | Rank 0 | Train Epoch: 0 [215968/250314 (86%)]\tLoss: 1.017843\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:33 | INFO | Rank 0 | Train Epoch: 0 [216000/250314 (86%)]\tLoss: 0.438226\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:33 | INFO | Rank 0 | Train Epoch: 0 [216032/250314 (86%)]\tLoss: 0.539254\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:34 | INFO | Rank 0 | Train Epoch: 0 [216064/250314 (86%)]\tLoss: 0.738755\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:34 | INFO | Rank 0 | Train Epoch: 0 [216096/250314 (86%)]\tLoss: 0.606978\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:35 | INFO | Rank 0 | Train Epoch: 0 [216128/250314 (86%)]\tLoss: 0.388226\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:35 | INFO | Rank 0 | Train Epoch: 0 [216160/250314 (86%)]\tLoss: 0.422362\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:36 | INFO | Rank 0 | Train Epoch: 0 [216192/250314 (86%)]\tLoss: 0.220408\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:36 | INFO | Rank 0 | Train Epoch: 0 [216224/250314 (86%)]\tLoss: 0.489072\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:37 | INFO | Rank 0 | Train Epoch: 0 [216256/250314 (86%)]\tLoss: 1.017400\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:37 | INFO | Rank 0 | Train Epoch: 0 [216288/250314 (86%)]\tLoss: 0.827885\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:38 | INFO | Rank 0 | Train Epoch: 0 [216320/250314 (86%)]\tLoss: 1.122741\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:38 | INFO | Rank 0 | Train Epoch: 0 [216352/250314 (86%)]\tLoss: 0.662388\tData (t) 0.307\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:39 | INFO | Rank 0 | Train Epoch: 0 [216384/250314 (86%)]\tLoss: 0.678589\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:39 | INFO | Rank 0 | Train Epoch: 0 [216416/250314 (86%)]\tLoss: 0.350211\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:40 | INFO | Rank 0 | Train Epoch: 0 [216448/250314 (86%)]\tLoss: 0.803016\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:40 | INFO | Rank 0 | Train Epoch: 0 [216480/250314 (86%)]\tLoss: 0.624221\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:40 | INFO | Rank 0 | Train Epoch: 0 [216512/250314 (86%)]\tLoss: 0.565744\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:41 | INFO | Rank 0 | Train Epoch: 0 [216544/250314 (87%)]\tLoss: 0.533854\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:41 | INFO | Rank 0 | Train Epoch: 0 [216576/250314 (87%)]\tLoss: 0.661761\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:42 | INFO | Rank 0 | Train Epoch: 0 [216608/250314 (87%)]\tLoss: 0.641735\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:42 | INFO | Rank 0 | Train Epoch: 0 [216640/250314 (87%)]\tLoss: 0.809424\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:43 | INFO | Rank 0 | Train Epoch: 0 [216672/250314 (87%)]\tLoss: 0.313417\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:43 | INFO | Rank 0 | Train Epoch: 0 [216704/250314 (87%)]\tLoss: 0.607544\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:44 | INFO | Rank 0 | Train Epoch: 0 [216736/250314 (87%)]\tLoss: 0.813052\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:44 | INFO | Rank 0 | Train Epoch: 0 [216768/250314 (87%)]\tLoss: 0.699319\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:45 | INFO | Rank 0 | Train Epoch: 0 [216800/250314 (87%)]\tLoss: 1.297834\tData (t) 0.302\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:45 | INFO | Rank 0 | Train Epoch: 0 [216832/250314 (87%)]\tLoss: 0.570322\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:46 | INFO | Rank 0 | Train Epoch: 0 [216864/250314 (87%)]\tLoss: 0.813002\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:46 | INFO | Rank 0 | Train Epoch: 0 [216896/250314 (87%)]\tLoss: 0.565414\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:47 | INFO | Rank 0 | Train Epoch: 0 [216928/250314 (87%)]\tLoss: 0.866137\tData (t) 0.225\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:47 | INFO | Rank 0 | Train Epoch: 0 [216960/250314 (87%)]\tLoss: 0.534953\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:48 | INFO | Rank 0 | Train Epoch: 0 [216992/250314 (87%)]\tLoss: 0.681569\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:49 | INFO | Rank 0 | Train Epoch: 0 [217024/250314 (87%)]\tLoss: 0.850331\tData (t) 0.533\tBatch (t) 0.744\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:49 | INFO | Rank 0 | Train Epoch: 0 [217056/250314 (87%)]\tLoss: 1.049017\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:50 | INFO | Rank 0 | Train Epoch: 0 [217088/250314 (87%)]\tLoss: 0.673426\tData (t) 0.314\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:50 | INFO | Rank 0 | Train Epoch: 0 [217120/250314 (87%)]\tLoss: 1.007410\tData (t) 0.321\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:51 | INFO | Rank 0 | Train Epoch: 0 [217152/250314 (87%)]\tLoss: 0.640430\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:51 | INFO | Rank 0 | Train Epoch: 0 [217184/250314 (87%)]\tLoss: 0.651360\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:52 | INFO | Rank 0 | Train Epoch: 0 [217216/250314 (87%)]\tLoss: 0.454993\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:52 | INFO | Rank 0 | Train Epoch: 0 [217248/250314 (87%)]\tLoss: 0.391872\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:53 | INFO | Rank 0 | Train Epoch: 0 [217280/250314 (87%)]\tLoss: 0.692289\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:53 | INFO | Rank 0 | Train Epoch: 0 [217312/250314 (87%)]\tLoss: 0.668951\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:54 | INFO | Rank 0 | Train Epoch: 0 [217344/250314 (87%)]\tLoss: 0.744700\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:54 | INFO | Rank 0 | Train Epoch: 0 [217376/250314 (87%)]\tLoss: 0.974722\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:55 | INFO | Rank 0 | Train Epoch: 0 [217408/250314 (87%)]\tLoss: 0.567033\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:55 | INFO | Rank 0 | Train Epoch: 0 [217440/250314 (87%)]\tLoss: 0.672664\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:55 | INFO | Rank 0 | Train Epoch: 0 [217472/250314 (87%)]\tLoss: 0.348326\tData (t) 0.200\tBatch (t) 0.411\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:56 | INFO | Rank 0 | Train Epoch: 0 [217504/250314 (87%)]\tLoss: 0.622494\tData (t) 0.314\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:56 | INFO | Rank 0 | Train Epoch: 0 [217536/250314 (87%)]\tLoss: 0.501647\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:57 | INFO | Rank 0 | Train Epoch: 0 [217568/250314 (87%)]\tLoss: 0.678783\tData (t) 0.212\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:57 | INFO | Rank 0 | Train Epoch: 0 [217600/250314 (87%)]\tLoss: 0.408523\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:58 | INFO | Rank 0 | Train Epoch: 0 [217632/250314 (87%)]\tLoss: 0.834819\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:58 | INFO | Rank 0 | Train Epoch: 0 [217664/250314 (87%)]\tLoss: 0.476513\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:59 | INFO | Rank 0 | Train Epoch: 0 [217696/250314 (87%)]\tLoss: 0.649722\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:05:59 | INFO | Rank 0 | Train Epoch: 0 [217728/250314 (87%)]\tLoss: 0.580128\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:00 | INFO | Rank 0 | Train Epoch: 0 [217760/250314 (87%)]\tLoss: 1.000500\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:00 | INFO | Rank 0 | Train Epoch: 0 [217792/250314 (87%)]\tLoss: 0.575224\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:01 | INFO | Rank 0 | Train Epoch: 0 [217824/250314 (87%)]\tLoss: 0.708480\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:01 | INFO | Rank 0 | Train Epoch: 0 [217856/250314 (87%)]\tLoss: 0.569552\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:02 | INFO | Rank 0 | Train Epoch: 0 [217888/250314 (87%)]\tLoss: 0.228147\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:02 | INFO | Rank 0 | Train Epoch: 0 [217920/250314 (87%)]\tLoss: 0.534900\tData (t) 0.335\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:03 | INFO | Rank 0 | Train Epoch: 0 [217952/250314 (87%)]\tLoss: 0.514598\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:03 | INFO | Rank 0 | Train Epoch: 0 [217984/250314 (87%)]\tLoss: 0.618133\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:04 | INFO | Rank 0 | Train Epoch: 0 [218016/250314 (87%)]\tLoss: 0.385304\tData (t) 0.355\tBatch (t) 0.567\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:04 | INFO | Rank 0 | Train Epoch: 0 [218048/250314 (87%)]\tLoss: 0.440916\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:05 | INFO | Rank 0 | Train Epoch: 0 [218080/250314 (87%)]\tLoss: 0.630721\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:05 | INFO | Rank 0 | Train Epoch: 0 [218112/250314 (87%)]\tLoss: 1.067863\tData (t) 0.350\tBatch (t) 0.564\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:06 | INFO | Rank 0 | Train Epoch: 0 [218144/250314 (87%)]\tLoss: 0.810444\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:06 | INFO | Rank 0 | Train Epoch: 0 [218176/250314 (87%)]\tLoss: 0.797987\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:07 | INFO | Rank 0 | Train Epoch: 0 [218208/250314 (87%)]\tLoss: 0.604581\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:07 | INFO | Rank 0 | Train Epoch: 0 [218240/250314 (87%)]\tLoss: 0.506571\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:08 | INFO | Rank 0 | Train Epoch: 0 [218272/250314 (87%)]\tLoss: 0.613890\tData (t) 0.219\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:08 | INFO | Rank 0 | Train Epoch: 0 [218304/250314 (87%)]\tLoss: 0.310616\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:09 | INFO | Rank 0 | Train Epoch: 0 [218336/250314 (87%)]\tLoss: 0.824274\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:09 | INFO | Rank 0 | Train Epoch: 0 [218368/250314 (87%)]\tLoss: 0.417902\tData (t) 0.211\tBatch (t) 0.422\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:10 | INFO | Rank 0 | Train Epoch: 0 [218400/250314 (87%)]\tLoss: 0.680096\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:10 | INFO | Rank 0 | Train Epoch: 0 [218432/250314 (87%)]\tLoss: 0.544850\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:10 | INFO | Rank 0 | Train Epoch: 0 [218464/250314 (87%)]\tLoss: 0.770921\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:11 | INFO | Rank 0 | Train Epoch: 0 [218496/250314 (87%)]\tLoss: 0.419125\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:11 | INFO | Rank 0 | Train Epoch: 0 [218528/250314 (87%)]\tLoss: 0.809398\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:12 | INFO | Rank 0 | Train Epoch: 0 [218560/250314 (87%)]\tLoss: 0.936621\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:12 | INFO | Rank 0 | Train Epoch: 0 [218592/250314 (87%)]\tLoss: 0.929756\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:13 | INFO | Rank 0 | Train Epoch: 0 [218624/250314 (87%)]\tLoss: 0.564333\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:13 | INFO | Rank 0 | Train Epoch: 0 [218656/250314 (87%)]\tLoss: 0.571808\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:14 | INFO | Rank 0 | Train Epoch: 0 [218688/250314 (87%)]\tLoss: 1.094764\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:14 | INFO | Rank 0 | Train Epoch: 0 [218720/250314 (87%)]\tLoss: 0.704847\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:15 | INFO | Rank 0 | Train Epoch: 0 [218752/250314 (87%)]\tLoss: 0.625556\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:15 | INFO | Rank 0 | Train Epoch: 0 [218784/250314 (87%)]\tLoss: 0.545810\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:16 | INFO | Rank 0 | Train Epoch: 0 [218816/250314 (87%)]\tLoss: 0.250987\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:16 | INFO | Rank 0 | Train Epoch: 0 [218848/250314 (87%)]\tLoss: 0.539421\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:17 | INFO | Rank 0 | Train Epoch: 0 [218880/250314 (87%)]\tLoss: 0.503406\tData (t) 0.240\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:17 | INFO | Rank 0 | Train Epoch: 0 [218912/250314 (87%)]\tLoss: 0.932664\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:18 | INFO | Rank 0 | Train Epoch: 0 [218944/250314 (87%)]\tLoss: 0.445122\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:18 | INFO | Rank 0 | Train Epoch: 0 [218976/250314 (87%)]\tLoss: 0.346119\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:19 | INFO | Rank 0 | Train Epoch: 0 [219008/250314 (87%)]\tLoss: 0.759764\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:19 | INFO | Rank 0 | Train Epoch: 0 [219040/250314 (88%)]\tLoss: 0.503369\tData (t) 0.212\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:20 | INFO | Rank 0 | Train Epoch: 0 [219072/250314 (88%)]\tLoss: 0.411245\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:20 | INFO | Rank 0 | Train Epoch: 0 [219104/250314 (88%)]\tLoss: 0.721686\tData (t) 0.320\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:21 | INFO | Rank 0 | Train Epoch: 0 [219136/250314 (88%)]\tLoss: 1.321851\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:21 | INFO | Rank 0 | Train Epoch: 0 [219168/250314 (88%)]\tLoss: 0.627648\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:22 | INFO | Rank 0 | Train Epoch: 0 [219200/250314 (88%)]\tLoss: 0.671241\tData (t) 0.293\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:22 | INFO | Rank 0 | Train Epoch: 0 [219232/250314 (88%)]\tLoss: 0.567778\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:23 | INFO | Rank 0 | Train Epoch: 0 [219264/250314 (88%)]\tLoss: 1.038170\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:23 | INFO | Rank 0 | Train Epoch: 0 [219296/250314 (88%)]\tLoss: 0.195205\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:23 | INFO | Rank 0 | Train Epoch: 0 [219328/250314 (88%)]\tLoss: 0.558346\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:24 | INFO | Rank 0 | Train Epoch: 0 [219360/250314 (88%)]\tLoss: 1.010573\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:24 | INFO | Rank 0 | Train Epoch: 0 [219392/250314 (88%)]\tLoss: 0.760890\tData (t) 0.340\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:25 | INFO | Rank 0 | Train Epoch: 0 [219424/250314 (88%)]\tLoss: 0.572660\tData (t) 0.345\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:26 | INFO | Rank 0 | Train Epoch: 0 [219456/250314 (88%)]\tLoss: 0.699366\tData (t) 0.278\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:26 | INFO | Rank 0 | Train Epoch: 0 [219488/250314 (88%)]\tLoss: 0.532655\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:27 | INFO | Rank 0 | Train Epoch: 0 [219520/250314 (88%)]\tLoss: 0.909850\tData (t) 0.307\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:27 | INFO | Rank 0 | Train Epoch: 0 [219552/250314 (88%)]\tLoss: 1.017022\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:28 | INFO | Rank 0 | Train Epoch: 0 [219584/250314 (88%)]\tLoss: 0.572413\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:28 | INFO | Rank 0 | Train Epoch: 0 [219616/250314 (88%)]\tLoss: 0.586176\tData (t) 0.356\tBatch (t) 0.568\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:29 | INFO | Rank 0 | Train Epoch: 0 [219648/250314 (88%)]\tLoss: 0.670263\tData (t) 0.252\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:29 | INFO | Rank 0 | Train Epoch: 0 [219680/250314 (88%)]\tLoss: 0.728354\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:30 | INFO | Rank 0 | Train Epoch: 0 [219712/250314 (88%)]\tLoss: 0.690895\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:30 | INFO | Rank 0 | Train Epoch: 0 [219744/250314 (88%)]\tLoss: 0.436118\tData (t) 0.250\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:30 | INFO | Rank 0 | Train Epoch: 0 [219776/250314 (88%)]\tLoss: 0.701363\tData (t) 0.219\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:31 | INFO | Rank 0 | Train Epoch: 0 [219808/250314 (88%)]\tLoss: 0.772383\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:31 | INFO | Rank 0 | Train Epoch: 0 [219840/250314 (88%)]\tLoss: 0.791819\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:32 | INFO | Rank 0 | Train Epoch: 0 [219872/250314 (88%)]\tLoss: 0.240172\tData (t) 0.209\tBatch (t) 0.421\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:32 | INFO | Rank 0 | Train Epoch: 0 [219904/250314 (88%)]\tLoss: 0.834081\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:33 | INFO | Rank 0 | Train Epoch: 0 [219936/250314 (88%)]\tLoss: 0.866856\tData (t) 0.198\tBatch (t) 0.410\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:33 | INFO | Rank 0 | Train Epoch: 0 [219968/250314 (88%)]\tLoss: 0.707610\tData (t) 0.333\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:34 | INFO | Rank 0 | Train Epoch: 0 [220000/250314 (88%)]\tLoss: 0.518915\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:34 | INFO | Rank 0 | Train Epoch: 0 [220032/250314 (88%)]\tLoss: 0.691427\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:35 | INFO | Rank 0 | Train Epoch: 0 [220064/250314 (88%)]\tLoss: 0.636186\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:35 | INFO | Rank 0 | Train Epoch: 0 [220096/250314 (88%)]\tLoss: 0.561131\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:36 | INFO | Rank 0 | Train Epoch: 0 [220128/250314 (88%)]\tLoss: 0.580240\tData (t) 0.209\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:36 | INFO | Rank 0 | Train Epoch: 0 [220160/250314 (88%)]\tLoss: 0.441458\tData (t) 0.242\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:37 | INFO | Rank 0 | Train Epoch: 0 [220192/250314 (88%)]\tLoss: 0.381538\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:37 | INFO | Rank 0 | Train Epoch: 0 [220224/250314 (88%)]\tLoss: 0.380441\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:38 | INFO | Rank 0 | Train Epoch: 0 [220256/250314 (88%)]\tLoss: 0.726676\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:38 | INFO | Rank 0 | Train Epoch: 0 [220288/250314 (88%)]\tLoss: 0.323354\tData (t) 0.223\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:39 | INFO | Rank 0 | Train Epoch: 0 [220320/250314 (88%)]\tLoss: 0.586483\tData (t) 0.440\tBatch (t) 0.652\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:39 | INFO | Rank 0 | Train Epoch: 0 [220352/250314 (88%)]\tLoss: 0.509120\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:40 | INFO | Rank 0 | Train Epoch: 0 [220384/250314 (88%)]\tLoss: 0.649275\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:40 | INFO | Rank 0 | Train Epoch: 0 [220416/250314 (88%)]\tLoss: 0.714043\tData (t) 0.324\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:41 | INFO | Rank 0 | Train Epoch: 0 [220448/250314 (88%)]\tLoss: 0.612076\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:41 | INFO | Rank 0 | Train Epoch: 0 [220480/250314 (88%)]\tLoss: 0.767678\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:42 | INFO | Rank 0 | Train Epoch: 0 [220512/250314 (88%)]\tLoss: 0.547324\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:42 | INFO | Rank 0 | Train Epoch: 0 [220544/250314 (88%)]\tLoss: 0.298964\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:43 | INFO | Rank 0 | Train Epoch: 0 [220576/250314 (88%)]\tLoss: 0.538911\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:43 | INFO | Rank 0 | Train Epoch: 0 [220608/250314 (88%)]\tLoss: 0.757756\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:44 | INFO | Rank 0 | Train Epoch: 0 [220640/250314 (88%)]\tLoss: 0.779148\tData (t) 0.343\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:44 | INFO | Rank 0 | Train Epoch: 0 [220672/250314 (88%)]\tLoss: 0.217126\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:45 | INFO | Rank 0 | Train Epoch: 0 [220704/250314 (88%)]\tLoss: 0.857785\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:45 | INFO | Rank 0 | Train Epoch: 0 [220736/250314 (88%)]\tLoss: 0.932824\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:46 | INFO | Rank 0 | Train Epoch: 0 [220768/250314 (88%)]\tLoss: 0.755314\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:46 | INFO | Rank 0 | Train Epoch: 0 [220800/250314 (88%)]\tLoss: 0.399898\tData (t) 0.334\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:47 | INFO | Rank 0 | Train Epoch: 0 [220832/250314 (88%)]\tLoss: 0.682843\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:47 | INFO | Rank 0 | Train Epoch: 0 [220864/250314 (88%)]\tLoss: 0.670438\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:48 | INFO | Rank 0 | Train Epoch: 0 [220896/250314 (88%)]\tLoss: 0.612819\tData (t) 0.210\tBatch (t) 0.421\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:48 | INFO | Rank 0 | Train Epoch: 0 [220928/250314 (88%)]\tLoss: 1.313308\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:49 | INFO | Rank 0 | Train Epoch: 0 [220960/250314 (88%)]\tLoss: 0.504715\tData (t) 0.331\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:49 | INFO | Rank 0 | Train Epoch: 0 [220992/250314 (88%)]\tLoss: 0.542825\tData (t) 0.210\tBatch (t) 0.422\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:50 | INFO | Rank 0 | Train Epoch: 0 [221024/250314 (88%)]\tLoss: 0.723255\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:50 | INFO | Rank 0 | Train Epoch: 0 [221056/250314 (88%)]\tLoss: 0.609123\tData (t) 0.330\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:51 | INFO | Rank 0 | Train Epoch: 0 [221088/250314 (88%)]\tLoss: 0.779099\tData (t) 0.219\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:51 | INFO | Rank 0 | Train Epoch: 0 [221120/250314 (88%)]\tLoss: 1.071597\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:52 | INFO | Rank 0 | Train Epoch: 0 [221152/250314 (88%)]\tLoss: 0.660184\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:52 | INFO | Rank 0 | Train Epoch: 0 [221184/250314 (88%)]\tLoss: 0.670835\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:52 | INFO | Rank 0 | Train Epoch: 0 [221216/250314 (88%)]\tLoss: 0.389553\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:53 | INFO | Rank 0 | Train Epoch: 0 [221248/250314 (88%)]\tLoss: 0.374853\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:53 | INFO | Rank 0 | Train Epoch: 0 [221280/250314 (88%)]\tLoss: 0.831373\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:54 | INFO | Rank 0 | Train Epoch: 0 [221312/250314 (88%)]\tLoss: 0.651080\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:54 | INFO | Rank 0 | Train Epoch: 0 [221344/250314 (88%)]\tLoss: 0.632423\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:55 | INFO | Rank 0 | Train Epoch: 0 [221376/250314 (88%)]\tLoss: 0.549787\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:55 | INFO | Rank 0 | Train Epoch: 0 [221408/250314 (88%)]\tLoss: 0.599660\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:56 | INFO | Rank 0 | Train Epoch: 0 [221440/250314 (88%)]\tLoss: 0.650984\tData (t) 0.366\tBatch (t) 0.578\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:56 | INFO | Rank 0 | Train Epoch: 0 [221472/250314 (88%)]\tLoss: 0.639134\tData (t) 0.189\tBatch (t) 0.400\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:57 | INFO | Rank 0 | Train Epoch: 0 [221504/250314 (88%)]\tLoss: 1.120266\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:57 | INFO | Rank 0 | Train Epoch: 0 [221536/250314 (89%)]\tLoss: 0.329806\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:58 | INFO | Rank 0 | Train Epoch: 0 [221568/250314 (89%)]\tLoss: 0.380270\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:58 | INFO | Rank 0 | Train Epoch: 0 [221600/250314 (89%)]\tLoss: 0.431757\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:59 | INFO | Rank 0 | Train Epoch: 0 [221632/250314 (89%)]\tLoss: 0.780746\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:06:59 | INFO | Rank 0 | Train Epoch: 0 [221664/250314 (89%)]\tLoss: 0.688323\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:00 | INFO | Rank 0 | Train Epoch: 0 [221696/250314 (89%)]\tLoss: 0.552209\tData (t) 0.334\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:00 | INFO | Rank 0 | Train Epoch: 0 [221728/250314 (89%)]\tLoss: 0.894331\tData (t) 0.222\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:01 | INFO | Rank 0 | Train Epoch: 0 [221760/250314 (89%)]\tLoss: 0.471451\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:01 | INFO | Rank 0 | Train Epoch: 0 [221792/250314 (89%)]\tLoss: 0.616415\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:02 | INFO | Rank 0 | Train Epoch: 0 [221824/250314 (89%)]\tLoss: 0.962495\tData (t) 0.281\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:02 | INFO | Rank 0 | Train Epoch: 0 [221856/250314 (89%)]\tLoss: 0.718802\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:03 | INFO | Rank 0 | Train Epoch: 0 [221888/250314 (89%)]\tLoss: 0.329504\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:03 | INFO | Rank 0 | Train Epoch: 0 [221920/250314 (89%)]\tLoss: 0.395709\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:04 | INFO | Rank 0 | Train Epoch: 0 [221952/250314 (89%)]\tLoss: 0.376434\tData (t) 0.206\tBatch (t) 0.417\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:04 | INFO | Rank 0 | Train Epoch: 0 [221984/250314 (89%)]\tLoss: 0.768060\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:05 | INFO | Rank 0 | Train Epoch: 0 [222016/250314 (89%)]\tLoss: 0.565643\tData (t) 0.352\tBatch (t) 0.564\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:05 | INFO | Rank 0 | Train Epoch: 0 [222048/250314 (89%)]\tLoss: 0.702722\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:06 | INFO | Rank 0 | Train Epoch: 0 [222080/250314 (89%)]\tLoss: 0.743048\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:06 | INFO | Rank 0 | Train Epoch: 0 [222112/250314 (89%)]\tLoss: 0.936988\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:07 | INFO | Rank 0 | Train Epoch: 0 [222144/250314 (89%)]\tLoss: 0.457721\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:07 | INFO | Rank 0 | Train Epoch: 0 [222176/250314 (89%)]\tLoss: 0.817791\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:07 | INFO | Rank 0 | Train Epoch: 0 [222208/250314 (89%)]\tLoss: 0.632215\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:08 | INFO | Rank 0 | Train Epoch: 0 [222240/250314 (89%)]\tLoss: 0.315257\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:08 | INFO | Rank 0 | Train Epoch: 0 [222272/250314 (89%)]\tLoss: 0.639426\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:09 | INFO | Rank 0 | Train Epoch: 0 [222304/250314 (89%)]\tLoss: 0.601558\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:09 | INFO | Rank 0 | Train Epoch: 0 [222336/250314 (89%)]\tLoss: 0.522982\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:10 | INFO | Rank 0 | Train Epoch: 0 [222368/250314 (89%)]\tLoss: 0.864497\tData (t) 0.268\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:10 | INFO | Rank 0 | Train Epoch: 0 [222400/250314 (89%)]\tLoss: 0.878034\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:11 | INFO | Rank 0 | Train Epoch: 0 [222432/250314 (89%)]\tLoss: 0.389810\tData (t) 0.296\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:11 | INFO | Rank 0 | Train Epoch: 0 [222464/250314 (89%)]\tLoss: 0.592188\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:12 | INFO | Rank 0 | Train Epoch: 0 [222496/250314 (89%)]\tLoss: 0.543437\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:12 | INFO | Rank 0 | Train Epoch: 0 [222528/250314 (89%)]\tLoss: 0.350249\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:13 | INFO | Rank 0 | Train Epoch: 0 [222560/250314 (89%)]\tLoss: 0.237441\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:13 | INFO | Rank 0 | Train Epoch: 0 [222592/250314 (89%)]\tLoss: 0.530012\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:14 | INFO | Rank 0 | Train Epoch: 0 [222624/250314 (89%)]\tLoss: 0.473542\tData (t) 0.218\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:14 | INFO | Rank 0 | Train Epoch: 0 [222656/250314 (89%)]\tLoss: 0.842885\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:15 | INFO | Rank 0 | Train Epoch: 0 [222688/250314 (89%)]\tLoss: 0.673762\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:15 | INFO | Rank 0 | Train Epoch: 0 [222720/250314 (89%)]\tLoss: 0.500237\tData (t) 0.219\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:16 | INFO | Rank 0 | Train Epoch: 0 [222752/250314 (89%)]\tLoss: 0.880814\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:16 | INFO | Rank 0 | Train Epoch: 0 [222784/250314 (89%)]\tLoss: 0.677015\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:17 | INFO | Rank 0 | Train Epoch: 0 [222816/250314 (89%)]\tLoss: 0.687555\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:17 | INFO | Rank 0 | Train Epoch: 0 [222848/250314 (89%)]\tLoss: 0.792266\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:18 | INFO | Rank 0 | Train Epoch: 0 [222880/250314 (89%)]\tLoss: 1.287246\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:18 | INFO | Rank 0 | Train Epoch: 0 [222912/250314 (89%)]\tLoss: 0.352183\tData (t) 0.275\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:19 | INFO | Rank 0 | Train Epoch: 0 [222944/250314 (89%)]\tLoss: 0.732651\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:19 | INFO | Rank 0 | Train Epoch: 0 [222976/250314 (89%)]\tLoss: 0.534663\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:20 | INFO | Rank 0 | Train Epoch: 0 [223008/250314 (89%)]\tLoss: 0.378682\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:20 | INFO | Rank 0 | Train Epoch: 0 [223040/250314 (89%)]\tLoss: 0.404544\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:21 | INFO | Rank 0 | Train Epoch: 0 [223072/250314 (89%)]\tLoss: 0.490958\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:21 | INFO | Rank 0 | Train Epoch: 0 [223104/250314 (89%)]\tLoss: 1.155082\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:21 | INFO | Rank 0 | Train Epoch: 0 [223136/250314 (89%)]\tLoss: 0.444738\tData (t) 0.228\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:22 | INFO | Rank 0 | Train Epoch: 0 [223168/250314 (89%)]\tLoss: 0.587049\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:22 | INFO | Rank 0 | Train Epoch: 0 [223200/250314 (89%)]\tLoss: 0.767901\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:23 | INFO | Rank 0 | Train Epoch: 0 [223232/250314 (89%)]\tLoss: 0.689587\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:23 | INFO | Rank 0 | Train Epoch: 0 [223264/250314 (89%)]\tLoss: 0.301668\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:24 | INFO | Rank 0 | Train Epoch: 0 [223296/250314 (89%)]\tLoss: 1.080020\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:24 | INFO | Rank 0 | Train Epoch: 0 [223328/250314 (89%)]\tLoss: 0.279364\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:25 | INFO | Rank 0 | Train Epoch: 0 [223360/250314 (89%)]\tLoss: 0.502929\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:25 | INFO | Rank 0 | Train Epoch: 0 [223392/250314 (89%)]\tLoss: 0.902339\tData (t) 0.222\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:26 | INFO | Rank 0 | Train Epoch: 0 [223424/250314 (89%)]\tLoss: 0.794184\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:26 | INFO | Rank 0 | Train Epoch: 0 [223456/250314 (89%)]\tLoss: 0.640623\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:27 | INFO | Rank 0 | Train Epoch: 0 [223488/250314 (89%)]\tLoss: 0.869512\tData (t) 0.218\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:27 | INFO | Rank 0 | Train Epoch: 0 [223520/250314 (89%)]\tLoss: 0.494235\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:28 | INFO | Rank 0 | Train Epoch: 0 [223552/250314 (89%)]\tLoss: 0.599084\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:28 | INFO | Rank 0 | Train Epoch: 0 [223584/250314 (89%)]\tLoss: 0.967503\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:29 | INFO | Rank 0 | Train Epoch: 0 [223616/250314 (89%)]\tLoss: 0.921137\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:29 | INFO | Rank 0 | Train Epoch: 0 [223648/250314 (89%)]\tLoss: 0.845668\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:30 | INFO | Rank 0 | Train Epoch: 0 [223680/250314 (89%)]\tLoss: 0.364640\tData (t) 0.200\tBatch (t) 0.412\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:30 | INFO | Rank 0 | Train Epoch: 0 [223712/250314 (89%)]\tLoss: 0.343637\tData (t) 0.360\tBatch (t) 0.572\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:31 | INFO | Rank 0 | Train Epoch: 0 [223744/250314 (89%)]\tLoss: 0.557874\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:31 | INFO | Rank 0 | Train Epoch: 0 [223776/250314 (89%)]\tLoss: 0.342378\tData (t) 0.210\tBatch (t) 0.421\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:31 | INFO | Rank 0 | Train Epoch: 0 [223808/250314 (89%)]\tLoss: 0.485875\tData (t) 0.205\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:32 | INFO | Rank 0 | Train Epoch: 0 [223840/250314 (89%)]\tLoss: 0.470328\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:32 | INFO | Rank 0 | Train Epoch: 0 [223872/250314 (89%)]\tLoss: 0.847086\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:33 | INFO | Rank 0 | Train Epoch: 0 [223904/250314 (89%)]\tLoss: 0.982988\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:33 | INFO | Rank 0 | Train Epoch: 0 [223936/250314 (89%)]\tLoss: 0.375555\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:34 | INFO | Rank 0 | Train Epoch: 0 [223968/250314 (89%)]\tLoss: 0.721340\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:34 | INFO | Rank 0 | Train Epoch: 0 [224000/250314 (89%)]\tLoss: 0.598734\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:35 | INFO | Rank 0 | Train Epoch: 0 [224032/250314 (90%)]\tLoss: 0.544775\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:35 | INFO | Rank 0 | Train Epoch: 0 [224064/250314 (90%)]\tLoss: 0.423422\tData (t) 0.325\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:36 | INFO | Rank 0 | Train Epoch: 0 [224096/250314 (90%)]\tLoss: 0.549842\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:36 | INFO | Rank 0 | Train Epoch: 0 [224128/250314 (90%)]\tLoss: 0.610846\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:37 | INFO | Rank 0 | Train Epoch: 0 [224160/250314 (90%)]\tLoss: 0.798411\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:37 | INFO | Rank 0 | Train Epoch: 0 [224192/250314 (90%)]\tLoss: 0.513340\tData (t) 0.218\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:38 | INFO | Rank 0 | Train Epoch: 0 [224224/250314 (90%)]\tLoss: 0.933861\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:38 | INFO | Rank 0 | Train Epoch: 0 [224256/250314 (90%)]\tLoss: 0.487748\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:39 | INFO | Rank 0 | Train Epoch: 0 [224288/250314 (90%)]\tLoss: 0.820946\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:39 | INFO | Rank 0 | Train Epoch: 0 [224320/250314 (90%)]\tLoss: 0.967347\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:40 | INFO | Rank 0 | Train Epoch: 0 [224352/250314 (90%)]\tLoss: 0.274493\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:40 | INFO | Rank 0 | Train Epoch: 0 [224384/250314 (90%)]\tLoss: 0.669096\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:41 | INFO | Rank 0 | Train Epoch: 0 [224416/250314 (90%)]\tLoss: 0.505105\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:41 | INFO | Rank 0 | Train Epoch: 0 [224448/250314 (90%)]\tLoss: 0.636444\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:42 | INFO | Rank 0 | Train Epoch: 0 [224480/250314 (90%)]\tLoss: 0.464376\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:42 | INFO | Rank 0 | Train Epoch: 0 [224512/250314 (90%)]\tLoss: 0.494545\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:43 | INFO | Rank 0 | Train Epoch: 0 [224544/250314 (90%)]\tLoss: 0.514721\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:43 | INFO | Rank 0 | Train Epoch: 0 [224576/250314 (90%)]\tLoss: 0.534054\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:44 | INFO | Rank 0 | Train Epoch: 0 [224608/250314 (90%)]\tLoss: 0.736444\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:44 | INFO | Rank 0 | Train Epoch: 0 [224640/250314 (90%)]\tLoss: 0.803532\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:45 | INFO | Rank 0 | Train Epoch: 0 [224672/250314 (90%)]\tLoss: 0.713226\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:45 | INFO | Rank 0 | Train Epoch: 0 [224704/250314 (90%)]\tLoss: 0.664502\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:46 | INFO | Rank 0 | Train Epoch: 0 [224736/250314 (90%)]\tLoss: 0.661671\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:46 | INFO | Rank 0 | Train Epoch: 0 [224768/250314 (90%)]\tLoss: 0.340959\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:47 | INFO | Rank 0 | Train Epoch: 0 [224800/250314 (90%)]\tLoss: 0.566798\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:47 | INFO | Rank 0 | Train Epoch: 0 [224832/250314 (90%)]\tLoss: 0.388192\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:48 | INFO | Rank 0 | Train Epoch: 0 [224864/250314 (90%)]\tLoss: 0.506308\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:48 | INFO | Rank 0 | Train Epoch: 0 [224896/250314 (90%)]\tLoss: 0.757806\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:49 | INFO | Rank 0 | Train Epoch: 0 [224928/250314 (90%)]\tLoss: 0.631890\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:49 | INFO | Rank 0 | Train Epoch: 0 [224960/250314 (90%)]\tLoss: 0.854339\tData (t) 0.259\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:49 | INFO | Rank 0 | Train Epoch: 0 [224992/250314 (90%)]\tLoss: 0.440334\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:50 | INFO | Rank 0 | Train Epoch: 0 [225024/250314 (90%)]\tLoss: 0.452013\tData (t) 0.218\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:51 | INFO | Rank 0 | Train Epoch: 0 [225056/250314 (90%)]\tLoss: 0.588238\tData (t) 0.405\tBatch (t) 0.616\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:51 | INFO | Rank 0 | Train Epoch: 0 [225088/250314 (90%)]\tLoss: 0.394508\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:52 | INFO | Rank 0 | Train Epoch: 0 [225120/250314 (90%)]\tLoss: 0.464126\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:52 | INFO | Rank 0 | Train Epoch: 0 [225152/250314 (90%)]\tLoss: 0.391042\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:52 | INFO | Rank 0 | Train Epoch: 0 [225184/250314 (90%)]\tLoss: 0.517691\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:53 | INFO | Rank 0 | Train Epoch: 0 [225216/250314 (90%)]\tLoss: 0.820577\tData (t) 0.186\tBatch (t) 0.399\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:53 | INFO | Rank 0 | Train Epoch: 0 [225248/250314 (90%)]\tLoss: 0.289450\tData (t) 0.338\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:54 | INFO | Rank 0 | Train Epoch: 0 [225280/250314 (90%)]\tLoss: 0.323457\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:54 | INFO | Rank 0 | Train Epoch: 0 [225312/250314 (90%)]\tLoss: 1.084962\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:55 | INFO | Rank 0 | Train Epoch: 0 [225344/250314 (90%)]\tLoss: 0.462305\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:55 | INFO | Rank 0 | Train Epoch: 0 [225376/250314 (90%)]\tLoss: 0.198129\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:56 | INFO | Rank 0 | Train Epoch: 0 [225408/250314 (90%)]\tLoss: 0.828761\tData (t) 0.330\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:56 | INFO | Rank 0 | Train Epoch: 0 [225440/250314 (90%)]\tLoss: 0.492651\tData (t) 0.216\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:57 | INFO | Rank 0 | Train Epoch: 0 [225472/250314 (90%)]\tLoss: 0.602929\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:57 | INFO | Rank 0 | Train Epoch: 0 [225504/250314 (90%)]\tLoss: 0.557667\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:58 | INFO | Rank 0 | Train Epoch: 0 [225536/250314 (90%)]\tLoss: 0.545384\tData (t) 0.198\tBatch (t) 0.410\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:58 | INFO | Rank 0 | Train Epoch: 0 [225568/250314 (90%)]\tLoss: 0.626072\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:59 | INFO | Rank 0 | Train Epoch: 0 [225600/250314 (90%)]\tLoss: 0.823731\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:07:59 | INFO | Rank 0 | Train Epoch: 0 [225632/250314 (90%)]\tLoss: 0.437105\tData (t) 0.235\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:00 | INFO | Rank 0 | Train Epoch: 0 [225664/250314 (90%)]\tLoss: 0.508628\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:00 | INFO | Rank 0 | Train Epoch: 0 [225696/250314 (90%)]\tLoss: 0.785030\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:01 | INFO | Rank 0 | Train Epoch: 0 [225728/250314 (90%)]\tLoss: 0.728554\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:01 | INFO | Rank 0 | Train Epoch: 0 [225760/250314 (90%)]\tLoss: 0.567653\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:02 | INFO | Rank 0 | Train Epoch: 0 [225792/250314 (90%)]\tLoss: 0.332936\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:02 | INFO | Rank 0 | Train Epoch: 0 [225824/250314 (90%)]\tLoss: 0.673892\tData (t) 0.219\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:03 | INFO | Rank 0 | Train Epoch: 0 [225856/250314 (90%)]\tLoss: 0.610274\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:03 | INFO | Rank 0 | Train Epoch: 0 [225888/250314 (90%)]\tLoss: 0.389467\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:04 | INFO | Rank 0 | Train Epoch: 0 [225920/250314 (90%)]\tLoss: 0.499500\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:04 | INFO | Rank 0 | Train Epoch: 0 [225952/250314 (90%)]\tLoss: 0.702356\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:04 | INFO | Rank 0 | Train Epoch: 0 [225984/250314 (90%)]\tLoss: 0.600343\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:05 | INFO | Rank 0 | Train Epoch: 0 [226016/250314 (90%)]\tLoss: 0.775370\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:06 | INFO | Rank 0 | Train Epoch: 0 [226048/250314 (90%)]\tLoss: 0.595038\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:06 | INFO | Rank 0 | Train Epoch: 0 [226080/250314 (90%)]\tLoss: 0.697056\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:07 | INFO | Rank 0 | Train Epoch: 0 [226112/250314 (90%)]\tLoss: 0.593571\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:07 | INFO | Rank 0 | Train Epoch: 0 [226144/250314 (90%)]\tLoss: 0.587671\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:07 | INFO | Rank 0 | Train Epoch: 0 [226176/250314 (90%)]\tLoss: 0.760085\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:08 | INFO | Rank 0 | Train Epoch: 0 [226208/250314 (90%)]\tLoss: 0.493615\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:08 | INFO | Rank 0 | Train Epoch: 0 [226240/250314 (90%)]\tLoss: 0.543680\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:09 | INFO | Rank 0 | Train Epoch: 0 [226272/250314 (90%)]\tLoss: 0.517924\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:09 | INFO | Rank 0 | Train Epoch: 0 [226304/250314 (90%)]\tLoss: 0.286416\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:10 | INFO | Rank 0 | Train Epoch: 0 [226336/250314 (90%)]\tLoss: 0.677416\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:10 | INFO | Rank 0 | Train Epoch: 0 [226368/250314 (90%)]\tLoss: 0.649309\tData (t) 0.263\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:11 | INFO | Rank 0 | Train Epoch: 0 [226400/250314 (90%)]\tLoss: 0.535835\tData (t) 0.227\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:11 | INFO | Rank 0 | Train Epoch: 0 [226432/250314 (90%)]\tLoss: 0.559231\tData (t) 0.225\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:12 | INFO | Rank 0 | Train Epoch: 0 [226464/250314 (90%)]\tLoss: 0.632951\tData (t) 0.324\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:12 | INFO | Rank 0 | Train Epoch: 0 [226496/250314 (90%)]\tLoss: 0.552451\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:13 | INFO | Rank 0 | Train Epoch: 0 [226528/250314 (91%)]\tLoss: 0.931700\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:13 | INFO | Rank 0 | Train Epoch: 0 [226560/250314 (91%)]\tLoss: 0.574068\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:14 | INFO | Rank 0 | Train Epoch: 0 [226592/250314 (91%)]\tLoss: 0.491482\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:14 | INFO | Rank 0 | Train Epoch: 0 [226624/250314 (91%)]\tLoss: 0.510278\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:15 | INFO | Rank 0 | Train Epoch: 0 [226656/250314 (91%)]\tLoss: 0.633393\tData (t) 0.216\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:15 | INFO | Rank 0 | Train Epoch: 0 [226688/250314 (91%)]\tLoss: 0.710328\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:16 | INFO | Rank 0 | Train Epoch: 0 [226720/250314 (91%)]\tLoss: 0.884659\tData (t) 0.322\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:16 | INFO | Rank 0 | Train Epoch: 0 [226752/250314 (91%)]\tLoss: 0.632731\tData (t) 0.333\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:17 | INFO | Rank 0 | Train Epoch: 0 [226784/250314 (91%)]\tLoss: 0.523613\tData (t) 0.363\tBatch (t) 0.575\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:17 | INFO | Rank 0 | Train Epoch: 0 [226816/250314 (91%)]\tLoss: 0.732953\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:18 | INFO | Rank 0 | Train Epoch: 0 [226848/250314 (91%)]\tLoss: 0.447699\tData (t) 0.321\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:18 | INFO | Rank 0 | Train Epoch: 0 [226880/250314 (91%)]\tLoss: 0.711646\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:19 | INFO | Rank 0 | Train Epoch: 0 [226912/250314 (91%)]\tLoss: 0.462725\tData (t) 0.247\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:19 | INFO | Rank 0 | Train Epoch: 0 [226944/250314 (91%)]\tLoss: 0.950841\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:20 | INFO | Rank 0 | Train Epoch: 0 [226976/250314 (91%)]\tLoss: 0.233130\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:20 | INFO | Rank 0 | Train Epoch: 0 [227008/250314 (91%)]\tLoss: 0.512009\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:21 | INFO | Rank 0 | Train Epoch: 0 [227040/250314 (91%)]\tLoss: 0.583155\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:21 | INFO | Rank 0 | Train Epoch: 0 [227072/250314 (91%)]\tLoss: 0.693775\tData (t) 0.338\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:22 | INFO | Rank 0 | Train Epoch: 0 [227104/250314 (91%)]\tLoss: 0.575667\tData (t) 0.350\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:22 | INFO | Rank 0 | Train Epoch: 0 [227136/250314 (91%)]\tLoss: 0.540496\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:23 | INFO | Rank 0 | Train Epoch: 0 [227168/250314 (91%)]\tLoss: 0.505056\tData (t) 0.218\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:23 | INFO | Rank 0 | Train Epoch: 0 [227200/250314 (91%)]\tLoss: 0.661693\tData (t) 0.220\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:24 | INFO | Rank 0 | Train Epoch: 0 [227232/250314 (91%)]\tLoss: 0.786117\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:24 | INFO | Rank 0 | Train Epoch: 0 [227264/250314 (91%)]\tLoss: 0.460457\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:25 | INFO | Rank 0 | Train Epoch: 0 [227296/250314 (91%)]\tLoss: 0.849302\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:25 | INFO | Rank 0 | Train Epoch: 0 [227328/250314 (91%)]\tLoss: 0.733551\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:26 | INFO | Rank 0 | Train Epoch: 0 [227360/250314 (91%)]\tLoss: 0.671264\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:26 | INFO | Rank 0 | Train Epoch: 0 [227392/250314 (91%)]\tLoss: 0.503126\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:27 | INFO | Rank 0 | Train Epoch: 0 [227424/250314 (91%)]\tLoss: 0.330548\tData (t) 0.226\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:27 | INFO | Rank 0 | Train Epoch: 0 [227456/250314 (91%)]\tLoss: 0.627773\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:28 | INFO | Rank 0 | Train Epoch: 0 [227488/250314 (91%)]\tLoss: 0.570915\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:28 | INFO | Rank 0 | Train Epoch: 0 [227520/250314 (91%)]\tLoss: 0.486102\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:29 | INFO | Rank 0 | Train Epoch: 0 [227552/250314 (91%)]\tLoss: 0.682380\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:29 | INFO | Rank 0 | Train Epoch: 0 [227584/250314 (91%)]\tLoss: 0.299176\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:29 | INFO | Rank 0 | Train Epoch: 0 [227616/250314 (91%)]\tLoss: 0.518952\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:30 | INFO | Rank 0 | Train Epoch: 0 [227648/250314 (91%)]\tLoss: 0.831190\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:30 | INFO | Rank 0 | Train Epoch: 0 [227680/250314 (91%)]\tLoss: 0.830638\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:31 | INFO | Rank 0 | Train Epoch: 0 [227712/250314 (91%)]\tLoss: 0.692720\tData (t) 0.268\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:31 | INFO | Rank 0 | Train Epoch: 0 [227744/250314 (91%)]\tLoss: 0.463897\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:32 | INFO | Rank 0 | Train Epoch: 0 [227776/250314 (91%)]\tLoss: 0.777860\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:33 | INFO | Rank 0 | Train Epoch: 0 [227808/250314 (91%)]\tLoss: 0.597352\tData (t) 0.362\tBatch (t) 0.574\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:33 | INFO | Rank 0 | Train Epoch: 0 [227840/250314 (91%)]\tLoss: 1.131371\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:33 | INFO | Rank 0 | Train Epoch: 0 [227872/250314 (91%)]\tLoss: 1.099292\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:34 | INFO | Rank 0 | Train Epoch: 0 [227904/250314 (91%)]\tLoss: 0.744482\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:34 | INFO | Rank 0 | Train Epoch: 0 [227936/250314 (91%)]\tLoss: 0.791875\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:35 | INFO | Rank 0 | Train Epoch: 0 [227968/250314 (91%)]\tLoss: 0.436090\tData (t) 0.204\tBatch (t) 0.416\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:35 | INFO | Rank 0 | Train Epoch: 0 [228000/250314 (91%)]\tLoss: 0.592758\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:36 | INFO | Rank 0 | Train Epoch: 0 [228032/250314 (91%)]\tLoss: 0.664133\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:36 | INFO | Rank 0 | Train Epoch: 0 [228064/250314 (91%)]\tLoss: 0.774437\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:37 | INFO | Rank 0 | Train Epoch: 0 [228096/250314 (91%)]\tLoss: 0.957445\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:37 | INFO | Rank 0 | Train Epoch: 0 [228128/250314 (91%)]\tLoss: 0.527822\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:38 | INFO | Rank 0 | Train Epoch: 0 [228160/250314 (91%)]\tLoss: 0.498853\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:38 | INFO | Rank 0 | Train Epoch: 0 [228192/250314 (91%)]\tLoss: 0.564792\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:39 | INFO | Rank 0 | Train Epoch: 0 [228224/250314 (91%)]\tLoss: 0.319866\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:39 | INFO | Rank 0 | Train Epoch: 0 [228256/250314 (91%)]\tLoss: 0.609325\tData (t) 0.287\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:40 | INFO | Rank 0 | Train Epoch: 0 [228288/250314 (91%)]\tLoss: 0.498740\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:40 | INFO | Rank 0 | Train Epoch: 0 [228320/250314 (91%)]\tLoss: 0.569509\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:41 | INFO | Rank 0 | Train Epoch: 0 [228352/250314 (91%)]\tLoss: 0.314118\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:41 | INFO | Rank 0 | Train Epoch: 0 [228384/250314 (91%)]\tLoss: 0.612861\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:42 | INFO | Rank 0 | Train Epoch: 0 [228416/250314 (91%)]\tLoss: 0.505658\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:42 | INFO | Rank 0 | Train Epoch: 0 [228448/250314 (91%)]\tLoss: 0.750494\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:43 | INFO | Rank 0 | Train Epoch: 0 [228480/250314 (91%)]\tLoss: 0.380601\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:43 | INFO | Rank 0 | Train Epoch: 0 [228512/250314 (91%)]\tLoss: 0.569421\tData (t) 0.365\tBatch (t) 0.576\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:44 | INFO | Rank 0 | Train Epoch: 0 [228544/250314 (91%)]\tLoss: 0.563236\tData (t) 0.223\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:44 | INFO | Rank 0 | Train Epoch: 0 [228576/250314 (91%)]\tLoss: 0.767565\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:45 | INFO | Rank 0 | Train Epoch: 0 [228608/250314 (91%)]\tLoss: 0.617456\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:45 | INFO | Rank 0 | Train Epoch: 0 [228640/250314 (91%)]\tLoss: 0.451551\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:46 | INFO | Rank 0 | Train Epoch: 0 [228672/250314 (91%)]\tLoss: 0.883103\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:46 | INFO | Rank 0 | Train Epoch: 0 [228704/250314 (91%)]\tLoss: 0.660731\tData (t) 0.233\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:47 | INFO | Rank 0 | Train Epoch: 0 [228736/250314 (91%)]\tLoss: 0.796660\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:47 | INFO | Rank 0 | Train Epoch: 0 [228768/250314 (91%)]\tLoss: 0.559136\tData (t) 0.281\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:48 | INFO | Rank 0 | Train Epoch: 0 [228800/250314 (91%)]\tLoss: 0.558192\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:48 | INFO | Rank 0 | Train Epoch: 0 [228832/250314 (91%)]\tLoss: 0.692750\tData (t) 0.289\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:49 | INFO | Rank 0 | Train Epoch: 0 [228864/250314 (91%)]\tLoss: 0.647873\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:49 | INFO | Rank 0 | Train Epoch: 0 [228896/250314 (91%)]\tLoss: 0.932474\tData (t) 0.331\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:50 | INFO | Rank 0 | Train Epoch: 0 [228928/250314 (91%)]\tLoss: 0.697330\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:50 | INFO | Rank 0 | Train Epoch: 0 [228960/250314 (91%)]\tLoss: 0.338253\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:51 | INFO | Rank 0 | Train Epoch: 0 [228992/250314 (91%)]\tLoss: 0.608887\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:51 | INFO | Rank 0 | Train Epoch: 0 [229024/250314 (91%)]\tLoss: 0.792258\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:52 | INFO | Rank 0 | Train Epoch: 0 [229056/250314 (92%)]\tLoss: 0.759755\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:52 | INFO | Rank 0 | Train Epoch: 0 [229088/250314 (92%)]\tLoss: 0.696837\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:53 | INFO | Rank 0 | Train Epoch: 0 [229120/250314 (92%)]\tLoss: 1.055686\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:53 | INFO | Rank 0 | Train Epoch: 0 [229152/250314 (92%)]\tLoss: 0.677215\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:54 | INFO | Rank 0 | Train Epoch: 0 [229184/250314 (92%)]\tLoss: 0.569694\tData (t) 0.230\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:54 | INFO | Rank 0 | Train Epoch: 0 [229216/250314 (92%)]\tLoss: 0.487702\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:55 | INFO | Rank 0 | Train Epoch: 0 [229248/250314 (92%)]\tLoss: 0.418399\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:55 | INFO | Rank 0 | Train Epoch: 0 [229280/250314 (92%)]\tLoss: 0.472959\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:56 | INFO | Rank 0 | Train Epoch: 0 [229312/250314 (92%)]\tLoss: 0.368535\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:56 | INFO | Rank 0 | Train Epoch: 0 [229344/250314 (92%)]\tLoss: 0.342322\tData (t) 0.223\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:57 | INFO | Rank 0 | Train Epoch: 0 [229376/250314 (92%)]\tLoss: 0.925503\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:57 | INFO | Rank 0 | Train Epoch: 0 [229408/250314 (92%)]\tLoss: 0.326673\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:57 | INFO | Rank 0 | Train Epoch: 0 [229440/250314 (92%)]\tLoss: 0.475172\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:58 | INFO | Rank 0 | Train Epoch: 0 [229472/250314 (92%)]\tLoss: 0.895677\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:58 | INFO | Rank 0 | Train Epoch: 0 [229504/250314 (92%)]\tLoss: 0.370097\tData (t) 0.313\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:59 | INFO | Rank 0 | Train Epoch: 0 [229536/250314 (92%)]\tLoss: 0.592733\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:08:59 | INFO | Rank 0 | Train Epoch: 0 [229568/250314 (92%)]\tLoss: 1.557851\tData (t) 0.298\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:00 | INFO | Rank 0 | Train Epoch: 0 [229600/250314 (92%)]\tLoss: 1.149110\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:00 | INFO | Rank 0 | Train Epoch: 0 [229632/250314 (92%)]\tLoss: 0.514498\tData (t) 0.296\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:01 | INFO | Rank 0 | Train Epoch: 0 [229664/250314 (92%)]\tLoss: 0.479566\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:01 | INFO | Rank 0 | Train Epoch: 0 [229696/250314 (92%)]\tLoss: 1.072562\tData (t) 0.178\tBatch (t) 0.389\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:02 | INFO | Rank 0 | Train Epoch: 0 [229728/250314 (92%)]\tLoss: 0.812699\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:02 | INFO | Rank 0 | Train Epoch: 0 [229760/250314 (92%)]\tLoss: 0.809135\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:03 | INFO | Rank 0 | Train Epoch: 0 [229792/250314 (92%)]\tLoss: 0.402382\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:03 | INFO | Rank 0 | Train Epoch: 0 [229824/250314 (92%)]\tLoss: 0.518157\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:04 | INFO | Rank 0 | Train Epoch: 0 [229856/250314 (92%)]\tLoss: 0.923201\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:04 | INFO | Rank 0 | Train Epoch: 0 [229888/250314 (92%)]\tLoss: 0.589447\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:05 | INFO | Rank 0 | Train Epoch: 0 [229920/250314 (92%)]\tLoss: 0.612716\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:05 | INFO | Rank 0 | Train Epoch: 0 [229952/250314 (92%)]\tLoss: 0.431582\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:06 | INFO | Rank 0 | Train Epoch: 0 [229984/250314 (92%)]\tLoss: 0.558295\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:06 | INFO | Rank 0 | Train Epoch: 0 [230016/250314 (92%)]\tLoss: 0.175461\tData (t) 0.199\tBatch (t) 0.410\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:07 | INFO | Rank 0 | Train Epoch: 0 [230048/250314 (92%)]\tLoss: 0.793644\tData (t) 0.286\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:07 | INFO | Rank 0 | Train Epoch: 0 [230080/250314 (92%)]\tLoss: 0.625654\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:08 | INFO | Rank 0 | Train Epoch: 0 [230112/250314 (92%)]\tLoss: 0.598488\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:08 | INFO | Rank 0 | Train Epoch: 0 [230144/250314 (92%)]\tLoss: 0.683911\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:09 | INFO | Rank 0 | Train Epoch: 0 [230176/250314 (92%)]\tLoss: 0.444853\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:09 | INFO | Rank 0 | Train Epoch: 0 [230208/250314 (92%)]\tLoss: 0.817772\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:10 | INFO | Rank 0 | Train Epoch: 0 [230240/250314 (92%)]\tLoss: 0.517602\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:10 | INFO | Rank 0 | Train Epoch: 0 [230272/250314 (92%)]\tLoss: 0.893466\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:11 | INFO | Rank 0 | Train Epoch: 0 [230304/250314 (92%)]\tLoss: 0.416076\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:11 | INFO | Rank 0 | Train Epoch: 0 [230336/250314 (92%)]\tLoss: 0.606314\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:12 | INFO | Rank 0 | Train Epoch: 0 [230368/250314 (92%)]\tLoss: 0.673823\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:12 | INFO | Rank 0 | Train Epoch: 0 [230400/250314 (92%)]\tLoss: 0.366867\tData (t) 0.231\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:12 | INFO | Rank 0 | Train Epoch: 0 [230432/250314 (92%)]\tLoss: 0.566180\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:13 | INFO | Rank 0 | Train Epoch: 0 [230464/250314 (92%)]\tLoss: 0.681942\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:13 | INFO | Rank 0 | Train Epoch: 0 [230496/250314 (92%)]\tLoss: 0.221340\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:14 | INFO | Rank 0 | Train Epoch: 0 [230528/250314 (92%)]\tLoss: 0.546387\tData (t) 0.226\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:14 | INFO | Rank 0 | Train Epoch: 0 [230560/250314 (92%)]\tLoss: 0.696387\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:15 | INFO | Rank 0 | Train Epoch: 0 [230592/250314 (92%)]\tLoss: 0.614746\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:15 | INFO | Rank 0 | Train Epoch: 0 [230624/250314 (92%)]\tLoss: 0.458984\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:16 | INFO | Rank 0 | Train Epoch: 0 [230656/250314 (92%)]\tLoss: 0.606606\tData (t) 0.285\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:16 | INFO | Rank 0 | Train Epoch: 0 [230688/250314 (92%)]\tLoss: 0.787632\tData (t) 0.223\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:17 | INFO | Rank 0 | Train Epoch: 0 [230720/250314 (92%)]\tLoss: 0.645939\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:17 | INFO | Rank 0 | Train Epoch: 0 [230752/250314 (92%)]\tLoss: 0.449688\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:18 | INFO | Rank 0 | Train Epoch: 0 [230784/250314 (92%)]\tLoss: 0.711469\tData (t) 0.230\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:18 | INFO | Rank 0 | Train Epoch: 0 [230816/250314 (92%)]\tLoss: 0.592092\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:19 | INFO | Rank 0 | Train Epoch: 0 [230848/250314 (92%)]\tLoss: 0.713772\tData (t) 0.221\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:19 | INFO | Rank 0 | Train Epoch: 0 [230880/250314 (92%)]\tLoss: 0.990230\tData (t) 0.277\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:19 | INFO | Rank 0 | Train Epoch: 0 [230912/250314 (92%)]\tLoss: 0.857326\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:20 | INFO | Rank 0 | Train Epoch: 0 [230944/250314 (92%)]\tLoss: 0.455468\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:20 | INFO | Rank 0 | Train Epoch: 0 [230976/250314 (92%)]\tLoss: 0.362731\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:21 | INFO | Rank 0 | Train Epoch: 0 [231008/250314 (92%)]\tLoss: 0.323828\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:21 | INFO | Rank 0 | Train Epoch: 0 [231040/250314 (92%)]\tLoss: 0.360825\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:22 | INFO | Rank 0 | Train Epoch: 0 [231072/250314 (92%)]\tLoss: 0.348988\tData (t) 0.233\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:22 | INFO | Rank 0 | Train Epoch: 0 [231104/250314 (92%)]\tLoss: 0.623128\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:23 | INFO | Rank 0 | Train Epoch: 0 [231136/250314 (92%)]\tLoss: 0.604896\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:23 | INFO | Rank 0 | Train Epoch: 0 [231168/250314 (92%)]\tLoss: 0.637984\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:24 | INFO | Rank 0 | Train Epoch: 0 [231200/250314 (92%)]\tLoss: 0.310672\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:24 | INFO | Rank 0 | Train Epoch: 0 [231232/250314 (92%)]\tLoss: 0.724777\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:25 | INFO | Rank 0 | Train Epoch: 0 [231264/250314 (92%)]\tLoss: 0.819323\tData (t) 0.341\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:25 | INFO | Rank 0 | Train Epoch: 0 [231296/250314 (92%)]\tLoss: 0.630794\tData (t) 0.215\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:26 | INFO | Rank 0 | Train Epoch: 0 [231328/250314 (92%)]\tLoss: 0.625559\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:26 | INFO | Rank 0 | Train Epoch: 0 [231360/250314 (92%)]\tLoss: 0.652132\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:27 | INFO | Rank 0 | Train Epoch: 0 [231392/250314 (92%)]\tLoss: 0.491087\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:27 | INFO | Rank 0 | Train Epoch: 0 [231424/250314 (92%)]\tLoss: 0.797983\tData (t) 0.252\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:28 | INFO | Rank 0 | Train Epoch: 0 [231456/250314 (92%)]\tLoss: 1.033473\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:28 | INFO | Rank 0 | Train Epoch: 0 [231488/250314 (92%)]\tLoss: 0.423169\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:28 | INFO | Rank 0 | Train Epoch: 0 [231520/250314 (92%)]\tLoss: 0.753367\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:29 | INFO | Rank 0 | Train Epoch: 0 [231552/250314 (93%)]\tLoss: 0.842255\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:29 | INFO | Rank 0 | Train Epoch: 0 [231584/250314 (93%)]\tLoss: 0.441952\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:30 | INFO | Rank 0 | Train Epoch: 0 [231616/250314 (93%)]\tLoss: 0.378446\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:30 | INFO | Rank 0 | Train Epoch: 0 [231648/250314 (93%)]\tLoss: 0.722818\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:31 | INFO | Rank 0 | Train Epoch: 0 [231680/250314 (93%)]\tLoss: 0.726270\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:31 | INFO | Rank 0 | Train Epoch: 0 [231712/250314 (93%)]\tLoss: 0.746846\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:32 | INFO | Rank 0 | Train Epoch: 0 [231744/250314 (93%)]\tLoss: 0.480066\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:32 | INFO | Rank 0 | Train Epoch: 0 [231776/250314 (93%)]\tLoss: 0.770609\tData (t) 0.274\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:33 | INFO | Rank 0 | Train Epoch: 0 [231808/250314 (93%)]\tLoss: 0.726406\tData (t) 0.360\tBatch (t) 0.571\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:33 | INFO | Rank 0 | Train Epoch: 0 [231840/250314 (93%)]\tLoss: 0.571075\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:34 | INFO | Rank 0 | Train Epoch: 0 [231872/250314 (93%)]\tLoss: 0.646490\tData (t) 0.230\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:34 | INFO | Rank 0 | Train Epoch: 0 [231904/250314 (93%)]\tLoss: 0.357877\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:35 | INFO | Rank 0 | Train Epoch: 0 [231936/250314 (93%)]\tLoss: 0.374965\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:35 | INFO | Rank 0 | Train Epoch: 0 [231968/250314 (93%)]\tLoss: 0.372620\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:36 | INFO | Rank 0 | Train Epoch: 0 [232000/250314 (93%)]\tLoss: 0.725313\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:36 | INFO | Rank 0 | Train Epoch: 0 [232032/250314 (93%)]\tLoss: 0.479018\tData (t) 0.260\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:37 | INFO | Rank 0 | Train Epoch: 0 [232064/250314 (93%)]\tLoss: 0.659559\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:37 | INFO | Rank 0 | Train Epoch: 0 [232096/250314 (93%)]\tLoss: 0.565682\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:38 | INFO | Rank 0 | Train Epoch: 0 [232128/250314 (93%)]\tLoss: 0.551547\tData (t) 0.213\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:38 | INFO | Rank 0 | Train Epoch: 0 [232160/250314 (93%)]\tLoss: 0.451723\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:39 | INFO | Rank 0 | Train Epoch: 0 [232192/250314 (93%)]\tLoss: 0.636305\tData (t) 0.228\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:39 | INFO | Rank 0 | Train Epoch: 0 [232224/250314 (93%)]\tLoss: 0.690328\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:40 | INFO | Rank 0 | Train Epoch: 0 [232256/250314 (93%)]\tLoss: 0.598866\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:40 | INFO | Rank 0 | Train Epoch: 0 [232288/250314 (93%)]\tLoss: 0.687293\tData (t) 0.227\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:41 | INFO | Rank 0 | Train Epoch: 0 [232320/250314 (93%)]\tLoss: 0.723506\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:41 | INFO | Rank 0 | Train Epoch: 0 [232352/250314 (93%)]\tLoss: 0.414339\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:42 | INFO | Rank 0 | Train Epoch: 0 [232384/250314 (93%)]\tLoss: 0.518065\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:42 | INFO | Rank 0 | Train Epoch: 0 [232416/250314 (93%)]\tLoss: 0.633748\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:43 | INFO | Rank 0 | Train Epoch: 0 [232448/250314 (93%)]\tLoss: 0.425211\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:43 | INFO | Rank 0 | Train Epoch: 0 [232480/250314 (93%)]\tLoss: 0.518090\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:44 | INFO | Rank 0 | Train Epoch: 0 [232512/250314 (93%)]\tLoss: 0.722870\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:44 | INFO | Rank 0 | Train Epoch: 0 [232544/250314 (93%)]\tLoss: 1.021020\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:45 | INFO | Rank 0 | Train Epoch: 0 [232576/250314 (93%)]\tLoss: 0.340206\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:45 | INFO | Rank 0 | Train Epoch: 0 [232608/250314 (93%)]\tLoss: 0.514132\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:46 | INFO | Rank 0 | Train Epoch: 0 [232640/250314 (93%)]\tLoss: 0.801392\tData (t) 0.209\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:46 | INFO | Rank 0 | Train Epoch: 0 [232672/250314 (93%)]\tLoss: 0.508594\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:47 | INFO | Rank 0 | Train Epoch: 0 [232704/250314 (93%)]\tLoss: 0.467568\tData (t) 0.275\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:47 | INFO | Rank 0 | Train Epoch: 0 [232736/250314 (93%)]\tLoss: 0.822221\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:48 | INFO | Rank 0 | Train Epoch: 0 [232768/250314 (93%)]\tLoss: 0.440005\tData (t) 0.267\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:48 | INFO | Rank 0 | Train Epoch: 0 [232800/250314 (93%)]\tLoss: 0.451677\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:49 | INFO | Rank 0 | Train Epoch: 0 [232832/250314 (93%)]\tLoss: 0.853505\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:49 | INFO | Rank 0 | Train Epoch: 0 [232864/250314 (93%)]\tLoss: 0.631170\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:49 | INFO | Rank 0 | Train Epoch: 0 [232896/250314 (93%)]\tLoss: 0.693577\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:50 | INFO | Rank 0 | Train Epoch: 0 [232928/250314 (93%)]\tLoss: 0.678592\tData (t) 0.330\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:51 | INFO | Rank 0 | Train Epoch: 0 [232960/250314 (93%)]\tLoss: 0.624156\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:51 | INFO | Rank 0 | Train Epoch: 0 [232992/250314 (93%)]\tLoss: 0.520476\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:51 | INFO | Rank 0 | Train Epoch: 0 [233024/250314 (93%)]\tLoss: 0.668868\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:52 | INFO | Rank 0 | Train Epoch: 0 [233056/250314 (93%)]\tLoss: 0.438510\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:52 | INFO | Rank 0 | Train Epoch: 0 [233088/250314 (93%)]\tLoss: 0.787280\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:53 | INFO | Rank 0 | Train Epoch: 0 [233120/250314 (93%)]\tLoss: 0.769404\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:53 | INFO | Rank 0 | Train Epoch: 0 [233152/250314 (93%)]\tLoss: 0.856610\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:54 | INFO | Rank 0 | Train Epoch: 0 [233184/250314 (93%)]\tLoss: 0.451058\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:54 | INFO | Rank 0 | Train Epoch: 0 [233216/250314 (93%)]\tLoss: 0.471655\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:55 | INFO | Rank 0 | Train Epoch: 0 [233248/250314 (93%)]\tLoss: 1.049649\tData (t) 0.375\tBatch (t) 0.587\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:55 | INFO | Rank 0 | Train Epoch: 0 [233280/250314 (93%)]\tLoss: 0.324289\tData (t) 0.228\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:56 | INFO | Rank 0 | Train Epoch: 0 [233312/250314 (93%)]\tLoss: 0.421059\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:56 | INFO | Rank 0 | Train Epoch: 0 [233344/250314 (93%)]\tLoss: 0.547074\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:57 | INFO | Rank 0 | Train Epoch: 0 [233376/250314 (93%)]\tLoss: 0.826811\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:57 | INFO | Rank 0 | Train Epoch: 0 [233408/250314 (93%)]\tLoss: 0.733794\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:58 | INFO | Rank 0 | Train Epoch: 0 [233440/250314 (93%)]\tLoss: 0.574159\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:58 | INFO | Rank 0 | Train Epoch: 0 [233472/250314 (93%)]\tLoss: 0.465875\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:59 | INFO | Rank 0 | Train Epoch: 0 [233504/250314 (93%)]\tLoss: 0.658845\tData (t) 0.233\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:09:59 | INFO | Rank 0 | Train Epoch: 0 [233536/250314 (93%)]\tLoss: 0.696765\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:00 | INFO | Rank 0 | Train Epoch: 0 [233568/250314 (93%)]\tLoss: 0.735663\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:00 | INFO | Rank 0 | Train Epoch: 0 [233600/250314 (93%)]\tLoss: 0.472544\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:01 | INFO | Rank 0 | Train Epoch: 0 [233632/250314 (93%)]\tLoss: 0.259607\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:01 | INFO | Rank 0 | Train Epoch: 0 [233664/250314 (93%)]\tLoss: 0.642651\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:02 | INFO | Rank 0 | Train Epoch: 0 [233696/250314 (93%)]\tLoss: 0.542761\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:02 | INFO | Rank 0 | Train Epoch: 0 [233728/250314 (93%)]\tLoss: 0.793069\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:03 | INFO | Rank 0 | Train Epoch: 0 [233760/250314 (93%)]\tLoss: 1.099544\tData (t) 0.252\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:03 | INFO | Rank 0 | Train Epoch: 0 [233792/250314 (93%)]\tLoss: 0.980458\tData (t) 0.274\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:04 | INFO | Rank 0 | Train Epoch: 0 [233824/250314 (93%)]\tLoss: 0.943025\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:04 | INFO | Rank 0 | Train Epoch: 0 [233856/250314 (93%)]\tLoss: 0.482980\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:05 | INFO | Rank 0 | Train Epoch: 0 [233888/250314 (93%)]\tLoss: 0.480152\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:05 | INFO | Rank 0 | Train Epoch: 0 [233920/250314 (93%)]\tLoss: 0.704267\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:06 | INFO | Rank 0 | Train Epoch: 0 [233952/250314 (93%)]\tLoss: 0.677501\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:06 | INFO | Rank 0 | Train Epoch: 0 [233984/250314 (93%)]\tLoss: 1.205196\tData (t) 0.333\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:07 | INFO | Rank 0 | Train Epoch: 0 [234016/250314 (93%)]\tLoss: 0.601452\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:07 | INFO | Rank 0 | Train Epoch: 0 [234048/250314 (94%)]\tLoss: 0.305926\tData (t) 0.201\tBatch (t) 0.412\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:08 | INFO | Rank 0 | Train Epoch: 0 [234080/250314 (94%)]\tLoss: 0.531444\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:08 | INFO | Rank 0 | Train Epoch: 0 [234112/250314 (94%)]\tLoss: 0.640542\tData (t) 0.218\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:09 | INFO | Rank 0 | Train Epoch: 0 [234144/250314 (94%)]\tLoss: 0.544027\tData (t) 0.439\tBatch (t) 0.651\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:09 | INFO | Rank 0 | Train Epoch: 0 [234176/250314 (94%)]\tLoss: 0.638663\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:10 | INFO | Rank 0 | Train Epoch: 0 [234208/250314 (94%)]\tLoss: 0.791474\tData (t) 0.193\tBatch (t) 0.404\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:10 | INFO | Rank 0 | Train Epoch: 0 [234240/250314 (94%)]\tLoss: 0.289131\tData (t) 0.216\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:10 | INFO | Rank 0 | Train Epoch: 0 [234272/250314 (94%)]\tLoss: 0.350872\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:11 | INFO | Rank 0 | Train Epoch: 0 [234304/250314 (94%)]\tLoss: 0.502876\tData (t) 0.328\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:11 | INFO | Rank 0 | Train Epoch: 0 [234336/250314 (94%)]\tLoss: 0.307782\tData (t) 0.218\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:12 | INFO | Rank 0 | Train Epoch: 0 [234368/250314 (94%)]\tLoss: 0.569523\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:12 | INFO | Rank 0 | Train Epoch: 0 [234400/250314 (94%)]\tLoss: 0.617616\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:13 | INFO | Rank 0 | Train Epoch: 0 [234432/250314 (94%)]\tLoss: 0.411548\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:13 | INFO | Rank 0 | Train Epoch: 0 [234464/250314 (94%)]\tLoss: 0.935248\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:14 | INFO | Rank 0 | Train Epoch: 0 [234496/250314 (94%)]\tLoss: 0.364663\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:14 | INFO | Rank 0 | Train Epoch: 0 [234528/250314 (94%)]\tLoss: 0.418317\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:15 | INFO | Rank 0 | Train Epoch: 0 [234560/250314 (94%)]\tLoss: 0.883731\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:15 | INFO | Rank 0 | Train Epoch: 0 [234592/250314 (94%)]\tLoss: 0.817801\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:16 | INFO | Rank 0 | Train Epoch: 0 [234624/250314 (94%)]\tLoss: 0.523512\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:16 | INFO | Rank 0 | Train Epoch: 0 [234656/250314 (94%)]\tLoss: 0.573012\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:17 | INFO | Rank 0 | Train Epoch: 0 [234688/250314 (94%)]\tLoss: 0.814931\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:17 | INFO | Rank 0 | Train Epoch: 0 [234720/250314 (94%)]\tLoss: 0.617656\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:18 | INFO | Rank 0 | Train Epoch: 0 [234752/250314 (94%)]\tLoss: 0.583632\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:18 | INFO | Rank 0 | Train Epoch: 0 [234784/250314 (94%)]\tLoss: 0.567531\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:19 | INFO | Rank 0 | Train Epoch: 0 [234816/250314 (94%)]\tLoss: 0.247996\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:19 | INFO | Rank 0 | Train Epoch: 0 [234848/250314 (94%)]\tLoss: 1.005786\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:20 | INFO | Rank 0 | Train Epoch: 0 [234880/250314 (94%)]\tLoss: 0.812893\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:20 | INFO | Rank 0 | Train Epoch: 0 [234912/250314 (94%)]\tLoss: 0.556404\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:20 | INFO | Rank 0 | Train Epoch: 0 [234944/250314 (94%)]\tLoss: 0.496887\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:21 | INFO | Rank 0 | Train Epoch: 0 [234976/250314 (94%)]\tLoss: 0.731348\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:22 | INFO | Rank 0 | Train Epoch: 0 [235008/250314 (94%)]\tLoss: 0.780904\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:22 | INFO | Rank 0 | Train Epoch: 0 [235040/250314 (94%)]\tLoss: 0.417814\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:22 | INFO | Rank 0 | Train Epoch: 0 [235072/250314 (94%)]\tLoss: 0.947603\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:23 | INFO | Rank 0 | Train Epoch: 0 [235104/250314 (94%)]\tLoss: 0.582448\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:23 | INFO | Rank 0 | Train Epoch: 0 [235136/250314 (94%)]\tLoss: 0.503465\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:24 | INFO | Rank 0 | Train Epoch: 0 [235168/250314 (94%)]\tLoss: 0.481303\tData (t) 0.188\tBatch (t) 0.399\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:24 | INFO | Rank 0 | Train Epoch: 0 [235200/250314 (94%)]\tLoss: 0.339984\tData (t) 0.200\tBatch (t) 0.411\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:25 | INFO | Rank 0 | Train Epoch: 0 [235232/250314 (94%)]\tLoss: 0.206208\tData (t) 0.220\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:25 | INFO | Rank 0 | Train Epoch: 0 [235264/250314 (94%)]\tLoss: 0.537282\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:26 | INFO | Rank 0 | Train Epoch: 0 [235296/250314 (94%)]\tLoss: 0.554412\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:26 | INFO | Rank 0 | Train Epoch: 0 [235328/250314 (94%)]\tLoss: 0.752991\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:27 | INFO | Rank 0 | Train Epoch: 0 [235360/250314 (94%)]\tLoss: 0.481192\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:27 | INFO | Rank 0 | Train Epoch: 0 [235392/250314 (94%)]\tLoss: 0.588617\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:28 | INFO | Rank 0 | Train Epoch: 0 [235424/250314 (94%)]\tLoss: 0.689226\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:28 | INFO | Rank 0 | Train Epoch: 0 [235456/250314 (94%)]\tLoss: 0.668645\tData (t) 0.223\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:29 | INFO | Rank 0 | Train Epoch: 0 [235488/250314 (94%)]\tLoss: 0.420962\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:29 | INFO | Rank 0 | Train Epoch: 0 [235520/250314 (94%)]\tLoss: 0.906115\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:30 | INFO | Rank 0 | Train Epoch: 0 [235552/250314 (94%)]\tLoss: 0.441321\tData (t) 0.240\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:30 | INFO | Rank 0 | Train Epoch: 0 [235584/250314 (94%)]\tLoss: 0.755249\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:31 | INFO | Rank 0 | Train Epoch: 0 [235616/250314 (94%)]\tLoss: 0.686474\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:31 | INFO | Rank 0 | Train Epoch: 0 [235648/250314 (94%)]\tLoss: 0.610166\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:32 | INFO | Rank 0 | Train Epoch: 0 [235680/250314 (94%)]\tLoss: 0.698794\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:32 | INFO | Rank 0 | Train Epoch: 0 [235712/250314 (94%)]\tLoss: 0.747716\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:33 | INFO | Rank 0 | Train Epoch: 0 [235744/250314 (94%)]\tLoss: 0.805206\tData (t) 0.350\tBatch (t) 0.562\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:33 | INFO | Rank 0 | Train Epoch: 0 [235776/250314 (94%)]\tLoss: 0.358519\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:34 | INFO | Rank 0 | Train Epoch: 0 [235808/250314 (94%)]\tLoss: 0.569296\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:34 | INFO | Rank 0 | Train Epoch: 0 [235840/250314 (94%)]\tLoss: 0.465517\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:34 | INFO | Rank 0 | Train Epoch: 0 [235872/250314 (94%)]\tLoss: 0.491783\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:35 | INFO | Rank 0 | Train Epoch: 0 [235904/250314 (94%)]\tLoss: 0.810423\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:35 | INFO | Rank 0 | Train Epoch: 0 [235936/250314 (94%)]\tLoss: 0.669250\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:36 | INFO | Rank 0 | Train Epoch: 0 [235968/250314 (94%)]\tLoss: 0.845752\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:36 | INFO | Rank 0 | Train Epoch: 0 [236000/250314 (94%)]\tLoss: 0.577811\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:37 | INFO | Rank 0 | Train Epoch: 0 [236032/250314 (94%)]\tLoss: 0.527113\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:38 | INFO | Rank 0 | Train Epoch: 0 [236064/250314 (94%)]\tLoss: 0.485185\tData (t) 0.345\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:38 | INFO | Rank 0 | Train Epoch: 0 [236096/250314 (94%)]\tLoss: 0.450626\tData (t) 0.331\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:39 | INFO | Rank 0 | Train Epoch: 0 [236128/250314 (94%)]\tLoss: 0.295213\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:39 | INFO | Rank 0 | Train Epoch: 0 [236160/250314 (94%)]\tLoss: 0.607940\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:39 | INFO | Rank 0 | Train Epoch: 0 [236192/250314 (94%)]\tLoss: 0.702870\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:40 | INFO | Rank 0 | Train Epoch: 0 [236224/250314 (94%)]\tLoss: 0.781003\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:40 | INFO | Rank 0 | Train Epoch: 0 [236256/250314 (94%)]\tLoss: 0.469163\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:41 | INFO | Rank 0 | Train Epoch: 0 [236288/250314 (94%)]\tLoss: 0.683337\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:41 | INFO | Rank 0 | Train Epoch: 0 [236320/250314 (94%)]\tLoss: 0.459683\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:42 | INFO | Rank 0 | Train Epoch: 0 [236352/250314 (94%)]\tLoss: 0.422903\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:42 | INFO | Rank 0 | Train Epoch: 0 [236384/250314 (94%)]\tLoss: 0.766853\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:43 | INFO | Rank 0 | Train Epoch: 0 [236416/250314 (94%)]\tLoss: 0.740029\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:43 | INFO | Rank 0 | Train Epoch: 0 [236448/250314 (94%)]\tLoss: 1.010031\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:44 | INFO | Rank 0 | Train Epoch: 0 [236480/250314 (94%)]\tLoss: 0.928754\tData (t) 0.279\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:44 | INFO | Rank 0 | Train Epoch: 0 [236512/250314 (94%)]\tLoss: 0.681519\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:45 | INFO | Rank 0 | Train Epoch: 0 [236544/250314 (95%)]\tLoss: 0.869256\tData (t) 0.330\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:45 | INFO | Rank 0 | Train Epoch: 0 [236576/250314 (95%)]\tLoss: 0.710707\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:46 | INFO | Rank 0 | Train Epoch: 0 [236608/250314 (95%)]\tLoss: 0.862746\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:46 | INFO | Rank 0 | Train Epoch: 0 [236640/250314 (95%)]\tLoss: 1.099503\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:47 | INFO | Rank 0 | Train Epoch: 0 [236672/250314 (95%)]\tLoss: 0.947055\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:47 | INFO | Rank 0 | Train Epoch: 0 [236704/250314 (95%)]\tLoss: 0.248671\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:48 | INFO | Rank 0 | Train Epoch: 0 [236736/250314 (95%)]\tLoss: 0.533745\tData (t) 0.345\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:48 | INFO | Rank 0 | Train Epoch: 0 [236768/250314 (95%)]\tLoss: 0.715125\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:49 | INFO | Rank 0 | Train Epoch: 0 [236800/250314 (95%)]\tLoss: 0.339141\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:49 | INFO | Rank 0 | Train Epoch: 0 [236832/250314 (95%)]\tLoss: 0.977048\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:50 | INFO | Rank 0 | Train Epoch: 0 [236864/250314 (95%)]\tLoss: 0.716930\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:50 | INFO | Rank 0 | Train Epoch: 0 [236896/250314 (95%)]\tLoss: 0.758827\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:51 | INFO | Rank 0 | Train Epoch: 0 [236928/250314 (95%)]\tLoss: 0.500213\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:51 | INFO | Rank 0 | Train Epoch: 0 [236960/250314 (95%)]\tLoss: 0.948223\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:52 | INFO | Rank 0 | Train Epoch: 0 [236992/250314 (95%)]\tLoss: 0.343914\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:52 | INFO | Rank 0 | Train Epoch: 0 [237024/250314 (95%)]\tLoss: 0.526172\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:53 | INFO | Rank 0 | Train Epoch: 0 [237056/250314 (95%)]\tLoss: 0.608282\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:53 | INFO | Rank 0 | Train Epoch: 0 [237088/250314 (95%)]\tLoss: 0.510607\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:54 | INFO | Rank 0 | Train Epoch: 0 [237120/250314 (95%)]\tLoss: 0.287402\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:54 | INFO | Rank 0 | Train Epoch: 0 [237152/250314 (95%)]\tLoss: 0.387865\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:55 | INFO | Rank 0 | Train Epoch: 0 [237184/250314 (95%)]\tLoss: 0.701220\tData (t) 0.222\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:55 | INFO | Rank 0 | Train Epoch: 0 [237216/250314 (95%)]\tLoss: 0.371088\tData (t) 0.218\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:56 | INFO | Rank 0 | Train Epoch: 0 [237248/250314 (95%)]\tLoss: 0.551072\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:56 | INFO | Rank 0 | Train Epoch: 0 [237280/250314 (95%)]\tLoss: 0.513758\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:57 | INFO | Rank 0 | Train Epoch: 0 [237312/250314 (95%)]\tLoss: 0.442712\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:57 | INFO | Rank 0 | Train Epoch: 0 [237344/250314 (95%)]\tLoss: 0.496421\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:58 | INFO | Rank 0 | Train Epoch: 0 [237376/250314 (95%)]\tLoss: 0.473457\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:58 | INFO | Rank 0 | Train Epoch: 0 [237408/250314 (95%)]\tLoss: 0.748533\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:59 | INFO | Rank 0 | Train Epoch: 0 [237440/250314 (95%)]\tLoss: 0.883362\tData (t) 0.305\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:10:59 | INFO | Rank 0 | Train Epoch: 0 [237472/250314 (95%)]\tLoss: 0.813058\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:00 | INFO | Rank 0 | Train Epoch: 0 [237504/250314 (95%)]\tLoss: 0.617738\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:00 | INFO | Rank 0 | Train Epoch: 0 [237536/250314 (95%)]\tLoss: 0.805627\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:01 | INFO | Rank 0 | Train Epoch: 0 [237568/250314 (95%)]\tLoss: 0.917610\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:01 | INFO | Rank 0 | Train Epoch: 0 [237600/250314 (95%)]\tLoss: 0.949816\tData (t) 0.222\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:02 | INFO | Rank 0 | Train Epoch: 0 [237632/250314 (95%)]\tLoss: 0.697528\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:02 | INFO | Rank 0 | Train Epoch: 0 [237664/250314 (95%)]\tLoss: 0.369238\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:02 | INFO | Rank 0 | Train Epoch: 0 [237696/250314 (95%)]\tLoss: 0.638198\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:03 | INFO | Rank 0 | Train Epoch: 0 [237728/250314 (95%)]\tLoss: 0.442825\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:04 | INFO | Rank 0 | Train Epoch: 0 [237760/250314 (95%)]\tLoss: 0.569210\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:04 | INFO | Rank 0 | Train Epoch: 0 [237792/250314 (95%)]\tLoss: 0.591111\tData (t) 0.307\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:05 | INFO | Rank 0 | Train Epoch: 0 [237824/250314 (95%)]\tLoss: 0.355989\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:05 | INFO | Rank 0 | Train Epoch: 0 [237856/250314 (95%)]\tLoss: 0.910445\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:05 | INFO | Rank 0 | Train Epoch: 0 [237888/250314 (95%)]\tLoss: 0.658353\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:06 | INFO | Rank 0 | Train Epoch: 0 [237920/250314 (95%)]\tLoss: 0.571973\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:06 | INFO | Rank 0 | Train Epoch: 0 [237952/250314 (95%)]\tLoss: 0.590940\tData (t) 0.290\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:07 | INFO | Rank 0 | Train Epoch: 0 [237984/250314 (95%)]\tLoss: 0.685078\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:07 | INFO | Rank 0 | Train Epoch: 0 [238016/250314 (95%)]\tLoss: 0.705783\tData (t) 0.324\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:08 | INFO | Rank 0 | Train Epoch: 0 [238048/250314 (95%)]\tLoss: 0.763696\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:08 | INFO | Rank 0 | Train Epoch: 0 [238080/250314 (95%)]\tLoss: 0.562230\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:09 | INFO | Rank 0 | Train Epoch: 0 [238112/250314 (95%)]\tLoss: 0.439908\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:09 | INFO | Rank 0 | Train Epoch: 0 [238144/250314 (95%)]\tLoss: 0.747862\tData (t) 0.236\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:10 | INFO | Rank 0 | Train Epoch: 0 [238176/250314 (95%)]\tLoss: 0.569072\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:10 | INFO | Rank 0 | Train Epoch: 0 [238208/250314 (95%)]\tLoss: 0.539814\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:11 | INFO | Rank 0 | Train Epoch: 0 [238240/250314 (95%)]\tLoss: 0.329837\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:11 | INFO | Rank 0 | Train Epoch: 0 [238272/250314 (95%)]\tLoss: 0.536141\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:12 | INFO | Rank 0 | Train Epoch: 0 [238304/250314 (95%)]\tLoss: 0.399209\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:12 | INFO | Rank 0 | Train Epoch: 0 [238336/250314 (95%)]\tLoss: 0.612069\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:13 | INFO | Rank 0 | Train Epoch: 0 [238368/250314 (95%)]\tLoss: 0.646709\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:13 | INFO | Rank 0 | Train Epoch: 0 [238400/250314 (95%)]\tLoss: 0.489250\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:14 | INFO | Rank 0 | Train Epoch: 0 [238432/250314 (95%)]\tLoss: 0.320439\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:14 | INFO | Rank 0 | Train Epoch: 0 [238464/250314 (95%)]\tLoss: 0.777688\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:15 | INFO | Rank 0 | Train Epoch: 0 [238496/250314 (95%)]\tLoss: 0.708342\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:15 | INFO | Rank 0 | Train Epoch: 0 [238528/250314 (95%)]\tLoss: 0.533888\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:16 | INFO | Rank 0 | Train Epoch: 0 [238560/250314 (95%)]\tLoss: 0.890433\tData (t) 0.264\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:16 | INFO | Rank 0 | Train Epoch: 0 [238592/250314 (95%)]\tLoss: 0.582626\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:17 | INFO | Rank 0 | Train Epoch: 0 [238624/250314 (95%)]\tLoss: 0.607776\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:17 | INFO | Rank 0 | Train Epoch: 0 [238656/250314 (95%)]\tLoss: 0.562594\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:18 | INFO | Rank 0 | Train Epoch: 0 [238688/250314 (95%)]\tLoss: 0.615907\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:18 | INFO | Rank 0 | Train Epoch: 0 [238720/250314 (95%)]\tLoss: 0.585582\tData (t) 0.280\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:19 | INFO | Rank 0 | Train Epoch: 0 [238752/250314 (95%)]\tLoss: 0.829844\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:19 | INFO | Rank 0 | Train Epoch: 0 [238784/250314 (95%)]\tLoss: 1.302938\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:20 | INFO | Rank 0 | Train Epoch: 0 [238816/250314 (95%)]\tLoss: 1.143259\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:20 | INFO | Rank 0 | Train Epoch: 0 [238848/250314 (95%)]\tLoss: 0.625724\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:21 | INFO | Rank 0 | Train Epoch: 0 [238880/250314 (95%)]\tLoss: 0.467196\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:21 | INFO | Rank 0 | Train Epoch: 0 [238912/250314 (95%)]\tLoss: 0.364498\tData (t) 0.314\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:22 | INFO | Rank 0 | Train Epoch: 0 [238944/250314 (95%)]\tLoss: 0.524124\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:22 | INFO | Rank 0 | Train Epoch: 0 [238976/250314 (95%)]\tLoss: 0.727759\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.589\n",
      "2022-11-09,14:11:23 | INFO | Rank 0 | Train Epoch: 0 [239008/250314 (95%)]\tLoss: 0.848035\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:23 | INFO | Rank 0 | Train Epoch: 0 [239040/250314 (95%)]\tLoss: 0.503971\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:23 | INFO | Rank 0 | Train Epoch: 0 [239072/250314 (96%)]\tLoss: 0.618898\tData (t) 0.199\tBatch (t) 0.411\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:24 | INFO | Rank 0 | Train Epoch: 0 [239104/250314 (96%)]\tLoss: 0.812818\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:25 | INFO | Rank 0 | Train Epoch: 0 [239136/250314 (96%)]\tLoss: 0.516690\tData (t) 0.389\tBatch (t) 0.601\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:25 | INFO | Rank 0 | Train Epoch: 0 [239168/250314 (96%)]\tLoss: 0.635041\tData (t) 0.220\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:25 | INFO | Rank 0 | Train Epoch: 0 [239200/250314 (96%)]\tLoss: 0.694376\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:26 | INFO | Rank 0 | Train Epoch: 0 [239232/250314 (96%)]\tLoss: 0.733758\tData (t) 0.244\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:26 | INFO | Rank 0 | Train Epoch: 0 [239264/250314 (96%)]\tLoss: 0.546076\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:27 | INFO | Rank 0 | Train Epoch: 0 [239296/250314 (96%)]\tLoss: 0.331424\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:27 | INFO | Rank 0 | Train Epoch: 0 [239328/250314 (96%)]\tLoss: 0.431839\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:28 | INFO | Rank 0 | Train Epoch: 0 [239360/250314 (96%)]\tLoss: 0.440549\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:28 | INFO | Rank 0 | Train Epoch: 0 [239392/250314 (96%)]\tLoss: 0.575923\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:29 | INFO | Rank 0 | Train Epoch: 0 [239424/250314 (96%)]\tLoss: 0.781435\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:29 | INFO | Rank 0 | Train Epoch: 0 [239456/250314 (96%)]\tLoss: 0.372521\tData (t) 0.261\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:30 | INFO | Rank 0 | Train Epoch: 0 [239488/250314 (96%)]\tLoss: 0.461953\tData (t) 0.334\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:30 | INFO | Rank 0 | Train Epoch: 0 [239520/250314 (96%)]\tLoss: 0.987179\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:31 | INFO | Rank 0 | Train Epoch: 0 [239552/250314 (96%)]\tLoss: 0.527704\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:31 | INFO | Rank 0 | Train Epoch: 0 [239584/250314 (96%)]\tLoss: 0.586094\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:32 | INFO | Rank 0 | Train Epoch: 0 [239616/250314 (96%)]\tLoss: 0.642886\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:32 | INFO | Rank 0 | Train Epoch: 0 [239648/250314 (96%)]\tLoss: 0.379141\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:33 | INFO | Rank 0 | Train Epoch: 0 [239680/250314 (96%)]\tLoss: 0.612441\tData (t) 0.210\tBatch (t) 0.421\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:33 | INFO | Rank 0 | Train Epoch: 0 [239712/250314 (96%)]\tLoss: 0.999545\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:34 | INFO | Rank 0 | Train Epoch: 0 [239744/250314 (96%)]\tLoss: 0.537112\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:34 | INFO | Rank 0 | Train Epoch: 0 [239776/250314 (96%)]\tLoss: 0.511473\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:35 | INFO | Rank 0 | Train Epoch: 0 [239808/250314 (96%)]\tLoss: 0.428635\tData (t) 0.298\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:35 | INFO | Rank 0 | Train Epoch: 0 [239840/250314 (96%)]\tLoss: 0.522756\tData (t) 0.357\tBatch (t) 0.568\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:36 | INFO | Rank 0 | Train Epoch: 0 [239872/250314 (96%)]\tLoss: 0.656464\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:36 | INFO | Rank 0 | Train Epoch: 0 [239904/250314 (96%)]\tLoss: 0.564281\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:37 | INFO | Rank 0 | Train Epoch: 0 [239936/250314 (96%)]\tLoss: 0.551562\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:37 | INFO | Rank 0 | Train Epoch: 0 [239968/250314 (96%)]\tLoss: 0.429741\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:38 | INFO | Rank 0 | Train Epoch: 0 [240000/250314 (96%)]\tLoss: 0.396977\tData (t) 0.253\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:38 | INFO | Rank 0 | Train Epoch: 0 [240032/250314 (96%)]\tLoss: 0.605759\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:39 | INFO | Rank 0 | Train Epoch: 0 [240064/250314 (96%)]\tLoss: 0.749818\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:39 | INFO | Rank 0 | Train Epoch: 0 [240096/250314 (96%)]\tLoss: 0.511067\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:40 | INFO | Rank 0 | Train Epoch: 0 [240128/250314 (96%)]\tLoss: 0.807117\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:40 | INFO | Rank 0 | Train Epoch: 0 [240160/250314 (96%)]\tLoss: 0.276357\tData (t) 0.326\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:41 | INFO | Rank 0 | Train Epoch: 0 [240192/250314 (96%)]\tLoss: 0.510992\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:41 | INFO | Rank 0 | Train Epoch: 0 [240224/250314 (96%)]\tLoss: 0.289580\tData (t) 0.304\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:42 | INFO | Rank 0 | Train Epoch: 0 [240256/250314 (96%)]\tLoss: 0.695570\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:42 | INFO | Rank 0 | Train Epoch: 0 [240288/250314 (96%)]\tLoss: 0.505421\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:43 | INFO | Rank 0 | Train Epoch: 0 [240320/250314 (96%)]\tLoss: 0.708668\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:43 | INFO | Rank 0 | Train Epoch: 0 [240352/250314 (96%)]\tLoss: 0.571049\tData (t) 0.237\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:44 | INFO | Rank 0 | Train Epoch: 0 [240384/250314 (96%)]\tLoss: 0.428184\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:44 | INFO | Rank 0 | Train Epoch: 0 [240416/250314 (96%)]\tLoss: 0.925863\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:44 | INFO | Rank 0 | Train Epoch: 0 [240448/250314 (96%)]\tLoss: 0.693444\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:45 | INFO | Rank 0 | Train Epoch: 0 [240480/250314 (96%)]\tLoss: 0.713128\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:45 | INFO | Rank 0 | Train Epoch: 0 [240512/250314 (96%)]\tLoss: 0.660838\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:46 | INFO | Rank 0 | Train Epoch: 0 [240544/250314 (96%)]\tLoss: 0.347846\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:46 | INFO | Rank 0 | Train Epoch: 0 [240576/250314 (96%)]\tLoss: 0.274464\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:47 | INFO | Rank 0 | Train Epoch: 0 [240608/250314 (96%)]\tLoss: 0.708212\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:47 | INFO | Rank 0 | Train Epoch: 0 [240640/250314 (96%)]\tLoss: 0.704702\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:48 | INFO | Rank 0 | Train Epoch: 0 [240672/250314 (96%)]\tLoss: 0.636930\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:48 | INFO | Rank 0 | Train Epoch: 0 [240704/250314 (96%)]\tLoss: 0.456457\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:49 | INFO | Rank 0 | Train Epoch: 0 [240736/250314 (96%)]\tLoss: 0.309130\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:49 | INFO | Rank 0 | Train Epoch: 0 [240768/250314 (96%)]\tLoss: 0.471406\tData (t) 0.280\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:50 | INFO | Rank 0 | Train Epoch: 0 [240800/250314 (96%)]\tLoss: 0.807888\tData (t) 0.291\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:50 | INFO | Rank 0 | Train Epoch: 0 [240832/250314 (96%)]\tLoss: 0.886222\tData (t) 0.279\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:51 | INFO | Rank 0 | Train Epoch: 0 [240864/250314 (96%)]\tLoss: 0.711547\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:51 | INFO | Rank 0 | Train Epoch: 0 [240896/250314 (96%)]\tLoss: 0.448396\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:52 | INFO | Rank 0 | Train Epoch: 0 [240928/250314 (96%)]\tLoss: 0.562418\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:52 | INFO | Rank 0 | Train Epoch: 0 [240960/250314 (96%)]\tLoss: 0.584932\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:53 | INFO | Rank 0 | Train Epoch: 0 [240992/250314 (96%)]\tLoss: 0.591207\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:53 | INFO | Rank 0 | Train Epoch: 0 [241024/250314 (96%)]\tLoss: 1.104443\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:54 | INFO | Rank 0 | Train Epoch: 0 [241056/250314 (96%)]\tLoss: 0.974250\tData (t) 0.223\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:54 | INFO | Rank 0 | Train Epoch: 0 [241088/250314 (96%)]\tLoss: 0.543758\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:55 | INFO | Rank 0 | Train Epoch: 0 [241120/250314 (96%)]\tLoss: 0.503196\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:55 | INFO | Rank 0 | Train Epoch: 0 [241152/250314 (96%)]\tLoss: 0.696101\tData (t) 0.212\tBatch (t) 0.423\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:56 | INFO | Rank 0 | Train Epoch: 0 [241184/250314 (96%)]\tLoss: 0.381226\tData (t) 0.294\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:56 | INFO | Rank 0 | Train Epoch: 0 [241216/250314 (96%)]\tLoss: 0.438701\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:57 | INFO | Rank 0 | Train Epoch: 0 [241248/250314 (96%)]\tLoss: 0.595946\tData (t) 0.396\tBatch (t) 0.607\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:57 | INFO | Rank 0 | Train Epoch: 0 [241280/250314 (96%)]\tLoss: 0.439509\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:58 | INFO | Rank 0 | Train Epoch: 0 [241312/250314 (96%)]\tLoss: 0.573192\tData (t) 0.320\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:58 | INFO | Rank 0 | Train Epoch: 0 [241344/250314 (96%)]\tLoss: 0.314990\tData (t) 0.215\tBatch (t) 0.426\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:59 | INFO | Rank 0 | Train Epoch: 0 [241376/250314 (96%)]\tLoss: 0.970526\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:11:59 | INFO | Rank 0 | Train Epoch: 0 [241408/250314 (96%)]\tLoss: 0.680279\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:00 | INFO | Rank 0 | Train Epoch: 0 [241440/250314 (96%)]\tLoss: 0.331615\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:00 | INFO | Rank 0 | Train Epoch: 0 [241472/250314 (96%)]\tLoss: 0.543184\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:01 | INFO | Rank 0 | Train Epoch: 0 [241504/250314 (96%)]\tLoss: 0.526115\tData (t) 0.383\tBatch (t) 0.595\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:01 | INFO | Rank 0 | Train Epoch: 0 [241536/250314 (96%)]\tLoss: 0.668833\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:02 | INFO | Rank 0 | Train Epoch: 0 [241568/250314 (97%)]\tLoss: 0.494661\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:02 | INFO | Rank 0 | Train Epoch: 0 [241600/250314 (97%)]\tLoss: 0.766056\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:03 | INFO | Rank 0 | Train Epoch: 0 [241632/250314 (97%)]\tLoss: 0.327925\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:03 | INFO | Rank 0 | Train Epoch: 0 [241664/250314 (97%)]\tLoss: 0.439541\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:04 | INFO | Rank 0 | Train Epoch: 0 [241696/250314 (97%)]\tLoss: 0.742423\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:04 | INFO | Rank 0 | Train Epoch: 0 [241728/250314 (97%)]\tLoss: 0.333919\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:05 | INFO | Rank 0 | Train Epoch: 0 [241760/250314 (97%)]\tLoss: 0.757819\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:05 | INFO | Rank 0 | Train Epoch: 0 [241792/250314 (97%)]\tLoss: 0.416292\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:06 | INFO | Rank 0 | Train Epoch: 0 [241824/250314 (97%)]\tLoss: 0.512790\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:06 | INFO | Rank 0 | Train Epoch: 0 [241856/250314 (97%)]\tLoss: 0.469737\tData (t) 0.400\tBatch (t) 0.612\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:07 | INFO | Rank 0 | Train Epoch: 0 [241888/250314 (97%)]\tLoss: 0.624838\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:07 | INFO | Rank 0 | Train Epoch: 0 [241920/250314 (97%)]\tLoss: 0.558673\tData (t) 0.287\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:08 | INFO | Rank 0 | Train Epoch: 0 [241952/250314 (97%)]\tLoss: 0.351378\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:08 | INFO | Rank 0 | Train Epoch: 0 [241984/250314 (97%)]\tLoss: 0.950158\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:09 | INFO | Rank 0 | Train Epoch: 0 [242016/250314 (97%)]\tLoss: 0.826078\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:09 | INFO | Rank 0 | Train Epoch: 0 [242048/250314 (97%)]\tLoss: 0.585842\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:10 | INFO | Rank 0 | Train Epoch: 0 [242080/250314 (97%)]\tLoss: 0.485570\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:10 | INFO | Rank 0 | Train Epoch: 0 [242112/250314 (97%)]\tLoss: 0.608976\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:11 | INFO | Rank 0 | Train Epoch: 0 [242144/250314 (97%)]\tLoss: 0.802948\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:11 | INFO | Rank 0 | Train Epoch: 0 [242176/250314 (97%)]\tLoss: 0.571867\tData (t) 0.352\tBatch (t) 0.564\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:12 | INFO | Rank 0 | Train Epoch: 0 [242208/250314 (97%)]\tLoss: 0.493727\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:12 | INFO | Rank 0 | Train Epoch: 0 [242240/250314 (97%)]\tLoss: 0.442797\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:13 | INFO | Rank 0 | Train Epoch: 0 [242272/250314 (97%)]\tLoss: 0.527424\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:13 | INFO | Rank 0 | Train Epoch: 0 [242304/250314 (97%)]\tLoss: 0.333556\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:14 | INFO | Rank 0 | Train Epoch: 0 [242336/250314 (97%)]\tLoss: 0.448930\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:14 | INFO | Rank 0 | Train Epoch: 0 [242368/250314 (97%)]\tLoss: 0.809147\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:15 | INFO | Rank 0 | Train Epoch: 0 [242400/250314 (97%)]\tLoss: 0.991127\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:15 | INFO | Rank 0 | Train Epoch: 0 [242432/250314 (97%)]\tLoss: 0.724509\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:16 | INFO | Rank 0 | Train Epoch: 0 [242464/250314 (97%)]\tLoss: 0.505580\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:16 | INFO | Rank 0 | Train Epoch: 0 [242496/250314 (97%)]\tLoss: 0.569168\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:17 | INFO | Rank 0 | Train Epoch: 0 [242528/250314 (97%)]\tLoss: 0.614363\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:17 | INFO | Rank 0 | Train Epoch: 0 [242560/250314 (97%)]\tLoss: 0.605312\tData (t) 0.274\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:18 | INFO | Rank 0 | Train Epoch: 0 [242592/250314 (97%)]\tLoss: 0.814637\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:18 | INFO | Rank 0 | Train Epoch: 0 [242624/250314 (97%)]\tLoss: 0.707990\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:19 | INFO | Rank 0 | Train Epoch: 0 [242656/250314 (97%)]\tLoss: 0.694815\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:19 | INFO | Rank 0 | Train Epoch: 0 [242688/250314 (97%)]\tLoss: 0.526647\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:20 | INFO | Rank 0 | Train Epoch: 0 [242720/250314 (97%)]\tLoss: 0.882862\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:20 | INFO | Rank 0 | Train Epoch: 0 [242752/250314 (97%)]\tLoss: 0.429379\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:20 | INFO | Rank 0 | Train Epoch: 0 [242784/250314 (97%)]\tLoss: 0.500802\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:21 | INFO | Rank 0 | Train Epoch: 0 [242816/250314 (97%)]\tLoss: 0.739946\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:21 | INFO | Rank 0 | Train Epoch: 0 [242848/250314 (97%)]\tLoss: 0.803019\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:22 | INFO | Rank 0 | Train Epoch: 0 [242880/250314 (97%)]\tLoss: 0.529115\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:22 | INFO | Rank 0 | Train Epoch: 0 [242912/250314 (97%)]\tLoss: 0.928898\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:23 | INFO | Rank 0 | Train Epoch: 0 [242944/250314 (97%)]\tLoss: 0.419828\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:23 | INFO | Rank 0 | Train Epoch: 0 [242976/250314 (97%)]\tLoss: 0.655263\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:24 | INFO | Rank 0 | Train Epoch: 0 [243008/250314 (97%)]\tLoss: 0.652010\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:24 | INFO | Rank 0 | Train Epoch: 0 [243040/250314 (97%)]\tLoss: 1.075113\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:25 | INFO | Rank 0 | Train Epoch: 0 [243072/250314 (97%)]\tLoss: 0.587608\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:25 | INFO | Rank 0 | Train Epoch: 0 [243104/250314 (97%)]\tLoss: 0.551044\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:26 | INFO | Rank 0 | Train Epoch: 0 [243136/250314 (97%)]\tLoss: 0.775921\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:26 | INFO | Rank 0 | Train Epoch: 0 [243168/250314 (97%)]\tLoss: 0.336774\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:27 | INFO | Rank 0 | Train Epoch: 0 [243200/250314 (97%)]\tLoss: 0.478590\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:27 | INFO | Rank 0 | Train Epoch: 0 [243232/250314 (97%)]\tLoss: 0.297938\tData (t) 0.276\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:28 | INFO | Rank 0 | Train Epoch: 0 [243264/250314 (97%)]\tLoss: 0.761817\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:28 | INFO | Rank 0 | Train Epoch: 0 [243296/250314 (97%)]\tLoss: 0.723046\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:29 | INFO | Rank 0 | Train Epoch: 0 [243328/250314 (97%)]\tLoss: 0.632508\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:29 | INFO | Rank 0 | Train Epoch: 0 [243360/250314 (97%)]\tLoss: 0.846871\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:30 | INFO | Rank 0 | Train Epoch: 0 [243392/250314 (97%)]\tLoss: 0.422385\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:30 | INFO | Rank 0 | Train Epoch: 0 [243424/250314 (97%)]\tLoss: 0.618160\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:31 | INFO | Rank 0 | Train Epoch: 0 [243456/250314 (97%)]\tLoss: 0.820796\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:31 | INFO | Rank 0 | Train Epoch: 0 [243488/250314 (97%)]\tLoss: 0.350273\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:32 | INFO | Rank 0 | Train Epoch: 0 [243520/250314 (97%)]\tLoss: 0.387336\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:32 | INFO | Rank 0 | Train Epoch: 0 [243552/250314 (97%)]\tLoss: 0.438836\tData (t) 0.425\tBatch (t) 0.637\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:33 | INFO | Rank 0 | Train Epoch: 0 [243584/250314 (97%)]\tLoss: 0.466374\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:33 | INFO | Rank 0 | Train Epoch: 0 [243616/250314 (97%)]\tLoss: 0.242551\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:34 | INFO | Rank 0 | Train Epoch: 0 [243648/250314 (97%)]\tLoss: 0.651093\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:34 | INFO | Rank 0 | Train Epoch: 0 [243680/250314 (97%)]\tLoss: 0.587559\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:35 | INFO | Rank 0 | Train Epoch: 0 [243712/250314 (97%)]\tLoss: 0.646569\tData (t) 0.199\tBatch (t) 0.411\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:35 | INFO | Rank 0 | Train Epoch: 0 [243744/250314 (97%)]\tLoss: 1.053421\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:36 | INFO | Rank 0 | Train Epoch: 0 [243776/250314 (97%)]\tLoss: 0.583582\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:36 | INFO | Rank 0 | Train Epoch: 0 [243808/250314 (97%)]\tLoss: 0.676486\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:37 | INFO | Rank 0 | Train Epoch: 0 [243840/250314 (97%)]\tLoss: 0.665180\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:37 | INFO | Rank 0 | Train Epoch: 0 [243872/250314 (97%)]\tLoss: 0.521790\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:38 | INFO | Rank 0 | Train Epoch: 0 [243904/250314 (97%)]\tLoss: 0.618106\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:38 | INFO | Rank 0 | Train Epoch: 0 [243936/250314 (97%)]\tLoss: 0.711888\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:38 | INFO | Rank 0 | Train Epoch: 0 [243968/250314 (97%)]\tLoss: 0.842654\tData (t) 0.207\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:39 | INFO | Rank 0 | Train Epoch: 0 [244000/250314 (97%)]\tLoss: 0.858148\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:39 | INFO | Rank 0 | Train Epoch: 0 [244032/250314 (97%)]\tLoss: 0.440061\tData (t) 0.216\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:40 | INFO | Rank 0 | Train Epoch: 0 [244064/250314 (98%)]\tLoss: 0.391325\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:40 | INFO | Rank 0 | Train Epoch: 0 [244096/250314 (98%)]\tLoss: 0.416628\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:41 | INFO | Rank 0 | Train Epoch: 0 [244128/250314 (98%)]\tLoss: 0.783138\tData (t) 0.205\tBatch (t) 0.416\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:41 | INFO | Rank 0 | Train Epoch: 0 [244160/250314 (98%)]\tLoss: 0.766389\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:42 | INFO | Rank 0 | Train Epoch: 0 [244192/250314 (98%)]\tLoss: 0.392709\tData (t) 0.342\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:42 | INFO | Rank 0 | Train Epoch: 0 [244224/250314 (98%)]\tLoss: 0.535574\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:43 | INFO | Rank 0 | Train Epoch: 0 [244256/250314 (98%)]\tLoss: 0.490980\tData (t) 0.314\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:43 | INFO | Rank 0 | Train Epoch: 0 [244288/250314 (98%)]\tLoss: 0.520713\tData (t) 0.251\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:44 | INFO | Rank 0 | Train Epoch: 0 [244320/250314 (98%)]\tLoss: 0.342411\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:44 | INFO | Rank 0 | Train Epoch: 0 [244352/250314 (98%)]\tLoss: 0.393071\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:45 | INFO | Rank 0 | Train Epoch: 0 [244384/250314 (98%)]\tLoss: 0.886883\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:45 | INFO | Rank 0 | Train Epoch: 0 [244416/250314 (98%)]\tLoss: 0.975862\tData (t) 0.225\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:46 | INFO | Rank 0 | Train Epoch: 0 [244448/250314 (98%)]\tLoss: 0.631293\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:46 | INFO | Rank 0 | Train Epoch: 0 [244480/250314 (98%)]\tLoss: 0.561063\tData (t) 0.220\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:47 | INFO | Rank 0 | Train Epoch: 0 [244512/250314 (98%)]\tLoss: 0.567283\tData (t) 0.201\tBatch (t) 0.413\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:47 | INFO | Rank 0 | Train Epoch: 0 [244544/250314 (98%)]\tLoss: 0.736713\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:48 | INFO | Rank 0 | Train Epoch: 0 [244576/250314 (98%)]\tLoss: 0.635114\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:48 | INFO | Rank 0 | Train Epoch: 0 [244608/250314 (98%)]\tLoss: 0.197742\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:49 | INFO | Rank 0 | Train Epoch: 0 [244640/250314 (98%)]\tLoss: 0.894489\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:49 | INFO | Rank 0 | Train Epoch: 0 [244672/250314 (98%)]\tLoss: 0.636201\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:50 | INFO | Rank 0 | Train Epoch: 0 [244704/250314 (98%)]\tLoss: 1.099210\tData (t) 0.329\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:50 | INFO | Rank 0 | Train Epoch: 0 [244736/250314 (98%)]\tLoss: 0.511225\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:51 | INFO | Rank 0 | Train Epoch: 0 [244768/250314 (98%)]\tLoss: 0.572049\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:51 | INFO | Rank 0 | Train Epoch: 0 [244800/250314 (98%)]\tLoss: 0.696530\tData (t) 0.253\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:51 | INFO | Rank 0 | Train Epoch: 0 [244832/250314 (98%)]\tLoss: 0.667813\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:52 | INFO | Rank 0 | Train Epoch: 0 [244864/250314 (98%)]\tLoss: 1.014067\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:52 | INFO | Rank 0 | Train Epoch: 0 [244896/250314 (98%)]\tLoss: 0.638407\tData (t) 0.239\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:53 | INFO | Rank 0 | Train Epoch: 0 [244928/250314 (98%)]\tLoss: 0.912055\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:53 | INFO | Rank 0 | Train Epoch: 0 [244960/250314 (98%)]\tLoss: 0.492188\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:54 | INFO | Rank 0 | Train Epoch: 0 [244992/250314 (98%)]\tLoss: 0.667424\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:54 | INFO | Rank 0 | Train Epoch: 0 [245024/250314 (98%)]\tLoss: 0.493792\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:55 | INFO | Rank 0 | Train Epoch: 0 [245056/250314 (98%)]\tLoss: 0.319724\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:55 | INFO | Rank 0 | Train Epoch: 0 [245088/250314 (98%)]\tLoss: 0.596615\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:56 | INFO | Rank 0 | Train Epoch: 0 [245120/250314 (98%)]\tLoss: 0.573498\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:56 | INFO | Rank 0 | Train Epoch: 0 [245152/250314 (98%)]\tLoss: 0.545265\tData (t) 0.220\tBatch (t) 0.432\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:57 | INFO | Rank 0 | Train Epoch: 0 [245184/250314 (98%)]\tLoss: 0.909505\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:57 | INFO | Rank 0 | Train Epoch: 0 [245216/250314 (98%)]\tLoss: 0.857361\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:58 | INFO | Rank 0 | Train Epoch: 0 [245248/250314 (98%)]\tLoss: 0.647692\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:58 | INFO | Rank 0 | Train Epoch: 0 [245280/250314 (98%)]\tLoss: 0.751680\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:59 | INFO | Rank 0 | Train Epoch: 0 [245312/250314 (98%)]\tLoss: 0.671189\tData (t) 0.402\tBatch (t) 0.613\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:12:59 | INFO | Rank 0 | Train Epoch: 0 [245344/250314 (98%)]\tLoss: 0.235830\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:00 | INFO | Rank 0 | Train Epoch: 0 [245376/250314 (98%)]\tLoss: 0.505362\tData (t) 0.202\tBatch (t) 0.413\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:00 | INFO | Rank 0 | Train Epoch: 0 [245408/250314 (98%)]\tLoss: 0.522269\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:01 | INFO | Rank 0 | Train Epoch: 0 [245440/250314 (98%)]\tLoss: 0.866900\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:01 | INFO | Rank 0 | Train Epoch: 0 [245472/250314 (98%)]\tLoss: 0.483806\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:02 | INFO | Rank 0 | Train Epoch: 0 [245504/250314 (98%)]\tLoss: 0.821343\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:02 | INFO | Rank 0 | Train Epoch: 0 [245536/250314 (98%)]\tLoss: 0.841437\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:03 | INFO | Rank 0 | Train Epoch: 0 [245568/250314 (98%)]\tLoss: 0.425530\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:03 | INFO | Rank 0 | Train Epoch: 0 [245600/250314 (98%)]\tLoss: 0.395766\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:04 | INFO | Rank 0 | Train Epoch: 0 [245632/250314 (98%)]\tLoss: 0.740946\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:04 | INFO | Rank 0 | Train Epoch: 0 [245664/250314 (98%)]\tLoss: 0.535779\tData (t) 0.271\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:05 | INFO | Rank 0 | Train Epoch: 0 [245696/250314 (98%)]\tLoss: 0.375549\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:05 | INFO | Rank 0 | Train Epoch: 0 [245728/250314 (98%)]\tLoss: 0.894147\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:06 | INFO | Rank 0 | Train Epoch: 0 [245760/250314 (98%)]\tLoss: 0.334817\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:06 | INFO | Rank 0 | Train Epoch: 0 [245792/250314 (98%)]\tLoss: 0.540759\tData (t) 0.310\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:07 | INFO | Rank 0 | Train Epoch: 0 [245824/250314 (98%)]\tLoss: 0.945279\tData (t) 0.226\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:07 | INFO | Rank 0 | Train Epoch: 0 [245856/250314 (98%)]\tLoss: 0.578430\tData (t) 0.225\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:07 | INFO | Rank 0 | Train Epoch: 0 [245888/250314 (98%)]\tLoss: 1.184297\tData (t) 0.226\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:08 | INFO | Rank 0 | Train Epoch: 0 [245920/250314 (98%)]\tLoss: 0.350713\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:09 | INFO | Rank 0 | Train Epoch: 0 [245952/250314 (98%)]\tLoss: 0.252188\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:09 | INFO | Rank 0 | Train Epoch: 0 [245984/250314 (98%)]\tLoss: 0.426453\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:09 | INFO | Rank 0 | Train Epoch: 0 [246016/250314 (98%)]\tLoss: 0.553812\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:10 | INFO | Rank 0 | Train Epoch: 0 [246048/250314 (98%)]\tLoss: 0.302743\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:10 | INFO | Rank 0 | Train Epoch: 0 [246080/250314 (98%)]\tLoss: 0.640988\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:11 | INFO | Rank 0 | Train Epoch: 0 [246112/250314 (98%)]\tLoss: 0.709403\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:11 | INFO | Rank 0 | Train Epoch: 0 [246144/250314 (98%)]\tLoss: 0.398614\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:12 | INFO | Rank 0 | Train Epoch: 0 [246176/250314 (98%)]\tLoss: 0.238996\tData (t) 0.216\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:12 | INFO | Rank 0 | Train Epoch: 0 [246208/250314 (98%)]\tLoss: 0.593056\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:13 | INFO | Rank 0 | Train Epoch: 0 [246240/250314 (98%)]\tLoss: 0.503857\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:13 | INFO | Rank 0 | Train Epoch: 0 [246272/250314 (98%)]\tLoss: 0.654581\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:14 | INFO | Rank 0 | Train Epoch: 0 [246304/250314 (98%)]\tLoss: 0.502991\tData (t) 0.355\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:14 | INFO | Rank 0 | Train Epoch: 0 [246336/250314 (98%)]\tLoss: 1.472759\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:15 | INFO | Rank 0 | Train Epoch: 0 [246368/250314 (98%)]\tLoss: 0.958559\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:15 | INFO | Rank 0 | Train Epoch: 0 [246400/250314 (98%)]\tLoss: 0.678314\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:16 | INFO | Rank 0 | Train Epoch: 0 [246432/250314 (98%)]\tLoss: 0.645339\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:16 | INFO | Rank 0 | Train Epoch: 0 [246464/250314 (98%)]\tLoss: 0.618214\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:17 | INFO | Rank 0 | Train Epoch: 0 [246496/250314 (98%)]\tLoss: 0.652766\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:17 | INFO | Rank 0 | Train Epoch: 0 [246528/250314 (98%)]\tLoss: 0.381757\tData (t) 0.336\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:18 | INFO | Rank 0 | Train Epoch: 0 [246560/250314 (99%)]\tLoss: 0.627821\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:18 | INFO | Rank 0 | Train Epoch: 0 [246592/250314 (99%)]\tLoss: 1.046717\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:19 | INFO | Rank 0 | Train Epoch: 0 [246624/250314 (99%)]\tLoss: 0.683367\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:19 | INFO | Rank 0 | Train Epoch: 0 [246656/250314 (99%)]\tLoss: 0.452014\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:20 | INFO | Rank 0 | Train Epoch: 0 [246688/250314 (99%)]\tLoss: 0.485378\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:20 | INFO | Rank 0 | Train Epoch: 0 [246720/250314 (99%)]\tLoss: 0.423909\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:21 | INFO | Rank 0 | Train Epoch: 0 [246752/250314 (99%)]\tLoss: 0.687347\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:21 | INFO | Rank 0 | Train Epoch: 0 [246784/250314 (99%)]\tLoss: 0.857628\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:22 | INFO | Rank 0 | Train Epoch: 0 [246816/250314 (99%)]\tLoss: 0.568264\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:22 | INFO | Rank 0 | Train Epoch: 0 [246848/250314 (99%)]\tLoss: 1.002751\tData (t) 0.253\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:23 | INFO | Rank 0 | Train Epoch: 0 [246880/250314 (99%)]\tLoss: 0.346618\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:23 | INFO | Rank 0 | Train Epoch: 0 [246912/250314 (99%)]\tLoss: 0.400407\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:24 | INFO | Rank 0 | Train Epoch: 0 [246944/250314 (99%)]\tLoss: 0.832735\tData (t) 0.330\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:24 | INFO | Rank 0 | Train Epoch: 0 [246976/250314 (99%)]\tLoss: 0.545947\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:25 | INFO | Rank 0 | Train Epoch: 0 [247008/250314 (99%)]\tLoss: 0.557790\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:25 | INFO | Rank 0 | Train Epoch: 0 [247040/250314 (99%)]\tLoss: 0.903969\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:26 | INFO | Rank 0 | Train Epoch: 0 [247072/250314 (99%)]\tLoss: 0.903358\tData (t) 0.296\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:26 | INFO | Rank 0 | Train Epoch: 0 [247104/250314 (99%)]\tLoss: 0.467622\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:27 | INFO | Rank 0 | Train Epoch: 0 [247136/250314 (99%)]\tLoss: 0.313354\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:27 | INFO | Rank 0 | Train Epoch: 0 [247168/250314 (99%)]\tLoss: 1.055129\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:28 | INFO | Rank 0 | Train Epoch: 0 [247200/250314 (99%)]\tLoss: 0.942331\tData (t) 0.228\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:28 | INFO | Rank 0 | Train Epoch: 0 [247232/250314 (99%)]\tLoss: 0.387496\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:28 | INFO | Rank 0 | Train Epoch: 0 [247264/250314 (99%)]\tLoss: 0.300623\tData (t) 0.233\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:29 | INFO | Rank 0 | Train Epoch: 0 [247296/250314 (99%)]\tLoss: 0.413866\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:30 | INFO | Rank 0 | Train Epoch: 0 [247328/250314 (99%)]\tLoss: 0.549257\tData (t) 0.360\tBatch (t) 0.572\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:30 | INFO | Rank 0 | Train Epoch: 0 [247360/250314 (99%)]\tLoss: 0.707996\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:30 | INFO | Rank 0 | Train Epoch: 0 [247392/250314 (99%)]\tLoss: 0.611222\tData (t) 0.226\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:31 | INFO | Rank 0 | Train Epoch: 0 [247424/250314 (99%)]\tLoss: 0.519323\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:31 | INFO | Rank 0 | Train Epoch: 0 [247456/250314 (99%)]\tLoss: 0.646032\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:32 | INFO | Rank 0 | Train Epoch: 0 [247488/250314 (99%)]\tLoss: 0.959172\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:32 | INFO | Rank 0 | Train Epoch: 0 [247520/250314 (99%)]\tLoss: 0.520824\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:33 | INFO | Rank 0 | Train Epoch: 0 [247552/250314 (99%)]\tLoss: 0.510319\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:33 | INFO | Rank 0 | Train Epoch: 0 [247584/250314 (99%)]\tLoss: 0.892311\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:34 | INFO | Rank 0 | Train Epoch: 0 [247616/250314 (99%)]\tLoss: 0.643206\tData (t) 0.337\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:35 | INFO | Rank 0 | Train Epoch: 0 [247648/250314 (99%)]\tLoss: 0.873999\tData (t) 0.472\tBatch (t) 0.683\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:35 | INFO | Rank 0 | Train Epoch: 0 [247680/250314 (99%)]\tLoss: 1.225415\tData (t) 0.336\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:36 | INFO | Rank 0 | Train Epoch: 0 [247712/250314 (99%)]\tLoss: 0.872362\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:36 | INFO | Rank 0 | Train Epoch: 0 [247744/250314 (99%)]\tLoss: 0.335779\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:37 | INFO | Rank 0 | Train Epoch: 0 [247776/250314 (99%)]\tLoss: 0.312856\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:37 | INFO | Rank 0 | Train Epoch: 0 [247808/250314 (99%)]\tLoss: 0.476510\tData (t) 0.332\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:38 | INFO | Rank 0 | Train Epoch: 0 [247840/250314 (99%)]\tLoss: 0.423580\tData (t) 0.264\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:38 | INFO | Rank 0 | Train Epoch: 0 [247872/250314 (99%)]\tLoss: 1.133092\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:39 | INFO | Rank 0 | Train Epoch: 0 [247904/250314 (99%)]\tLoss: 0.956502\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:39 | INFO | Rank 0 | Train Epoch: 0 [247936/250314 (99%)]\tLoss: 0.756237\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:40 | INFO | Rank 0 | Train Epoch: 0 [247968/250314 (99%)]\tLoss: 0.685033\tData (t) 0.429\tBatch (t) 0.641\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:40 | INFO | Rank 0 | Train Epoch: 0 [248000/250314 (99%)]\tLoss: 0.496600\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:41 | INFO | Rank 0 | Train Epoch: 0 [248032/250314 (99%)]\tLoss: 0.213851\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:41 | INFO | Rank 0 | Train Epoch: 0 [248064/250314 (99%)]\tLoss: 0.629405\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:42 | INFO | Rank 0 | Train Epoch: 0 [248096/250314 (99%)]\tLoss: 0.354841\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:42 | INFO | Rank 0 | Train Epoch: 0 [248128/250314 (99%)]\tLoss: 0.342595\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:43 | INFO | Rank 0 | Train Epoch: 0 [248160/250314 (99%)]\tLoss: 0.631083\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:43 | INFO | Rank 0 | Train Epoch: 0 [248192/250314 (99%)]\tLoss: 0.630977\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:44 | INFO | Rank 0 | Train Epoch: 0 [248224/250314 (99%)]\tLoss: 0.853948\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:44 | INFO | Rank 0 | Train Epoch: 0 [248256/250314 (99%)]\tLoss: 0.489175\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:45 | INFO | Rank 0 | Train Epoch: 0 [248288/250314 (99%)]\tLoss: 0.544185\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:45 | INFO | Rank 0 | Train Epoch: 0 [248320/250314 (99%)]\tLoss: 0.655963\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:46 | INFO | Rank 0 | Train Epoch: 0 [248352/250314 (99%)]\tLoss: 0.679088\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:46 | INFO | Rank 0 | Train Epoch: 0 [248384/250314 (99%)]\tLoss: 0.180744\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:47 | INFO | Rank 0 | Train Epoch: 0 [248416/250314 (99%)]\tLoss: 0.812908\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:47 | INFO | Rank 0 | Train Epoch: 0 [248448/250314 (99%)]\tLoss: 0.586197\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:48 | INFO | Rank 0 | Train Epoch: 0 [248480/250314 (99%)]\tLoss: 0.580511\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:48 | INFO | Rank 0 | Train Epoch: 0 [248512/250314 (99%)]\tLoss: 0.636399\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:49 | INFO | Rank 0 | Train Epoch: 0 [248544/250314 (99%)]\tLoss: 0.682005\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:49 | INFO | Rank 0 | Train Epoch: 0 [248576/250314 (99%)]\tLoss: 0.737588\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:50 | INFO | Rank 0 | Train Epoch: 0 [248608/250314 (99%)]\tLoss: 0.576524\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:50 | INFO | Rank 0 | Train Epoch: 0 [248640/250314 (99%)]\tLoss: 0.619164\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:51 | INFO | Rank 0 | Train Epoch: 0 [248672/250314 (99%)]\tLoss: 0.582052\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:51 | INFO | Rank 0 | Train Epoch: 0 [248704/250314 (99%)]\tLoss: 0.916077\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:52 | INFO | Rank 0 | Train Epoch: 0 [248736/250314 (99%)]\tLoss: 0.134229\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:52 | INFO | Rank 0 | Train Epoch: 0 [248768/250314 (99%)]\tLoss: 0.151720\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:53 | INFO | Rank 0 | Train Epoch: 0 [248800/250314 (99%)]\tLoss: 0.697570\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:53 | INFO | Rank 0 | Train Epoch: 0 [248832/250314 (99%)]\tLoss: 0.577898\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:54 | INFO | Rank 0 | Train Epoch: 0 [248864/250314 (99%)]\tLoss: 0.349450\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:54 | INFO | Rank 0 | Train Epoch: 0 [248896/250314 (99%)]\tLoss: 0.548640\tData (t) 0.219\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:55 | INFO | Rank 0 | Train Epoch: 0 [248928/250314 (99%)]\tLoss: 0.473266\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:55 | INFO | Rank 0 | Train Epoch: 0 [248960/250314 (99%)]\tLoss: 0.510461\tData (t) 0.362\tBatch (t) 0.573\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:56 | INFO | Rank 0 | Train Epoch: 0 [248992/250314 (99%)]\tLoss: 0.664990\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:56 | INFO | Rank 0 | Train Epoch: 0 [249024/250314 (99%)]\tLoss: 0.349372\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:57 | INFO | Rank 0 | Train Epoch: 0 [249056/250314 (100%)]\tLoss: 0.507434\tData (t) 0.235\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:57 | INFO | Rank 0 | Train Epoch: 0 [249088/250314 (100%)]\tLoss: 0.675906\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:58 | INFO | Rank 0 | Train Epoch: 0 [249120/250314 (100%)]\tLoss: 0.569727\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:58 | INFO | Rank 0 | Train Epoch: 0 [249152/250314 (100%)]\tLoss: 0.652262\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:59 | INFO | Rank 0 | Train Epoch: 0 [249184/250314 (100%)]\tLoss: 0.839234\tData (t) 0.255\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:13:59 | INFO | Rank 0 | Train Epoch: 0 [249216/250314 (100%)]\tLoss: 0.486111\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:00 | INFO | Rank 0 | Train Epoch: 0 [249248/250314 (100%)]\tLoss: 0.702114\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:00 | INFO | Rank 0 | Train Epoch: 0 [249280/250314 (100%)]\tLoss: 0.241671\tData (t) 0.227\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:00 | INFO | Rank 0 | Train Epoch: 0 [249312/250314 (100%)]\tLoss: 0.743439\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:01 | INFO | Rank 0 | Train Epoch: 0 [249344/250314 (100%)]\tLoss: 0.654820\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:01 | INFO | Rank 0 | Train Epoch: 0 [249376/250314 (100%)]\tLoss: 0.520633\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:02 | INFO | Rank 0 | Train Epoch: 0 [249408/250314 (100%)]\tLoss: 0.248850\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:02 | INFO | Rank 0 | Train Epoch: 0 [249440/250314 (100%)]\tLoss: 0.624008\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:03 | INFO | Rank 0 | Train Epoch: 0 [249472/250314 (100%)]\tLoss: 0.659934\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:03 | INFO | Rank 0 | Train Epoch: 0 [249504/250314 (100%)]\tLoss: 0.330174\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:04 | INFO | Rank 0 | Train Epoch: 0 [249536/250314 (100%)]\tLoss: 0.702752\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:04 | INFO | Rank 0 | Train Epoch: 0 [249568/250314 (100%)]\tLoss: 0.894368\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:05 | INFO | Rank 0 | Train Epoch: 0 [249600/250314 (100%)]\tLoss: 0.499944\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:05 | INFO | Rank 0 | Train Epoch: 0 [249632/250314 (100%)]\tLoss: 0.397870\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:06 | INFO | Rank 0 | Train Epoch: 0 [249664/250314 (100%)]\tLoss: 0.536483\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:06 | INFO | Rank 0 | Train Epoch: 0 [249696/250314 (100%)]\tLoss: 0.728474\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:07 | INFO | Rank 0 | Train Epoch: 0 [249728/250314 (100%)]\tLoss: 1.076183\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:07 | INFO | Rank 0 | Train Epoch: 0 [249760/250314 (100%)]\tLoss: 0.425375\tData (t) 0.231\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:08 | INFO | Rank 0 | Train Epoch: 0 [249792/250314 (100%)]\tLoss: 0.645224\tData (t) 0.321\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:08 | INFO | Rank 0 | Train Epoch: 0 [249824/250314 (100%)]\tLoss: 0.696774\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:09 | INFO | Rank 0 | Train Epoch: 0 [249856/250314 (100%)]\tLoss: 0.789626\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:09 | INFO | Rank 0 | Train Epoch: 0 [249888/250314 (100%)]\tLoss: 0.608117\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:10 | INFO | Rank 0 | Train Epoch: 0 [249920/250314 (100%)]\tLoss: 0.437642\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:10 | INFO | Rank 0 | Train Epoch: 0 [249952/250314 (100%)]\tLoss: 0.427641\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:11 | INFO | Rank 0 | Train Epoch: 0 [249984/250314 (100%)]\tLoss: 0.656260\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:11 | INFO | Rank 0 | Train Epoch: 0 [250016/250314 (100%)]\tLoss: 0.722640\tData (t) 0.324\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:12 | INFO | Rank 0 | Train Epoch: 0 [250048/250314 (100%)]\tLoss: 0.726159\tData (t) 0.304\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:12 | INFO | Rank 0 | Train Epoch: 0 [250080/250314 (100%)]\tLoss: 0.727702\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:13 | INFO | Rank 0 | Train Epoch: 0 [250112/250314 (100%)]\tLoss: 0.607149\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:13 | INFO | Rank 0 | Train Epoch: 0 [250144/250314 (100%)]\tLoss: 0.466065\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:14 | INFO | Rank 0 | Train Epoch: 0 [250176/250314 (100%)]\tLoss: 0.826876\tData (t) 0.343\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:14 | INFO | Rank 0 | Train Epoch: 0 [250208/250314 (100%)]\tLoss: 0.520769\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:15 | INFO | Rank 0 | Train Epoch: 0 [250240/250314 (100%)]\tLoss: 0.373318\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:15 | INFO | Rank 0 | Train Epoch: 0 [250272/250314 (100%)]\tLoss: 0.344609\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:14:15 | INFO | Rank 0 | Begin to eval epoch: 1...\n",
      "100%|█████████████████████████████████████████| 956/956 [04:49<00:00,  3.30it/s]\n",
      "2022-11-09,14:19:05 | INFO | Rank 0 | Eval Epoch: 1 val_loss: 2.1729\tepoch: 1.0000\tnum_elements: 30588.0000\n",
      "2022-11-09,14:19:05 | INFO | Rank 0 | Start epoch 1\n",
      "2022-11-09,14:19:06 | INFO | Rank 0 | Train Epoch: 1 [0/250314 (0%)]\tLoss: 0.377218\tData (t) 0.421\tBatch (t) 0.646\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:06 | INFO | Rank 0 | Train Epoch: 1 [32/250314 (0%)]\tLoss: 0.422124\tData (t) 0.361\tBatch (t) 0.572\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:07 | INFO | Rank 0 | Train Epoch: 1 [64/250314 (0%)]\tLoss: 0.478912\tData (t) 0.417\tBatch (t) 0.629\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:08 | INFO | Rank 0 | Train Epoch: 1 [96/250314 (0%)]\tLoss: 0.473113\tData (t) 0.431\tBatch (t) 0.643\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:08 | INFO | Rank 0 | Train Epoch: 1 [128/250314 (0%)]\tLoss: 0.436257\tData (t) 0.435\tBatch (t) 0.647\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:09 | INFO | Rank 0 | Train Epoch: 1 [160/250314 (0%)]\tLoss: 0.703776\tData (t) 0.397\tBatch (t) 0.609\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:10 | INFO | Rank 0 | Train Epoch: 1 [192/250314 (0%)]\tLoss: 0.420265\tData (t) 0.429\tBatch (t) 0.642\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:10 | INFO | Rank 0 | Train Epoch: 1 [224/250314 (0%)]\tLoss: 0.503222\tData (t) 0.463\tBatch (t) 0.674\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:11 | INFO | Rank 0 | Train Epoch: 1 [256/250314 (0%)]\tLoss: 0.463390\tData (t) 0.384\tBatch (t) 0.596\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:11 | INFO | Rank 0 | Train Epoch: 1 [288/250314 (0%)]\tLoss: 0.546753\tData (t) 0.396\tBatch (t) 0.608\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:12 | INFO | Rank 0 | Train Epoch: 1 [320/250314 (0%)]\tLoss: 0.399387\tData (t) 0.384\tBatch (t) 0.596\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:13 | INFO | Rank 0 | Train Epoch: 1 [352/250314 (0%)]\tLoss: 0.432279\tData (t) 0.382\tBatch (t) 0.593\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:13 | INFO | Rank 0 | Train Epoch: 1 [384/250314 (0%)]\tLoss: 0.325338\tData (t) 0.416\tBatch (t) 0.627\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:14 | INFO | Rank 0 | Train Epoch: 1 [416/250314 (0%)]\tLoss: 0.402574\tData (t) 0.442\tBatch (t) 0.654\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:14 | INFO | Rank 0 | Train Epoch: 1 [448/250314 (0%)]\tLoss: 0.453348\tData (t) 0.382\tBatch (t) 0.593\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:15 | INFO | Rank 0 | Train Epoch: 1 [480/250314 (0%)]\tLoss: 0.337507\tData (t) 0.447\tBatch (t) 0.658\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:16 | INFO | Rank 0 | Train Epoch: 1 [512/250314 (0%)]\tLoss: 0.429741\tData (t) 0.353\tBatch (t) 0.565\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:16 | INFO | Rank 0 | Train Epoch: 1 [544/250314 (0%)]\tLoss: 0.288968\tData (t) 0.428\tBatch (t) 0.640\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:17 | INFO | Rank 0 | Train Epoch: 1 [576/250314 (0%)]\tLoss: 0.259935\tData (t) 0.381\tBatch (t) 0.593\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:18 | INFO | Rank 0 | Train Epoch: 1 [608/250314 (0%)]\tLoss: 0.210212\tData (t) 0.405\tBatch (t) 0.616\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:18 | INFO | Rank 0 | Train Epoch: 1 [640/250314 (0%)]\tLoss: 0.274839\tData (t) 0.377\tBatch (t) 0.589\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:19 | INFO | Rank 0 | Train Epoch: 1 [672/250314 (0%)]\tLoss: 0.278346\tData (t) 0.395\tBatch (t) 0.607\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:19 | INFO | Rank 0 | Train Epoch: 1 [704/250314 (0%)]\tLoss: 0.557040\tData (t) 0.332\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:20 | INFO | Rank 0 | Train Epoch: 1 [736/250314 (0%)]\tLoss: 0.257495\tData (t) 0.365\tBatch (t) 0.577\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:20 | INFO | Rank 0 | Train Epoch: 1 [768/250314 (0%)]\tLoss: 0.377423\tData (t) 0.385\tBatch (t) 0.597\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:21 | INFO | Rank 0 | Train Epoch: 1 [800/250314 (0%)]\tLoss: 0.509848\tData (t) 0.411\tBatch (t) 0.623\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:22 | INFO | Rank 0 | Train Epoch: 1 [832/250314 (0%)]\tLoss: 0.819560\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:22 | INFO | Rank 0 | Train Epoch: 1 [864/250314 (0%)]\tLoss: 0.342670\tData (t) 0.368\tBatch (t) 0.580\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:23 | INFO | Rank 0 | Train Epoch: 1 [896/250314 (0%)]\tLoss: 0.181962\tData (t) 0.368\tBatch (t) 0.579\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:23 | INFO | Rank 0 | Train Epoch: 1 [928/250314 (0%)]\tLoss: 0.510838\tData (t) 0.413\tBatch (t) 0.625\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:24 | INFO | Rank 0 | Train Epoch: 1 [960/250314 (0%)]\tLoss: 0.495079\tData (t) 0.361\tBatch (t) 0.572\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:25 | INFO | Rank 0 | Train Epoch: 1 [992/250314 (0%)]\tLoss: 0.511817\tData (t) 0.383\tBatch (t) 0.595\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:25 | INFO | Rank 0 | Train Epoch: 1 [1024/250314 (0%)]\tLoss: 0.651886\tData (t) 0.372\tBatch (t) 0.583\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:26 | INFO | Rank 0 | Train Epoch: 1 [1056/250314 (0%)]\tLoss: 0.352780\tData (t) 0.369\tBatch (t) 0.582\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:26 | INFO | Rank 0 | Train Epoch: 1 [1088/250314 (0%)]\tLoss: 0.183655\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:27 | INFO | Rank 0 | Train Epoch: 1 [1120/250314 (0%)]\tLoss: 0.407307\tData (t) 0.362\tBatch (t) 0.574\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:27 | INFO | Rank 0 | Train Epoch: 1 [1152/250314 (0%)]\tLoss: 0.360487\tData (t) 0.393\tBatch (t) 0.604\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:28 | INFO | Rank 0 | Train Epoch: 1 [1184/250314 (0%)]\tLoss: 0.496311\tData (t) 0.396\tBatch (t) 0.608\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:29 | INFO | Rank 0 | Train Epoch: 1 [1216/250314 (0%)]\tLoss: 0.749357\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:29 | INFO | Rank 0 | Train Epoch: 1 [1248/250314 (0%)]\tLoss: 0.369402\tData (t) 0.358\tBatch (t) 0.569\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:30 | INFO | Rank 0 | Train Epoch: 1 [1280/250314 (1%)]\tLoss: 0.368055\tData (t) 0.371\tBatch (t) 0.583\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:30 | INFO | Rank 0 | Train Epoch: 1 [1312/250314 (1%)]\tLoss: 0.405605\tData (t) 0.393\tBatch (t) 0.605\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:31 | INFO | Rank 0 | Train Epoch: 1 [1344/250314 (1%)]\tLoss: 0.315120\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:31 | INFO | Rank 0 | Train Epoch: 1 [1376/250314 (1%)]\tLoss: 0.264236\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:32 | INFO | Rank 0 | Train Epoch: 1 [1408/250314 (1%)]\tLoss: 0.386809\tData (t) 0.384\tBatch (t) 0.596\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:33 | INFO | Rank 0 | Train Epoch: 1 [1440/250314 (1%)]\tLoss: 0.408014\tData (t) 0.422\tBatch (t) 0.634\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:33 | INFO | Rank 0 | Train Epoch: 1 [1472/250314 (1%)]\tLoss: 0.233319\tData (t) 0.397\tBatch (t) 0.608\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:34 | INFO | Rank 0 | Train Epoch: 1 [1504/250314 (1%)]\tLoss: 0.342852\tData (t) 0.388\tBatch (t) 0.600\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:35 | INFO | Rank 0 | Train Epoch: 1 [1536/250314 (1%)]\tLoss: 0.291689\tData (t) 0.368\tBatch (t) 0.579\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:35 | INFO | Rank 0 | Train Epoch: 1 [1568/250314 (1%)]\tLoss: 0.441639\tData (t) 0.375\tBatch (t) 0.587\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:36 | INFO | Rank 0 | Train Epoch: 1 [1600/250314 (1%)]\tLoss: 0.635602\tData (t) 0.375\tBatch (t) 0.587\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:36 | INFO | Rank 0 | Train Epoch: 1 [1632/250314 (1%)]\tLoss: 0.377573\tData (t) 0.349\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:37 | INFO | Rank 0 | Train Epoch: 1 [1664/250314 (1%)]\tLoss: 0.484155\tData (t) 0.775\tBatch (t) 0.987\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:38 | INFO | Rank 0 | Train Epoch: 1 [1696/250314 (1%)]\tLoss: 0.848465\tData (t) 0.382\tBatch (t) 0.593\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:38 | INFO | Rank 0 | Train Epoch: 1 [1728/250314 (1%)]\tLoss: 0.476917\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:39 | INFO | Rank 0 | Train Epoch: 1 [1760/250314 (1%)]\tLoss: 0.563447\tData (t) 0.374\tBatch (t) 0.586\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:40 | INFO | Rank 0 | Train Epoch: 1 [1792/250314 (1%)]\tLoss: 0.477174\tData (t) 0.363\tBatch (t) 0.575\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:40 | INFO | Rank 0 | Train Epoch: 1 [1824/250314 (1%)]\tLoss: 0.483408\tData (t) 0.361\tBatch (t) 0.573\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:41 | INFO | Rank 0 | Train Epoch: 1 [1856/250314 (1%)]\tLoss: 0.408264\tData (t) 0.363\tBatch (t) 0.574\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:41 | INFO | Rank 0 | Train Epoch: 1 [1888/250314 (1%)]\tLoss: 0.628166\tData (t) 0.388\tBatch (t) 0.600\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:42 | INFO | Rank 0 | Train Epoch: 1 [1920/250314 (1%)]\tLoss: 0.344376\tData (t) 0.363\tBatch (t) 0.576\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:42 | INFO | Rank 0 | Train Epoch: 1 [1952/250314 (1%)]\tLoss: 0.404627\tData (t) 0.375\tBatch (t) 0.586\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:43 | INFO | Rank 0 | Train Epoch: 1 [1984/250314 (1%)]\tLoss: 0.408275\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:44 | INFO | Rank 0 | Train Epoch: 1 [2016/250314 (1%)]\tLoss: 0.436982\tData (t) 0.353\tBatch (t) 0.565\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:44 | INFO | Rank 0 | Train Epoch: 1 [2048/250314 (1%)]\tLoss: 0.332573\tData (t) 0.375\tBatch (t) 0.587\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:45 | INFO | Rank 0 | Train Epoch: 1 [2080/250314 (1%)]\tLoss: 0.649770\tData (t) 0.379\tBatch (t) 0.591\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:45 | INFO | Rank 0 | Train Epoch: 1 [2112/250314 (1%)]\tLoss: 0.618697\tData (t) 0.392\tBatch (t) 0.604\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:46 | INFO | Rank 0 | Train Epoch: 1 [2144/250314 (1%)]\tLoss: 0.692641\tData (t) 0.380\tBatch (t) 0.592\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:47 | INFO | Rank 0 | Train Epoch: 1 [2176/250314 (1%)]\tLoss: 0.538784\tData (t) 0.367\tBatch (t) 0.579\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:47 | INFO | Rank 0 | Train Epoch: 1 [2208/250314 (1%)]\tLoss: 0.385709\tData (t) 0.385\tBatch (t) 0.597\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:48 | INFO | Rank 0 | Train Epoch: 1 [2240/250314 (1%)]\tLoss: 0.422711\tData (t) 0.388\tBatch (t) 0.600\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:48 | INFO | Rank 0 | Train Epoch: 1 [2272/250314 (1%)]\tLoss: 0.133687\tData (t) 0.384\tBatch (t) 0.596\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:49 | INFO | Rank 0 | Train Epoch: 1 [2304/250314 (1%)]\tLoss: 0.753780\tData (t) 0.347\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:49 | INFO | Rank 0 | Train Epoch: 1 [2336/250314 (1%)]\tLoss: 0.392719\tData (t) 0.390\tBatch (t) 0.602\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:50 | INFO | Rank 0 | Train Epoch: 1 [2368/250314 (1%)]\tLoss: 0.497302\tData (t) 0.361\tBatch (t) 0.573\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:51 | INFO | Rank 0 | Train Epoch: 1 [2400/250314 (1%)]\tLoss: 0.731617\tData (t) 0.381\tBatch (t) 0.592\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:51 | INFO | Rank 0 | Train Epoch: 1 [2432/250314 (1%)]\tLoss: 0.380187\tData (t) 0.341\tBatch (t) 0.553\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:52 | INFO | Rank 0 | Train Epoch: 1 [2464/250314 (1%)]\tLoss: 0.345019\tData (t) 0.365\tBatch (t) 0.577\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:52 | INFO | Rank 0 | Train Epoch: 1 [2496/250314 (1%)]\tLoss: 0.245034\tData (t) 0.335\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:53 | INFO | Rank 0 | Train Epoch: 1 [2528/250314 (1%)]\tLoss: 0.253009\tData (t) 0.368\tBatch (t) 0.579\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:53 | INFO | Rank 0 | Train Epoch: 1 [2560/250314 (1%)]\tLoss: 0.491320\tData (t) 0.332\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:54 | INFO | Rank 0 | Train Epoch: 1 [2592/250314 (1%)]\tLoss: 0.389802\tData (t) 0.386\tBatch (t) 0.597\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:55 | INFO | Rank 0 | Train Epoch: 1 [2624/250314 (1%)]\tLoss: 0.469229\tData (t) 0.373\tBatch (t) 0.585\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:55 | INFO | Rank 0 | Train Epoch: 1 [2656/250314 (1%)]\tLoss: 0.445774\tData (t) 0.348\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:56 | INFO | Rank 0 | Train Epoch: 1 [2688/250314 (1%)]\tLoss: 0.608541\tData (t) 0.354\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:56 | INFO | Rank 0 | Train Epoch: 1 [2720/250314 (1%)]\tLoss: 0.854228\tData (t) 0.378\tBatch (t) 0.589\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:57 | INFO | Rank 0 | Train Epoch: 1 [2752/250314 (1%)]\tLoss: 0.342389\tData (t) 0.387\tBatch (t) 0.599\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:57 | INFO | Rank 0 | Train Epoch: 1 [2784/250314 (1%)]\tLoss: 0.385211\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:58 | INFO | Rank 0 | Train Epoch: 1 [2816/250314 (1%)]\tLoss: 0.231390\tData (t) 0.359\tBatch (t) 0.571\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:59 | INFO | Rank 0 | Train Epoch: 1 [2848/250314 (1%)]\tLoss: 0.585693\tData (t) 0.377\tBatch (t) 0.589\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:19:59 | INFO | Rank 0 | Train Epoch: 1 [2880/250314 (1%)]\tLoss: 0.716662\tData (t) 0.357\tBatch (t) 0.569\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:00 | INFO | Rank 0 | Train Epoch: 1 [2912/250314 (1%)]\tLoss: 0.290642\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:00 | INFO | Rank 0 | Train Epoch: 1 [2944/250314 (1%)]\tLoss: 0.682581\tData (t) 0.369\tBatch (t) 0.580\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:01 | INFO | Rank 0 | Train Epoch: 1 [2976/250314 (1%)]\tLoss: 0.512416\tData (t) 0.369\tBatch (t) 0.581\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:01 | INFO | Rank 0 | Train Epoch: 1 [3008/250314 (1%)]\tLoss: 0.897064\tData (t) 0.379\tBatch (t) 0.590\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:02 | INFO | Rank 0 | Train Epoch: 1 [3040/250314 (1%)]\tLoss: 0.186520\tData (t) 0.302\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:03 | INFO | Rank 0 | Train Epoch: 1 [3072/250314 (1%)]\tLoss: 0.363606\tData (t) 0.411\tBatch (t) 0.623\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:03 | INFO | Rank 0 | Train Epoch: 1 [3104/250314 (1%)]\tLoss: 0.476992\tData (t) 0.376\tBatch (t) 0.588\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:04 | INFO | Rank 0 | Train Epoch: 1 [3136/250314 (1%)]\tLoss: 0.512398\tData (t) 0.363\tBatch (t) 0.575\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:04 | INFO | Rank 0 | Train Epoch: 1 [3168/250314 (1%)]\tLoss: 0.288180\tData (t) 0.394\tBatch (t) 0.606\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:05 | INFO | Rank 0 | Train Epoch: 1 [3200/250314 (1%)]\tLoss: 0.548620\tData (t) 0.359\tBatch (t) 0.571\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:06 | INFO | Rank 0 | Train Epoch: 1 [3232/250314 (1%)]\tLoss: 0.803895\tData (t) 0.393\tBatch (t) 0.605\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:06 | INFO | Rank 0 | Train Epoch: 1 [3264/250314 (1%)]\tLoss: 0.447031\tData (t) 0.328\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:07 | INFO | Rank 0 | Train Epoch: 1 [3296/250314 (1%)]\tLoss: 0.243748\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:07 | INFO | Rank 0 | Train Epoch: 1 [3328/250314 (1%)]\tLoss: 0.402741\tData (t) 0.393\tBatch (t) 0.606\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:08 | INFO | Rank 0 | Train Epoch: 1 [3360/250314 (1%)]\tLoss: 0.191153\tData (t) 0.359\tBatch (t) 0.571\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:08 | INFO | Rank 0 | Train Epoch: 1 [3392/250314 (1%)]\tLoss: 0.464605\tData (t) 0.402\tBatch (t) 0.614\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:09 | INFO | Rank 0 | Train Epoch: 1 [3424/250314 (1%)]\tLoss: 0.516741\tData (t) 0.343\tBatch (t) 0.555\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:10 | INFO | Rank 0 | Train Epoch: 1 [3456/250314 (1%)]\tLoss: 0.399141\tData (t) 0.368\tBatch (t) 0.580\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:10 | INFO | Rank 0 | Train Epoch: 1 [3488/250314 (1%)]\tLoss: 0.195834\tData (t) 0.378\tBatch (t) 0.590\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:11 | INFO | Rank 0 | Train Epoch: 1 [3520/250314 (1%)]\tLoss: 0.791975\tData (t) 0.331\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:11 | INFO | Rank 0 | Train Epoch: 1 [3552/250314 (1%)]\tLoss: 0.561341\tData (t) 0.353\tBatch (t) 0.565\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:12 | INFO | Rank 0 | Train Epoch: 1 [3584/250314 (1%)]\tLoss: 0.743202\tData (t) 0.378\tBatch (t) 0.589\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:12 | INFO | Rank 0 | Train Epoch: 1 [3616/250314 (1%)]\tLoss: 0.710381\tData (t) 0.337\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:13 | INFO | Rank 0 | Train Epoch: 1 [3648/250314 (1%)]\tLoss: 0.443167\tData (t) 0.336\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:14 | INFO | Rank 0 | Train Epoch: 1 [3680/250314 (1%)]\tLoss: 0.406559\tData (t) 0.341\tBatch (t) 0.553\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:14 | INFO | Rank 0 | Train Epoch: 1 [3712/250314 (1%)]\tLoss: 0.317590\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:15 | INFO | Rank 0 | Train Epoch: 1 [3744/250314 (1%)]\tLoss: 0.214641\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:15 | INFO | Rank 0 | Train Epoch: 1 [3776/250314 (2%)]\tLoss: 0.469236\tData (t) 0.355\tBatch (t) 0.567\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:16 | INFO | Rank 0 | Train Epoch: 1 [3808/250314 (2%)]\tLoss: 0.340687\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:16 | INFO | Rank 0 | Train Epoch: 1 [3840/250314 (2%)]\tLoss: 0.383923\tData (t) 0.335\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:17 | INFO | Rank 0 | Train Epoch: 1 [3872/250314 (2%)]\tLoss: 0.349744\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:17 | INFO | Rank 0 | Train Epoch: 1 [3904/250314 (2%)]\tLoss: 0.576534\tData (t) 0.364\tBatch (t) 0.576\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:18 | INFO | Rank 0 | Train Epoch: 1 [3936/250314 (2%)]\tLoss: 0.480831\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:19 | INFO | Rank 0 | Train Epoch: 1 [3968/250314 (2%)]\tLoss: 0.365874\tData (t) 0.368\tBatch (t) 0.580\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:19 | INFO | Rank 0 | Train Epoch: 1 [4000/250314 (2%)]\tLoss: 0.293858\tData (t) 0.401\tBatch (t) 0.613\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:20 | INFO | Rank 0 | Train Epoch: 1 [4032/250314 (2%)]\tLoss: 0.459404\tData (t) 0.354\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:20 | INFO | Rank 0 | Train Epoch: 1 [4064/250314 (2%)]\tLoss: 0.170132\tData (t) 0.385\tBatch (t) 0.597\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:21 | INFO | Rank 0 | Train Epoch: 1 [4096/250314 (2%)]\tLoss: 0.564516\tData (t) 0.352\tBatch (t) 0.564\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:21 | INFO | Rank 0 | Train Epoch: 1 [4128/250314 (2%)]\tLoss: 0.304048\tData (t) 0.371\tBatch (t) 0.583\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:22 | INFO | Rank 0 | Train Epoch: 1 [4160/250314 (2%)]\tLoss: 0.722144\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:23 | INFO | Rank 0 | Train Epoch: 1 [4192/250314 (2%)]\tLoss: 0.206938\tData (t) 0.380\tBatch (t) 0.591\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:23 | INFO | Rank 0 | Train Epoch: 1 [4224/250314 (2%)]\tLoss: 0.357676\tData (t) 0.343\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:24 | INFO | Rank 0 | Train Epoch: 1 [4256/250314 (2%)]\tLoss: 0.468306\tData (t) 0.370\tBatch (t) 0.581\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:24 | INFO | Rank 0 | Train Epoch: 1 [4288/250314 (2%)]\tLoss: 0.609829\tData (t) 0.363\tBatch (t) 0.575\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:25 | INFO | Rank 0 | Train Epoch: 1 [4320/250314 (2%)]\tLoss: 0.496644\tData (t) 0.380\tBatch (t) 0.592\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:25 | INFO | Rank 0 | Train Epoch: 1 [4352/250314 (2%)]\tLoss: 0.407199\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:26 | INFO | Rank 0 | Train Epoch: 1 [4384/250314 (2%)]\tLoss: 0.418051\tData (t) 0.353\tBatch (t) 0.564\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:27 | INFO | Rank 0 | Train Epoch: 1 [4416/250314 (2%)]\tLoss: 0.325443\tData (t) 0.395\tBatch (t) 0.607\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:27 | INFO | Rank 0 | Train Epoch: 1 [4448/250314 (2%)]\tLoss: 0.523656\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:28 | INFO | Rank 0 | Train Epoch: 1 [4480/250314 (2%)]\tLoss: 0.326895\tData (t) 0.379\tBatch (t) 0.591\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:28 | INFO | Rank 0 | Train Epoch: 1 [4512/250314 (2%)]\tLoss: 0.130513\tData (t) 0.328\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:29 | INFO | Rank 0 | Train Epoch: 1 [4544/250314 (2%)]\tLoss: 0.577351\tData (t) 0.361\tBatch (t) 0.572\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:29 | INFO | Rank 0 | Train Epoch: 1 [4576/250314 (2%)]\tLoss: 0.447690\tData (t) 0.352\tBatch (t) 0.564\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:30 | INFO | Rank 0 | Train Epoch: 1 [4608/250314 (2%)]\tLoss: 0.218516\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:31 | INFO | Rank 0 | Train Epoch: 1 [4640/250314 (2%)]\tLoss: 0.581501\tData (t) 0.362\tBatch (t) 0.573\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:31 | INFO | Rank 0 | Train Epoch: 1 [4672/250314 (2%)]\tLoss: 0.395913\tData (t) 0.338\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:32 | INFO | Rank 0 | Train Epoch: 1 [4704/250314 (2%)]\tLoss: 0.443312\tData (t) 0.369\tBatch (t) 0.582\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:32 | INFO | Rank 0 | Train Epoch: 1 [4736/250314 (2%)]\tLoss: 0.902128\tData (t) 0.349\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:33 | INFO | Rank 0 | Train Epoch: 1 [4768/250314 (2%)]\tLoss: 0.471005\tData (t) 0.358\tBatch (t) 0.570\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:33 | INFO | Rank 0 | Train Epoch: 1 [4800/250314 (2%)]\tLoss: 0.262254\tData (t) 0.354\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:34 | INFO | Rank 0 | Train Epoch: 1 [4832/250314 (2%)]\tLoss: 0.294236\tData (t) 0.399\tBatch (t) 0.610\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:35 | INFO | Rank 0 | Train Epoch: 1 [4864/250314 (2%)]\tLoss: 0.319795\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:35 | INFO | Rank 0 | Train Epoch: 1 [4896/250314 (2%)]\tLoss: 0.634411\tData (t) 0.363\tBatch (t) 0.576\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:36 | INFO | Rank 0 | Train Epoch: 1 [4928/250314 (2%)]\tLoss: 0.423441\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:36 | INFO | Rank 0 | Train Epoch: 1 [4960/250314 (2%)]\tLoss: 0.206742\tData (t) 0.346\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:37 | INFO | Rank 0 | Train Epoch: 1 [4992/250314 (2%)]\tLoss: 0.643983\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:37 | INFO | Rank 0 | Train Epoch: 1 [5024/250314 (2%)]\tLoss: 0.324200\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:38 | INFO | Rank 0 | Train Epoch: 1 [5056/250314 (2%)]\tLoss: 0.426518\tData (t) 0.354\tBatch (t) 0.565\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:38 | INFO | Rank 0 | Train Epoch: 1 [5088/250314 (2%)]\tLoss: 0.656590\tData (t) 0.338\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:39 | INFO | Rank 0 | Train Epoch: 1 [5120/250314 (2%)]\tLoss: 0.735790\tData (t) 0.380\tBatch (t) 0.592\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:39 | INFO | Rank 0 | Train Epoch: 1 [5152/250314 (2%)]\tLoss: 0.263889\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:40 | INFO | Rank 0 | Train Epoch: 1 [5184/250314 (2%)]\tLoss: 0.559682\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:41 | INFO | Rank 0 | Train Epoch: 1 [5216/250314 (2%)]\tLoss: 0.665562\tData (t) 0.362\tBatch (t) 0.574\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:41 | INFO | Rank 0 | Train Epoch: 1 [5248/250314 (2%)]\tLoss: 0.240118\tData (t) 0.319\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:42 | INFO | Rank 0 | Train Epoch: 1 [5280/250314 (2%)]\tLoss: 0.353222\tData (t) 0.347\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:42 | INFO | Rank 0 | Train Epoch: 1 [5312/250314 (2%)]\tLoss: 0.355439\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:43 | INFO | Rank 0 | Train Epoch: 1 [5344/250314 (2%)]\tLoss: 0.804252\tData (t) 0.352\tBatch (t) 0.564\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:43 | INFO | Rank 0 | Train Epoch: 1 [5376/250314 (2%)]\tLoss: 0.518324\tData (t) 0.374\tBatch (t) 0.586\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:44 | INFO | Rank 0 | Train Epoch: 1 [5408/250314 (2%)]\tLoss: 0.442359\tData (t) 0.334\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:44 | INFO | Rank 0 | Train Epoch: 1 [5440/250314 (2%)]\tLoss: 0.342750\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:45 | INFO | Rank 0 | Train Epoch: 1 [5472/250314 (2%)]\tLoss: 0.279958\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:46 | INFO | Rank 0 | Train Epoch: 1 [5504/250314 (2%)]\tLoss: 0.470120\tData (t) 0.336\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:46 | INFO | Rank 0 | Train Epoch: 1 [5536/250314 (2%)]\tLoss: 0.375188\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:47 | INFO | Rank 0 | Train Epoch: 1 [5568/250314 (2%)]\tLoss: 0.595293\tData (t) 0.362\tBatch (t) 0.576\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:47 | INFO | Rank 0 | Train Epoch: 1 [5600/250314 (2%)]\tLoss: 0.436562\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:48 | INFO | Rank 0 | Train Epoch: 1 [5632/250314 (2%)]\tLoss: 0.314701\tData (t) 0.338\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:48 | INFO | Rank 0 | Train Epoch: 1 [5664/250314 (2%)]\tLoss: 0.767495\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:49 | INFO | Rank 0 | Train Epoch: 1 [5696/250314 (2%)]\tLoss: 0.319802\tData (t) 0.342\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:49 | INFO | Rank 0 | Train Epoch: 1 [5728/250314 (2%)]\tLoss: 0.560192\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:50 | INFO | Rank 0 | Train Epoch: 1 [5760/250314 (2%)]\tLoss: 0.748566\tData (t) 0.369\tBatch (t) 0.580\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:51 | INFO | Rank 0 | Train Epoch: 1 [5792/250314 (2%)]\tLoss: 0.396602\tData (t) 0.371\tBatch (t) 0.583\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:51 | INFO | Rank 0 | Train Epoch: 1 [5824/250314 (2%)]\tLoss: 0.347168\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:52 | INFO | Rank 0 | Train Epoch: 1 [5856/250314 (2%)]\tLoss: 0.567773\tData (t) 0.353\tBatch (t) 0.564\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:52 | INFO | Rank 0 | Train Epoch: 1 [5888/250314 (2%)]\tLoss: 0.343592\tData (t) 0.360\tBatch (t) 0.572\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:53 | INFO | Rank 0 | Train Epoch: 1 [5920/250314 (2%)]\tLoss: 0.511290\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:53 | INFO | Rank 0 | Train Epoch: 1 [5952/250314 (2%)]\tLoss: 0.547091\tData (t) 0.360\tBatch (t) 0.572\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:54 | INFO | Rank 0 | Train Epoch: 1 [5984/250314 (2%)]\tLoss: 0.491962\tData (t) 0.336\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:54 | INFO | Rank 0 | Train Epoch: 1 [6016/250314 (2%)]\tLoss: 0.537905\tData (t) 0.350\tBatch (t) 0.562\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:55 | INFO | Rank 0 | Train Epoch: 1 [6048/250314 (2%)]\tLoss: 0.507262\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:56 | INFO | Rank 0 | Train Epoch: 1 [6080/250314 (2%)]\tLoss: 0.365000\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:56 | INFO | Rank 0 | Train Epoch: 1 [6112/250314 (2%)]\tLoss: 0.186193\tData (t) 0.345\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:57 | INFO | Rank 0 | Train Epoch: 1 [6144/250314 (2%)]\tLoss: 0.774655\tData (t) 0.365\tBatch (t) 0.577\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:57 | INFO | Rank 0 | Train Epoch: 1 [6176/250314 (2%)]\tLoss: 0.560224\tData (t) 0.379\tBatch (t) 0.592\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:58 | INFO | Rank 0 | Train Epoch: 1 [6208/250314 (2%)]\tLoss: 0.289787\tData (t) 0.335\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:58 | INFO | Rank 0 | Train Epoch: 1 [6240/250314 (2%)]\tLoss: 0.537460\tData (t) 0.355\tBatch (t) 0.568\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:59 | INFO | Rank 0 | Train Epoch: 1 [6272/250314 (3%)]\tLoss: 0.436147\tData (t) 0.385\tBatch (t) 0.597\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:20:59 | INFO | Rank 0 | Train Epoch: 1 [6304/250314 (3%)]\tLoss: 0.552799\tData (t) 0.324\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:00 | INFO | Rank 0 | Train Epoch: 1 [6336/250314 (3%)]\tLoss: 0.468125\tData (t) 0.366\tBatch (t) 0.577\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:01 | INFO | Rank 0 | Train Epoch: 1 [6368/250314 (3%)]\tLoss: 0.320744\tData (t) 0.335\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:01 | INFO | Rank 0 | Train Epoch: 1 [6400/250314 (3%)]\tLoss: 0.568119\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:02 | INFO | Rank 0 | Train Epoch: 1 [6432/250314 (3%)]\tLoss: 0.421178\tData (t) 0.357\tBatch (t) 0.570\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:02 | INFO | Rank 0 | Train Epoch: 1 [6464/250314 (3%)]\tLoss: 0.192587\tData (t) 0.378\tBatch (t) 0.591\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:03 | INFO | Rank 0 | Train Epoch: 1 [6496/250314 (3%)]\tLoss: 0.615289\tData (t) 0.355\tBatch (t) 0.567\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:03 | INFO | Rank 0 | Train Epoch: 1 [6528/250314 (3%)]\tLoss: 0.395082\tData (t) 0.301\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:04 | INFO | Rank 0 | Train Epoch: 1 [6560/250314 (3%)]\tLoss: 0.228967\tData (t) 0.371\tBatch (t) 0.583\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:05 | INFO | Rank 0 | Train Epoch: 1 [6592/250314 (3%)]\tLoss: 0.246429\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:05 | INFO | Rank 0 | Train Epoch: 1 [6624/250314 (3%)]\tLoss: 0.504439\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:06 | INFO | Rank 0 | Train Epoch: 1 [6656/250314 (3%)]\tLoss: 0.602846\tData (t) 0.400\tBatch (t) 0.612\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:06 | INFO | Rank 0 | Train Epoch: 1 [6688/250314 (3%)]\tLoss: 0.256714\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:07 | INFO | Rank 0 | Train Epoch: 1 [6720/250314 (3%)]\tLoss: 0.444209\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:07 | INFO | Rank 0 | Train Epoch: 1 [6752/250314 (3%)]\tLoss: 0.382956\tData (t) 0.381\tBatch (t) 0.593\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:08 | INFO | Rank 0 | Train Epoch: 1 [6784/250314 (3%)]\tLoss: 0.361392\tData (t) 0.348\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:08 | INFO | Rank 0 | Train Epoch: 1 [6816/250314 (3%)]\tLoss: 0.350391\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:09 | INFO | Rank 0 | Train Epoch: 1 [6848/250314 (3%)]\tLoss: 0.304196\tData (t) 0.363\tBatch (t) 0.575\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:10 | INFO | Rank 0 | Train Epoch: 1 [6880/250314 (3%)]\tLoss: 0.625724\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:10 | INFO | Rank 0 | Train Epoch: 1 [6912/250314 (3%)]\tLoss: 0.323485\tData (t) 0.342\tBatch (t) 0.553\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:11 | INFO | Rank 0 | Train Epoch: 1 [6944/250314 (3%)]\tLoss: 1.062390\tData (t) 0.334\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:11 | INFO | Rank 0 | Train Epoch: 1 [6976/250314 (3%)]\tLoss: 0.294024\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:12 | INFO | Rank 0 | Train Epoch: 1 [7008/250314 (3%)]\tLoss: 0.571651\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:12 | INFO | Rank 0 | Train Epoch: 1 [7040/250314 (3%)]\tLoss: 0.811068\tData (t) 0.352\tBatch (t) 0.564\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:13 | INFO | Rank 0 | Train Epoch: 1 [7072/250314 (3%)]\tLoss: 0.387395\tData (t) 0.375\tBatch (t) 0.586\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:13 | INFO | Rank 0 | Train Epoch: 1 [7104/250314 (3%)]\tLoss: 0.873031\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:14 | INFO | Rank 0 | Train Epoch: 1 [7136/250314 (3%)]\tLoss: 0.305986\tData (t) 0.359\tBatch (t) 0.571\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:15 | INFO | Rank 0 | Train Epoch: 1 [7168/250314 (3%)]\tLoss: 0.521845\tData (t) 0.379\tBatch (t) 0.590\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:15 | INFO | Rank 0 | Train Epoch: 1 [7200/250314 (3%)]\tLoss: 0.317319\tData (t) 0.378\tBatch (t) 0.590\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:16 | INFO | Rank 0 | Train Epoch: 1 [7232/250314 (3%)]\tLoss: 0.572427\tData (t) 0.357\tBatch (t) 0.569\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:16 | INFO | Rank 0 | Train Epoch: 1 [7264/250314 (3%)]\tLoss: 0.844394\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:17 | INFO | Rank 0 | Train Epoch: 1 [7296/250314 (3%)]\tLoss: 0.515464\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:17 | INFO | Rank 0 | Train Epoch: 1 [7328/250314 (3%)]\tLoss: 0.458698\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:18 | INFO | Rank 0 | Train Epoch: 1 [7360/250314 (3%)]\tLoss: 0.460054\tData (t) 0.353\tBatch (t) 0.565\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:18 | INFO | Rank 0 | Train Epoch: 1 [7392/250314 (3%)]\tLoss: 0.543737\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:19 | INFO | Rank 0 | Train Epoch: 1 [7424/250314 (3%)]\tLoss: 0.323524\tData (t) 0.351\tBatch (t) 0.563\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:19 | INFO | Rank 0 | Train Epoch: 1 [7456/250314 (3%)]\tLoss: 0.216530\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:20 | INFO | Rank 0 | Train Epoch: 1 [7488/250314 (3%)]\tLoss: 0.281277\tData (t) 0.352\tBatch (t) 0.564\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:21 | INFO | Rank 0 | Train Epoch: 1 [7520/250314 (3%)]\tLoss: 0.175353\tData (t) 0.326\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:21 | INFO | Rank 0 | Train Epoch: 1 [7552/250314 (3%)]\tLoss: 0.531296\tData (t) 0.366\tBatch (t) 0.578\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:22 | INFO | Rank 0 | Train Epoch: 1 [7584/250314 (3%)]\tLoss: 0.417583\tData (t) 0.349\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:22 | INFO | Rank 0 | Train Epoch: 1 [7616/250314 (3%)]\tLoss: 0.847539\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:23 | INFO | Rank 0 | Train Epoch: 1 [7648/250314 (3%)]\tLoss: 0.299775\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:23 | INFO | Rank 0 | Train Epoch: 1 [7680/250314 (3%)]\tLoss: 0.263920\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:24 | INFO | Rank 0 | Train Epoch: 1 [7712/250314 (3%)]\tLoss: 0.284034\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:24 | INFO | Rank 0 | Train Epoch: 1 [7744/250314 (3%)]\tLoss: 0.464302\tData (t) 0.369\tBatch (t) 0.581\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:25 | INFO | Rank 0 | Train Epoch: 1 [7776/250314 (3%)]\tLoss: 0.511061\tData (t) 0.319\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:26 | INFO | Rank 0 | Train Epoch: 1 [7808/250314 (3%)]\tLoss: 0.358471\tData (t) 0.364\tBatch (t) 0.575\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:26 | INFO | Rank 0 | Train Epoch: 1 [7840/250314 (3%)]\tLoss: 0.476678\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:27 | INFO | Rank 0 | Train Epoch: 1 [7872/250314 (3%)]\tLoss: 0.393737\tData (t) 0.378\tBatch (t) 0.590\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:27 | INFO | Rank 0 | Train Epoch: 1 [7904/250314 (3%)]\tLoss: 0.220943\tData (t) 0.372\tBatch (t) 0.584\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:28 | INFO | Rank 0 | Train Epoch: 1 [7936/250314 (3%)]\tLoss: 0.515895\tData (t) 0.338\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:28 | INFO | Rank 0 | Train Epoch: 1 [7968/250314 (3%)]\tLoss: 0.367170\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:29 | INFO | Rank 0 | Train Epoch: 1 [8000/250314 (3%)]\tLoss: 0.464446\tData (t) 0.373\tBatch (t) 0.584\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:29 | INFO | Rank 0 | Train Epoch: 1 [8032/250314 (3%)]\tLoss: 0.532037\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:30 | INFO | Rank 0 | Train Epoch: 1 [8064/250314 (3%)]\tLoss: 0.249126\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:31 | INFO | Rank 0 | Train Epoch: 1 [8096/250314 (3%)]\tLoss: 0.178218\tData (t) 0.372\tBatch (t) 0.584\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:31 | INFO | Rank 0 | Train Epoch: 1 [8128/250314 (3%)]\tLoss: 0.284418\tData (t) 0.332\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:32 | INFO | Rank 0 | Train Epoch: 1 [8160/250314 (3%)]\tLoss: 0.314446\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:32 | INFO | Rank 0 | Train Epoch: 1 [8192/250314 (3%)]\tLoss: 0.144677\tData (t) 0.350\tBatch (t) 0.562\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:33 | INFO | Rank 0 | Train Epoch: 1 [8224/250314 (3%)]\tLoss: 0.603125\tData (t) 0.355\tBatch (t) 0.568\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:33 | INFO | Rank 0 | Train Epoch: 1 [8256/250314 (3%)]\tLoss: 0.379100\tData (t) 0.326\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:34 | INFO | Rank 0 | Train Epoch: 1 [8288/250314 (3%)]\tLoss: 0.322467\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:34 | INFO | Rank 0 | Train Epoch: 1 [8320/250314 (3%)]\tLoss: 0.634403\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:35 | INFO | Rank 0 | Train Epoch: 1 [8352/250314 (3%)]\tLoss: 0.447471\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:35 | INFO | Rank 0 | Train Epoch: 1 [8384/250314 (3%)]\tLoss: 0.300384\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:36 | INFO | Rank 0 | Train Epoch: 1 [8416/250314 (3%)]\tLoss: 0.528403\tData (t) 0.335\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:37 | INFO | Rank 0 | Train Epoch: 1 [8448/250314 (3%)]\tLoss: 0.425632\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:37 | INFO | Rank 0 | Train Epoch: 1 [8480/250314 (3%)]\tLoss: 0.381609\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:38 | INFO | Rank 0 | Train Epoch: 1 [8512/250314 (3%)]\tLoss: 0.468989\tData (t) 0.384\tBatch (t) 0.596\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:38 | INFO | Rank 0 | Train Epoch: 1 [8544/250314 (3%)]\tLoss: 0.556336\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:39 | INFO | Rank 0 | Train Epoch: 1 [8576/250314 (3%)]\tLoss: 0.194430\tData (t) 0.368\tBatch (t) 0.580\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:39 | INFO | Rank 0 | Train Epoch: 1 [8608/250314 (3%)]\tLoss: 0.467695\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:40 | INFO | Rank 0 | Train Epoch: 1 [8640/250314 (3%)]\tLoss: 0.423820\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:40 | INFO | Rank 0 | Train Epoch: 1 [8672/250314 (3%)]\tLoss: 0.241108\tData (t) 0.337\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:41 | INFO | Rank 0 | Train Epoch: 1 [8704/250314 (3%)]\tLoss: 0.452361\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:41 | INFO | Rank 0 | Train Epoch: 1 [8736/250314 (3%)]\tLoss: 0.427199\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:42 | INFO | Rank 0 | Train Epoch: 1 [8768/250314 (4%)]\tLoss: 0.290238\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:42 | INFO | Rank 0 | Train Epoch: 1 [8800/250314 (4%)]\tLoss: 0.553193\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:43 | INFO | Rank 0 | Train Epoch: 1 [8832/250314 (4%)]\tLoss: 0.482078\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:44 | INFO | Rank 0 | Train Epoch: 1 [8864/250314 (4%)]\tLoss: 0.313602\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:44 | INFO | Rank 0 | Train Epoch: 1 [8896/250314 (4%)]\tLoss: 0.557614\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:45 | INFO | Rank 0 | Train Epoch: 1 [8928/250314 (4%)]\tLoss: 0.206476\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:45 | INFO | Rank 0 | Train Epoch: 1 [8960/250314 (4%)]\tLoss: 0.345263\tData (t) 0.343\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:46 | INFO | Rank 0 | Train Epoch: 1 [8992/250314 (4%)]\tLoss: 0.258765\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:46 | INFO | Rank 0 | Train Epoch: 1 [9024/250314 (4%)]\tLoss: 0.313049\tData (t) 0.362\tBatch (t) 0.575\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:47 | INFO | Rank 0 | Train Epoch: 1 [9056/250314 (4%)]\tLoss: 0.379680\tData (t) 0.359\tBatch (t) 0.570\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:47 | INFO | Rank 0 | Train Epoch: 1 [9088/250314 (4%)]\tLoss: 0.364343\tData (t) 0.366\tBatch (t) 0.578\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:48 | INFO | Rank 0 | Train Epoch: 1 [9120/250314 (4%)]\tLoss: 0.270452\tData (t) 0.349\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:49 | INFO | Rank 0 | Train Epoch: 1 [9152/250314 (4%)]\tLoss: 0.252128\tData (t) 0.343\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:49 | INFO | Rank 0 | Train Epoch: 1 [9184/250314 (4%)]\tLoss: 0.471243\tData (t) 0.371\tBatch (t) 0.582\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:50 | INFO | Rank 0 | Train Epoch: 1 [9216/250314 (4%)]\tLoss: 0.555511\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:50 | INFO | Rank 0 | Train Epoch: 1 [9248/250314 (4%)]\tLoss: 0.287886\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:51 | INFO | Rank 0 | Train Epoch: 1 [9280/250314 (4%)]\tLoss: 0.430315\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:51 | INFO | Rank 0 | Train Epoch: 1 [9312/250314 (4%)]\tLoss: 0.248231\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:52 | INFO | Rank 0 | Train Epoch: 1 [9344/250314 (4%)]\tLoss: 0.378504\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:52 | INFO | Rank 0 | Train Epoch: 1 [9376/250314 (4%)]\tLoss: 0.687765\tData (t) 0.376\tBatch (t) 0.588\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:53 | INFO | Rank 0 | Train Epoch: 1 [9408/250314 (4%)]\tLoss: 0.403260\tData (t) 0.397\tBatch (t) 0.609\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:54 | INFO | Rank 0 | Train Epoch: 1 [9440/250314 (4%)]\tLoss: 0.375296\tData (t) 0.325\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:54 | INFO | Rank 0 | Train Epoch: 1 [9472/250314 (4%)]\tLoss: 0.407607\tData (t) 0.362\tBatch (t) 0.575\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:55 | INFO | Rank 0 | Train Epoch: 1 [9504/250314 (4%)]\tLoss: 0.434343\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:55 | INFO | Rank 0 | Train Epoch: 1 [9536/250314 (4%)]\tLoss: 0.356796\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:56 | INFO | Rank 0 | Train Epoch: 1 [9568/250314 (4%)]\tLoss: 0.144981\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:56 | INFO | Rank 0 | Train Epoch: 1 [9600/250314 (4%)]\tLoss: 0.293098\tData (t) 0.343\tBatch (t) 0.555\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:57 | INFO | Rank 0 | Train Epoch: 1 [9632/250314 (4%)]\tLoss: 0.236795\tData (t) 0.363\tBatch (t) 0.574\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:57 | INFO | Rank 0 | Train Epoch: 1 [9664/250314 (4%)]\tLoss: 0.892563\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:58 | INFO | Rank 0 | Train Epoch: 1 [9696/250314 (4%)]\tLoss: 0.419773\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:58 | INFO | Rank 0 | Train Epoch: 1 [9728/250314 (4%)]\tLoss: 0.096036\tData (t) 0.345\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:21:59 | INFO | Rank 0 | Train Epoch: 1 [9760/250314 (4%)]\tLoss: 0.491409\tData (t) 0.346\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:00 | INFO | Rank 0 | Train Epoch: 1 [9792/250314 (4%)]\tLoss: 0.187432\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:00 | INFO | Rank 0 | Train Epoch: 1 [9824/250314 (4%)]\tLoss: 0.218724\tData (t) 0.321\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:01 | INFO | Rank 0 | Train Epoch: 1 [9856/250314 (4%)]\tLoss: 0.543699\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:01 | INFO | Rank 0 | Train Epoch: 1 [9888/250314 (4%)]\tLoss: 0.336210\tData (t) 0.352\tBatch (t) 0.563\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:02 | INFO | Rank 0 | Train Epoch: 1 [9920/250314 (4%)]\tLoss: 0.207177\tData (t) 0.322\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:02 | INFO | Rank 0 | Train Epoch: 1 [9952/250314 (4%)]\tLoss: 0.145948\tData (t) 0.377\tBatch (t) 0.588\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:03 | INFO | Rank 0 | Train Epoch: 1 [9984/250314 (4%)]\tLoss: 0.638400\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:03 | INFO | Rank 0 | Train Epoch: 1 [10016/250314 (4%)]\tLoss: 0.532573\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:04 | INFO | Rank 0 | Train Epoch: 1 [10048/250314 (4%)]\tLoss: 0.721280\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:04 | INFO | Rank 0 | Train Epoch: 1 [10080/250314 (4%)]\tLoss: 0.412625\tData (t) 0.334\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:05 | INFO | Rank 0 | Train Epoch: 1 [10112/250314 (4%)]\tLoss: 0.319988\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:06 | INFO | Rank 0 | Train Epoch: 1 [10144/250314 (4%)]\tLoss: 0.592641\tData (t) 0.369\tBatch (t) 0.580\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:06 | INFO | Rank 0 | Train Epoch: 1 [10176/250314 (4%)]\tLoss: 0.420288\tData (t) 0.387\tBatch (t) 0.599\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:07 | INFO | Rank 0 | Train Epoch: 1 [10208/250314 (4%)]\tLoss: 0.354172\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:07 | INFO | Rank 0 | Train Epoch: 1 [10240/250314 (4%)]\tLoss: 0.124091\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:08 | INFO | Rank 0 | Train Epoch: 1 [10272/250314 (4%)]\tLoss: 0.660160\tData (t) 0.310\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:08 | INFO | Rank 0 | Train Epoch: 1 [10304/250314 (4%)]\tLoss: 0.539689\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:09 | INFO | Rank 0 | Train Epoch: 1 [10336/250314 (4%)]\tLoss: 0.192761\tData (t) 0.354\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:09 | INFO | Rank 0 | Train Epoch: 1 [10368/250314 (4%)]\tLoss: 0.487264\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:10 | INFO | Rank 0 | Train Epoch: 1 [10400/250314 (4%)]\tLoss: 0.192222\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:10 | INFO | Rank 0 | Train Epoch: 1 [10432/250314 (4%)]\tLoss: 0.381268\tData (t) 0.345\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:11 | INFO | Rank 0 | Train Epoch: 1 [10464/250314 (4%)]\tLoss: 0.434617\tData (t) 0.290\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:11 | INFO | Rank 0 | Train Epoch: 1 [10496/250314 (4%)]\tLoss: 0.557239\tData (t) 0.340\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:12 | INFO | Rank 0 | Train Epoch: 1 [10528/250314 (4%)]\tLoss: 0.571384\tData (t) 0.358\tBatch (t) 0.570\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:13 | INFO | Rank 0 | Train Epoch: 1 [10560/250314 (4%)]\tLoss: 0.386716\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:13 | INFO | Rank 0 | Train Epoch: 1 [10592/250314 (4%)]\tLoss: 0.281378\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:14 | INFO | Rank 0 | Train Epoch: 1 [10624/250314 (4%)]\tLoss: 0.282857\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:14 | INFO | Rank 0 | Train Epoch: 1 [10656/250314 (4%)]\tLoss: 0.286594\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:15 | INFO | Rank 0 | Train Epoch: 1 [10688/250314 (4%)]\tLoss: 0.424444\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:15 | INFO | Rank 0 | Train Epoch: 1 [10720/250314 (4%)]\tLoss: 0.508699\tData (t) 0.374\tBatch (t) 0.586\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:16 | INFO | Rank 0 | Train Epoch: 1 [10752/250314 (4%)]\tLoss: 0.329044\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:16 | INFO | Rank 0 | Train Epoch: 1 [10784/250314 (4%)]\tLoss: 0.284354\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:17 | INFO | Rank 0 | Train Epoch: 1 [10816/250314 (4%)]\tLoss: 0.422004\tData (t) 0.318\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:17 | INFO | Rank 0 | Train Epoch: 1 [10848/250314 (4%)]\tLoss: 0.353010\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:18 | INFO | Rank 0 | Train Epoch: 1 [10880/250314 (4%)]\tLoss: 0.350561\tData (t) 0.352\tBatch (t) 0.564\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:18 | INFO | Rank 0 | Train Epoch: 1 [10912/250314 (4%)]\tLoss: 0.800927\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:19 | INFO | Rank 0 | Train Epoch: 1 [10944/250314 (4%)]\tLoss: 0.417595\tData (t) 0.345\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:20 | INFO | Rank 0 | Train Epoch: 1 [10976/250314 (4%)]\tLoss: 0.583781\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:20 | INFO | Rank 0 | Train Epoch: 1 [11008/250314 (4%)]\tLoss: 0.438043\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:21 | INFO | Rank 0 | Train Epoch: 1 [11040/250314 (4%)]\tLoss: 0.683721\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:21 | INFO | Rank 0 | Train Epoch: 1 [11072/250314 (4%)]\tLoss: 0.396115\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:22 | INFO | Rank 0 | Train Epoch: 1 [11104/250314 (4%)]\tLoss: 0.317629\tData (t) 0.319\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:22 | INFO | Rank 0 | Train Epoch: 1 [11136/250314 (4%)]\tLoss: 0.444641\tData (t) 0.327\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:23 | INFO | Rank 0 | Train Epoch: 1 [11168/250314 (4%)]\tLoss: 0.255203\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:23 | INFO | Rank 0 | Train Epoch: 1 [11200/250314 (4%)]\tLoss: 0.545939\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:24 | INFO | Rank 0 | Train Epoch: 1 [11232/250314 (4%)]\tLoss: 0.388289\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:24 | INFO | Rank 0 | Train Epoch: 1 [11264/250314 (5%)]\tLoss: 0.500909\tData (t) 0.352\tBatch (t) 0.564\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:25 | INFO | Rank 0 | Train Epoch: 1 [11296/250314 (5%)]\tLoss: 0.592721\tData (t) 0.386\tBatch (t) 0.598\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:26 | INFO | Rank 0 | Train Epoch: 1 [11328/250314 (5%)]\tLoss: 0.269207\tData (t) 0.371\tBatch (t) 0.583\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:26 | INFO | Rank 0 | Train Epoch: 1 [11360/250314 (5%)]\tLoss: 0.283054\tData (t) 0.365\tBatch (t) 0.577\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:27 | INFO | Rank 0 | Train Epoch: 1 [11392/250314 (5%)]\tLoss: 0.448031\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:27 | INFO | Rank 0 | Train Epoch: 1 [11424/250314 (5%)]\tLoss: 0.375699\tData (t) 0.324\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:28 | INFO | Rank 0 | Train Epoch: 1 [11456/250314 (5%)]\tLoss: 0.487703\tData (t) 0.363\tBatch (t) 0.575\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:28 | INFO | Rank 0 | Train Epoch: 1 [11488/250314 (5%)]\tLoss: 0.430652\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:29 | INFO | Rank 0 | Train Epoch: 1 [11520/250314 (5%)]\tLoss: 0.500270\tData (t) 0.371\tBatch (t) 0.583\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:29 | INFO | Rank 0 | Train Epoch: 1 [11552/250314 (5%)]\tLoss: 0.696045\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:30 | INFO | Rank 0 | Train Epoch: 1 [11584/250314 (5%)]\tLoss: 0.473883\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:30 | INFO | Rank 0 | Train Epoch: 1 [11616/250314 (5%)]\tLoss: 0.642948\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:31 | INFO | Rank 0 | Train Epoch: 1 [11648/250314 (5%)]\tLoss: 0.560520\tData (t) 0.361\tBatch (t) 0.573\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:32 | INFO | Rank 0 | Train Epoch: 1 [11680/250314 (5%)]\tLoss: 0.509265\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:32 | INFO | Rank 0 | Train Epoch: 1 [11712/250314 (5%)]\tLoss: 0.439297\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:33 | INFO | Rank 0 | Train Epoch: 1 [11744/250314 (5%)]\tLoss: 0.511875\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:33 | INFO | Rank 0 | Train Epoch: 1 [11776/250314 (5%)]\tLoss: 0.436452\tData (t) 0.333\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:34 | INFO | Rank 0 | Train Epoch: 1 [11808/250314 (5%)]\tLoss: 0.396086\tData (t) 0.282\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:34 | INFO | Rank 0 | Train Epoch: 1 [11840/250314 (5%)]\tLoss: 0.863503\tData (t) 0.303\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:35 | INFO | Rank 0 | Train Epoch: 1 [11872/250314 (5%)]\tLoss: 0.775109\tData (t) 0.358\tBatch (t) 0.570\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:35 | INFO | Rank 0 | Train Epoch: 1 [11904/250314 (5%)]\tLoss: 0.501938\tData (t) 0.306\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:36 | INFO | Rank 0 | Train Epoch: 1 [11936/250314 (5%)]\tLoss: 0.636421\tData (t) 0.299\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:36 | INFO | Rank 0 | Train Epoch: 1 [11968/250314 (5%)]\tLoss: 0.670119\tData (t) 0.359\tBatch (t) 0.571\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:37 | INFO | Rank 0 | Train Epoch: 1 [12000/250314 (5%)]\tLoss: 0.475554\tData (t) 0.333\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:38 | INFO | Rank 0 | Train Epoch: 1 [12032/250314 (5%)]\tLoss: 0.368771\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:38 | INFO | Rank 0 | Train Epoch: 1 [12064/250314 (5%)]\tLoss: 0.394490\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:39 | INFO | Rank 0 | Train Epoch: 1 [12096/250314 (5%)]\tLoss: 0.327171\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:39 | INFO | Rank 0 | Train Epoch: 1 [12128/250314 (5%)]\tLoss: 0.352685\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:40 | INFO | Rank 0 | Train Epoch: 1 [12160/250314 (5%)]\tLoss: 0.585981\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:40 | INFO | Rank 0 | Train Epoch: 1 [12192/250314 (5%)]\tLoss: 0.499094\tData (t) 0.361\tBatch (t) 0.573\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:41 | INFO | Rank 0 | Train Epoch: 1 [12224/250314 (5%)]\tLoss: 0.231104\tData (t) 0.344\tBatch (t) 0.555\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:41 | INFO | Rank 0 | Train Epoch: 1 [12256/250314 (5%)]\tLoss: 0.417025\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:42 | INFO | Rank 0 | Train Epoch: 1 [12288/250314 (5%)]\tLoss: 0.320996\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:42 | INFO | Rank 0 | Train Epoch: 1 [12320/250314 (5%)]\tLoss: 0.339874\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:43 | INFO | Rank 0 | Train Epoch: 1 [12352/250314 (5%)]\tLoss: 0.688981\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:43 | INFO | Rank 0 | Train Epoch: 1 [12384/250314 (5%)]\tLoss: 0.295851\tData (t) 0.339\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:44 | INFO | Rank 0 | Train Epoch: 1 [12416/250314 (5%)]\tLoss: 0.694481\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:45 | INFO | Rank 0 | Train Epoch: 1 [12448/250314 (5%)]\tLoss: 0.520137\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:45 | INFO | Rank 0 | Train Epoch: 1 [12480/250314 (5%)]\tLoss: 0.666615\tData (t) 0.332\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:46 | INFO | Rank 0 | Train Epoch: 1 [12512/250314 (5%)]\tLoss: 0.440293\tData (t) 0.350\tBatch (t) 0.562\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:46 | INFO | Rank 0 | Train Epoch: 1 [12544/250314 (5%)]\tLoss: 0.426666\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:47 | INFO | Rank 0 | Train Epoch: 1 [12576/250314 (5%)]\tLoss: 0.338499\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:47 | INFO | Rank 0 | Train Epoch: 1 [12608/250314 (5%)]\tLoss: 0.370039\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:48 | INFO | Rank 0 | Train Epoch: 1 [12640/250314 (5%)]\tLoss: 0.447708\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:48 | INFO | Rank 0 | Train Epoch: 1 [12672/250314 (5%)]\tLoss: 0.815463\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:49 | INFO | Rank 0 | Train Epoch: 1 [12704/250314 (5%)]\tLoss: 0.650348\tData (t) 0.325\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:49 | INFO | Rank 0 | Train Epoch: 1 [12736/250314 (5%)]\tLoss: 0.411543\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:50 | INFO | Rank 0 | Train Epoch: 1 [12768/250314 (5%)]\tLoss: 0.324062\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:50 | INFO | Rank 0 | Train Epoch: 1 [12800/250314 (5%)]\tLoss: 0.448984\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:51 | INFO | Rank 0 | Train Epoch: 1 [12832/250314 (5%)]\tLoss: 0.285067\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:51 | INFO | Rank 0 | Train Epoch: 1 [12864/250314 (5%)]\tLoss: 0.380410\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:52 | INFO | Rank 0 | Train Epoch: 1 [12896/250314 (5%)]\tLoss: 0.636574\tData (t) 0.332\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:52 | INFO | Rank 0 | Train Epoch: 1 [12928/250314 (5%)]\tLoss: 0.534971\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:53 | INFO | Rank 0 | Train Epoch: 1 [12960/250314 (5%)]\tLoss: 0.297734\tData (t) 0.342\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:53 | INFO | Rank 0 | Train Epoch: 1 [12992/250314 (5%)]\tLoss: 0.524032\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:54 | INFO | Rank 0 | Train Epoch: 1 [13024/250314 (5%)]\tLoss: 0.634713\tData (t) 0.339\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:55 | INFO | Rank 0 | Train Epoch: 1 [13056/250314 (5%)]\tLoss: 0.302893\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:55 | INFO | Rank 0 | Train Epoch: 1 [13088/250314 (5%)]\tLoss: 0.388403\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:56 | INFO | Rank 0 | Train Epoch: 1 [13120/250314 (5%)]\tLoss: 0.382051\tData (t) 0.341\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:56 | INFO | Rank 0 | Train Epoch: 1 [13152/250314 (5%)]\tLoss: 0.248345\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:57 | INFO | Rank 0 | Train Epoch: 1 [13184/250314 (5%)]\tLoss: 0.428163\tData (t) 0.356\tBatch (t) 0.568\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:57 | INFO | Rank 0 | Train Epoch: 1 [13216/250314 (5%)]\tLoss: 0.463749\tData (t) 0.320\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:58 | INFO | Rank 0 | Train Epoch: 1 [13248/250314 (5%)]\tLoss: 0.768737\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:58 | INFO | Rank 0 | Train Epoch: 1 [13280/250314 (5%)]\tLoss: 0.456144\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:59 | INFO | Rank 0 | Train Epoch: 1 [13312/250314 (5%)]\tLoss: 0.376554\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:22:59 | INFO | Rank 0 | Train Epoch: 1 [13344/250314 (5%)]\tLoss: 0.498913\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:00 | INFO | Rank 0 | Train Epoch: 1 [13376/250314 (5%)]\tLoss: 0.421615\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:00 | INFO | Rank 0 | Train Epoch: 1 [13408/250314 (5%)]\tLoss: 0.536471\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:01 | INFO | Rank 0 | Train Epoch: 1 [13440/250314 (5%)]\tLoss: 0.473348\tData (t) 0.374\tBatch (t) 0.586\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:02 | INFO | Rank 0 | Train Epoch: 1 [13472/250314 (5%)]\tLoss: 0.470518\tData (t) 0.360\tBatch (t) 0.572\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:02 | INFO | Rank 0 | Train Epoch: 1 [13504/250314 (5%)]\tLoss: 0.307616\tData (t) 0.329\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:03 | INFO | Rank 0 | Train Epoch: 1 [13536/250314 (5%)]\tLoss: 0.268102\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:03 | INFO | Rank 0 | Train Epoch: 1 [13568/250314 (5%)]\tLoss: 0.464449\tData (t) 0.320\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:04 | INFO | Rank 0 | Train Epoch: 1 [13600/250314 (5%)]\tLoss: 0.482568\tData (t) 0.328\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:04 | INFO | Rank 0 | Train Epoch: 1 [13632/250314 (5%)]\tLoss: 0.712947\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:05 | INFO | Rank 0 | Train Epoch: 1 [13664/250314 (5%)]\tLoss: 0.190225\tData (t) 0.314\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:05 | INFO | Rank 0 | Train Epoch: 1 [13696/250314 (5%)]\tLoss: 0.818500\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:06 | INFO | Rank 0 | Train Epoch: 1 [13728/250314 (5%)]\tLoss: 0.262657\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:06 | INFO | Rank 0 | Train Epoch: 1 [13760/250314 (5%)]\tLoss: 0.306122\tData (t) 0.309\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:07 | INFO | Rank 0 | Train Epoch: 1 [13792/250314 (6%)]\tLoss: 0.382107\tData (t) 0.340\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:07 | INFO | Rank 0 | Train Epoch: 1 [13824/250314 (6%)]\tLoss: 0.486478\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:08 | INFO | Rank 0 | Train Epoch: 1 [13856/250314 (6%)]\tLoss: 0.613184\tData (t) 0.365\tBatch (t) 0.577\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:09 | INFO | Rank 0 | Train Epoch: 1 [13888/250314 (6%)]\tLoss: 0.527114\tData (t) 0.364\tBatch (t) 0.576\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:09 | INFO | Rank 0 | Train Epoch: 1 [13920/250314 (6%)]\tLoss: 0.422750\tData (t) 0.341\tBatch (t) 0.553\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:10 | INFO | Rank 0 | Train Epoch: 1 [13952/250314 (6%)]\tLoss: 0.449474\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:10 | INFO | Rank 0 | Train Epoch: 1 [13984/250314 (6%)]\tLoss: 0.525883\tData (t) 0.335\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:11 | INFO | Rank 0 | Train Epoch: 1 [14016/250314 (6%)]\tLoss: 0.356265\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:11 | INFO | Rank 0 | Train Epoch: 1 [14048/250314 (6%)]\tLoss: 0.430501\tData (t) 0.342\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:12 | INFO | Rank 0 | Train Epoch: 1 [14080/250314 (6%)]\tLoss: 0.748478\tData (t) 0.353\tBatch (t) 0.565\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:12 | INFO | Rank 0 | Train Epoch: 1 [14112/250314 (6%)]\tLoss: 0.322414\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:13 | INFO | Rank 0 | Train Epoch: 1 [14144/250314 (6%)]\tLoss: 0.590620\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:13 | INFO | Rank 0 | Train Epoch: 1 [14176/250314 (6%)]\tLoss: 0.427633\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:14 | INFO | Rank 0 | Train Epoch: 1 [14208/250314 (6%)]\tLoss: 0.172497\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:14 | INFO | Rank 0 | Train Epoch: 1 [14240/250314 (6%)]\tLoss: 0.379489\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:15 | INFO | Rank 0 | Train Epoch: 1 [14272/250314 (6%)]\tLoss: 0.387246\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:16 | INFO | Rank 0 | Train Epoch: 1 [14304/250314 (6%)]\tLoss: 0.306006\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:16 | INFO | Rank 0 | Train Epoch: 1 [14336/250314 (6%)]\tLoss: 0.494551\tData (t) 0.335\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:17 | INFO | Rank 0 | Train Epoch: 1 [14368/250314 (6%)]\tLoss: 0.745676\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:17 | INFO | Rank 0 | Train Epoch: 1 [14400/250314 (6%)]\tLoss: 0.357460\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:18 | INFO | Rank 0 | Train Epoch: 1 [14432/250314 (6%)]\tLoss: 0.289587\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:18 | INFO | Rank 0 | Train Epoch: 1 [14464/250314 (6%)]\tLoss: 0.328062\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:19 | INFO | Rank 0 | Train Epoch: 1 [14496/250314 (6%)]\tLoss: 0.514620\tData (t) 0.355\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:19 | INFO | Rank 0 | Train Epoch: 1 [14528/250314 (6%)]\tLoss: 0.373797\tData (t) 0.346\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:20 | INFO | Rank 0 | Train Epoch: 1 [14560/250314 (6%)]\tLoss: 0.404935\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:20 | INFO | Rank 0 | Train Epoch: 1 [14592/250314 (6%)]\tLoss: 0.312032\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:21 | INFO | Rank 0 | Train Epoch: 1 [14624/250314 (6%)]\tLoss: 0.434566\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:21 | INFO | Rank 0 | Train Epoch: 1 [14656/250314 (6%)]\tLoss: 0.212163\tData (t) 0.307\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:22 | INFO | Rank 0 | Train Epoch: 1 [14688/250314 (6%)]\tLoss: 0.596512\tData (t) 0.332\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:22 | INFO | Rank 0 | Train Epoch: 1 [14720/250314 (6%)]\tLoss: 0.440807\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:23 | INFO | Rank 0 | Train Epoch: 1 [14752/250314 (6%)]\tLoss: 0.319325\tData (t) 0.324\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:24 | INFO | Rank 0 | Train Epoch: 1 [14784/250314 (6%)]\tLoss: 0.513514\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:24 | INFO | Rank 0 | Train Epoch: 1 [14816/250314 (6%)]\tLoss: 0.476016\tData (t) 0.351\tBatch (t) 0.563\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:25 | INFO | Rank 0 | Train Epoch: 1 [14848/250314 (6%)]\tLoss: 0.510698\tData (t) 0.363\tBatch (t) 0.574\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:25 | INFO | Rank 0 | Train Epoch: 1 [14880/250314 (6%)]\tLoss: 0.514319\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:26 | INFO | Rank 0 | Train Epoch: 1 [14912/250314 (6%)]\tLoss: 0.770536\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:26 | INFO | Rank 0 | Train Epoch: 1 [14944/250314 (6%)]\tLoss: 0.439060\tData (t) 0.338\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:27 | INFO | Rank 0 | Train Epoch: 1 [14976/250314 (6%)]\tLoss: 0.696372\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:27 | INFO | Rank 0 | Train Epoch: 1 [15008/250314 (6%)]\tLoss: 0.492367\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:28 | INFO | Rank 0 | Train Epoch: 1 [15040/250314 (6%)]\tLoss: 0.319147\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:28 | INFO | Rank 0 | Train Epoch: 1 [15072/250314 (6%)]\tLoss: 0.698454\tData (t) 0.331\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:29 | INFO | Rank 0 | Train Epoch: 1 [15104/250314 (6%)]\tLoss: 0.424725\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:29 | INFO | Rank 0 | Train Epoch: 1 [15136/250314 (6%)]\tLoss: 0.647601\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:30 | INFO | Rank 0 | Train Epoch: 1 [15168/250314 (6%)]\tLoss: 0.425594\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:30 | INFO | Rank 0 | Train Epoch: 1 [15200/250314 (6%)]\tLoss: 0.332057\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:31 | INFO | Rank 0 | Train Epoch: 1 [15232/250314 (6%)]\tLoss: 0.229150\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:32 | INFO | Rank 0 | Train Epoch: 1 [15264/250314 (6%)]\tLoss: 0.456817\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:32 | INFO | Rank 0 | Train Epoch: 1 [15296/250314 (6%)]\tLoss: 0.523780\tData (t) 0.333\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:33 | INFO | Rank 0 | Train Epoch: 1 [15328/250314 (6%)]\tLoss: 0.520706\tData (t) 0.341\tBatch (t) 0.553\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:33 | INFO | Rank 0 | Train Epoch: 1 [15360/250314 (6%)]\tLoss: 0.456647\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:34 | INFO | Rank 0 | Train Epoch: 1 [15392/250314 (6%)]\tLoss: 0.572963\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:34 | INFO | Rank 0 | Train Epoch: 1 [15424/250314 (6%)]\tLoss: 0.277735\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:35 | INFO | Rank 0 | Train Epoch: 1 [15456/250314 (6%)]\tLoss: 0.668597\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:35 | INFO | Rank 0 | Train Epoch: 1 [15488/250314 (6%)]\tLoss: 0.702812\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:36 | INFO | Rank 0 | Train Epoch: 1 [15520/250314 (6%)]\tLoss: 0.387627\tData (t) 0.322\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:36 | INFO | Rank 0 | Train Epoch: 1 [15552/250314 (6%)]\tLoss: 0.613894\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:37 | INFO | Rank 0 | Train Epoch: 1 [15584/250314 (6%)]\tLoss: 0.501826\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:37 | INFO | Rank 0 | Train Epoch: 1 [15616/250314 (6%)]\tLoss: 0.472521\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:38 | INFO | Rank 0 | Train Epoch: 1 [15648/250314 (6%)]\tLoss: 0.391161\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:38 | INFO | Rank 0 | Train Epoch: 1 [15680/250314 (6%)]\tLoss: 0.383070\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:39 | INFO | Rank 0 | Train Epoch: 1 [15712/250314 (6%)]\tLoss: 0.217913\tData (t) 0.306\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:39 | INFO | Rank 0 | Train Epoch: 1 [15744/250314 (6%)]\tLoss: 0.509274\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:40 | INFO | Rank 0 | Train Epoch: 1 [15776/250314 (6%)]\tLoss: 0.407623\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:40 | INFO | Rank 0 | Train Epoch: 1 [15808/250314 (6%)]\tLoss: 0.847174\tData (t) 0.355\tBatch (t) 0.567\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:41 | INFO | Rank 0 | Train Epoch: 1 [15840/250314 (6%)]\tLoss: 0.395549\tData (t) 0.351\tBatch (t) 0.563\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:42 | INFO | Rank 0 | Train Epoch: 1 [15872/250314 (6%)]\tLoss: 0.436866\tData (t) 0.326\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:42 | INFO | Rank 0 | Train Epoch: 1 [15904/250314 (6%)]\tLoss: 0.324857\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:43 | INFO | Rank 0 | Train Epoch: 1 [15936/250314 (6%)]\tLoss: 0.546587\tData (t) 0.329\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:43 | INFO | Rank 0 | Train Epoch: 1 [15968/250314 (6%)]\tLoss: 0.483623\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:44 | INFO | Rank 0 | Train Epoch: 1 [16000/250314 (6%)]\tLoss: 0.504091\tData (t) 0.340\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:44 | INFO | Rank 0 | Train Epoch: 1 [16032/250314 (6%)]\tLoss: 0.315187\tData (t) 0.333\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:45 | INFO | Rank 0 | Train Epoch: 1 [16064/250314 (6%)]\tLoss: 0.480167\tData (t) 0.307\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:45 | INFO | Rank 0 | Train Epoch: 1 [16096/250314 (6%)]\tLoss: 0.736462\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:46 | INFO | Rank 0 | Train Epoch: 1 [16128/250314 (6%)]\tLoss: 0.796685\tData (t) 0.336\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:46 | INFO | Rank 0 | Train Epoch: 1 [16160/250314 (6%)]\tLoss: 0.545112\tData (t) 0.351\tBatch (t) 0.563\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:47 | INFO | Rank 0 | Train Epoch: 1 [16192/250314 (6%)]\tLoss: 0.229315\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:47 | INFO | Rank 0 | Train Epoch: 1 [16224/250314 (6%)]\tLoss: 0.781411\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:48 | INFO | Rank 0 | Train Epoch: 1 [16256/250314 (6%)]\tLoss: 0.354195\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:48 | INFO | Rank 0 | Train Epoch: 1 [16288/250314 (7%)]\tLoss: 0.392888\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:49 | INFO | Rank 0 | Train Epoch: 1 [16320/250314 (7%)]\tLoss: 0.523520\tData (t) 0.339\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:50 | INFO | Rank 0 | Train Epoch: 1 [16352/250314 (7%)]\tLoss: 0.331190\tData (t) 0.358\tBatch (t) 0.570\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:50 | INFO | Rank 0 | Train Epoch: 1 [16384/250314 (7%)]\tLoss: 0.581347\tData (t) 0.340\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:23:51 | INFO | Rank 0 | Train Epoch: 1 [16416/250314 (7%)]\tLoss: 0.547007\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:23:51 | INFO | Rank 0 | Train Epoch: 1 [16448/250314 (7%)]\tLoss: 0.778731\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:23:52 | INFO | Rank 0 | Train Epoch: 1 [16480/250314 (7%)]\tLoss: 0.392548\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:23:52 | INFO | Rank 0 | Train Epoch: 1 [16512/250314 (7%)]\tLoss: 0.323894\tData (t) 0.335\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:23:53 | INFO | Rank 0 | Train Epoch: 1 [16544/250314 (7%)]\tLoss: 0.423023\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:23:53 | INFO | Rank 0 | Train Epoch: 1 [16576/250314 (7%)]\tLoss: 0.628422\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:23:54 | INFO | Rank 0 | Train Epoch: 1 [16608/250314 (7%)]\tLoss: 0.521739\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:23:54 | INFO | Rank 0 | Train Epoch: 1 [16640/250314 (7%)]\tLoss: 0.347037\tData (t) 0.341\tBatch (t) 0.553\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:23:55 | INFO | Rank 0 | Train Epoch: 1 [16672/250314 (7%)]\tLoss: 0.357256\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:23:55 | INFO | Rank 0 | Train Epoch: 1 [16704/250314 (7%)]\tLoss: 0.487578\tData (t) 0.383\tBatch (t) 0.595\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:23:56 | INFO | Rank 0 | Train Epoch: 1 [16736/250314 (7%)]\tLoss: 0.489685\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:23:56 | INFO | Rank 0 | Train Epoch: 1 [16768/250314 (7%)]\tLoss: 0.516325\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:23:57 | INFO | Rank 0 | Train Epoch: 1 [16800/250314 (7%)]\tLoss: 0.214819\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:23:57 | INFO | Rank 0 | Train Epoch: 1 [16832/250314 (7%)]\tLoss: 0.349733\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:23:58 | INFO | Rank 0 | Train Epoch: 1 [16864/250314 (7%)]\tLoss: 0.717582\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:23:59 | INFO | Rank 0 | Train Epoch: 1 [16896/250314 (7%)]\tLoss: 0.380603\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:23:59 | INFO | Rank 0 | Train Epoch: 1 [16928/250314 (7%)]\tLoss: 0.389964\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:00 | INFO | Rank 0 | Train Epoch: 1 [16960/250314 (7%)]\tLoss: 0.466840\tData (t) 0.314\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:00 | INFO | Rank 0 | Train Epoch: 1 [16992/250314 (7%)]\tLoss: 0.437232\tData (t) 0.300\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:01 | INFO | Rank 0 | Train Epoch: 1 [17024/250314 (7%)]\tLoss: 0.437709\tData (t) 0.264\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:01 | INFO | Rank 0 | Train Epoch: 1 [17056/250314 (7%)]\tLoss: 0.593590\tData (t) 0.333\tBatch (t) 0.547\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:02 | INFO | Rank 0 | Train Epoch: 1 [17088/250314 (7%)]\tLoss: 0.414045\tData (t) 0.287\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:02 | INFO | Rank 0 | Train Epoch: 1 [17120/250314 (7%)]\tLoss: 0.661126\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:03 | INFO | Rank 0 | Train Epoch: 1 [17152/250314 (7%)]\tLoss: 0.350890\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:03 | INFO | Rank 0 | Train Epoch: 1 [17184/250314 (7%)]\tLoss: 0.369255\tData (t) 0.345\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:04 | INFO | Rank 0 | Train Epoch: 1 [17216/250314 (7%)]\tLoss: 0.224419\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:04 | INFO | Rank 0 | Train Epoch: 1 [17248/250314 (7%)]\tLoss: 0.329075\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:05 | INFO | Rank 0 | Train Epoch: 1 [17280/250314 (7%)]\tLoss: 0.444191\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:05 | INFO | Rank 0 | Train Epoch: 1 [17312/250314 (7%)]\tLoss: 0.413966\tData (t) 0.338\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:06 | INFO | Rank 0 | Train Epoch: 1 [17344/250314 (7%)]\tLoss: 0.212163\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:06 | INFO | Rank 0 | Train Epoch: 1 [17376/250314 (7%)]\tLoss: 0.422656\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:07 | INFO | Rank 0 | Train Epoch: 1 [17408/250314 (7%)]\tLoss: 0.360497\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:07 | INFO | Rank 0 | Train Epoch: 1 [17440/250314 (7%)]\tLoss: 0.436874\tData (t) 0.324\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:08 | INFO | Rank 0 | Train Epoch: 1 [17472/250314 (7%)]\tLoss: 0.724270\tData (t) 0.307\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:08 | INFO | Rank 0 | Train Epoch: 1 [17504/250314 (7%)]\tLoss: 0.600741\tData (t) 0.338\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:09 | INFO | Rank 0 | Train Epoch: 1 [17536/250314 (7%)]\tLoss: 0.336715\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:09 | INFO | Rank 0 | Train Epoch: 1 [17568/250314 (7%)]\tLoss: 0.695673\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:10 | INFO | Rank 0 | Train Epoch: 1 [17600/250314 (7%)]\tLoss: 0.360438\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:10 | INFO | Rank 0 | Train Epoch: 1 [17632/250314 (7%)]\tLoss: 0.554752\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:11 | INFO | Rank 0 | Train Epoch: 1 [17664/250314 (7%)]\tLoss: 0.450229\tData (t) 0.340\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:12 | INFO | Rank 0 | Train Epoch: 1 [17696/250314 (7%)]\tLoss: 0.439236\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:12 | INFO | Rank 0 | Train Epoch: 1 [17728/250314 (7%)]\tLoss: 0.197254\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:13 | INFO | Rank 0 | Train Epoch: 1 [17760/250314 (7%)]\tLoss: 0.312482\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:13 | INFO | Rank 0 | Train Epoch: 1 [17792/250314 (7%)]\tLoss: 0.313497\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:14 | INFO | Rank 0 | Train Epoch: 1 [17824/250314 (7%)]\tLoss: 0.738658\tData (t) 0.367\tBatch (t) 0.579\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:14 | INFO | Rank 0 | Train Epoch: 1 [17856/250314 (7%)]\tLoss: 0.558999\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:15 | INFO | Rank 0 | Train Epoch: 1 [17888/250314 (7%)]\tLoss: 0.349932\tData (t) 0.365\tBatch (t) 0.577\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:15 | INFO | Rank 0 | Train Epoch: 1 [17920/250314 (7%)]\tLoss: 0.298250\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:16 | INFO | Rank 0 | Train Epoch: 1 [17952/250314 (7%)]\tLoss: 0.451626\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:16 | INFO | Rank 0 | Train Epoch: 1 [17984/250314 (7%)]\tLoss: 0.267027\tData (t) 0.353\tBatch (t) 0.565\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:17 | INFO | Rank 0 | Train Epoch: 1 [18016/250314 (7%)]\tLoss: 0.220803\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:17 | INFO | Rank 0 | Train Epoch: 1 [18048/250314 (7%)]\tLoss: 0.452789\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:18 | INFO | Rank 0 | Train Epoch: 1 [18080/250314 (7%)]\tLoss: 0.602518\tData (t) 0.369\tBatch (t) 0.581\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:18 | INFO | Rank 0 | Train Epoch: 1 [18112/250314 (7%)]\tLoss: 0.389865\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:19 | INFO | Rank 0 | Train Epoch: 1 [18144/250314 (7%)]\tLoss: 0.426011\tData (t) 0.327\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:20 | INFO | Rank 0 | Train Epoch: 1 [18176/250314 (7%)]\tLoss: 0.446795\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:20 | INFO | Rank 0 | Train Epoch: 1 [18208/250314 (7%)]\tLoss: 0.523787\tData (t) 0.340\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:21 | INFO | Rank 0 | Train Epoch: 1 [18240/250314 (7%)]\tLoss: 0.210752\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:21 | INFO | Rank 0 | Train Epoch: 1 [18272/250314 (7%)]\tLoss: 0.465996\tData (t) 0.327\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:22 | INFO | Rank 0 | Train Epoch: 1 [18304/250314 (7%)]\tLoss: 0.681885\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:22 | INFO | Rank 0 | Train Epoch: 1 [18336/250314 (7%)]\tLoss: 0.295092\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:23 | INFO | Rank 0 | Train Epoch: 1 [18368/250314 (7%)]\tLoss: 0.232691\tData (t) 0.302\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:23 | INFO | Rank 0 | Train Epoch: 1 [18400/250314 (7%)]\tLoss: 0.180842\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:24 | INFO | Rank 0 | Train Epoch: 1 [18432/250314 (7%)]\tLoss: 0.515008\tData (t) 0.331\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:24 | INFO | Rank 0 | Train Epoch: 1 [18464/250314 (7%)]\tLoss: 0.379269\tData (t) 0.341\tBatch (t) 0.553\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:25 | INFO | Rank 0 | Train Epoch: 1 [18496/250314 (7%)]\tLoss: 0.277015\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:25 | INFO | Rank 0 | Train Epoch: 1 [18528/250314 (7%)]\tLoss: 0.241955\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:26 | INFO | Rank 0 | Train Epoch: 1 [18560/250314 (7%)]\tLoss: 0.584192\tData (t) 0.339\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:26 | INFO | Rank 0 | Train Epoch: 1 [18592/250314 (7%)]\tLoss: 0.293891\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:27 | INFO | Rank 0 | Train Epoch: 1 [18624/250314 (7%)]\tLoss: 0.587997\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:27 | INFO | Rank 0 | Train Epoch: 1 [18656/250314 (7%)]\tLoss: 0.294742\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:28 | INFO | Rank 0 | Train Epoch: 1 [18688/250314 (7%)]\tLoss: 0.490688\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:28 | INFO | Rank 0 | Train Epoch: 1 [18720/250314 (7%)]\tLoss: 0.385119\tData (t) 0.334\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:29 | INFO | Rank 0 | Train Epoch: 1 [18752/250314 (7%)]\tLoss: 0.179474\tData (t) 0.306\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:29 | INFO | Rank 0 | Train Epoch: 1 [18784/250314 (8%)]\tLoss: 0.401686\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:30 | INFO | Rank 0 | Train Epoch: 1 [18816/250314 (8%)]\tLoss: 0.731483\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:31 | INFO | Rank 0 | Train Epoch: 1 [18848/250314 (8%)]\tLoss: 0.474122\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:31 | INFO | Rank 0 | Train Epoch: 1 [18880/250314 (8%)]\tLoss: 0.205989\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:32 | INFO | Rank 0 | Train Epoch: 1 [18912/250314 (8%)]\tLoss: 0.457875\tData (t) 0.318\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:32 | INFO | Rank 0 | Train Epoch: 1 [18944/250314 (8%)]\tLoss: 0.250036\tData (t) 0.317\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:33 | INFO | Rank 0 | Train Epoch: 1 [18976/250314 (8%)]\tLoss: 0.244523\tData (t) 0.285\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:33 | INFO | Rank 0 | Train Epoch: 1 [19008/250314 (8%)]\tLoss: 0.444248\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:34 | INFO | Rank 0 | Train Epoch: 1 [19040/250314 (8%)]\tLoss: 0.306920\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:34 | INFO | Rank 0 | Train Epoch: 1 [19072/250314 (8%)]\tLoss: 0.297632\tData (t) 0.349\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:35 | INFO | Rank 0 | Train Epoch: 1 [19104/250314 (8%)]\tLoss: 0.544105\tData (t) 0.338\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:35 | INFO | Rank 0 | Train Epoch: 1 [19136/250314 (8%)]\tLoss: 0.718819\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:36 | INFO | Rank 0 | Train Epoch: 1 [19168/250314 (8%)]\tLoss: 0.370775\tData (t) 0.316\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:36 | INFO | Rank 0 | Train Epoch: 1 [19200/250314 (8%)]\tLoss: 0.255435\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:37 | INFO | Rank 0 | Train Epoch: 1 [19232/250314 (8%)]\tLoss: 0.600633\tData (t) 0.312\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:37 | INFO | Rank 0 | Train Epoch: 1 [19264/250314 (8%)]\tLoss: 0.493474\tData (t) 0.289\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:38 | INFO | Rank 0 | Train Epoch: 1 [19296/250314 (8%)]\tLoss: 0.322645\tData (t) 0.316\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:38 | INFO | Rank 0 | Train Epoch: 1 [19328/250314 (8%)]\tLoss: 0.890779\tData (t) 0.286\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:39 | INFO | Rank 0 | Train Epoch: 1 [19360/250314 (8%)]\tLoss: 0.712672\tData (t) 0.310\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:39 | INFO | Rank 0 | Train Epoch: 1 [19392/250314 (8%)]\tLoss: 0.263828\tData (t) 0.317\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:40 | INFO | Rank 0 | Train Epoch: 1 [19424/250314 (8%)]\tLoss: 0.478479\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:40 | INFO | Rank 0 | Train Epoch: 1 [19456/250314 (8%)]\tLoss: 0.391920\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:41 | INFO | Rank 0 | Train Epoch: 1 [19488/250314 (8%)]\tLoss: 0.584654\tData (t) 0.349\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:41 | INFO | Rank 0 | Train Epoch: 1 [19520/250314 (8%)]\tLoss: 0.511018\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:42 | INFO | Rank 0 | Train Epoch: 1 [19552/250314 (8%)]\tLoss: 0.481009\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:42 | INFO | Rank 0 | Train Epoch: 1 [19584/250314 (8%)]\tLoss: 0.182075\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:43 | INFO | Rank 0 | Train Epoch: 1 [19616/250314 (8%)]\tLoss: 0.242965\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:44 | INFO | Rank 0 | Train Epoch: 1 [19648/250314 (8%)]\tLoss: 0.577862\tData (t) 0.338\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:44 | INFO | Rank 0 | Train Epoch: 1 [19680/250314 (8%)]\tLoss: 0.266677\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:45 | INFO | Rank 0 | Train Epoch: 1 [19712/250314 (8%)]\tLoss: 0.278614\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:45 | INFO | Rank 0 | Train Epoch: 1 [19744/250314 (8%)]\tLoss: 0.508123\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:46 | INFO | Rank 0 | Train Epoch: 1 [19776/250314 (8%)]\tLoss: 0.333375\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:46 | INFO | Rank 0 | Train Epoch: 1 [19808/250314 (8%)]\tLoss: 0.307015\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:47 | INFO | Rank 0 | Train Epoch: 1 [19840/250314 (8%)]\tLoss: 0.304176\tData (t) 0.263\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:47 | INFO | Rank 0 | Train Epoch: 1 [19872/250314 (8%)]\tLoss: 0.402090\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:48 | INFO | Rank 0 | Train Epoch: 1 [19904/250314 (8%)]\tLoss: 0.781718\tData (t) 0.301\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:48 | INFO | Rank 0 | Train Epoch: 1 [19936/250314 (8%)]\tLoss: 0.302888\tData (t) 0.294\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:49 | INFO | Rank 0 | Train Epoch: 1 [19968/250314 (8%)]\tLoss: 0.424915\tData (t) 0.317\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.588\n",
      "2022-11-09,14:24:49 | INFO | Rank 0 | Train Epoch: 1 [20000/250314 (8%)]\tLoss: 0.596074\tData (t) 0.306\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:50 | INFO | Rank 0 | Train Epoch: 1 [20032/250314 (8%)]\tLoss: 0.212869\tData (t) 0.338\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:50 | INFO | Rank 0 | Train Epoch: 1 [20064/250314 (8%)]\tLoss: 0.491400\tData (t) 0.323\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:51 | INFO | Rank 0 | Train Epoch: 1 [20096/250314 (8%)]\tLoss: 0.578894\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:51 | INFO | Rank 0 | Train Epoch: 1 [20128/250314 (8%)]\tLoss: 0.953837\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:52 | INFO | Rank 0 | Train Epoch: 1 [20160/250314 (8%)]\tLoss: 0.385443\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:52 | INFO | Rank 0 | Train Epoch: 1 [20192/250314 (8%)]\tLoss: 0.399421\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:53 | INFO | Rank 0 | Train Epoch: 1 [20224/250314 (8%)]\tLoss: 0.415940\tData (t) 0.358\tBatch (t) 0.571\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:54 | INFO | Rank 0 | Train Epoch: 1 [20256/250314 (8%)]\tLoss: 0.466722\tData (t) 0.364\tBatch (t) 0.576\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:54 | INFO | Rank 0 | Train Epoch: 1 [20288/250314 (8%)]\tLoss: 0.690535\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:54 | INFO | Rank 0 | Train Epoch: 1 [20320/250314 (8%)]\tLoss: 0.358840\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:55 | INFO | Rank 0 | Train Epoch: 1 [20352/250314 (8%)]\tLoss: 0.303573\tData (t) 0.298\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:56 | INFO | Rank 0 | Train Epoch: 1 [20384/250314 (8%)]\tLoss: 0.754138\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:56 | INFO | Rank 0 | Train Epoch: 1 [20416/250314 (8%)]\tLoss: 0.582669\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:57 | INFO | Rank 0 | Train Epoch: 1 [20448/250314 (8%)]\tLoss: 0.416846\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:57 | INFO | Rank 0 | Train Epoch: 1 [20480/250314 (8%)]\tLoss: 0.334868\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:58 | INFO | Rank 0 | Train Epoch: 1 [20512/250314 (8%)]\tLoss: 0.165979\tData (t) 0.322\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:58 | INFO | Rank 0 | Train Epoch: 1 [20544/250314 (8%)]\tLoss: 0.580203\tData (t) 0.292\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:59 | INFO | Rank 0 | Train Epoch: 1 [20576/250314 (8%)]\tLoss: 0.520305\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:24:59 | INFO | Rank 0 | Train Epoch: 1 [20608/250314 (8%)]\tLoss: 0.861314\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:00 | INFO | Rank 0 | Train Epoch: 1 [20640/250314 (8%)]\tLoss: 0.549800\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:00 | INFO | Rank 0 | Train Epoch: 1 [20672/250314 (8%)]\tLoss: 0.449038\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:01 | INFO | Rank 0 | Train Epoch: 1 [20704/250314 (8%)]\tLoss: 0.409261\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:01 | INFO | Rank 0 | Train Epoch: 1 [20736/250314 (8%)]\tLoss: 0.533221\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:02 | INFO | Rank 0 | Train Epoch: 1 [20768/250314 (8%)]\tLoss: 0.199345\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:02 | INFO | Rank 0 | Train Epoch: 1 [20800/250314 (8%)]\tLoss: 0.293487\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:03 | INFO | Rank 0 | Train Epoch: 1 [20832/250314 (8%)]\tLoss: 0.348474\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:03 | INFO | Rank 0 | Train Epoch: 1 [20864/250314 (8%)]\tLoss: 0.261662\tData (t) 0.345\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:04 | INFO | Rank 0 | Train Epoch: 1 [20896/250314 (8%)]\tLoss: 0.492681\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:04 | INFO | Rank 0 | Train Epoch: 1 [20928/250314 (8%)]\tLoss: 0.584842\tData (t) 0.337\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:05 | INFO | Rank 0 | Train Epoch: 1 [20960/250314 (8%)]\tLoss: 0.357717\tData (t) 0.285\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:05 | INFO | Rank 0 | Train Epoch: 1 [20992/250314 (8%)]\tLoss: 0.576720\tData (t) 0.289\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:06 | INFO | Rank 0 | Train Epoch: 1 [21024/250314 (8%)]\tLoss: 0.241068\tData (t) 0.285\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:06 | INFO | Rank 0 | Train Epoch: 1 [21056/250314 (8%)]\tLoss: 0.229461\tData (t) 0.262\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:07 | INFO | Rank 0 | Train Epoch: 1 [21088/250314 (8%)]\tLoss: 0.374364\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:07 | INFO | Rank 0 | Train Epoch: 1 [21120/250314 (8%)]\tLoss: 0.426191\tData (t) 0.347\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:08 | INFO | Rank 0 | Train Epoch: 1 [21152/250314 (8%)]\tLoss: 0.518875\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:08 | INFO | Rank 0 | Train Epoch: 1 [21184/250314 (8%)]\tLoss: 0.361369\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:09 | INFO | Rank 0 | Train Epoch: 1 [21216/250314 (8%)]\tLoss: 0.266032\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:09 | INFO | Rank 0 | Train Epoch: 1 [21248/250314 (8%)]\tLoss: 0.465755\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:10 | INFO | Rank 0 | Train Epoch: 1 [21280/250314 (9%)]\tLoss: 0.251386\tData (t) 0.355\tBatch (t) 0.567\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:10 | INFO | Rank 0 | Train Epoch: 1 [21312/250314 (9%)]\tLoss: 0.188475\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:11 | INFO | Rank 0 | Train Epoch: 1 [21344/250314 (9%)]\tLoss: 0.493010\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:11 | INFO | Rank 0 | Train Epoch: 1 [21376/250314 (9%)]\tLoss: 0.430710\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:12 | INFO | Rank 0 | Train Epoch: 1 [21408/250314 (9%)]\tLoss: 0.375053\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:12 | INFO | Rank 0 | Train Epoch: 1 [21440/250314 (9%)]\tLoss: 0.513283\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:13 | INFO | Rank 0 | Train Epoch: 1 [21472/250314 (9%)]\tLoss: 0.367643\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:13 | INFO | Rank 0 | Train Epoch: 1 [21504/250314 (9%)]\tLoss: 0.208009\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:14 | INFO | Rank 0 | Train Epoch: 1 [21536/250314 (9%)]\tLoss: 0.544155\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:14 | INFO | Rank 0 | Train Epoch: 1 [21568/250314 (9%)]\tLoss: 0.507548\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:15 | INFO | Rank 0 | Train Epoch: 1 [21600/250314 (9%)]\tLoss: 0.369974\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:15 | INFO | Rank 0 | Train Epoch: 1 [21632/250314 (9%)]\tLoss: 0.715601\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:16 | INFO | Rank 0 | Train Epoch: 1 [21664/250314 (9%)]\tLoss: 0.270134\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:16 | INFO | Rank 0 | Train Epoch: 1 [21696/250314 (9%)]\tLoss: 0.261470\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:17 | INFO | Rank 0 | Train Epoch: 1 [21728/250314 (9%)]\tLoss: 0.484236\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:18 | INFO | Rank 0 | Train Epoch: 1 [21760/250314 (9%)]\tLoss: 0.429494\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:18 | INFO | Rank 0 | Train Epoch: 1 [21792/250314 (9%)]\tLoss: 0.544946\tData (t) 0.328\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:19 | INFO | Rank 0 | Train Epoch: 1 [21824/250314 (9%)]\tLoss: 0.358555\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:19 | INFO | Rank 0 | Train Epoch: 1 [21856/250314 (9%)]\tLoss: 0.504284\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:20 | INFO | Rank 0 | Train Epoch: 1 [21888/250314 (9%)]\tLoss: 0.489771\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:20 | INFO | Rank 0 | Train Epoch: 1 [21920/250314 (9%)]\tLoss: 0.575471\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:21 | INFO | Rank 0 | Train Epoch: 1 [21952/250314 (9%)]\tLoss: 0.404225\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:21 | INFO | Rank 0 | Train Epoch: 1 [21984/250314 (9%)]\tLoss: 0.311723\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:22 | INFO | Rank 0 | Train Epoch: 1 [22016/250314 (9%)]\tLoss: 0.257484\tData (t) 0.341\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:22 | INFO | Rank 0 | Train Epoch: 1 [22048/250314 (9%)]\tLoss: 0.552445\tData (t) 0.306\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:23 | INFO | Rank 0 | Train Epoch: 1 [22080/250314 (9%)]\tLoss: 0.664203\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:23 | INFO | Rank 0 | Train Epoch: 1 [22112/250314 (9%)]\tLoss: 0.163405\tData (t) 0.339\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:24 | INFO | Rank 0 | Train Epoch: 1 [22144/250314 (9%)]\tLoss: 0.379302\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:24 | INFO | Rank 0 | Train Epoch: 1 [22176/250314 (9%)]\tLoss: 0.251107\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:25 | INFO | Rank 0 | Train Epoch: 1 [22208/250314 (9%)]\tLoss: 0.116881\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:25 | INFO | Rank 0 | Train Epoch: 1 [22240/250314 (9%)]\tLoss: 0.720682\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:26 | INFO | Rank 0 | Train Epoch: 1 [22272/250314 (9%)]\tLoss: 0.194552\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:26 | INFO | Rank 0 | Train Epoch: 1 [22304/250314 (9%)]\tLoss: 0.606727\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:27 | INFO | Rank 0 | Train Epoch: 1 [22336/250314 (9%)]\tLoss: 0.266429\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:27 | INFO | Rank 0 | Train Epoch: 1 [22368/250314 (9%)]\tLoss: 0.647562\tData (t) 0.349\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:28 | INFO | Rank 0 | Train Epoch: 1 [22400/250314 (9%)]\tLoss: 0.247737\tData (t) 0.328\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:28 | INFO | Rank 0 | Train Epoch: 1 [22432/250314 (9%)]\tLoss: 0.428234\tData (t) 0.278\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:29 | INFO | Rank 0 | Train Epoch: 1 [22464/250314 (9%)]\tLoss: 0.530220\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:29 | INFO | Rank 0 | Train Epoch: 1 [22496/250314 (9%)]\tLoss: 0.386831\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:30 | INFO | Rank 0 | Train Epoch: 1 [22528/250314 (9%)]\tLoss: 0.279570\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:30 | INFO | Rank 0 | Train Epoch: 1 [22560/250314 (9%)]\tLoss: 0.384637\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:31 | INFO | Rank 0 | Train Epoch: 1 [22592/250314 (9%)]\tLoss: 0.286442\tData (t) 0.332\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:31 | INFO | Rank 0 | Train Epoch: 1 [22624/250314 (9%)]\tLoss: 0.358695\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:32 | INFO | Rank 0 | Train Epoch: 1 [22656/250314 (9%)]\tLoss: 0.373555\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:32 | INFO | Rank 0 | Train Epoch: 1 [22688/250314 (9%)]\tLoss: 0.495159\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:33 | INFO | Rank 0 | Train Epoch: 1 [22720/250314 (9%)]\tLoss: 0.267483\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:33 | INFO | Rank 0 | Train Epoch: 1 [22752/250314 (9%)]\tLoss: 0.686117\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:34 | INFO | Rank 0 | Train Epoch: 1 [22784/250314 (9%)]\tLoss: 0.463823\tData (t) 0.339\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:34 | INFO | Rank 0 | Train Epoch: 1 [22816/250314 (9%)]\tLoss: 0.091539\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:35 | INFO | Rank 0 | Train Epoch: 1 [22848/250314 (9%)]\tLoss: 0.382119\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:35 | INFO | Rank 0 | Train Epoch: 1 [22880/250314 (9%)]\tLoss: 0.471606\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:36 | INFO | Rank 0 | Train Epoch: 1 [22912/250314 (9%)]\tLoss: 0.703751\tData (t) 0.272\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:36 | INFO | Rank 0 | Train Epoch: 1 [22944/250314 (9%)]\tLoss: 0.357683\tData (t) 0.321\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:37 | INFO | Rank 0 | Train Epoch: 1 [22976/250314 (9%)]\tLoss: 0.581205\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:37 | INFO | Rank 0 | Train Epoch: 1 [23008/250314 (9%)]\tLoss: 0.553325\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:38 | INFO | Rank 0 | Train Epoch: 1 [23040/250314 (9%)]\tLoss: 0.320877\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:38 | INFO | Rank 0 | Train Epoch: 1 [23072/250314 (9%)]\tLoss: 0.573667\tData (t) 0.302\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:39 | INFO | Rank 0 | Train Epoch: 1 [23104/250314 (9%)]\tLoss: 0.345780\tData (t) 0.204\tBatch (t) 0.416\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:39 | INFO | Rank 0 | Train Epoch: 1 [23136/250314 (9%)]\tLoss: 0.460592\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:40 | INFO | Rank 0 | Train Epoch: 1 [23168/250314 (9%)]\tLoss: 0.350299\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:40 | INFO | Rank 0 | Train Epoch: 1 [23200/250314 (9%)]\tLoss: 0.629088\tData (t) 0.382\tBatch (t) 0.594\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:41 | INFO | Rank 0 | Train Epoch: 1 [23232/250314 (9%)]\tLoss: 0.580851\tData (t) 0.332\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:41 | INFO | Rank 0 | Train Epoch: 1 [23264/250314 (9%)]\tLoss: 0.481676\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:42 | INFO | Rank 0 | Train Epoch: 1 [23296/250314 (9%)]\tLoss: 0.518109\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:42 | INFO | Rank 0 | Train Epoch: 1 [23328/250314 (9%)]\tLoss: 0.599183\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:43 | INFO | Rank 0 | Train Epoch: 1 [23360/250314 (9%)]\tLoss: 0.568630\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:43 | INFO | Rank 0 | Train Epoch: 1 [23392/250314 (9%)]\tLoss: 0.661174\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:44 | INFO | Rank 0 | Train Epoch: 1 [23424/250314 (9%)]\tLoss: 0.175616\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:44 | INFO | Rank 0 | Train Epoch: 1 [23456/250314 (9%)]\tLoss: 0.546320\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:45 | INFO | Rank 0 | Train Epoch: 1 [23488/250314 (9%)]\tLoss: 0.383624\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:45 | INFO | Rank 0 | Train Epoch: 1 [23520/250314 (9%)]\tLoss: 0.447912\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:46 | INFO | Rank 0 | Train Epoch: 1 [23552/250314 (9%)]\tLoss: 0.401779\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:46 | INFO | Rank 0 | Train Epoch: 1 [23584/250314 (9%)]\tLoss: 0.434084\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:47 | INFO | Rank 0 | Train Epoch: 1 [23616/250314 (9%)]\tLoss: 0.539445\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:47 | INFO | Rank 0 | Train Epoch: 1 [23648/250314 (9%)]\tLoss: 0.435136\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:48 | INFO | Rank 0 | Train Epoch: 1 [23680/250314 (9%)]\tLoss: 0.495971\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:48 | INFO | Rank 0 | Train Epoch: 1 [23712/250314 (9%)]\tLoss: 0.401842\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:49 | INFO | Rank 0 | Train Epoch: 1 [23744/250314 (9%)]\tLoss: 0.179155\tData (t) 0.345\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:50 | INFO | Rank 0 | Train Epoch: 1 [23776/250314 (9%)]\tLoss: 0.654365\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:50 | INFO | Rank 0 | Train Epoch: 1 [23808/250314 (10%)]\tLoss: 0.441167\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:51 | INFO | Rank 0 | Train Epoch: 1 [23840/250314 (10%)]\tLoss: 0.593303\tData (t) 0.338\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:51 | INFO | Rank 0 | Train Epoch: 1 [23872/250314 (10%)]\tLoss: 0.386181\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:52 | INFO | Rank 0 | Train Epoch: 1 [23904/250314 (10%)]\tLoss: 0.736656\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:52 | INFO | Rank 0 | Train Epoch: 1 [23936/250314 (10%)]\tLoss: 0.254398\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:53 | INFO | Rank 0 | Train Epoch: 1 [23968/250314 (10%)]\tLoss: 0.449872\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:53 | INFO | Rank 0 | Train Epoch: 1 [24000/250314 (10%)]\tLoss: 0.716546\tData (t) 0.331\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:54 | INFO | Rank 0 | Train Epoch: 1 [24032/250314 (10%)]\tLoss: 0.511388\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:54 | INFO | Rank 0 | Train Epoch: 1 [24064/250314 (10%)]\tLoss: 0.371345\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:55 | INFO | Rank 0 | Train Epoch: 1 [24096/250314 (10%)]\tLoss: 0.564232\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:55 | INFO | Rank 0 | Train Epoch: 1 [24128/250314 (10%)]\tLoss: 0.362865\tData (t) 0.320\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:56 | INFO | Rank 0 | Train Epoch: 1 [24160/250314 (10%)]\tLoss: 0.514849\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:56 | INFO | Rank 0 | Train Epoch: 1 [24192/250314 (10%)]\tLoss: 0.451398\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:57 | INFO | Rank 0 | Train Epoch: 1 [24224/250314 (10%)]\tLoss: 0.469506\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:57 | INFO | Rank 0 | Train Epoch: 1 [24256/250314 (10%)]\tLoss: 0.521173\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:58 | INFO | Rank 0 | Train Epoch: 1 [24288/250314 (10%)]\tLoss: 0.327832\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:58 | INFO | Rank 0 | Train Epoch: 1 [24320/250314 (10%)]\tLoss: 0.433254\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:59 | INFO | Rank 0 | Train Epoch: 1 [24352/250314 (10%)]\tLoss: 0.378340\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:25:59 | INFO | Rank 0 | Train Epoch: 1 [24384/250314 (10%)]\tLoss: 0.387811\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:00 | INFO | Rank 0 | Train Epoch: 1 [24416/250314 (10%)]\tLoss: 0.521039\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:00 | INFO | Rank 0 | Train Epoch: 1 [24448/250314 (10%)]\tLoss: 0.610693\tData (t) 0.312\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:01 | INFO | Rank 0 | Train Epoch: 1 [24480/250314 (10%)]\tLoss: 0.494088\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:01 | INFO | Rank 0 | Train Epoch: 1 [24512/250314 (10%)]\tLoss: 0.301271\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:02 | INFO | Rank 0 | Train Epoch: 1 [24544/250314 (10%)]\tLoss: 0.505528\tData (t) 0.340\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:02 | INFO | Rank 0 | Train Epoch: 1 [24576/250314 (10%)]\tLoss: 0.748164\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:03 | INFO | Rank 0 | Train Epoch: 1 [24608/250314 (10%)]\tLoss: 0.819470\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:03 | INFO | Rank 0 | Train Epoch: 1 [24640/250314 (10%)]\tLoss: 0.319583\tData (t) 0.313\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:04 | INFO | Rank 0 | Train Epoch: 1 [24672/250314 (10%)]\tLoss: 0.518661\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:04 | INFO | Rank 0 | Train Epoch: 1 [24704/250314 (10%)]\tLoss: 0.142696\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:05 | INFO | Rank 0 | Train Epoch: 1 [24736/250314 (10%)]\tLoss: 0.252024\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:05 | INFO | Rank 0 | Train Epoch: 1 [24768/250314 (10%)]\tLoss: 0.516729\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:06 | INFO | Rank 0 | Train Epoch: 1 [24800/250314 (10%)]\tLoss: 0.492140\tData (t) 0.350\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:06 | INFO | Rank 0 | Train Epoch: 1 [24832/250314 (10%)]\tLoss: 0.187246\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:07 | INFO | Rank 0 | Train Epoch: 1 [24864/250314 (10%)]\tLoss: 0.379444\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:07 | INFO | Rank 0 | Train Epoch: 1 [24896/250314 (10%)]\tLoss: 0.287319\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:08 | INFO | Rank 0 | Train Epoch: 1 [24928/250314 (10%)]\tLoss: 0.439110\tData (t) 0.316\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:08 | INFO | Rank 0 | Train Epoch: 1 [24960/250314 (10%)]\tLoss: 0.233668\tData (t) 0.277\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:09 | INFO | Rank 0 | Train Epoch: 1 [24992/250314 (10%)]\tLoss: 0.307575\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:09 | INFO | Rank 0 | Train Epoch: 1 [25024/250314 (10%)]\tLoss: 0.790205\tData (t) 0.259\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:10 | INFO | Rank 0 | Train Epoch: 1 [25056/250314 (10%)]\tLoss: 0.419623\tData (t) 0.339\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:11 | INFO | Rank 0 | Train Epoch: 1 [25088/250314 (10%)]\tLoss: 0.380006\tData (t) 0.348\tBatch (t) 0.560\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:11 | INFO | Rank 0 | Train Epoch: 1 [25120/250314 (10%)]\tLoss: 0.733555\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:12 | INFO | Rank 0 | Train Epoch: 1 [25152/250314 (10%)]\tLoss: 0.381447\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:12 | INFO | Rank 0 | Train Epoch: 1 [25184/250314 (10%)]\tLoss: 0.279651\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:13 | INFO | Rank 0 | Train Epoch: 1 [25216/250314 (10%)]\tLoss: 0.250252\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:13 | INFO | Rank 0 | Train Epoch: 1 [25248/250314 (10%)]\tLoss: 0.274257\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:14 | INFO | Rank 0 | Train Epoch: 1 [25280/250314 (10%)]\tLoss: 0.294997\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:14 | INFO | Rank 0 | Train Epoch: 1 [25312/250314 (10%)]\tLoss: 0.512628\tData (t) 0.320\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:15 | INFO | Rank 0 | Train Epoch: 1 [25344/250314 (10%)]\tLoss: 0.564790\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:15 | INFO | Rank 0 | Train Epoch: 1 [25376/250314 (10%)]\tLoss: 0.523606\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:16 | INFO | Rank 0 | Train Epoch: 1 [25408/250314 (10%)]\tLoss: 0.252502\tData (t) 0.332\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:16 | INFO | Rank 0 | Train Epoch: 1 [25440/250314 (10%)]\tLoss: 0.125738\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:17 | INFO | Rank 0 | Train Epoch: 1 [25472/250314 (10%)]\tLoss: 1.010943\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:17 | INFO | Rank 0 | Train Epoch: 1 [25504/250314 (10%)]\tLoss: 0.839931\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:18 | INFO | Rank 0 | Train Epoch: 1 [25536/250314 (10%)]\tLoss: 0.229168\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:18 | INFO | Rank 0 | Train Epoch: 1 [25568/250314 (10%)]\tLoss: 0.547462\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:19 | INFO | Rank 0 | Train Epoch: 1 [25600/250314 (10%)]\tLoss: 0.439167\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:19 | INFO | Rank 0 | Train Epoch: 1 [25632/250314 (10%)]\tLoss: 0.276365\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:20 | INFO | Rank 0 | Train Epoch: 1 [25664/250314 (10%)]\tLoss: 0.765064\tData (t) 0.351\tBatch (t) 0.563\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:20 | INFO | Rank 0 | Train Epoch: 1 [25696/250314 (10%)]\tLoss: 0.357554\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:21 | INFO | Rank 0 | Train Epoch: 1 [25728/250314 (10%)]\tLoss: 0.265920\tData (t) 0.342\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:21 | INFO | Rank 0 | Train Epoch: 1 [25760/250314 (10%)]\tLoss: 0.473768\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:22 | INFO | Rank 0 | Train Epoch: 1 [25792/250314 (10%)]\tLoss: 0.503318\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:22 | INFO | Rank 0 | Train Epoch: 1 [25824/250314 (10%)]\tLoss: 0.283064\tData (t) 0.288\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:23 | INFO | Rank 0 | Train Epoch: 1 [25856/250314 (10%)]\tLoss: 0.630582\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:23 | INFO | Rank 0 | Train Epoch: 1 [25888/250314 (10%)]\tLoss: 0.473205\tData (t) 0.203\tBatch (t) 0.415\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:24 | INFO | Rank 0 | Train Epoch: 1 [25920/250314 (10%)]\tLoss: 0.355894\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:24 | INFO | Rank 0 | Train Epoch: 1 [25952/250314 (10%)]\tLoss: 0.407561\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:25 | INFO | Rank 0 | Train Epoch: 1 [25984/250314 (10%)]\tLoss: 0.548181\tData (t) 0.308\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:25 | INFO | Rank 0 | Train Epoch: 1 [26016/250314 (10%)]\tLoss: 0.594278\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:26 | INFO | Rank 0 | Train Epoch: 1 [26048/250314 (10%)]\tLoss: 0.279497\tData (t) 0.286\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:26 | INFO | Rank 0 | Train Epoch: 1 [26080/250314 (10%)]\tLoss: 0.755995\tData (t) 0.299\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:27 | INFO | Rank 0 | Train Epoch: 1 [26112/250314 (10%)]\tLoss: 0.521508\tData (t) 0.262\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:27 | INFO | Rank 0 | Train Epoch: 1 [26144/250314 (10%)]\tLoss: 0.203061\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:28 | INFO | Rank 0 | Train Epoch: 1 [26176/250314 (10%)]\tLoss: 0.186523\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:28 | INFO | Rank 0 | Train Epoch: 1 [26208/250314 (10%)]\tLoss: 0.129874\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:29 | INFO | Rank 0 | Train Epoch: 1 [26240/250314 (10%)]\tLoss: 0.616618\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:29 | INFO | Rank 0 | Train Epoch: 1 [26272/250314 (10%)]\tLoss: 0.489148\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:30 | INFO | Rank 0 | Train Epoch: 1 [26304/250314 (11%)]\tLoss: 0.363426\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:30 | INFO | Rank 0 | Train Epoch: 1 [26336/250314 (11%)]\tLoss: 0.343744\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:31 | INFO | Rank 0 | Train Epoch: 1 [26368/250314 (11%)]\tLoss: 0.425671\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:31 | INFO | Rank 0 | Train Epoch: 1 [26400/250314 (11%)]\tLoss: 0.412425\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:32 | INFO | Rank 0 | Train Epoch: 1 [26432/250314 (11%)]\tLoss: 0.173157\tData (t) 0.326\tBatch (t) 0.538\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:32 | INFO | Rank 0 | Train Epoch: 1 [26464/250314 (11%)]\tLoss: 0.498674\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:33 | INFO | Rank 0 | Train Epoch: 1 [26496/250314 (11%)]\tLoss: 0.692848\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:33 | INFO | Rank 0 | Train Epoch: 1 [26528/250314 (11%)]\tLoss: 0.688854\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:34 | INFO | Rank 0 | Train Epoch: 1 [26560/250314 (11%)]\tLoss: 0.293550\tData (t) 0.251\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:34 | INFO | Rank 0 | Train Epoch: 1 [26592/250314 (11%)]\tLoss: 0.409284\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:35 | INFO | Rank 0 | Train Epoch: 1 [26624/250314 (11%)]\tLoss: 0.590540\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:35 | INFO | Rank 0 | Train Epoch: 1 [26656/250314 (11%)]\tLoss: 0.281602\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:36 | INFO | Rank 0 | Train Epoch: 1 [26688/250314 (11%)]\tLoss: 0.146214\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:36 | INFO | Rank 0 | Train Epoch: 1 [26720/250314 (11%)]\tLoss: 0.265545\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:37 | INFO | Rank 0 | Train Epoch: 1 [26752/250314 (11%)]\tLoss: 0.334574\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:37 | INFO | Rank 0 | Train Epoch: 1 [26784/250314 (11%)]\tLoss: 0.644283\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:38 | INFO | Rank 0 | Train Epoch: 1 [26816/250314 (11%)]\tLoss: 0.578578\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:38 | INFO | Rank 0 | Train Epoch: 1 [26848/250314 (11%)]\tLoss: 0.632190\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:39 | INFO | Rank 0 | Train Epoch: 1 [26880/250314 (11%)]\tLoss: 0.382358\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:39 | INFO | Rank 0 | Train Epoch: 1 [26912/250314 (11%)]\tLoss: 0.554852\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:40 | INFO | Rank 0 | Train Epoch: 1 [26944/250314 (11%)]\tLoss: 0.242624\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:40 | INFO | Rank 0 | Train Epoch: 1 [26976/250314 (11%)]\tLoss: 0.197887\tData (t) 0.271\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:40 | INFO | Rank 0 | Train Epoch: 1 [27008/250314 (11%)]\tLoss: 0.246088\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:41 | INFO | Rank 0 | Train Epoch: 1 [27040/250314 (11%)]\tLoss: 0.443951\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:42 | INFO | Rank 0 | Train Epoch: 1 [27072/250314 (11%)]\tLoss: 0.476672\tData (t) 0.340\tBatch (t) 0.552\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:42 | INFO | Rank 0 | Train Epoch: 1 [27104/250314 (11%)]\tLoss: 0.692118\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:43 | INFO | Rank 0 | Train Epoch: 1 [27136/250314 (11%)]\tLoss: 0.925354\tData (t) 0.267\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:43 | INFO | Rank 0 | Train Epoch: 1 [27168/250314 (11%)]\tLoss: 0.421079\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:44 | INFO | Rank 0 | Train Epoch: 1 [27200/250314 (11%)]\tLoss: 0.303389\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:44 | INFO | Rank 0 | Train Epoch: 1 [27232/250314 (11%)]\tLoss: 0.329791\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:45 | INFO | Rank 0 | Train Epoch: 1 [27264/250314 (11%)]\tLoss: 0.274515\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:45 | INFO | Rank 0 | Train Epoch: 1 [27296/250314 (11%)]\tLoss: 0.423882\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:46 | INFO | Rank 0 | Train Epoch: 1 [27328/250314 (11%)]\tLoss: 0.249583\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:46 | INFO | Rank 0 | Train Epoch: 1 [27360/250314 (11%)]\tLoss: 0.797987\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:47 | INFO | Rank 0 | Train Epoch: 1 [27392/250314 (11%)]\tLoss: 0.271876\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:47 | INFO | Rank 0 | Train Epoch: 1 [27424/250314 (11%)]\tLoss: 0.274282\tData (t) 0.316\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:48 | INFO | Rank 0 | Train Epoch: 1 [27456/250314 (11%)]\tLoss: 0.356095\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:48 | INFO | Rank 0 | Train Epoch: 1 [27488/250314 (11%)]\tLoss: 0.520145\tData (t) 0.307\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:49 | INFO | Rank 0 | Train Epoch: 1 [27520/250314 (11%)]\tLoss: 0.642298\tData (t) 0.268\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:49 | INFO | Rank 0 | Train Epoch: 1 [27552/250314 (11%)]\tLoss: 0.503122\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:50 | INFO | Rank 0 | Train Epoch: 1 [27584/250314 (11%)]\tLoss: 0.533973\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:50 | INFO | Rank 0 | Train Epoch: 1 [27616/250314 (11%)]\tLoss: 0.219779\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:51 | INFO | Rank 0 | Train Epoch: 1 [27648/250314 (11%)]\tLoss: 0.622601\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:51 | INFO | Rank 0 | Train Epoch: 1 [27680/250314 (11%)]\tLoss: 0.301646\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:52 | INFO | Rank 0 | Train Epoch: 1 [27712/250314 (11%)]\tLoss: 0.486394\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:52 | INFO | Rank 0 | Train Epoch: 1 [27744/250314 (11%)]\tLoss: 0.298846\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:53 | INFO | Rank 0 | Train Epoch: 1 [27776/250314 (11%)]\tLoss: 0.424497\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:53 | INFO | Rank 0 | Train Epoch: 1 [27808/250314 (11%)]\tLoss: 0.268585\tData (t) 0.261\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:54 | INFO | Rank 0 | Train Epoch: 1 [27840/250314 (11%)]\tLoss: 0.429910\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:54 | INFO | Rank 0 | Train Epoch: 1 [27872/250314 (11%)]\tLoss: 0.613733\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:55 | INFO | Rank 0 | Train Epoch: 1 [27904/250314 (11%)]\tLoss: 0.389161\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:55 | INFO | Rank 0 | Train Epoch: 1 [27936/250314 (11%)]\tLoss: 0.384046\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:56 | INFO | Rank 0 | Train Epoch: 1 [27968/250314 (11%)]\tLoss: 0.837878\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:56 | INFO | Rank 0 | Train Epoch: 1 [28000/250314 (11%)]\tLoss: 0.371094\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:57 | INFO | Rank 0 | Train Epoch: 1 [28032/250314 (11%)]\tLoss: 0.327801\tData (t) 0.228\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:57 | INFO | Rank 0 | Train Epoch: 1 [28064/250314 (11%)]\tLoss: 0.245808\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:58 | INFO | Rank 0 | Train Epoch: 1 [28096/250314 (11%)]\tLoss: 1.142824\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:58 | INFO | Rank 0 | Train Epoch: 1 [28128/250314 (11%)]\tLoss: 0.597141\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:59 | INFO | Rank 0 | Train Epoch: 1 [28160/250314 (11%)]\tLoss: 0.482888\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:26:59 | INFO | Rank 0 | Train Epoch: 1 [28192/250314 (11%)]\tLoss: 0.467196\tData (t) 0.302\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:00 | INFO | Rank 0 | Train Epoch: 1 [28224/250314 (11%)]\tLoss: 0.662234\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:00 | INFO | Rank 0 | Train Epoch: 1 [28256/250314 (11%)]\tLoss: 0.685566\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:01 | INFO | Rank 0 | Train Epoch: 1 [28288/250314 (11%)]\tLoss: 0.373878\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:01 | INFO | Rank 0 | Train Epoch: 1 [28320/250314 (11%)]\tLoss: 0.456040\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:02 | INFO | Rank 0 | Train Epoch: 1 [28352/250314 (11%)]\tLoss: 0.318980\tData (t) 0.321\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:02 | INFO | Rank 0 | Train Epoch: 1 [28384/250314 (11%)]\tLoss: 0.622359\tData (t) 0.269\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:03 | INFO | Rank 0 | Train Epoch: 1 [28416/250314 (11%)]\tLoss: 0.348317\tData (t) 0.318\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:03 | INFO | Rank 0 | Train Epoch: 1 [28448/250314 (11%)]\tLoss: 0.559985\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:04 | INFO | Rank 0 | Train Epoch: 1 [28480/250314 (11%)]\tLoss: 0.597867\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:04 | INFO | Rank 0 | Train Epoch: 1 [28512/250314 (11%)]\tLoss: 0.519831\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:05 | INFO | Rank 0 | Train Epoch: 1 [28544/250314 (11%)]\tLoss: 0.660852\tData (t) 0.289\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:05 | INFO | Rank 0 | Train Epoch: 1 [28576/250314 (11%)]\tLoss: 0.484682\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:06 | INFO | Rank 0 | Train Epoch: 1 [28608/250314 (11%)]\tLoss: 0.198287\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:06 | INFO | Rank 0 | Train Epoch: 1 [28640/250314 (11%)]\tLoss: 0.503341\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:07 | INFO | Rank 0 | Train Epoch: 1 [28672/250314 (11%)]\tLoss: 0.378828\tData (t) 0.318\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:07 | INFO | Rank 0 | Train Epoch: 1 [28704/250314 (11%)]\tLoss: 0.340977\tData (t) 0.248\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:08 | INFO | Rank 0 | Train Epoch: 1 [28736/250314 (11%)]\tLoss: 0.248084\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:08 | INFO | Rank 0 | Train Epoch: 1 [28768/250314 (11%)]\tLoss: 0.481405\tData (t) 0.368\tBatch (t) 0.580\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:09 | INFO | Rank 0 | Train Epoch: 1 [28800/250314 (12%)]\tLoss: 0.481510\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:09 | INFO | Rank 0 | Train Epoch: 1 [28832/250314 (12%)]\tLoss: 0.494140\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:10 | INFO | Rank 0 | Train Epoch: 1 [28864/250314 (12%)]\tLoss: 0.589064\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:10 | INFO | Rank 0 | Train Epoch: 1 [28896/250314 (12%)]\tLoss: 0.192635\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:11 | INFO | Rank 0 | Train Epoch: 1 [28928/250314 (12%)]\tLoss: 0.495045\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:11 | INFO | Rank 0 | Train Epoch: 1 [28960/250314 (12%)]\tLoss: 0.289995\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:12 | INFO | Rank 0 | Train Epoch: 1 [28992/250314 (12%)]\tLoss: 0.453702\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:12 | INFO | Rank 0 | Train Epoch: 1 [29024/250314 (12%)]\tLoss: 0.617438\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:13 | INFO | Rank 0 | Train Epoch: 1 [29056/250314 (12%)]\tLoss: 0.544422\tData (t) 0.307\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:13 | INFO | Rank 0 | Train Epoch: 1 [29088/250314 (12%)]\tLoss: 0.277031\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:14 | INFO | Rank 0 | Train Epoch: 1 [29120/250314 (12%)]\tLoss: 0.466243\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:14 | INFO | Rank 0 | Train Epoch: 1 [29152/250314 (12%)]\tLoss: 0.192617\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:15 | INFO | Rank 0 | Train Epoch: 1 [29184/250314 (12%)]\tLoss: 0.179849\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:15 | INFO | Rank 0 | Train Epoch: 1 [29216/250314 (12%)]\tLoss: 0.499913\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:16 | INFO | Rank 0 | Train Epoch: 1 [29248/250314 (12%)]\tLoss: 0.413791\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:16 | INFO | Rank 0 | Train Epoch: 1 [29280/250314 (12%)]\tLoss: 0.376487\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:17 | INFO | Rank 0 | Train Epoch: 1 [29312/250314 (12%)]\tLoss: 0.294176\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:17 | INFO | Rank 0 | Train Epoch: 1 [29344/250314 (12%)]\tLoss: 0.290871\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:18 | INFO | Rank 0 | Train Epoch: 1 [29376/250314 (12%)]\tLoss: 0.363834\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:18 | INFO | Rank 0 | Train Epoch: 1 [29408/250314 (12%)]\tLoss: 0.526258\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:19 | INFO | Rank 0 | Train Epoch: 1 [29440/250314 (12%)]\tLoss: 0.375911\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:19 | INFO | Rank 0 | Train Epoch: 1 [29472/250314 (12%)]\tLoss: 0.597459\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:20 | INFO | Rank 0 | Train Epoch: 1 [29504/250314 (12%)]\tLoss: 0.361985\tData (t) 0.327\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:20 | INFO | Rank 0 | Train Epoch: 1 [29536/250314 (12%)]\tLoss: 0.749810\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:21 | INFO | Rank 0 | Train Epoch: 1 [29568/250314 (12%)]\tLoss: 0.974485\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:21 | INFO | Rank 0 | Train Epoch: 1 [29600/250314 (12%)]\tLoss: 0.376538\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:22 | INFO | Rank 0 | Train Epoch: 1 [29632/250314 (12%)]\tLoss: 0.401368\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:22 | INFO | Rank 0 | Train Epoch: 1 [29664/250314 (12%)]\tLoss: 0.440211\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:23 | INFO | Rank 0 | Train Epoch: 1 [29696/250314 (12%)]\tLoss: 0.560778\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:23 | INFO | Rank 0 | Train Epoch: 1 [29728/250314 (12%)]\tLoss: 0.183090\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:24 | INFO | Rank 0 | Train Epoch: 1 [29760/250314 (12%)]\tLoss: 0.494644\tData (t) 0.253\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:24 | INFO | Rank 0 | Train Epoch: 1 [29792/250314 (12%)]\tLoss: 0.401191\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:25 | INFO | Rank 0 | Train Epoch: 1 [29824/250314 (12%)]\tLoss: 0.621345\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:25 | INFO | Rank 0 | Train Epoch: 1 [29856/250314 (12%)]\tLoss: 0.348610\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:26 | INFO | Rank 0 | Train Epoch: 1 [29888/250314 (12%)]\tLoss: 0.729966\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:26 | INFO | Rank 0 | Train Epoch: 1 [29920/250314 (12%)]\tLoss: 0.736316\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:26 | INFO | Rank 0 | Train Epoch: 1 [29952/250314 (12%)]\tLoss: 0.553526\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:27 | INFO | Rank 0 | Train Epoch: 1 [29984/250314 (12%)]\tLoss: 0.284821\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:27 | INFO | Rank 0 | Train Epoch: 1 [30016/250314 (12%)]\tLoss: 0.524003\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:28 | INFO | Rank 0 | Train Epoch: 1 [30048/250314 (12%)]\tLoss: 0.379382\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:28 | INFO | Rank 0 | Train Epoch: 1 [30080/250314 (12%)]\tLoss: 0.381677\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:29 | INFO | Rank 0 | Train Epoch: 1 [30112/250314 (12%)]\tLoss: 0.219734\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:29 | INFO | Rank 0 | Train Epoch: 1 [30144/250314 (12%)]\tLoss: 0.603195\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:30 | INFO | Rank 0 | Train Epoch: 1 [30176/250314 (12%)]\tLoss: 0.462828\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:30 | INFO | Rank 0 | Train Epoch: 1 [30208/250314 (12%)]\tLoss: 0.321864\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:31 | INFO | Rank 0 | Train Epoch: 1 [30240/250314 (12%)]\tLoss: 0.592636\tData (t) 0.323\tBatch (t) 0.536\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:31 | INFO | Rank 0 | Train Epoch: 1 [30272/250314 (12%)]\tLoss: 0.357082\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:32 | INFO | Rank 0 | Train Epoch: 1 [30304/250314 (12%)]\tLoss: 0.370085\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:32 | INFO | Rank 0 | Train Epoch: 1 [30336/250314 (12%)]\tLoss: 0.322548\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:33 | INFO | Rank 0 | Train Epoch: 1 [30368/250314 (12%)]\tLoss: 0.540954\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:33 | INFO | Rank 0 | Train Epoch: 1 [30400/250314 (12%)]\tLoss: 0.432254\tData (t) 0.257\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:34 | INFO | Rank 0 | Train Epoch: 1 [30432/250314 (12%)]\tLoss: 0.401791\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:34 | INFO | Rank 0 | Train Epoch: 1 [30464/250314 (12%)]\tLoss: 0.539020\tData (t) 0.248\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:35 | INFO | Rank 0 | Train Epoch: 1 [30496/250314 (12%)]\tLoss: 0.235289\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:35 | INFO | Rank 0 | Train Epoch: 1 [30528/250314 (12%)]\tLoss: 0.639165\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:36 | INFO | Rank 0 | Train Epoch: 1 [30560/250314 (12%)]\tLoss: 0.371961\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:36 | INFO | Rank 0 | Train Epoch: 1 [30592/250314 (12%)]\tLoss: 0.505391\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:37 | INFO | Rank 0 | Train Epoch: 1 [30624/250314 (12%)]\tLoss: 0.457538\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:37 | INFO | Rank 0 | Train Epoch: 1 [30656/250314 (12%)]\tLoss: 0.540646\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:38 | INFO | Rank 0 | Train Epoch: 1 [30688/250314 (12%)]\tLoss: 0.361656\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:38 | INFO | Rank 0 | Train Epoch: 1 [30720/250314 (12%)]\tLoss: 0.538265\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:39 | INFO | Rank 0 | Train Epoch: 1 [30752/250314 (12%)]\tLoss: 0.360839\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:39 | INFO | Rank 0 | Train Epoch: 1 [30784/250314 (12%)]\tLoss: 0.483137\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:40 | INFO | Rank 0 | Train Epoch: 1 [30816/250314 (12%)]\tLoss: 0.334126\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:40 | INFO | Rank 0 | Train Epoch: 1 [30848/250314 (12%)]\tLoss: 0.507356\tData (t) 0.300\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:41 | INFO | Rank 0 | Train Epoch: 1 [30880/250314 (12%)]\tLoss: 0.586698\tData (t) 0.276\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:41 | INFO | Rank 0 | Train Epoch: 1 [30912/250314 (12%)]\tLoss: 0.736280\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:42 | INFO | Rank 0 | Train Epoch: 1 [30944/250314 (12%)]\tLoss: 0.222643\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:42 | INFO | Rank 0 | Train Epoch: 1 [30976/250314 (12%)]\tLoss: 0.633175\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:43 | INFO | Rank 0 | Train Epoch: 1 [31008/250314 (12%)]\tLoss: 0.860393\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:43 | INFO | Rank 0 | Train Epoch: 1 [31040/250314 (12%)]\tLoss: 0.547054\tData (t) 0.212\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:44 | INFO | Rank 0 | Train Epoch: 1 [31072/250314 (12%)]\tLoss: 0.674847\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:44 | INFO | Rank 0 | Train Epoch: 1 [31104/250314 (12%)]\tLoss: 0.492723\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:45 | INFO | Rank 0 | Train Epoch: 1 [31136/250314 (12%)]\tLoss: 0.475051\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:45 | INFO | Rank 0 | Train Epoch: 1 [31168/250314 (12%)]\tLoss: 0.355456\tData (t) 0.321\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:46 | INFO | Rank 0 | Train Epoch: 1 [31200/250314 (12%)]\tLoss: 0.389613\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:46 | INFO | Rank 0 | Train Epoch: 1 [31232/250314 (12%)]\tLoss: 0.485023\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:47 | INFO | Rank 0 | Train Epoch: 1 [31264/250314 (12%)]\tLoss: 0.224000\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:47 | INFO | Rank 0 | Train Epoch: 1 [31296/250314 (13%)]\tLoss: 0.368781\tData (t) 0.217\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:47 | INFO | Rank 0 | Train Epoch: 1 [31328/250314 (13%)]\tLoss: 0.327100\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:48 | INFO | Rank 0 | Train Epoch: 1 [31360/250314 (13%)]\tLoss: 0.487006\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:49 | INFO | Rank 0 | Train Epoch: 1 [31392/250314 (13%)]\tLoss: 0.544931\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:49 | INFO | Rank 0 | Train Epoch: 1 [31424/250314 (13%)]\tLoss: 0.308559\tData (t) 0.208\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:49 | INFO | Rank 0 | Train Epoch: 1 [31456/250314 (13%)]\tLoss: 0.744742\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:50 | INFO | Rank 0 | Train Epoch: 1 [31488/250314 (13%)]\tLoss: 0.641612\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:50 | INFO | Rank 0 | Train Epoch: 1 [31520/250314 (13%)]\tLoss: 0.513141\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:51 | INFO | Rank 0 | Train Epoch: 1 [31552/250314 (13%)]\tLoss: 0.444078\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:51 | INFO | Rank 0 | Train Epoch: 1 [31584/250314 (13%)]\tLoss: 0.391491\tData (t) 0.376\tBatch (t) 0.588\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:52 | INFO | Rank 0 | Train Epoch: 1 [31616/250314 (13%)]\tLoss: 0.178271\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:52 | INFO | Rank 0 | Train Epoch: 1 [31648/250314 (13%)]\tLoss: 0.814631\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:53 | INFO | Rank 0 | Train Epoch: 1 [31680/250314 (13%)]\tLoss: 0.240576\tData (t) 0.223\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:53 | INFO | Rank 0 | Train Epoch: 1 [31712/250314 (13%)]\tLoss: 0.422896\tData (t) 0.346\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:54 | INFO | Rank 0 | Train Epoch: 1 [31744/250314 (13%)]\tLoss: 0.598140\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:54 | INFO | Rank 0 | Train Epoch: 1 [31776/250314 (13%)]\tLoss: 0.332208\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:55 | INFO | Rank 0 | Train Epoch: 1 [31808/250314 (13%)]\tLoss: 0.321004\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:55 | INFO | Rank 0 | Train Epoch: 1 [31840/250314 (13%)]\tLoss: 0.428369\tData (t) 0.285\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:56 | INFO | Rank 0 | Train Epoch: 1 [31872/250314 (13%)]\tLoss: 0.221861\tData (t) 0.301\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:57 | INFO | Rank 0 | Train Epoch: 1 [31904/250314 (13%)]\tLoss: 0.360132\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:57 | INFO | Rank 0 | Train Epoch: 1 [31936/250314 (13%)]\tLoss: 0.242526\tData (t) 0.239\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:57 | INFO | Rank 0 | Train Epoch: 1 [31968/250314 (13%)]\tLoss: 0.341021\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:58 | INFO | Rank 0 | Train Epoch: 1 [32000/250314 (13%)]\tLoss: 0.548934\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:58 | INFO | Rank 0 | Train Epoch: 1 [32032/250314 (13%)]\tLoss: 0.555622\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:59 | INFO | Rank 0 | Train Epoch: 1 [32064/250314 (13%)]\tLoss: 0.508070\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:27:59 | INFO | Rank 0 | Train Epoch: 1 [32096/250314 (13%)]\tLoss: 0.437500\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:00 | INFO | Rank 0 | Train Epoch: 1 [32128/250314 (13%)]\tLoss: 0.744102\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:00 | INFO | Rank 0 | Train Epoch: 1 [32160/250314 (13%)]\tLoss: 0.355331\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:01 | INFO | Rank 0 | Train Epoch: 1 [32192/250314 (13%)]\tLoss: 0.376091\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:01 | INFO | Rank 0 | Train Epoch: 1 [32224/250314 (13%)]\tLoss: 0.414463\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:02 | INFO | Rank 0 | Train Epoch: 1 [32256/250314 (13%)]\tLoss: 0.189828\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:02 | INFO | Rank 0 | Train Epoch: 1 [32288/250314 (13%)]\tLoss: 0.297901\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:03 | INFO | Rank 0 | Train Epoch: 1 [32320/250314 (13%)]\tLoss: 0.366417\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:03 | INFO | Rank 0 | Train Epoch: 1 [32352/250314 (13%)]\tLoss: 0.365764\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:04 | INFO | Rank 0 | Train Epoch: 1 [32384/250314 (13%)]\tLoss: 0.989349\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:04 | INFO | Rank 0 | Train Epoch: 1 [32416/250314 (13%)]\tLoss: 0.219397\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:05 | INFO | Rank 0 | Train Epoch: 1 [32448/250314 (13%)]\tLoss: 0.341043\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:05 | INFO | Rank 0 | Train Epoch: 1 [32480/250314 (13%)]\tLoss: 0.382334\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:06 | INFO | Rank 0 | Train Epoch: 1 [32512/250314 (13%)]\tLoss: 0.596588\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:06 | INFO | Rank 0 | Train Epoch: 1 [32544/250314 (13%)]\tLoss: 0.518286\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:07 | INFO | Rank 0 | Train Epoch: 1 [32576/250314 (13%)]\tLoss: 0.748237\tData (t) 0.305\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:07 | INFO | Rank 0 | Train Epoch: 1 [32608/250314 (13%)]\tLoss: 0.196677\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:08 | INFO | Rank 0 | Train Epoch: 1 [32640/250314 (13%)]\tLoss: 0.314028\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:08 | INFO | Rank 0 | Train Epoch: 1 [32672/250314 (13%)]\tLoss: 0.510058\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:09 | INFO | Rank 0 | Train Epoch: 1 [32704/250314 (13%)]\tLoss: 0.394365\tData (t) 0.329\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:09 | INFO | Rank 0 | Train Epoch: 1 [32736/250314 (13%)]\tLoss: 0.212716\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:10 | INFO | Rank 0 | Train Epoch: 1 [32768/250314 (13%)]\tLoss: 0.822531\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:10 | INFO | Rank 0 | Train Epoch: 1 [32800/250314 (13%)]\tLoss: 0.556356\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:11 | INFO | Rank 0 | Train Epoch: 1 [32832/250314 (13%)]\tLoss: 0.361006\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:11 | INFO | Rank 0 | Train Epoch: 1 [32864/250314 (13%)]\tLoss: 0.563783\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:12 | INFO | Rank 0 | Train Epoch: 1 [32896/250314 (13%)]\tLoss: 0.454023\tData (t) 0.213\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:12 | INFO | Rank 0 | Train Epoch: 1 [32928/250314 (13%)]\tLoss: 0.278651\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:13 | INFO | Rank 0 | Train Epoch: 1 [32960/250314 (13%)]\tLoss: 0.363243\tData (t) 0.339\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:13 | INFO | Rank 0 | Train Epoch: 1 [32992/250314 (13%)]\tLoss: 0.941999\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:14 | INFO | Rank 0 | Train Epoch: 1 [33024/250314 (13%)]\tLoss: 0.852569\tData (t) 0.221\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:14 | INFO | Rank 0 | Train Epoch: 1 [33056/250314 (13%)]\tLoss: 0.293410\tData (t) 0.354\tBatch (t) 0.566\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:15 | INFO | Rank 0 | Train Epoch: 1 [33088/250314 (13%)]\tLoss: 0.277361\tData (t) 0.339\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:15 | INFO | Rank 0 | Train Epoch: 1 [33120/250314 (13%)]\tLoss: 0.280067\tData (t) 0.311\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:16 | INFO | Rank 0 | Train Epoch: 1 [33152/250314 (13%)]\tLoss: 0.341746\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:16 | INFO | Rank 0 | Train Epoch: 1 [33184/250314 (13%)]\tLoss: 0.344890\tData (t) 0.200\tBatch (t) 0.411\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:17 | INFO | Rank 0 | Train Epoch: 1 [33216/250314 (13%)]\tLoss: 0.254133\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:17 | INFO | Rank 0 | Train Epoch: 1 [33248/250314 (13%)]\tLoss: 0.591451\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:18 | INFO | Rank 0 | Train Epoch: 1 [33280/250314 (13%)]\tLoss: 0.859628\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:18 | INFO | Rank 0 | Train Epoch: 1 [33312/250314 (13%)]\tLoss: 0.545220\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:19 | INFO | Rank 0 | Train Epoch: 1 [33344/250314 (13%)]\tLoss: 0.518182\tData (t) 0.287\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:19 | INFO | Rank 0 | Train Epoch: 1 [33376/250314 (13%)]\tLoss: 0.312026\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:20 | INFO | Rank 0 | Train Epoch: 1 [33408/250314 (13%)]\tLoss: 0.538919\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:20 | INFO | Rank 0 | Train Epoch: 1 [33440/250314 (13%)]\tLoss: 0.709725\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:21 | INFO | Rank 0 | Train Epoch: 1 [33472/250314 (13%)]\tLoss: 0.572603\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:21 | INFO | Rank 0 | Train Epoch: 1 [33504/250314 (13%)]\tLoss: 0.761007\tData (t) 0.346\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:22 | INFO | Rank 0 | Train Epoch: 1 [33536/250314 (13%)]\tLoss: 0.443419\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:22 | INFO | Rank 0 | Train Epoch: 1 [33568/250314 (13%)]\tLoss: 0.271421\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:23 | INFO | Rank 0 | Train Epoch: 1 [33600/250314 (13%)]\tLoss: 0.492365\tData (t) 0.246\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:23 | INFO | Rank 0 | Train Epoch: 1 [33632/250314 (13%)]\tLoss: 0.544982\tData (t) 0.221\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:23 | INFO | Rank 0 | Train Epoch: 1 [33664/250314 (13%)]\tLoss: 0.380465\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:24 | INFO | Rank 0 | Train Epoch: 1 [33696/250314 (13%)]\tLoss: 0.333579\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:24 | INFO | Rank 0 | Train Epoch: 1 [33728/250314 (13%)]\tLoss: 0.394021\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:25 | INFO | Rank 0 | Train Epoch: 1 [33760/250314 (13%)]\tLoss: 0.337335\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:25 | INFO | Rank 0 | Train Epoch: 1 [33792/250314 (14%)]\tLoss: 0.612623\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:26 | INFO | Rank 0 | Train Epoch: 1 [33824/250314 (14%)]\tLoss: 0.538345\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:26 | INFO | Rank 0 | Train Epoch: 1 [33856/250314 (14%)]\tLoss: 0.528125\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:27 | INFO | Rank 0 | Train Epoch: 1 [33888/250314 (14%)]\tLoss: 0.150893\tData (t) 0.326\tBatch (t) 0.539\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:28 | INFO | Rank 0 | Train Epoch: 1 [33920/250314 (14%)]\tLoss: 0.619955\tData (t) 0.311\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:28 | INFO | Rank 0 | Train Epoch: 1 [33952/250314 (14%)]\tLoss: 0.418823\tData (t) 0.306\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:29 | INFO | Rank 0 | Train Epoch: 1 [33984/250314 (14%)]\tLoss: 0.495435\tData (t) 0.317\tBatch (t) 0.529\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:29 | INFO | Rank 0 | Train Epoch: 1 [34016/250314 (14%)]\tLoss: 0.240371\tData (t) 0.315\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:30 | INFO | Rank 0 | Train Epoch: 1 [34048/250314 (14%)]\tLoss: 0.431874\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:30 | INFO | Rank 0 | Train Epoch: 1 [34080/250314 (14%)]\tLoss: 0.659872\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:31 | INFO | Rank 0 | Train Epoch: 1 [34112/250314 (14%)]\tLoss: 0.600993\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:31 | INFO | Rank 0 | Train Epoch: 1 [34144/250314 (14%)]\tLoss: 0.508312\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:31 | INFO | Rank 0 | Train Epoch: 1 [34176/250314 (14%)]\tLoss: 0.350003\tData (t) 0.289\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:32 | INFO | Rank 0 | Train Epoch: 1 [34208/250314 (14%)]\tLoss: 0.265872\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:32 | INFO | Rank 0 | Train Epoch: 1 [34240/250314 (14%)]\tLoss: 0.275176\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:33 | INFO | Rank 0 | Train Epoch: 1 [34272/250314 (14%)]\tLoss: 0.164183\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:33 | INFO | Rank 0 | Train Epoch: 1 [34304/250314 (14%)]\tLoss: 0.384193\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:34 | INFO | Rank 0 | Train Epoch: 1 [34336/250314 (14%)]\tLoss: 0.417910\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:34 | INFO | Rank 0 | Train Epoch: 1 [34368/250314 (14%)]\tLoss: 0.427502\tData (t) 0.231\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:35 | INFO | Rank 0 | Train Epoch: 1 [34400/250314 (14%)]\tLoss: 0.456069\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:35 | INFO | Rank 0 | Train Epoch: 1 [34432/250314 (14%)]\tLoss: 0.285376\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:36 | INFO | Rank 0 | Train Epoch: 1 [34464/250314 (14%)]\tLoss: 0.262417\tData (t) 0.333\tBatch (t) 0.545\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:36 | INFO | Rank 0 | Train Epoch: 1 [34496/250314 (14%)]\tLoss: 0.328129\tData (t) 0.346\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:37 | INFO | Rank 0 | Train Epoch: 1 [34528/250314 (14%)]\tLoss: 0.538674\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:37 | INFO | Rank 0 | Train Epoch: 1 [34560/250314 (14%)]\tLoss: 0.290976\tData (t) 0.289\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:38 | INFO | Rank 0 | Train Epoch: 1 [34592/250314 (14%)]\tLoss: 0.537817\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:38 | INFO | Rank 0 | Train Epoch: 1 [34624/250314 (14%)]\tLoss: 0.521684\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:39 | INFO | Rank 0 | Train Epoch: 1 [34656/250314 (14%)]\tLoss: 0.307758\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:39 | INFO | Rank 0 | Train Epoch: 1 [34688/250314 (14%)]\tLoss: 0.426690\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:40 | INFO | Rank 0 | Train Epoch: 1 [34720/250314 (14%)]\tLoss: 0.592463\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:40 | INFO | Rank 0 | Train Epoch: 1 [34752/250314 (14%)]\tLoss: 0.278684\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:41 | INFO | Rank 0 | Train Epoch: 1 [34784/250314 (14%)]\tLoss: 0.116105\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:41 | INFO | Rank 0 | Train Epoch: 1 [34816/250314 (14%)]\tLoss: 0.131176\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:42 | INFO | Rank 0 | Train Epoch: 1 [34848/250314 (14%)]\tLoss: 0.477517\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:42 | INFO | Rank 0 | Train Epoch: 1 [34880/250314 (14%)]\tLoss: 0.518278\tData (t) 0.247\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:43 | INFO | Rank 0 | Train Epoch: 1 [34912/250314 (14%)]\tLoss: 0.486643\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:43 | INFO | Rank 0 | Train Epoch: 1 [34944/250314 (14%)]\tLoss: 0.720759\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:44 | INFO | Rank 0 | Train Epoch: 1 [34976/250314 (14%)]\tLoss: 0.360054\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:44 | INFO | Rank 0 | Train Epoch: 1 [35008/250314 (14%)]\tLoss: 0.430186\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:45 | INFO | Rank 0 | Train Epoch: 1 [35040/250314 (14%)]\tLoss: 0.687760\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:45 | INFO | Rank 0 | Train Epoch: 1 [35072/250314 (14%)]\tLoss: 0.642345\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:46 | INFO | Rank 0 | Train Epoch: 1 [35104/250314 (14%)]\tLoss: 0.568826\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:46 | INFO | Rank 0 | Train Epoch: 1 [35136/250314 (14%)]\tLoss: 0.289895\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:47 | INFO | Rank 0 | Train Epoch: 1 [35168/250314 (14%)]\tLoss: 0.540555\tData (t) 0.259\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:47 | INFO | Rank 0 | Train Epoch: 1 [35200/250314 (14%)]\tLoss: 0.519991\tData (t) 0.228\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:47 | INFO | Rank 0 | Train Epoch: 1 [35232/250314 (14%)]\tLoss: 0.508301\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:48 | INFO | Rank 0 | Train Epoch: 1 [35264/250314 (14%)]\tLoss: 0.615246\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:48 | INFO | Rank 0 | Train Epoch: 1 [35296/250314 (14%)]\tLoss: 0.493769\tData (t) 0.244\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:49 | INFO | Rank 0 | Train Epoch: 1 [35328/250314 (14%)]\tLoss: 0.615625\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:49 | INFO | Rank 0 | Train Epoch: 1 [35360/250314 (14%)]\tLoss: 0.348094\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:50 | INFO | Rank 0 | Train Epoch: 1 [35392/250314 (14%)]\tLoss: 1.104467\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:50 | INFO | Rank 0 | Train Epoch: 1 [35424/250314 (14%)]\tLoss: 0.600920\tData (t) 0.304\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:51 | INFO | Rank 0 | Train Epoch: 1 [35456/250314 (14%)]\tLoss: 0.745917\tData (t) 0.224\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:51 | INFO | Rank 0 | Train Epoch: 1 [35488/250314 (14%)]\tLoss: 0.597972\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:52 | INFO | Rank 0 | Train Epoch: 1 [35520/250314 (14%)]\tLoss: 0.380565\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:52 | INFO | Rank 0 | Train Epoch: 1 [35552/250314 (14%)]\tLoss: 0.655700\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:53 | INFO | Rank 0 | Train Epoch: 1 [35584/250314 (14%)]\tLoss: 0.406449\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:53 | INFO | Rank 0 | Train Epoch: 1 [35616/250314 (14%)]\tLoss: 0.336804\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:54 | INFO | Rank 0 | Train Epoch: 1 [35648/250314 (14%)]\tLoss: 0.248879\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:54 | INFO | Rank 0 | Train Epoch: 1 [35680/250314 (14%)]\tLoss: 0.490227\tData (t) 0.349\tBatch (t) 0.561\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:55 | INFO | Rank 0 | Train Epoch: 1 [35712/250314 (14%)]\tLoss: 0.218322\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:55 | INFO | Rank 0 | Train Epoch: 1 [35744/250314 (14%)]\tLoss: 0.351764\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:56 | INFO | Rank 0 | Train Epoch: 1 [35776/250314 (14%)]\tLoss: 0.329601\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:56 | INFO | Rank 0 | Train Epoch: 1 [35808/250314 (14%)]\tLoss: 0.518028\tData (t) 0.317\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:57 | INFO | Rank 0 | Train Epoch: 1 [35840/250314 (14%)]\tLoss: 0.520084\tData (t) 0.268\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:57 | INFO | Rank 0 | Train Epoch: 1 [35872/250314 (14%)]\tLoss: 0.293595\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:58 | INFO | Rank 0 | Train Epoch: 1 [35904/250314 (14%)]\tLoss: 0.465828\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:58 | INFO | Rank 0 | Train Epoch: 1 [35936/250314 (14%)]\tLoss: 0.775029\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:59 | INFO | Rank 0 | Train Epoch: 1 [35968/250314 (14%)]\tLoss: 0.296986\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:28:59 | INFO | Rank 0 | Train Epoch: 1 [36000/250314 (14%)]\tLoss: 0.642187\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:00 | INFO | Rank 0 | Train Epoch: 1 [36032/250314 (14%)]\tLoss: 0.416283\tData (t) 0.270\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:00 | INFO | Rank 0 | Train Epoch: 1 [36064/250314 (14%)]\tLoss: 0.420067\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:00 | INFO | Rank 0 | Train Epoch: 1 [36096/250314 (14%)]\tLoss: 0.256133\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:01 | INFO | Rank 0 | Train Epoch: 1 [36128/250314 (14%)]\tLoss: 0.646295\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:01 | INFO | Rank 0 | Train Epoch: 1 [36160/250314 (14%)]\tLoss: 0.498461\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:02 | INFO | Rank 0 | Train Epoch: 1 [36192/250314 (14%)]\tLoss: 0.389945\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:02 | INFO | Rank 0 | Train Epoch: 1 [36224/250314 (14%)]\tLoss: 0.441525\tData (t) 0.200\tBatch (t) 0.412\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:03 | INFO | Rank 0 | Train Epoch: 1 [36256/250314 (14%)]\tLoss: 0.766675\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:03 | INFO | Rank 0 | Train Epoch: 1 [36288/250314 (14%)]\tLoss: 0.553298\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:04 | INFO | Rank 0 | Train Epoch: 1 [36320/250314 (15%)]\tLoss: 0.532214\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:04 | INFO | Rank 0 | Train Epoch: 1 [36352/250314 (15%)]\tLoss: 0.388769\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:05 | INFO | Rank 0 | Train Epoch: 1 [36384/250314 (15%)]\tLoss: 0.366404\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:05 | INFO | Rank 0 | Train Epoch: 1 [36416/250314 (15%)]\tLoss: 0.276879\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:06 | INFO | Rank 0 | Train Epoch: 1 [36448/250314 (15%)]\tLoss: 0.549565\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:06 | INFO | Rank 0 | Train Epoch: 1 [36480/250314 (15%)]\tLoss: 0.293427\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:07 | INFO | Rank 0 | Train Epoch: 1 [36512/250314 (15%)]\tLoss: 0.450562\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:07 | INFO | Rank 0 | Train Epoch: 1 [36544/250314 (15%)]\tLoss: 0.451302\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:08 | INFO | Rank 0 | Train Epoch: 1 [36576/250314 (15%)]\tLoss: 0.265019\tData (t) 0.257\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:08 | INFO | Rank 0 | Train Epoch: 1 [36608/250314 (15%)]\tLoss: 0.343024\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:09 | INFO | Rank 0 | Train Epoch: 1 [36640/250314 (15%)]\tLoss: 0.478120\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:09 | INFO | Rank 0 | Train Epoch: 1 [36672/250314 (15%)]\tLoss: 0.589340\tData (t) 0.210\tBatch (t) 0.422\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:10 | INFO | Rank 0 | Train Epoch: 1 [36704/250314 (15%)]\tLoss: 0.439372\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:10 | INFO | Rank 0 | Train Epoch: 1 [36736/250314 (15%)]\tLoss: 0.497318\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:11 | INFO | Rank 0 | Train Epoch: 1 [36768/250314 (15%)]\tLoss: 0.440535\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:11 | INFO | Rank 0 | Train Epoch: 1 [36800/250314 (15%)]\tLoss: 0.729043\tData (t) 0.289\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:12 | INFO | Rank 0 | Train Epoch: 1 [36832/250314 (15%)]\tLoss: 0.606704\tData (t) 0.260\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:12 | INFO | Rank 0 | Train Epoch: 1 [36864/250314 (15%)]\tLoss: 0.269799\tData (t) 0.226\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:12 | INFO | Rank 0 | Train Epoch: 1 [36896/250314 (15%)]\tLoss: 0.191774\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:13 | INFO | Rank 0 | Train Epoch: 1 [36928/250314 (15%)]\tLoss: 0.236898\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:13 | INFO | Rank 0 | Train Epoch: 1 [36960/250314 (15%)]\tLoss: 0.135071\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:14 | INFO | Rank 0 | Train Epoch: 1 [36992/250314 (15%)]\tLoss: 0.503622\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:14 | INFO | Rank 0 | Train Epoch: 1 [37024/250314 (15%)]\tLoss: 0.560200\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:15 | INFO | Rank 0 | Train Epoch: 1 [37056/250314 (15%)]\tLoss: 0.280595\tData (t) 0.284\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:15 | INFO | Rank 0 | Train Epoch: 1 [37088/250314 (15%)]\tLoss: 0.328027\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:16 | INFO | Rank 0 | Train Epoch: 1 [37120/250314 (15%)]\tLoss: 0.389314\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:16 | INFO | Rank 0 | Train Epoch: 1 [37152/250314 (15%)]\tLoss: 0.504504\tData (t) 0.226\tBatch (t) 0.438\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:17 | INFO | Rank 0 | Train Epoch: 1 [37184/250314 (15%)]\tLoss: 0.413185\tData (t) 0.232\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:17 | INFO | Rank 0 | Train Epoch: 1 [37216/250314 (15%)]\tLoss: 0.328022\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:18 | INFO | Rank 0 | Train Epoch: 1 [37248/250314 (15%)]\tLoss: 0.427728\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:18 | INFO | Rank 0 | Train Epoch: 1 [37280/250314 (15%)]\tLoss: 0.377325\tData (t) 0.216\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:19 | INFO | Rank 0 | Train Epoch: 1 [37312/250314 (15%)]\tLoss: 0.154827\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:19 | INFO | Rank 0 | Train Epoch: 1 [37344/250314 (15%)]\tLoss: 0.386131\tData (t) 0.282\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:20 | INFO | Rank 0 | Train Epoch: 1 [37376/250314 (15%)]\tLoss: 0.469622\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:20 | INFO | Rank 0 | Train Epoch: 1 [37408/250314 (15%)]\tLoss: 0.526394\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:21 | INFO | Rank 0 | Train Epoch: 1 [37440/250314 (15%)]\tLoss: 0.376394\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:21 | INFO | Rank 0 | Train Epoch: 1 [37472/250314 (15%)]\tLoss: 0.571391\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:22 | INFO | Rank 0 | Train Epoch: 1 [37504/250314 (15%)]\tLoss: 0.416324\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:22 | INFO | Rank 0 | Train Epoch: 1 [37536/250314 (15%)]\tLoss: 0.327139\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:23 | INFO | Rank 0 | Train Epoch: 1 [37568/250314 (15%)]\tLoss: 0.527414\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:23 | INFO | Rank 0 | Train Epoch: 1 [37600/250314 (15%)]\tLoss: 0.516533\tData (t) 0.270\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:24 | INFO | Rank 0 | Train Epoch: 1 [37632/250314 (15%)]\tLoss: 0.302594\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:24 | INFO | Rank 0 | Train Epoch: 1 [37664/250314 (15%)]\tLoss: 0.241613\tData (t) 0.266\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:25 | INFO | Rank 0 | Train Epoch: 1 [37696/250314 (15%)]\tLoss: 0.541255\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:25 | INFO | Rank 0 | Train Epoch: 1 [37728/250314 (15%)]\tLoss: 0.342601\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:26 | INFO | Rank 0 | Train Epoch: 1 [37760/250314 (15%)]\tLoss: 0.538414\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:26 | INFO | Rank 0 | Train Epoch: 1 [37792/250314 (15%)]\tLoss: 0.529879\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:26 | INFO | Rank 0 | Train Epoch: 1 [37824/250314 (15%)]\tLoss: 0.343043\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:27 | INFO | Rank 0 | Train Epoch: 1 [37856/250314 (15%)]\tLoss: 0.738826\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:27 | INFO | Rank 0 | Train Epoch: 1 [37888/250314 (15%)]\tLoss: 0.519813\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:28 | INFO | Rank 0 | Train Epoch: 1 [37920/250314 (15%)]\tLoss: 0.510395\tData (t) 0.295\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:28 | INFO | Rank 0 | Train Epoch: 1 [37952/250314 (15%)]\tLoss: 0.246757\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:29 | INFO | Rank 0 | Train Epoch: 1 [37984/250314 (15%)]\tLoss: 0.260816\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:29 | INFO | Rank 0 | Train Epoch: 1 [38016/250314 (15%)]\tLoss: 0.463670\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:30 | INFO | Rank 0 | Train Epoch: 1 [38048/250314 (15%)]\tLoss: 0.368801\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:30 | INFO | Rank 0 | Train Epoch: 1 [38080/250314 (15%)]\tLoss: 0.663606\tData (t) 0.278\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:31 | INFO | Rank 0 | Train Epoch: 1 [38112/250314 (15%)]\tLoss: 0.528061\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:31 | INFO | Rank 0 | Train Epoch: 1 [38144/250314 (15%)]\tLoss: 0.224208\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:32 | INFO | Rank 0 | Train Epoch: 1 [38176/250314 (15%)]\tLoss: 0.306972\tData (t) 0.193\tBatch (t) 0.404\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:32 | INFO | Rank 0 | Train Epoch: 1 [38208/250314 (15%)]\tLoss: 0.669607\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:33 | INFO | Rank 0 | Train Epoch: 1 [38240/250314 (15%)]\tLoss: 0.527145\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:33 | INFO | Rank 0 | Train Epoch: 1 [38272/250314 (15%)]\tLoss: 0.528976\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:34 | INFO | Rank 0 | Train Epoch: 1 [38304/250314 (15%)]\tLoss: 0.311788\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:34 | INFO | Rank 0 | Train Epoch: 1 [38336/250314 (15%)]\tLoss: 0.310130\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:35 | INFO | Rank 0 | Train Epoch: 1 [38368/250314 (15%)]\tLoss: 0.252234\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:35 | INFO | Rank 0 | Train Epoch: 1 [38400/250314 (15%)]\tLoss: 0.201949\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:36 | INFO | Rank 0 | Train Epoch: 1 [38432/250314 (15%)]\tLoss: 0.414685\tData (t) 0.206\tBatch (t) 0.418\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:36 | INFO | Rank 0 | Train Epoch: 1 [38464/250314 (15%)]\tLoss: 0.576519\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:37 | INFO | Rank 0 | Train Epoch: 1 [38496/250314 (15%)]\tLoss: 0.329506\tData (t) 0.283\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:37 | INFO | Rank 0 | Train Epoch: 1 [38528/250314 (15%)]\tLoss: 0.584454\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:38 | INFO | Rank 0 | Train Epoch: 1 [38560/250314 (15%)]\tLoss: 0.479542\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:38 | INFO | Rank 0 | Train Epoch: 1 [38592/250314 (15%)]\tLoss: 0.520879\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:39 | INFO | Rank 0 | Train Epoch: 1 [38624/250314 (15%)]\tLoss: 0.421070\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:39 | INFO | Rank 0 | Train Epoch: 1 [38656/250314 (15%)]\tLoss: 0.451309\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:40 | INFO | Rank 0 | Train Epoch: 1 [38688/250314 (15%)]\tLoss: 0.349972\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:40 | INFO | Rank 0 | Train Epoch: 1 [38720/250314 (15%)]\tLoss: 0.331195\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:41 | INFO | Rank 0 | Train Epoch: 1 [38752/250314 (15%)]\tLoss: 0.419726\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:41 | INFO | Rank 0 | Train Epoch: 1 [38784/250314 (15%)]\tLoss: 0.448430\tData (t) 0.318\tBatch (t) 0.530\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:42 | INFO | Rank 0 | Train Epoch: 1 [38816/250314 (16%)]\tLoss: 0.381217\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:42 | INFO | Rank 0 | Train Epoch: 1 [38848/250314 (16%)]\tLoss: 0.170258\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:43 | INFO | Rank 0 | Train Epoch: 1 [38880/250314 (16%)]\tLoss: 0.310188\tData (t) 0.290\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:43 | INFO | Rank 0 | Train Epoch: 1 [38912/250314 (16%)]\tLoss: 0.513718\tData (t) 0.276\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:43 | INFO | Rank 0 | Train Epoch: 1 [38944/250314 (16%)]\tLoss: 0.420818\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:44 | INFO | Rank 0 | Train Epoch: 1 [38976/250314 (16%)]\tLoss: 0.559250\tData (t) 0.301\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:44 | INFO | Rank 0 | Train Epoch: 1 [39008/250314 (16%)]\tLoss: 0.479890\tData (t) 0.268\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:45 | INFO | Rank 0 | Train Epoch: 1 [39040/250314 (16%)]\tLoss: 0.703093\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:45 | INFO | Rank 0 | Train Epoch: 1 [39072/250314 (16%)]\tLoss: 0.384403\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:46 | INFO | Rank 0 | Train Epoch: 1 [39104/250314 (16%)]\tLoss: 0.284626\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:46 | INFO | Rank 0 | Train Epoch: 1 [39136/250314 (16%)]\tLoss: 0.466199\tData (t) 0.221\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:47 | INFO | Rank 0 | Train Epoch: 1 [39168/250314 (16%)]\tLoss: 0.464095\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:47 | INFO | Rank 0 | Train Epoch: 1 [39200/250314 (16%)]\tLoss: 0.350420\tData (t) 0.234\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:48 | INFO | Rank 0 | Train Epoch: 1 [39232/250314 (16%)]\tLoss: 0.567925\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:48 | INFO | Rank 0 | Train Epoch: 1 [39264/250314 (16%)]\tLoss: 0.520418\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:49 | INFO | Rank 0 | Train Epoch: 1 [39296/250314 (16%)]\tLoss: 0.684005\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:49 | INFO | Rank 0 | Train Epoch: 1 [39328/250314 (16%)]\tLoss: 0.432170\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:50 | INFO | Rank 0 | Train Epoch: 1 [39360/250314 (16%)]\tLoss: 0.346682\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:50 | INFO | Rank 0 | Train Epoch: 1 [39392/250314 (16%)]\tLoss: 0.367210\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:51 | INFO | Rank 0 | Train Epoch: 1 [39424/250314 (16%)]\tLoss: 0.699189\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:51 | INFO | Rank 0 | Train Epoch: 1 [39456/250314 (16%)]\tLoss: 0.258117\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:52 | INFO | Rank 0 | Train Epoch: 1 [39488/250314 (16%)]\tLoss: 0.544559\tData (t) 0.316\tBatch (t) 0.527\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:52 | INFO | Rank 0 | Train Epoch: 1 [39520/250314 (16%)]\tLoss: 0.313576\tData (t) 0.231\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:53 | INFO | Rank 0 | Train Epoch: 1 [39552/250314 (16%)]\tLoss: 0.293806\tData (t) 0.263\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:53 | INFO | Rank 0 | Train Epoch: 1 [39584/250314 (16%)]\tLoss: 0.301270\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:54 | INFO | Rank 0 | Train Epoch: 1 [39616/250314 (16%)]\tLoss: 0.545722\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:54 | INFO | Rank 0 | Train Epoch: 1 [39648/250314 (16%)]\tLoss: 0.356334\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:55 | INFO | Rank 0 | Train Epoch: 1 [39680/250314 (16%)]\tLoss: 0.505961\tData (t) 0.245\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:55 | INFO | Rank 0 | Train Epoch: 1 [39712/250314 (16%)]\tLoss: 0.535716\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:55 | INFO | Rank 0 | Train Epoch: 1 [39744/250314 (16%)]\tLoss: 0.771860\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:56 | INFO | Rank 0 | Train Epoch: 1 [39776/250314 (16%)]\tLoss: 0.435375\tData (t) 0.234\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:56 | INFO | Rank 0 | Train Epoch: 1 [39808/250314 (16%)]\tLoss: 0.429175\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:57 | INFO | Rank 0 | Train Epoch: 1 [39840/250314 (16%)]\tLoss: 0.252089\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:57 | INFO | Rank 0 | Train Epoch: 1 [39872/250314 (16%)]\tLoss: 0.323539\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:58 | INFO | Rank 0 | Train Epoch: 1 [39904/250314 (16%)]\tLoss: 0.649995\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:58 | INFO | Rank 0 | Train Epoch: 1 [39936/250314 (16%)]\tLoss: 0.362420\tData (t) 0.338\tBatch (t) 0.550\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:59 | INFO | Rank 0 | Train Epoch: 1 [39968/250314 (16%)]\tLoss: 0.738585\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:29:59 | INFO | Rank 0 | Train Epoch: 1 [40000/250314 (16%)]\tLoss: 0.483853\tData (t) 0.223\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:00 | INFO | Rank 0 | Train Epoch: 1 [40032/250314 (16%)]\tLoss: 0.347206\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:00 | INFO | Rank 0 | Train Epoch: 1 [40064/250314 (16%)]\tLoss: 0.206143\tData (t) 0.221\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:01 | INFO | Rank 0 | Train Epoch: 1 [40096/250314 (16%)]\tLoss: 0.218448\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:01 | INFO | Rank 0 | Train Epoch: 1 [40128/250314 (16%)]\tLoss: 0.396623\tData (t) 0.217\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:02 | INFO | Rank 0 | Train Epoch: 1 [40160/250314 (16%)]\tLoss: 0.323396\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:02 | INFO | Rank 0 | Train Epoch: 1 [40192/250314 (16%)]\tLoss: 0.420407\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:03 | INFO | Rank 0 | Train Epoch: 1 [40224/250314 (16%)]\tLoss: 0.619355\tData (t) 0.229\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:03 | INFO | Rank 0 | Train Epoch: 1 [40256/250314 (16%)]\tLoss: 0.537264\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:04 | INFO | Rank 0 | Train Epoch: 1 [40288/250314 (16%)]\tLoss: 0.291386\tData (t) 0.261\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:04 | INFO | Rank 0 | Train Epoch: 1 [40320/250314 (16%)]\tLoss: 0.434856\tData (t) 0.277\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:05 | INFO | Rank 0 | Train Epoch: 1 [40352/250314 (16%)]\tLoss: 0.369230\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:05 | INFO | Rank 0 | Train Epoch: 1 [40384/250314 (16%)]\tLoss: 0.355637\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:06 | INFO | Rank 0 | Train Epoch: 1 [40416/250314 (16%)]\tLoss: 0.297478\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:06 | INFO | Rank 0 | Train Epoch: 1 [40448/250314 (16%)]\tLoss: 0.387534\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:06 | INFO | Rank 0 | Train Epoch: 1 [40480/250314 (16%)]\tLoss: 0.461944\tData (t) 0.208\tBatch (t) 0.420\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:07 | INFO | Rank 0 | Train Epoch: 1 [40512/250314 (16%)]\tLoss: 0.439956\tData (t) 0.200\tBatch (t) 0.412\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:07 | INFO | Rank 0 | Train Epoch: 1 [40544/250314 (16%)]\tLoss: 0.492276\tData (t) 0.308\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:08 | INFO | Rank 0 | Train Epoch: 1 [40576/250314 (16%)]\tLoss: 0.443848\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:08 | INFO | Rank 0 | Train Epoch: 1 [40608/250314 (16%)]\tLoss: 0.616723\tData (t) 0.304\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:09 | INFO | Rank 0 | Train Epoch: 1 [40640/250314 (16%)]\tLoss: 0.214595\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:09 | INFO | Rank 0 | Train Epoch: 1 [40672/250314 (16%)]\tLoss: 0.202697\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:10 | INFO | Rank 0 | Train Epoch: 1 [40704/250314 (16%)]\tLoss: 0.487089\tData (t) 0.341\tBatch (t) 0.553\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:10 | INFO | Rank 0 | Train Epoch: 1 [40736/250314 (16%)]\tLoss: 0.562797\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:11 | INFO | Rank 0 | Train Epoch: 1 [40768/250314 (16%)]\tLoss: 0.348665\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:11 | INFO | Rank 0 | Train Epoch: 1 [40800/250314 (16%)]\tLoss: 0.236388\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:12 | INFO | Rank 0 | Train Epoch: 1 [40832/250314 (16%)]\tLoss: 0.429497\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:12 | INFO | Rank 0 | Train Epoch: 1 [40864/250314 (16%)]\tLoss: 0.240956\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:13 | INFO | Rank 0 | Train Epoch: 1 [40896/250314 (16%)]\tLoss: 0.470705\tData (t) 0.213\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:13 | INFO | Rank 0 | Train Epoch: 1 [40928/250314 (16%)]\tLoss: 0.501509\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:14 | INFO | Rank 0 | Train Epoch: 1 [40960/250314 (16%)]\tLoss: 0.530685\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:14 | INFO | Rank 0 | Train Epoch: 1 [40992/250314 (16%)]\tLoss: 0.289513\tData (t) 0.234\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:15 | INFO | Rank 0 | Train Epoch: 1 [41024/250314 (16%)]\tLoss: 0.420220\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:15 | INFO | Rank 0 | Train Epoch: 1 [41056/250314 (16%)]\tLoss: 0.423336\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:16 | INFO | Rank 0 | Train Epoch: 1 [41088/250314 (16%)]\tLoss: 0.580829\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:16 | INFO | Rank 0 | Train Epoch: 1 [41120/250314 (16%)]\tLoss: 0.148518\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:17 | INFO | Rank 0 | Train Epoch: 1 [41152/250314 (16%)]\tLoss: 0.593673\tData (t) 0.299\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:17 | INFO | Rank 0 | Train Epoch: 1 [41184/250314 (16%)]\tLoss: 0.359503\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:18 | INFO | Rank 0 | Train Epoch: 1 [41216/250314 (16%)]\tLoss: 0.350849\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:18 | INFO | Rank 0 | Train Epoch: 1 [41248/250314 (16%)]\tLoss: 0.552228\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:19 | INFO | Rank 0 | Train Epoch: 1 [41280/250314 (16%)]\tLoss: 0.793877\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:19 | INFO | Rank 0 | Train Epoch: 1 [41312/250314 (17%)]\tLoss: 0.430042\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:19 | INFO | Rank 0 | Train Epoch: 1 [41344/250314 (17%)]\tLoss: 0.393120\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:20 | INFO | Rank 0 | Train Epoch: 1 [41376/250314 (17%)]\tLoss: 0.902330\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:20 | INFO | Rank 0 | Train Epoch: 1 [41408/250314 (17%)]\tLoss: 0.280109\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:21 | INFO | Rank 0 | Train Epoch: 1 [41440/250314 (17%)]\tLoss: 0.266496\tData (t) 0.328\tBatch (t) 0.540\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:21 | INFO | Rank 0 | Train Epoch: 1 [41472/250314 (17%)]\tLoss: 0.842555\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:22 | INFO | Rank 0 | Train Epoch: 1 [41504/250314 (17%)]\tLoss: 0.330622\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:22 | INFO | Rank 0 | Train Epoch: 1 [41536/250314 (17%)]\tLoss: 0.284501\tData (t) 0.247\tBatch (t) 0.459\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:23 | INFO | Rank 0 | Train Epoch: 1 [41568/250314 (17%)]\tLoss: 0.306632\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:23 | INFO | Rank 0 | Train Epoch: 1 [41600/250314 (17%)]\tLoss: 0.127100\tData (t) 0.266\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:24 | INFO | Rank 0 | Train Epoch: 1 [41632/250314 (17%)]\tLoss: 0.488201\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:24 | INFO | Rank 0 | Train Epoch: 1 [41664/250314 (17%)]\tLoss: 0.323495\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:25 | INFO | Rank 0 | Train Epoch: 1 [41696/250314 (17%)]\tLoss: 0.080108\tData (t) 0.296\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:25 | INFO | Rank 0 | Train Epoch: 1 [41728/250314 (17%)]\tLoss: 0.243809\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:26 | INFO | Rank 0 | Train Epoch: 1 [41760/250314 (17%)]\tLoss: 0.268090\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:26 | INFO | Rank 0 | Train Epoch: 1 [41792/250314 (17%)]\tLoss: 0.613360\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:27 | INFO | Rank 0 | Train Epoch: 1 [41824/250314 (17%)]\tLoss: 0.335982\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:27 | INFO | Rank 0 | Train Epoch: 1 [41856/250314 (17%)]\tLoss: 0.349210\tData (t) 0.337\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:28 | INFO | Rank 0 | Train Epoch: 1 [41888/250314 (17%)]\tLoss: 0.725875\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:28 | INFO | Rank 0 | Train Epoch: 1 [41920/250314 (17%)]\tLoss: 0.761498\tData (t) 0.317\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:29 | INFO | Rank 0 | Train Epoch: 1 [41952/250314 (17%)]\tLoss: 0.937662\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:29 | INFO | Rank 0 | Train Epoch: 1 [41984/250314 (17%)]\tLoss: 0.228801\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:30 | INFO | Rank 0 | Train Epoch: 1 [42016/250314 (17%)]\tLoss: 0.476188\tData (t) 0.322\tBatch (t) 0.534\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:30 | INFO | Rank 0 | Train Epoch: 1 [42048/250314 (17%)]\tLoss: 0.637270\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:31 | INFO | Rank 0 | Train Epoch: 1 [42080/250314 (17%)]\tLoss: 0.610166\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:31 | INFO | Rank 0 | Train Epoch: 1 [42112/250314 (17%)]\tLoss: 0.449918\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:32 | INFO | Rank 0 | Train Epoch: 1 [42144/250314 (17%)]\tLoss: 0.292444\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:32 | INFO | Rank 0 | Train Epoch: 1 [42176/250314 (17%)]\tLoss: 0.498699\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:33 | INFO | Rank 0 | Train Epoch: 1 [42208/250314 (17%)]\tLoss: 0.258423\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:33 | INFO | Rank 0 | Train Epoch: 1 [42240/250314 (17%)]\tLoss: 0.464132\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:34 | INFO | Rank 0 | Train Epoch: 1 [42272/250314 (17%)]\tLoss: 0.576574\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:34 | INFO | Rank 0 | Train Epoch: 1 [42304/250314 (17%)]\tLoss: 0.251271\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:35 | INFO | Rank 0 | Train Epoch: 1 [42336/250314 (17%)]\tLoss: 0.787116\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:35 | INFO | Rank 0 | Train Epoch: 1 [42368/250314 (17%)]\tLoss: 0.208492\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:36 | INFO | Rank 0 | Train Epoch: 1 [42400/250314 (17%)]\tLoss: 0.273892\tData (t) 0.213\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:36 | INFO | Rank 0 | Train Epoch: 1 [42432/250314 (17%)]\tLoss: 0.385145\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:37 | INFO | Rank 0 | Train Epoch: 1 [42464/250314 (17%)]\tLoss: 0.215460\tData (t) 0.263\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:37 | INFO | Rank 0 | Train Epoch: 1 [42496/250314 (17%)]\tLoss: 0.519239\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:38 | INFO | Rank 0 | Train Epoch: 1 [42528/250314 (17%)]\tLoss: 0.301918\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:38 | INFO | Rank 0 | Train Epoch: 1 [42560/250314 (17%)]\tLoss: 0.261975\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:38 | INFO | Rank 0 | Train Epoch: 1 [42592/250314 (17%)]\tLoss: 0.615431\tData (t) 0.189\tBatch (t) 0.401\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:39 | INFO | Rank 0 | Train Epoch: 1 [42624/250314 (17%)]\tLoss: 0.699211\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:40 | INFO | Rank 0 | Train Epoch: 1 [42656/250314 (17%)]\tLoss: 0.517053\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:40 | INFO | Rank 0 | Train Epoch: 1 [42688/250314 (17%)]\tLoss: 0.718975\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:41 | INFO | Rank 0 | Train Epoch: 1 [42720/250314 (17%)]\tLoss: 0.758341\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:41 | INFO | Rank 0 | Train Epoch: 1 [42752/250314 (17%)]\tLoss: 0.480485\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:41 | INFO | Rank 0 | Train Epoch: 1 [42784/250314 (17%)]\tLoss: 0.369294\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:42 | INFO | Rank 0 | Train Epoch: 1 [42816/250314 (17%)]\tLoss: 0.382423\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:42 | INFO | Rank 0 | Train Epoch: 1 [42848/250314 (17%)]\tLoss: 0.579826\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:43 | INFO | Rank 0 | Train Epoch: 1 [42880/250314 (17%)]\tLoss: 0.583924\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:43 | INFO | Rank 0 | Train Epoch: 1 [42912/250314 (17%)]\tLoss: 0.505807\tData (t) 0.346\tBatch (t) 0.559\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:44 | INFO | Rank 0 | Train Epoch: 1 [42944/250314 (17%)]\tLoss: 0.256161\tData (t) 0.270\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:44 | INFO | Rank 0 | Train Epoch: 1 [42976/250314 (17%)]\tLoss: 0.450555\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:45 | INFO | Rank 0 | Train Epoch: 1 [43008/250314 (17%)]\tLoss: 0.334570\tData (t) 0.336\tBatch (t) 0.549\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:45 | INFO | Rank 0 | Train Epoch: 1 [43040/250314 (17%)]\tLoss: 1.004363\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:46 | INFO | Rank 0 | Train Epoch: 1 [43072/250314 (17%)]\tLoss: 0.415939\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:46 | INFO | Rank 0 | Train Epoch: 1 [43104/250314 (17%)]\tLoss: 0.403036\tData (t) 0.291\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:47 | INFO | Rank 0 | Train Epoch: 1 [43136/250314 (17%)]\tLoss: 0.742360\tData (t) 0.331\tBatch (t) 0.543\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:47 | INFO | Rank 0 | Train Epoch: 1 [43168/250314 (17%)]\tLoss: 0.482797\tData (t) 0.263\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:48 | INFO | Rank 0 | Train Epoch: 1 [43200/250314 (17%)]\tLoss: 0.594398\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:48 | INFO | Rank 0 | Train Epoch: 1 [43232/250314 (17%)]\tLoss: 0.411812\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:49 | INFO | Rank 0 | Train Epoch: 1 [43264/250314 (17%)]\tLoss: 0.187609\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:49 | INFO | Rank 0 | Train Epoch: 1 [43296/250314 (17%)]\tLoss: 0.619418\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:50 | INFO | Rank 0 | Train Epoch: 1 [43328/250314 (17%)]\tLoss: 0.396996\tData (t) 0.310\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:50 | INFO | Rank 0 | Train Epoch: 1 [43360/250314 (17%)]\tLoss: 0.477783\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:51 | INFO | Rank 0 | Train Epoch: 1 [43392/250314 (17%)]\tLoss: 0.635892\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:51 | INFO | Rank 0 | Train Epoch: 1 [43424/250314 (17%)]\tLoss: 0.340137\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:52 | INFO | Rank 0 | Train Epoch: 1 [43456/250314 (17%)]\tLoss: 0.376261\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:52 | INFO | Rank 0 | Train Epoch: 1 [43488/250314 (17%)]\tLoss: 0.507818\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:53 | INFO | Rank 0 | Train Epoch: 1 [43520/250314 (17%)]\tLoss: 0.542047\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:53 | INFO | Rank 0 | Train Epoch: 1 [43552/250314 (17%)]\tLoss: 0.524886\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:54 | INFO | Rank 0 | Train Epoch: 1 [43584/250314 (17%)]\tLoss: 0.310755\tData (t) 0.232\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:54 | INFO | Rank 0 | Train Epoch: 1 [43616/250314 (17%)]\tLoss: 0.421911\tData (t) 0.252\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:55 | INFO | Rank 0 | Train Epoch: 1 [43648/250314 (17%)]\tLoss: 0.527664\tData (t) 0.261\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:55 | INFO | Rank 0 | Train Epoch: 1 [43680/250314 (17%)]\tLoss: 0.757738\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:56 | INFO | Rank 0 | Train Epoch: 1 [43712/250314 (17%)]\tLoss: 0.615198\tData (t) 0.270\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:56 | INFO | Rank 0 | Train Epoch: 1 [43744/250314 (17%)]\tLoss: 0.257420\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:57 | INFO | Rank 0 | Train Epoch: 1 [43776/250314 (17%)]\tLoss: 0.571864\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:57 | INFO | Rank 0 | Train Epoch: 1 [43808/250314 (18%)]\tLoss: 0.602695\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:58 | INFO | Rank 0 | Train Epoch: 1 [43840/250314 (18%)]\tLoss: 0.154097\tData (t) 0.256\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:58 | INFO | Rank 0 | Train Epoch: 1 [43872/250314 (18%)]\tLoss: 0.466524\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:59 | INFO | Rank 0 | Train Epoch: 1 [43904/250314 (18%)]\tLoss: 0.596144\tData (t) 0.300\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:30:59 | INFO | Rank 0 | Train Epoch: 1 [43936/250314 (18%)]\tLoss: 0.426155\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:00 | INFO | Rank 0 | Train Epoch: 1 [43968/250314 (18%)]\tLoss: 0.539683\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:00 | INFO | Rank 0 | Train Epoch: 1 [44000/250314 (18%)]\tLoss: 0.596187\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:01 | INFO | Rank 0 | Train Epoch: 1 [44032/250314 (18%)]\tLoss: 0.284840\tData (t) 0.342\tBatch (t) 0.554\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:01 | INFO | Rank 0 | Train Epoch: 1 [44064/250314 (18%)]\tLoss: 0.311843\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:02 | INFO | Rank 0 | Train Epoch: 1 [44096/250314 (18%)]\tLoss: 0.246751\tData (t) 0.298\tBatch (t) 0.510\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:02 | INFO | Rank 0 | Train Epoch: 1 [44128/250314 (18%)]\tLoss: 0.558505\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:03 | INFO | Rank 0 | Train Epoch: 1 [44160/250314 (18%)]\tLoss: 0.554331\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:03 | INFO | Rank 0 | Train Epoch: 1 [44192/250314 (18%)]\tLoss: 0.413760\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:04 | INFO | Rank 0 | Train Epoch: 1 [44224/250314 (18%)]\tLoss: 0.359299\tData (t) 0.270\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:04 | INFO | Rank 0 | Train Epoch: 1 [44256/250314 (18%)]\tLoss: 0.350857\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:05 | INFO | Rank 0 | Train Epoch: 1 [44288/250314 (18%)]\tLoss: 0.517203\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:05 | INFO | Rank 0 | Train Epoch: 1 [44320/250314 (18%)]\tLoss: 0.884116\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:06 | INFO | Rank 0 | Train Epoch: 1 [44352/250314 (18%)]\tLoss: 0.509004\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:06 | INFO | Rank 0 | Train Epoch: 1 [44384/250314 (18%)]\tLoss: 0.481366\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:07 | INFO | Rank 0 | Train Epoch: 1 [44416/250314 (18%)]\tLoss: 0.247717\tData (t) 0.222\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:07 | INFO | Rank 0 | Train Epoch: 1 [44448/250314 (18%)]\tLoss: 0.536111\tData (t) 0.255\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:08 | INFO | Rank 0 | Train Epoch: 1 [44480/250314 (18%)]\tLoss: 0.287237\tData (t) 0.310\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:08 | INFO | Rank 0 | Train Epoch: 1 [44512/250314 (18%)]\tLoss: 0.336837\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:09 | INFO | Rank 0 | Train Epoch: 1 [44544/250314 (18%)]\tLoss: 0.583594\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:09 | INFO | Rank 0 | Train Epoch: 1 [44576/250314 (18%)]\tLoss: 0.467863\tData (t) 0.262\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:09 | INFO | Rank 0 | Train Epoch: 1 [44608/250314 (18%)]\tLoss: 0.186837\tData (t) 0.218\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:10 | INFO | Rank 0 | Train Epoch: 1 [44640/250314 (18%)]\tLoss: 0.761507\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:10 | INFO | Rank 0 | Train Epoch: 1 [44672/250314 (18%)]\tLoss: 0.347207\tData (t) 0.295\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:11 | INFO | Rank 0 | Train Epoch: 1 [44704/250314 (18%)]\tLoss: 0.313941\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:11 | INFO | Rank 0 | Train Epoch: 1 [44736/250314 (18%)]\tLoss: 0.369746\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:12 | INFO | Rank 0 | Train Epoch: 1 [44768/250314 (18%)]\tLoss: 0.574771\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:12 | INFO | Rank 0 | Train Epoch: 1 [44800/250314 (18%)]\tLoss: 0.288060\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:13 | INFO | Rank 0 | Train Epoch: 1 [44832/250314 (18%)]\tLoss: 0.580451\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:13 | INFO | Rank 0 | Train Epoch: 1 [44864/250314 (18%)]\tLoss: 0.328306\tData (t) 0.242\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:14 | INFO | Rank 0 | Train Epoch: 1 [44896/250314 (18%)]\tLoss: 0.454948\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:14 | INFO | Rank 0 | Train Epoch: 1 [44928/250314 (18%)]\tLoss: 0.706669\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:15 | INFO | Rank 0 | Train Epoch: 1 [44960/250314 (18%)]\tLoss: 0.374871\tData (t) 0.234\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:15 | INFO | Rank 0 | Train Epoch: 1 [44992/250314 (18%)]\tLoss: 0.341009\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:16 | INFO | Rank 0 | Train Epoch: 1 [45024/250314 (18%)]\tLoss: 0.601104\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:16 | INFO | Rank 0 | Train Epoch: 1 [45056/250314 (18%)]\tLoss: 0.292944\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:17 | INFO | Rank 0 | Train Epoch: 1 [45088/250314 (18%)]\tLoss: 0.353930\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:17 | INFO | Rank 0 | Train Epoch: 1 [45120/250314 (18%)]\tLoss: 0.191268\tData (t) 0.303\tBatch (t) 0.515\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:18 | INFO | Rank 0 | Train Epoch: 1 [45152/250314 (18%)]\tLoss: 0.746109\tData (t) 0.212\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:18 | INFO | Rank 0 | Train Epoch: 1 [45184/250314 (18%)]\tLoss: 0.599446\tData (t) 0.301\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:19 | INFO | Rank 0 | Train Epoch: 1 [45216/250314 (18%)]\tLoss: 0.485213\tData (t) 0.272\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:19 | INFO | Rank 0 | Train Epoch: 1 [45248/250314 (18%)]\tLoss: 0.264071\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:20 | INFO | Rank 0 | Train Epoch: 1 [45280/250314 (18%)]\tLoss: 0.471861\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:20 | INFO | Rank 0 | Train Epoch: 1 [45312/250314 (18%)]\tLoss: 0.830344\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:21 | INFO | Rank 0 | Train Epoch: 1 [45344/250314 (18%)]\tLoss: 0.897064\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.587\n",
      "2022-11-09,14:31:21 | INFO | Rank 0 | Train Epoch: 1 [45376/250314 (18%)]\tLoss: 0.802116\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:22 | INFO | Rank 0 | Train Epoch: 1 [45408/250314 (18%)]\tLoss: 0.465146\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:22 | INFO | Rank 0 | Train Epoch: 1 [45440/250314 (18%)]\tLoss: 0.272066\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:23 | INFO | Rank 0 | Train Epoch: 1 [45472/250314 (18%)]\tLoss: 0.231629\tData (t) 0.315\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:23 | INFO | Rank 0 | Train Epoch: 1 [45504/250314 (18%)]\tLoss: 0.381475\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:23 | INFO | Rank 0 | Train Epoch: 1 [45536/250314 (18%)]\tLoss: 0.365922\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:24 | INFO | Rank 0 | Train Epoch: 1 [45568/250314 (18%)]\tLoss: 0.543762\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:24 | INFO | Rank 0 | Train Epoch: 1 [45600/250314 (18%)]\tLoss: 0.554418\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:25 | INFO | Rank 0 | Train Epoch: 1 [45632/250314 (18%)]\tLoss: 0.212059\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:25 | INFO | Rank 0 | Train Epoch: 1 [45664/250314 (18%)]\tLoss: 0.376601\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:26 | INFO | Rank 0 | Train Epoch: 1 [45696/250314 (18%)]\tLoss: 0.559201\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:26 | INFO | Rank 0 | Train Epoch: 1 [45728/250314 (18%)]\tLoss: 0.532463\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:27 | INFO | Rank 0 | Train Epoch: 1 [45760/250314 (18%)]\tLoss: 0.516614\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:27 | INFO | Rank 0 | Train Epoch: 1 [45792/250314 (18%)]\tLoss: 0.501075\tData (t) 0.344\tBatch (t) 0.556\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:28 | INFO | Rank 0 | Train Epoch: 1 [45824/250314 (18%)]\tLoss: 0.432252\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:28 | INFO | Rank 0 | Train Epoch: 1 [45856/250314 (18%)]\tLoss: 0.131090\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:29 | INFO | Rank 0 | Train Epoch: 1 [45888/250314 (18%)]\tLoss: 0.819561\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:29 | INFO | Rank 0 | Train Epoch: 1 [45920/250314 (18%)]\tLoss: 0.443379\tData (t) 0.315\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:30 | INFO | Rank 0 | Train Epoch: 1 [45952/250314 (18%)]\tLoss: 0.457691\tData (t) 0.262\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:30 | INFO | Rank 0 | Train Epoch: 1 [45984/250314 (18%)]\tLoss: 0.134268\tData (t) 0.270\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:31 | INFO | Rank 0 | Train Epoch: 1 [46016/250314 (18%)]\tLoss: 0.177162\tData (t) 0.231\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:31 | INFO | Rank 0 | Train Epoch: 1 [46048/250314 (18%)]\tLoss: 0.285663\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:32 | INFO | Rank 0 | Train Epoch: 1 [46080/250314 (18%)]\tLoss: 0.453112\tData (t) 0.315\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:32 | INFO | Rank 0 | Train Epoch: 1 [46112/250314 (18%)]\tLoss: 0.626200\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:33 | INFO | Rank 0 | Train Epoch: 1 [46144/250314 (18%)]\tLoss: 0.882926\tData (t) 0.283\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:33 | INFO | Rank 0 | Train Epoch: 1 [46176/250314 (18%)]\tLoss: 0.319072\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:34 | INFO | Rank 0 | Train Epoch: 1 [46208/250314 (18%)]\tLoss: 0.488003\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:34 | INFO | Rank 0 | Train Epoch: 1 [46240/250314 (18%)]\tLoss: 0.330955\tData (t) 0.281\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:35 | INFO | Rank 0 | Train Epoch: 1 [46272/250314 (18%)]\tLoss: 0.293875\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:35 | INFO | Rank 0 | Train Epoch: 1 [46304/250314 (18%)]\tLoss: 0.535314\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:36 | INFO | Rank 0 | Train Epoch: 1 [46336/250314 (19%)]\tLoss: 0.429417\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:36 | INFO | Rank 0 | Train Epoch: 1 [46368/250314 (19%)]\tLoss: 0.607796\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:37 | INFO | Rank 0 | Train Epoch: 1 [46400/250314 (19%)]\tLoss: 0.400700\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:37 | INFO | Rank 0 | Train Epoch: 1 [46432/250314 (19%)]\tLoss: 0.497662\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:38 | INFO | Rank 0 | Train Epoch: 1 [46464/250314 (19%)]\tLoss: 0.337885\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:38 | INFO | Rank 0 | Train Epoch: 1 [46496/250314 (19%)]\tLoss: 0.472075\tData (t) 0.201\tBatch (t) 0.413\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:39 | INFO | Rank 0 | Train Epoch: 1 [46528/250314 (19%)]\tLoss: 0.272612\tData (t) 0.345\tBatch (t) 0.558\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:39 | INFO | Rank 0 | Train Epoch: 1 [46560/250314 (19%)]\tLoss: 0.354306\tData (t) 0.311\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:40 | INFO | Rank 0 | Train Epoch: 1 [46592/250314 (19%)]\tLoss: 0.554173\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:40 | INFO | Rank 0 | Train Epoch: 1 [46624/250314 (19%)]\tLoss: 0.395130\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:41 | INFO | Rank 0 | Train Epoch: 1 [46656/250314 (19%)]\tLoss: 0.583891\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:41 | INFO | Rank 0 | Train Epoch: 1 [46688/250314 (19%)]\tLoss: 0.644191\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:42 | INFO | Rank 0 | Train Epoch: 1 [46720/250314 (19%)]\tLoss: 0.578994\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:42 | INFO | Rank 0 | Train Epoch: 1 [46752/250314 (19%)]\tLoss: 0.613947\tData (t) 0.269\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:42 | INFO | Rank 0 | Train Epoch: 1 [46784/250314 (19%)]\tLoss: 0.347933\tData (t) 0.213\tBatch (t) 0.424\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:43 | INFO | Rank 0 | Train Epoch: 1 [46816/250314 (19%)]\tLoss: 0.273266\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:43 | INFO | Rank 0 | Train Epoch: 1 [46848/250314 (19%)]\tLoss: 0.461175\tData (t) 0.312\tBatch (t) 0.524\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:44 | INFO | Rank 0 | Train Epoch: 1 [46880/250314 (19%)]\tLoss: 0.529720\tData (t) 0.333\tBatch (t) 0.546\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:45 | INFO | Rank 0 | Train Epoch: 1 [46912/250314 (19%)]\tLoss: 0.290050\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:45 | INFO | Rank 0 | Train Epoch: 1 [46944/250314 (19%)]\tLoss: 0.508429\tData (t) 0.270\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:46 | INFO | Rank 0 | Train Epoch: 1 [46976/250314 (19%)]\tLoss: 0.365240\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:46 | INFO | Rank 0 | Train Epoch: 1 [47008/250314 (19%)]\tLoss: 0.485420\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:46 | INFO | Rank 0 | Train Epoch: 1 [47040/250314 (19%)]\tLoss: 0.667803\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:47 | INFO | Rank 0 | Train Epoch: 1 [47072/250314 (19%)]\tLoss: 0.226263\tData (t) 0.218\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:47 | INFO | Rank 0 | Train Epoch: 1 [47104/250314 (19%)]\tLoss: 0.622250\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:48 | INFO | Rank 0 | Train Epoch: 1 [47136/250314 (19%)]\tLoss: 0.459525\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:48 | INFO | Rank 0 | Train Epoch: 1 [47168/250314 (19%)]\tLoss: 0.433777\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:49 | INFO | Rank 0 | Train Epoch: 1 [47200/250314 (19%)]\tLoss: 0.388316\tData (t) 0.238\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:49 | INFO | Rank 0 | Train Epoch: 1 [47232/250314 (19%)]\tLoss: 0.388084\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:50 | INFO | Rank 0 | Train Epoch: 1 [47264/250314 (19%)]\tLoss: 0.455892\tData (t) 0.285\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:50 | INFO | Rank 0 | Train Epoch: 1 [47296/250314 (19%)]\tLoss: 0.132352\tData (t) 0.336\tBatch (t) 0.548\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:51 | INFO | Rank 0 | Train Epoch: 1 [47328/250314 (19%)]\tLoss: 0.359597\tData (t) 0.249\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:51 | INFO | Rank 0 | Train Epoch: 1 [47360/250314 (19%)]\tLoss: 0.358030\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:52 | INFO | Rank 0 | Train Epoch: 1 [47392/250314 (19%)]\tLoss: 0.244295\tData (t) 0.223\tBatch (t) 0.435\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:52 | INFO | Rank 0 | Train Epoch: 1 [47424/250314 (19%)]\tLoss: 0.363503\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:53 | INFO | Rank 0 | Train Epoch: 1 [47456/250314 (19%)]\tLoss: 0.456308\tData (t) 0.252\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:53 | INFO | Rank 0 | Train Epoch: 1 [47488/250314 (19%)]\tLoss: 0.433604\tData (t) 0.258\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:54 | INFO | Rank 0 | Train Epoch: 1 [47520/250314 (19%)]\tLoss: 0.790584\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:54 | INFO | Rank 0 | Train Epoch: 1 [47552/250314 (19%)]\tLoss: 0.359543\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:55 | INFO | Rank 0 | Train Epoch: 1 [47584/250314 (19%)]\tLoss: 0.457132\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:55 | INFO | Rank 0 | Train Epoch: 1 [47616/250314 (19%)]\tLoss: 0.355165\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:56 | INFO | Rank 0 | Train Epoch: 1 [47648/250314 (19%)]\tLoss: 0.467074\tData (t) 0.230\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:56 | INFO | Rank 0 | Train Epoch: 1 [47680/250314 (19%)]\tLoss: 0.552774\tData (t) 0.273\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:57 | INFO | Rank 0 | Train Epoch: 1 [47712/250314 (19%)]\tLoss: 0.385649\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:57 | INFO | Rank 0 | Train Epoch: 1 [47744/250314 (19%)]\tLoss: 0.467461\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:58 | INFO | Rank 0 | Train Epoch: 1 [47776/250314 (19%)]\tLoss: 0.269631\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:58 | INFO | Rank 0 | Train Epoch: 1 [47808/250314 (19%)]\tLoss: 0.403939\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:58 | INFO | Rank 0 | Train Epoch: 1 [47840/250314 (19%)]\tLoss: 0.448199\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:59 | INFO | Rank 0 | Train Epoch: 1 [47872/250314 (19%)]\tLoss: 0.428558\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:31:59 | INFO | Rank 0 | Train Epoch: 1 [47904/250314 (19%)]\tLoss: 0.354428\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:00 | INFO | Rank 0 | Train Epoch: 1 [47936/250314 (19%)]\tLoss: 0.205823\tData (t) 0.286\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:00 | INFO | Rank 0 | Train Epoch: 1 [47968/250314 (19%)]\tLoss: 0.598642\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:01 | INFO | Rank 0 | Train Epoch: 1 [48000/250314 (19%)]\tLoss: 0.485571\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:01 | INFO | Rank 0 | Train Epoch: 1 [48032/250314 (19%)]\tLoss: 0.368636\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:02 | INFO | Rank 0 | Train Epoch: 1 [48064/250314 (19%)]\tLoss: 0.419330\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:02 | INFO | Rank 0 | Train Epoch: 1 [48096/250314 (19%)]\tLoss: 0.372340\tData (t) 0.313\tBatch (t) 0.525\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:03 | INFO | Rank 0 | Train Epoch: 1 [48128/250314 (19%)]\tLoss: 0.575971\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:03 | INFO | Rank 0 | Train Epoch: 1 [48160/250314 (19%)]\tLoss: 0.230358\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:04 | INFO | Rank 0 | Train Epoch: 1 [48192/250314 (19%)]\tLoss: 0.543020\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:04 | INFO | Rank 0 | Train Epoch: 1 [48224/250314 (19%)]\tLoss: 0.354647\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:05 | INFO | Rank 0 | Train Epoch: 1 [48256/250314 (19%)]\tLoss: 0.854533\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:05 | INFO | Rank 0 | Train Epoch: 1 [48288/250314 (19%)]\tLoss: 0.901066\tData (t) 0.251\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:06 | INFO | Rank 0 | Train Epoch: 1 [48320/250314 (19%)]\tLoss: 0.408371\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:06 | INFO | Rank 0 | Train Epoch: 1 [48352/250314 (19%)]\tLoss: 0.546486\tData (t) 0.231\tBatch (t) 0.443\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:07 | INFO | Rank 0 | Train Epoch: 1 [48384/250314 (19%)]\tLoss: 0.521320\tData (t) 0.219\tBatch (t) 0.431\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:07 | INFO | Rank 0 | Train Epoch: 1 [48416/250314 (19%)]\tLoss: 0.583432\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:08 | INFO | Rank 0 | Train Epoch: 1 [48448/250314 (19%)]\tLoss: 0.222843\tData (t) 0.262\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:08 | INFO | Rank 0 | Train Epoch: 1 [48480/250314 (19%)]\tLoss: 0.364420\tData (t) 0.191\tBatch (t) 0.403\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:09 | INFO | Rank 0 | Train Epoch: 1 [48512/250314 (19%)]\tLoss: 0.566190\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:09 | INFO | Rank 0 | Train Epoch: 1 [48544/250314 (19%)]\tLoss: 0.245735\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:10 | INFO | Rank 0 | Train Epoch: 1 [48576/250314 (19%)]\tLoss: 0.478108\tData (t) 0.309\tBatch (t) 0.520\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:10 | INFO | Rank 0 | Train Epoch: 1 [48608/250314 (19%)]\tLoss: 0.154219\tData (t) 0.296\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:11 | INFO | Rank 0 | Train Epoch: 1 [48640/250314 (19%)]\tLoss: 0.596525\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:11 | INFO | Rank 0 | Train Epoch: 1 [48672/250314 (19%)]\tLoss: 0.865020\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:12 | INFO | Rank 0 | Train Epoch: 1 [48704/250314 (19%)]\tLoss: 0.544349\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:12 | INFO | Rank 0 | Train Epoch: 1 [48736/250314 (19%)]\tLoss: 0.350293\tData (t) 0.293\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:12 | INFO | Rank 0 | Train Epoch: 1 [48768/250314 (19%)]\tLoss: 0.437389\tData (t) 0.219\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:13 | INFO | Rank 0 | Train Epoch: 1 [48800/250314 (19%)]\tLoss: 0.579674\tData (t) 0.290\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:13 | INFO | Rank 0 | Train Epoch: 1 [48832/250314 (20%)]\tLoss: 0.498339\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:14 | INFO | Rank 0 | Train Epoch: 1 [48864/250314 (20%)]\tLoss: 0.651085\tData (t) 0.315\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:14 | INFO | Rank 0 | Train Epoch: 1 [48896/250314 (20%)]\tLoss: 0.494295\tData (t) 0.247\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:15 | INFO | Rank 0 | Train Epoch: 1 [48928/250314 (20%)]\tLoss: 0.348752\tData (t) 0.308\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:15 | INFO | Rank 0 | Train Epoch: 1 [48960/250314 (20%)]\tLoss: 0.111201\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:16 | INFO | Rank 0 | Train Epoch: 1 [48992/250314 (20%)]\tLoss: 0.503437\tData (t) 0.257\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:16 | INFO | Rank 0 | Train Epoch: 1 [49024/250314 (20%)]\tLoss: 0.257699\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:17 | INFO | Rank 0 | Train Epoch: 1 [49056/250314 (20%)]\tLoss: 0.459631\tData (t) 0.241\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:17 | INFO | Rank 0 | Train Epoch: 1 [49088/250314 (20%)]\tLoss: 0.465327\tData (t) 0.200\tBatch (t) 0.412\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:18 | INFO | Rank 0 | Train Epoch: 1 [49120/250314 (20%)]\tLoss: 0.596498\tData (t) 0.227\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:18 | INFO | Rank 0 | Train Epoch: 1 [49152/250314 (20%)]\tLoss: 0.487133\tData (t) 0.233\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:19 | INFO | Rank 0 | Train Epoch: 1 [49184/250314 (20%)]\tLoss: 0.525509\tData (t) 0.245\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:19 | INFO | Rank 0 | Train Epoch: 1 [49216/250314 (20%)]\tLoss: 0.544803\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:20 | INFO | Rank 0 | Train Epoch: 1 [49248/250314 (20%)]\tLoss: 0.224672\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:20 | INFO | Rank 0 | Train Epoch: 1 [49280/250314 (20%)]\tLoss: 0.579482\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:20 | INFO | Rank 0 | Train Epoch: 1 [49312/250314 (20%)]\tLoss: 0.143151\tData (t) 0.209\tBatch (t) 0.421\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:21 | INFO | Rank 0 | Train Epoch: 1 [49344/250314 (20%)]\tLoss: 0.410909\tData (t) 0.321\tBatch (t) 0.533\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:21 | INFO | Rank 0 | Train Epoch: 1 [49376/250314 (20%)]\tLoss: 0.330364\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:22 | INFO | Rank 0 | Train Epoch: 1 [49408/250314 (20%)]\tLoss: 0.540283\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:22 | INFO | Rank 0 | Train Epoch: 1 [49440/250314 (20%)]\tLoss: 0.375429\tData (t) 0.266\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:23 | INFO | Rank 0 | Train Epoch: 1 [49472/250314 (20%)]\tLoss: 0.586303\tData (t) 0.281\tBatch (t) 0.493\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:23 | INFO | Rank 0 | Train Epoch: 1 [49504/250314 (20%)]\tLoss: 0.358282\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:24 | INFO | Rank 0 | Train Epoch: 1 [49536/250314 (20%)]\tLoss: 0.645872\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:24 | INFO | Rank 0 | Train Epoch: 1 [49568/250314 (20%)]\tLoss: 0.790058\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:25 | INFO | Rank 0 | Train Epoch: 1 [49600/250314 (20%)]\tLoss: 0.423322\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:25 | INFO | Rank 0 | Train Epoch: 1 [49632/250314 (20%)]\tLoss: 0.422216\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:26 | INFO | Rank 0 | Train Epoch: 1 [49664/250314 (20%)]\tLoss: 0.330988\tData (t) 0.298\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:26 | INFO | Rank 0 | Train Epoch: 1 [49696/250314 (20%)]\tLoss: 0.268642\tData (t) 0.275\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:27 | INFO | Rank 0 | Train Epoch: 1 [49728/250314 (20%)]\tLoss: 0.328773\tData (t) 0.199\tBatch (t) 0.410\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:27 | INFO | Rank 0 | Train Epoch: 1 [49760/250314 (20%)]\tLoss: 0.516550\tData (t) 0.218\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:27 | INFO | Rank 0 | Train Epoch: 1 [49792/250314 (20%)]\tLoss: 0.175838\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:28 | INFO | Rank 0 | Train Epoch: 1 [49824/250314 (20%)]\tLoss: 0.275064\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:28 | INFO | Rank 0 | Train Epoch: 1 [49856/250314 (20%)]\tLoss: 0.196273\tData (t) 0.303\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:29 | INFO | Rank 0 | Train Epoch: 1 [49888/250314 (20%)]\tLoss: 0.490328\tData (t) 0.215\tBatch (t) 0.427\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:29 | INFO | Rank 0 | Train Epoch: 1 [49920/250314 (20%)]\tLoss: 0.422490\tData (t) 0.293\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:30 | INFO | Rank 0 | Train Epoch: 1 [49952/250314 (20%)]\tLoss: 0.555816\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:30 | INFO | Rank 0 | Train Epoch: 1 [49984/250314 (20%)]\tLoss: 0.319267\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:31 | INFO | Rank 0 | Train Epoch: 1 [50016/250314 (20%)]\tLoss: 0.619389\tData (t) 0.267\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:31 | INFO | Rank 0 | Train Epoch: 1 [50048/250314 (20%)]\tLoss: 0.296012\tData (t) 0.221\tBatch (t) 0.433\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:32 | INFO | Rank 0 | Train Epoch: 1 [50080/250314 (20%)]\tLoss: 0.293672\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:32 | INFO | Rank 0 | Train Epoch: 1 [50112/250314 (20%)]\tLoss: 0.399127\tData (t) 0.271\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:33 | INFO | Rank 0 | Train Epoch: 1 [50144/250314 (20%)]\tLoss: 0.272521\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:33 | INFO | Rank 0 | Train Epoch: 1 [50176/250314 (20%)]\tLoss: 0.294843\tData (t) 0.257\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:34 | INFO | Rank 0 | Train Epoch: 1 [50208/250314 (20%)]\tLoss: 0.496108\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:34 | INFO | Rank 0 | Train Epoch: 1 [50240/250314 (20%)]\tLoss: 0.397785\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:35 | INFO | Rank 0 | Train Epoch: 1 [50272/250314 (20%)]\tLoss: 0.756206\tData (t) 0.202\tBatch (t) 0.414\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:35 | INFO | Rank 0 | Train Epoch: 1 [50304/250314 (20%)]\tLoss: 0.626525\tData (t) 0.325\tBatch (t) 0.537\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:36 | INFO | Rank 0 | Train Epoch: 1 [50336/250314 (20%)]\tLoss: 0.345496\tData (t) 0.276\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:36 | INFO | Rank 0 | Train Epoch: 1 [50368/250314 (20%)]\tLoss: 0.293505\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:37 | INFO | Rank 0 | Train Epoch: 1 [50400/250314 (20%)]\tLoss: 0.414781\tData (t) 0.233\tBatch (t) 0.445\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:37 | INFO | Rank 0 | Train Epoch: 1 [50432/250314 (20%)]\tLoss: 0.453858\tData (t) 0.265\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:38 | INFO | Rank 0 | Train Epoch: 1 [50464/250314 (20%)]\tLoss: 0.653280\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:38 | INFO | Rank 0 | Train Epoch: 1 [50496/250314 (20%)]\tLoss: 0.602988\tData (t) 0.205\tBatch (t) 0.417\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:38 | INFO | Rank 0 | Train Epoch: 1 [50528/250314 (20%)]\tLoss: 0.816639\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:39 | INFO | Rank 0 | Train Epoch: 1 [50560/250314 (20%)]\tLoss: 0.455363\tData (t) 0.256\tBatch (t) 0.468\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:39 | INFO | Rank 0 | Train Epoch: 1 [50592/250314 (20%)]\tLoss: 0.309585\tData (t) 0.287\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:40 | INFO | Rank 0 | Train Epoch: 1 [50624/250314 (20%)]\tLoss: 0.445098\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:40 | INFO | Rank 0 | Train Epoch: 1 [50656/250314 (20%)]\tLoss: 0.286775\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:41 | INFO | Rank 0 | Train Epoch: 1 [50688/250314 (20%)]\tLoss: 0.468529\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:41 | INFO | Rank 0 | Train Epoch: 1 [50720/250314 (20%)]\tLoss: 0.420110\tData (t) 0.300\tBatch (t) 0.512\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:42 | INFO | Rank 0 | Train Epoch: 1 [50752/250314 (20%)]\tLoss: 0.209151\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:42 | INFO | Rank 0 | Train Epoch: 1 [50784/250314 (20%)]\tLoss: 0.523987\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:43 | INFO | Rank 0 | Train Epoch: 1 [50816/250314 (20%)]\tLoss: 0.385011\tData (t) 0.319\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:43 | INFO | Rank 0 | Train Epoch: 1 [50848/250314 (20%)]\tLoss: 0.598764\tData (t) 0.210\tBatch (t) 0.421\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:44 | INFO | Rank 0 | Train Epoch: 1 [50880/250314 (20%)]\tLoss: 0.796857\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:44 | INFO | Rank 0 | Train Epoch: 1 [50912/250314 (20%)]\tLoss: 0.235209\tData (t) 0.268\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:45 | INFO | Rank 0 | Train Epoch: 1 [50944/250314 (20%)]\tLoss: 0.348127\tData (t) 0.246\tBatch (t) 0.458\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:45 | INFO | Rank 0 | Train Epoch: 1 [50976/250314 (20%)]\tLoss: 0.621427\tData (t) 0.292\tBatch (t) 0.504\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:46 | INFO | Rank 0 | Train Epoch: 1 [51008/250314 (20%)]\tLoss: 0.342661\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:46 | INFO | Rank 0 | Train Epoch: 1 [51040/250314 (20%)]\tLoss: 0.491622\tData (t) 0.299\tBatch (t) 0.511\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:47 | INFO | Rank 0 | Train Epoch: 1 [51072/250314 (20%)]\tLoss: 0.476339\tData (t) 0.286\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:47 | INFO | Rank 0 | Train Epoch: 1 [51104/250314 (20%)]\tLoss: 0.672584\tData (t) 0.269\tBatch (t) 0.480\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:48 | INFO | Rank 0 | Train Epoch: 1 [51136/250314 (20%)]\tLoss: 0.350502\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:48 | INFO | Rank 0 | Train Epoch: 1 [51168/250314 (20%)]\tLoss: 0.272069\tData (t) 0.252\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:49 | INFO | Rank 0 | Train Epoch: 1 [51200/250314 (20%)]\tLoss: 0.602534\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:49 | INFO | Rank 0 | Train Epoch: 1 [51232/250314 (20%)]\tLoss: 0.293184\tData (t) 0.323\tBatch (t) 0.535\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:50 | INFO | Rank 0 | Train Epoch: 1 [51264/250314 (20%)]\tLoss: 0.443969\tData (t) 0.240\tBatch (t) 0.452\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:50 | INFO | Rank 0 | Train Epoch: 1 [51296/250314 (20%)]\tLoss: 0.935687\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:51 | INFO | Rank 0 | Train Epoch: 1 [51328/250314 (21%)]\tLoss: 0.853960\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:51 | INFO | Rank 0 | Train Epoch: 1 [51360/250314 (21%)]\tLoss: 0.561251\tData (t) 0.237\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:52 | INFO | Rank 0 | Train Epoch: 1 [51392/250314 (21%)]\tLoss: 0.517912\tData (t) 0.266\tBatch (t) 0.478\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:52 | INFO | Rank 0 | Train Epoch: 1 [51424/250314 (21%)]\tLoss: 0.378183\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:53 | INFO | Rank 0 | Train Epoch: 1 [51456/250314 (21%)]\tLoss: 0.506540\tData (t) 0.318\tBatch (t) 0.531\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:53 | INFO | Rank 0 | Train Epoch: 1 [51488/250314 (21%)]\tLoss: 0.575515\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:54 | INFO | Rank 0 | Train Epoch: 1 [51520/250314 (21%)]\tLoss: 0.611816\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:54 | INFO | Rank 0 | Train Epoch: 1 [51552/250314 (21%)]\tLoss: 0.336783\tData (t) 0.250\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:54 | INFO | Rank 0 | Train Epoch: 1 [51584/250314 (21%)]\tLoss: 0.452311\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:55 | INFO | Rank 0 | Train Epoch: 1 [51616/250314 (21%)]\tLoss: 0.644229\tData (t) 0.262\tBatch (t) 0.474\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:55 | INFO | Rank 0 | Train Epoch: 1 [51648/250314 (21%)]\tLoss: 0.354401\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:56 | INFO | Rank 0 | Train Epoch: 1 [51680/250314 (21%)]\tLoss: 0.579218\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:56 | INFO | Rank 0 | Train Epoch: 1 [51712/250314 (21%)]\tLoss: 0.366715\tData (t) 0.287\tBatch (t) 0.499\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:57 | INFO | Rank 0 | Train Epoch: 1 [51744/250314 (21%)]\tLoss: 0.424826\tData (t) 0.278\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:57 | INFO | Rank 0 | Train Epoch: 1 [51776/250314 (21%)]\tLoss: 0.381528\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:58 | INFO | Rank 0 | Train Epoch: 1 [51808/250314 (21%)]\tLoss: 0.559139\tData (t) 0.332\tBatch (t) 0.544\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:58 | INFO | Rank 0 | Train Epoch: 1 [51840/250314 (21%)]\tLoss: 0.543593\tData (t) 0.251\tBatch (t) 0.463\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:59 | INFO | Rank 0 | Train Epoch: 1 [51872/250314 (21%)]\tLoss: 0.282815\tData (t) 0.309\tBatch (t) 0.522\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:32:59 | INFO | Rank 0 | Train Epoch: 1 [51904/250314 (21%)]\tLoss: 0.381581\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:00 | INFO | Rank 0 | Train Epoch: 1 [51936/250314 (21%)]\tLoss: 0.370268\tData (t) 0.284\tBatch (t) 0.496\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:00 | INFO | Rank 0 | Train Epoch: 1 [51968/250314 (21%)]\tLoss: 0.321844\tData (t) 0.291\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:01 | INFO | Rank 0 | Train Epoch: 1 [52000/250314 (21%)]\tLoss: 0.522023\tData (t) 0.217\tBatch (t) 0.429\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:01 | INFO | Rank 0 | Train Epoch: 1 [52032/250314 (21%)]\tLoss: 0.416930\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:02 | INFO | Rank 0 | Train Epoch: 1 [52064/250314 (21%)]\tLoss: 0.340241\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:02 | INFO | Rank 0 | Train Epoch: 1 [52096/250314 (21%)]\tLoss: 0.459374\tData (t) 0.292\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:03 | INFO | Rank 0 | Train Epoch: 1 [52128/250314 (21%)]\tLoss: 0.157804\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:03 | INFO | Rank 0 | Train Epoch: 1 [52160/250314 (21%)]\tLoss: 0.414369\tData (t) 0.274\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:04 | INFO | Rank 0 | Train Epoch: 1 [52192/250314 (21%)]\tLoss: 0.439868\tData (t) 0.229\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:04 | INFO | Rank 0 | Train Epoch: 1 [52224/250314 (21%)]\tLoss: 0.150247\tData (t) 0.237\tBatch (t) 0.449\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:05 | INFO | Rank 0 | Train Epoch: 1 [52256/250314 (21%)]\tLoss: 0.322667\tData (t) 0.252\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:05 | INFO | Rank 0 | Train Epoch: 1 [52288/250314 (21%)]\tLoss: 0.201571\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:06 | INFO | Rank 0 | Train Epoch: 1 [52320/250314 (21%)]\tLoss: 0.327854\tData (t) 0.225\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:06 | INFO | Rank 0 | Train Epoch: 1 [52352/250314 (21%)]\tLoss: 0.278221\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:06 | INFO | Rank 0 | Train Epoch: 1 [52384/250314 (21%)]\tLoss: 0.137686\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:07 | INFO | Rank 0 | Train Epoch: 1 [52416/250314 (21%)]\tLoss: 0.296242\tData (t) 0.290\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:07 | INFO | Rank 0 | Train Epoch: 1 [52448/250314 (21%)]\tLoss: 0.247331\tData (t) 0.243\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:08 | INFO | Rank 0 | Train Epoch: 1 [52480/250314 (21%)]\tLoss: 0.701593\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:08 | INFO | Rank 0 | Train Epoch: 1 [52512/250314 (21%)]\tLoss: 0.373684\tData (t) 0.213\tBatch (t) 0.425\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:09 | INFO | Rank 0 | Train Epoch: 1 [52544/250314 (21%)]\tLoss: 0.407372\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:09 | INFO | Rank 0 | Train Epoch: 1 [52576/250314 (21%)]\tLoss: 0.225971\tData (t) 0.268\tBatch (t) 0.479\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:10 | INFO | Rank 0 | Train Epoch: 1 [52608/250314 (21%)]\tLoss: 0.474145\tData (t) 0.306\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:10 | INFO | Rank 0 | Train Epoch: 1 [52640/250314 (21%)]\tLoss: 0.254738\tData (t) 0.264\tBatch (t) 0.476\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:11 | INFO | Rank 0 | Train Epoch: 1 [52672/250314 (21%)]\tLoss: 0.376598\tData (t) 0.295\tBatch (t) 0.507\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:11 | INFO | Rank 0 | Train Epoch: 1 [52704/250314 (21%)]\tLoss: 0.414844\tData (t) 0.231\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:12 | INFO | Rank 0 | Train Epoch: 1 [52736/250314 (21%)]\tLoss: 0.149319\tData (t) 0.244\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:12 | INFO | Rank 0 | Train Epoch: 1 [52768/250314 (21%)]\tLoss: 0.428169\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:13 | INFO | Rank 0 | Train Epoch: 1 [52800/250314 (21%)]\tLoss: 0.384726\tData (t) 0.261\tBatch (t) 0.473\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:13 | INFO | Rank 0 | Train Epoch: 1 [52832/250314 (21%)]\tLoss: 0.191450\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:14 | INFO | Rank 0 | Train Epoch: 1 [52864/250314 (21%)]\tLoss: 0.248498\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:14 | INFO | Rank 0 | Train Epoch: 1 [52896/250314 (21%)]\tLoss: 0.186680\tData (t) 0.257\tBatch (t) 0.469\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:15 | INFO | Rank 0 | Train Epoch: 1 [52928/250314 (21%)]\tLoss: 0.690946\tData (t) 0.287\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:15 | INFO | Rank 0 | Train Epoch: 1 [52960/250314 (21%)]\tLoss: 0.586674\tData (t) 0.345\tBatch (t) 0.557\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:16 | INFO | Rank 0 | Train Epoch: 1 [52992/250314 (21%)]\tLoss: 0.355067\tData (t) 0.253\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:16 | INFO | Rank 0 | Train Epoch: 1 [53024/250314 (21%)]\tLoss: 0.252862\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:17 | INFO | Rank 0 | Train Epoch: 1 [53056/250314 (21%)]\tLoss: 0.562047\tData (t) 0.297\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:17 | INFO | Rank 0 | Train Epoch: 1 [53088/250314 (21%)]\tLoss: 0.333501\tData (t) 0.241\tBatch (t) 0.455\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:18 | INFO | Rank 0 | Train Epoch: 1 [53120/250314 (21%)]\tLoss: 0.521089\tData (t) 0.230\tBatch (t) 0.444\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:18 | INFO | Rank 0 | Train Epoch: 1 [53152/250314 (21%)]\tLoss: 0.237755\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:19 | INFO | Rank 0 | Train Epoch: 1 [53184/250314 (21%)]\tLoss: 0.326491\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:19 | INFO | Rank 0 | Train Epoch: 1 [53216/250314 (21%)]\tLoss: 0.637791\tData (t) 0.316\tBatch (t) 0.528\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:20 | INFO | Rank 0 | Train Epoch: 1 [53248/250314 (21%)]\tLoss: 0.260867\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:20 | INFO | Rank 0 | Train Epoch: 1 [53280/250314 (21%)]\tLoss: 0.539257\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:21 | INFO | Rank 0 | Train Epoch: 1 [53312/250314 (21%)]\tLoss: 0.435082\tData (t) 0.253\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:21 | INFO | Rank 0 | Train Epoch: 1 [53344/250314 (21%)]\tLoss: 0.569595\tData (t) 0.243\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:21 | INFO | Rank 0 | Train Epoch: 1 [53376/250314 (21%)]\tLoss: 0.385127\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:22 | INFO | Rank 0 | Train Epoch: 1 [53408/250314 (21%)]\tLoss: 0.304944\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:22 | INFO | Rank 0 | Train Epoch: 1 [53440/250314 (21%)]\tLoss: 0.390892\tData (t) 0.289\tBatch (t) 0.502\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:23 | INFO | Rank 0 | Train Epoch: 1 [53472/250314 (21%)]\tLoss: 0.233714\tData (t) 0.329\tBatch (t) 0.541\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:23 | INFO | Rank 0 | Train Epoch: 1 [53504/250314 (21%)]\tLoss: 0.337279\tData (t) 0.273\tBatch (t) 0.485\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:24 | INFO | Rank 0 | Train Epoch: 1 [53536/250314 (21%)]\tLoss: 0.332903\tData (t) 0.245\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:24 | INFO | Rank 0 | Train Epoch: 1 [53568/250314 (21%)]\tLoss: 0.419116\tData (t) 0.339\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:25 | INFO | Rank 0 | Train Epoch: 1 [53600/250314 (21%)]\tLoss: 0.438726\tData (t) 0.239\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:25 | INFO | Rank 0 | Train Epoch: 1 [53632/250314 (21%)]\tLoss: 0.603991\tData (t) 0.245\tBatch (t) 0.456\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:26 | INFO | Rank 0 | Train Epoch: 1 [53664/250314 (21%)]\tLoss: 0.336677\tData (t) 0.250\tBatch (t) 0.462\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:26 | INFO | Rank 0 | Train Epoch: 1 [53696/250314 (21%)]\tLoss: 0.551583\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:27 | INFO | Rank 0 | Train Epoch: 1 [53728/250314 (21%)]\tLoss: 0.553541\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:27 | INFO | Rank 0 | Train Epoch: 1 [53760/250314 (21%)]\tLoss: 0.653059\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:28 | INFO | Rank 0 | Train Epoch: 1 [53792/250314 (21%)]\tLoss: 0.607584\tData (t) 0.251\tBatch (t) 0.464\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:28 | INFO | Rank 0 | Train Epoch: 1 [53824/250314 (22%)]\tLoss: 0.668319\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:29 | INFO | Rank 0 | Train Epoch: 1 [53856/250314 (22%)]\tLoss: 0.362327\tData (t) 0.241\tBatch (t) 0.453\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:29 | INFO | Rank 0 | Train Epoch: 1 [53888/250314 (22%)]\tLoss: 0.403916\tData (t) 0.254\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:30 | INFO | Rank 0 | Train Epoch: 1 [53920/250314 (22%)]\tLoss: 0.412215\tData (t) 0.314\tBatch (t) 0.526\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:30 | INFO | Rank 0 | Train Epoch: 1 [53952/250314 (22%)]\tLoss: 0.272139\tData (t) 0.228\tBatch (t) 0.440\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:31 | INFO | Rank 0 | Train Epoch: 1 [53984/250314 (22%)]\tLoss: 0.498692\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:31 | INFO | Rank 0 | Train Epoch: 1 [54016/250314 (22%)]\tLoss: 0.184596\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:32 | INFO | Rank 0 | Train Epoch: 1 [54048/250314 (22%)]\tLoss: 0.727715\tData (t) 0.259\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:32 | INFO | Rank 0 | Train Epoch: 1 [54080/250314 (22%)]\tLoss: 0.703732\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:33 | INFO | Rank 0 | Train Epoch: 1 [54112/250314 (22%)]\tLoss: 0.397451\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:33 | INFO | Rank 0 | Train Epoch: 1 [54144/250314 (22%)]\tLoss: 0.714520\tData (t) 0.240\tBatch (t) 0.451\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:34 | INFO | Rank 0 | Train Epoch: 1 [54176/250314 (22%)]\tLoss: 0.692436\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:34 | INFO | Rank 0 | Train Epoch: 1 [54208/250314 (22%)]\tLoss: 0.245251\tData (t) 0.339\tBatch (t) 0.551\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:35 | INFO | Rank 0 | Train Epoch: 1 [54240/250314 (22%)]\tLoss: 0.415997\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:35 | INFO | Rank 0 | Train Epoch: 1 [54272/250314 (22%)]\tLoss: 0.263230\tData (t) 0.206\tBatch (t) 0.418\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:35 | INFO | Rank 0 | Train Epoch: 1 [54304/250314 (22%)]\tLoss: 0.363466\tData (t) 0.225\tBatch (t) 0.437\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:36 | INFO | Rank 0 | Train Epoch: 1 [54336/250314 (22%)]\tLoss: 0.247044\tData (t) 0.263\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:36 | INFO | Rank 0 | Train Epoch: 1 [54368/250314 (22%)]\tLoss: 0.605523\tData (t) 0.289\tBatch (t) 0.501\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:37 | INFO | Rank 0 | Train Epoch: 1 [54400/250314 (22%)]\tLoss: 0.333300\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:37 | INFO | Rank 0 | Train Epoch: 1 [54432/250314 (22%)]\tLoss: 0.419631\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:38 | INFO | Rank 0 | Train Epoch: 1 [54464/250314 (22%)]\tLoss: 0.460472\tData (t) 0.248\tBatch (t) 0.460\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:38 | INFO | Rank 0 | Train Epoch: 1 [54496/250314 (22%)]\tLoss: 0.428582\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:39 | INFO | Rank 0 | Train Epoch: 1 [54528/250314 (22%)]\tLoss: 0.371517\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:39 | INFO | Rank 0 | Train Epoch: 1 [54560/250314 (22%)]\tLoss: 0.745433\tData (t) 0.286\tBatch (t) 0.498\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:40 | INFO | Rank 0 | Train Epoch: 1 [54592/250314 (22%)]\tLoss: 0.300494\tData (t) 0.229\tBatch (t) 0.441\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:40 | INFO | Rank 0 | Train Epoch: 1 [54624/250314 (22%)]\tLoss: 0.373943\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:41 | INFO | Rank 0 | Train Epoch: 1 [54656/250314 (22%)]\tLoss: 0.324836\tData (t) 0.249\tBatch (t) 0.461\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:41 | INFO | Rank 0 | Train Epoch: 1 [54688/250314 (22%)]\tLoss: 0.403494\tData (t) 0.320\tBatch (t) 0.532\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:42 | INFO | Rank 0 | Train Epoch: 1 [54720/250314 (22%)]\tLoss: 0.464655\tData (t) 0.307\tBatch (t) 0.519\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:42 | INFO | Rank 0 | Train Epoch: 1 [54752/250314 (22%)]\tLoss: 0.436499\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:43 | INFO | Rank 0 | Train Epoch: 1 [54784/250314 (22%)]\tLoss: 0.846748\tData (t) 0.235\tBatch (t) 0.447\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:43 | INFO | Rank 0 | Train Epoch: 1 [54816/250314 (22%)]\tLoss: 0.350180\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:44 | INFO | Rank 0 | Train Epoch: 1 [54848/250314 (22%)]\tLoss: 0.334675\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:44 | INFO | Rank 0 | Train Epoch: 1 [54880/250314 (22%)]\tLoss: 0.667634\tData (t) 0.255\tBatch (t) 0.466\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:45 | INFO | Rank 0 | Train Epoch: 1 [54912/250314 (22%)]\tLoss: 0.274400\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:45 | INFO | Rank 0 | Train Epoch: 1 [54944/250314 (22%)]\tLoss: 0.344401\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:46 | INFO | Rank 0 | Train Epoch: 1 [54976/250314 (22%)]\tLoss: 0.441963\tData (t) 0.230\tBatch (t) 0.442\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:46 | INFO | Rank 0 | Train Epoch: 1 [55008/250314 (22%)]\tLoss: 0.404017\tData (t) 0.242\tBatch (t) 0.454\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:47 | INFO | Rank 0 | Train Epoch: 1 [55040/250314 (22%)]\tLoss: 0.503847\tData (t) 0.296\tBatch (t) 0.508\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:47 | INFO | Rank 0 | Train Epoch: 1 [55072/250314 (22%)]\tLoss: 0.337002\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:48 | INFO | Rank 0 | Train Epoch: 1 [55104/250314 (22%)]\tLoss: 0.526204\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:48 | INFO | Rank 0 | Train Epoch: 1 [55136/250314 (22%)]\tLoss: 0.509380\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:48 | INFO | Rank 0 | Train Epoch: 1 [55168/250314 (22%)]\tLoss: 0.741515\tData (t) 0.238\tBatch (t) 0.450\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:49 | INFO | Rank 0 | Train Epoch: 1 [55200/250314 (22%)]\tLoss: 0.601898\tData (t) 0.215\tBatch (t) 0.428\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:49 | INFO | Rank 0 | Train Epoch: 1 [55232/250314 (22%)]\tLoss: 0.229048\tData (t) 0.234\tBatch (t) 0.446\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:50 | INFO | Rank 0 | Train Epoch: 1 [55264/250314 (22%)]\tLoss: 0.457544\tData (t) 0.306\tBatch (t) 0.518\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:50 | INFO | Rank 0 | Train Epoch: 1 [55296/250314 (22%)]\tLoss: 0.482314\tData (t) 0.282\tBatch (t) 0.494\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:51 | INFO | Rank 0 | Train Epoch: 1 [55328/250314 (22%)]\tLoss: 0.208245\tData (t) 0.254\tBatch (t) 0.465\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:51 | INFO | Rank 0 | Train Epoch: 1 [55360/250314 (22%)]\tLoss: 0.569616\tData (t) 0.294\tBatch (t) 0.505\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:52 | INFO | Rank 0 | Train Epoch: 1 [55392/250314 (22%)]\tLoss: 0.475148\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:52 | INFO | Rank 0 | Train Epoch: 1 [55424/250314 (22%)]\tLoss: 0.563046\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:53 | INFO | Rank 0 | Train Epoch: 1 [55456/250314 (22%)]\tLoss: 0.366741\tData (t) 0.283\tBatch (t) 0.495\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:53 | INFO | Rank 0 | Train Epoch: 1 [55488/250314 (22%)]\tLoss: 0.346882\tData (t) 0.278\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:54 | INFO | Rank 0 | Train Epoch: 1 [55520/250314 (22%)]\tLoss: 0.883415\tData (t) 0.280\tBatch (t) 0.492\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:54 | INFO | Rank 0 | Train Epoch: 1 [55552/250314 (22%)]\tLoss: 0.581500\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:55 | INFO | Rank 0 | Train Epoch: 1 [55584/250314 (22%)]\tLoss: 0.243645\tData (t) 0.302\tBatch (t) 0.514\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:55 | INFO | Rank 0 | Train Epoch: 1 [55616/250314 (22%)]\tLoss: 0.399630\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:56 | INFO | Rank 0 | Train Epoch: 1 [55648/250314 (22%)]\tLoss: 0.369237\tData (t) 0.330\tBatch (t) 0.542\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:56 | INFO | Rank 0 | Train Epoch: 1 [55680/250314 (22%)]\tLoss: 0.347488\tData (t) 0.222\tBatch (t) 0.434\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:57 | INFO | Rank 0 | Train Epoch: 1 [55712/250314 (22%)]\tLoss: 0.419535\tData (t) 0.272\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:57 | INFO | Rank 0 | Train Epoch: 1 [55744/250314 (22%)]\tLoss: 0.270923\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:58 | INFO | Rank 0 | Train Epoch: 1 [55776/250314 (22%)]\tLoss: 0.510390\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:58 | INFO | Rank 0 | Train Epoch: 1 [55808/250314 (22%)]\tLoss: 0.362804\tData (t) 0.255\tBatch (t) 0.467\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:59 | INFO | Rank 0 | Train Epoch: 1 [55840/250314 (22%)]\tLoss: 0.251547\tData (t) 0.259\tBatch (t) 0.471\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:33:59 | INFO | Rank 0 | Train Epoch: 1 [55872/250314 (22%)]\tLoss: 0.407102\tData (t) 0.279\tBatch (t) 0.490\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:00 | INFO | Rank 0 | Train Epoch: 1 [55904/250314 (22%)]\tLoss: 0.334657\tData (t) 0.260\tBatch (t) 0.472\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:00 | INFO | Rank 0 | Train Epoch: 1 [55936/250314 (22%)]\tLoss: 0.581001\tData (t) 0.219\tBatch (t) 0.430\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:01 | INFO | Rank 0 | Train Epoch: 1 [55968/250314 (22%)]\tLoss: 0.715333\tData (t) 0.285\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:01 | INFO | Rank 0 | Train Epoch: 1 [56000/250314 (22%)]\tLoss: 0.501644\tData (t) 0.311\tBatch (t) 0.523\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:01 | INFO | Rank 0 | Train Epoch: 1 [56032/250314 (22%)]\tLoss: 0.219249\tData (t) 0.207\tBatch (t) 0.419\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:02 | INFO | Rank 0 | Train Epoch: 1 [56064/250314 (22%)]\tLoss: 0.392673\tData (t) 0.258\tBatch (t) 0.470\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:02 | INFO | Rank 0 | Train Epoch: 1 [56096/250314 (22%)]\tLoss: 0.401192\tData (t) 0.275\tBatch (t) 0.487\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:03 | INFO | Rank 0 | Train Epoch: 1 [56128/250314 (22%)]\tLoss: 0.221045\tData (t) 0.274\tBatch (t) 0.486\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:03 | INFO | Rank 0 | Train Epoch: 1 [56160/250314 (22%)]\tLoss: 0.647108\tData (t) 0.288\tBatch (t) 0.500\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:04 | INFO | Rank 0 | Train Epoch: 1 [56192/250314 (22%)]\tLoss: 0.630526\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:04 | INFO | Rank 0 | Train Epoch: 1 [56224/250314 (22%)]\tLoss: 0.462070\tData (t) 0.304\tBatch (t) 0.516\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:05 | INFO | Rank 0 | Train Epoch: 1 [56256/250314 (22%)]\tLoss: 0.422060\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:05 | INFO | Rank 0 | Train Epoch: 1 [56288/250314 (22%)]\tLoss: 0.283818\tData (t) 0.301\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:06 | INFO | Rank 0 | Train Epoch: 1 [56320/250314 (23%)]\tLoss: 0.395721\tData (t) 0.294\tBatch (t) 0.506\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:06 | INFO | Rank 0 | Train Epoch: 1 [56352/250314 (23%)]\tLoss: 0.460337\tData (t) 0.273\tBatch (t) 0.484\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:07 | INFO | Rank 0 | Train Epoch: 1 [56384/250314 (23%)]\tLoss: 0.473787\tData (t) 0.200\tBatch (t) 0.412\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:07 | INFO | Rank 0 | Train Epoch: 1 [56416/250314 (23%)]\tLoss: 0.308371\tData (t) 0.224\tBatch (t) 0.436\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:08 | INFO | Rank 0 | Train Epoch: 1 [56448/250314 (23%)]\tLoss: 0.352678\tData (t) 0.276\tBatch (t) 0.488\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:08 | INFO | Rank 0 | Train Epoch: 1 [56480/250314 (23%)]\tLoss: 0.637337\tData (t) 0.305\tBatch (t) 0.517\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:09 | INFO | Rank 0 | Train Epoch: 1 [56512/250314 (23%)]\tLoss: 0.517945\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:09 | INFO | Rank 0 | Train Epoch: 1 [56544/250314 (23%)]\tLoss: 0.394379\tData (t) 0.284\tBatch (t) 0.497\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:10 | INFO | Rank 0 | Train Epoch: 1 [56576/250314 (23%)]\tLoss: 0.475660\tData (t) 0.271\tBatch (t) 0.483\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:10 | INFO | Rank 0 | Train Epoch: 1 [56608/250314 (23%)]\tLoss: 0.513299\tData (t) 0.309\tBatch (t) 0.521\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:11 | INFO | Rank 0 | Train Epoch: 1 [56640/250314 (23%)]\tLoss: 0.664901\tData (t) 0.270\tBatch (t) 0.482\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:11 | INFO | Rank 0 | Train Epoch: 1 [56672/250314 (23%)]\tLoss: 0.098341\tData (t) 0.214\tBatch (t) 0.426\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:12 | INFO | Rank 0 | Train Epoch: 1 [56704/250314 (23%)]\tLoss: 0.307328\tData (t) 0.203\tBatch (t) 0.415\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:12 | INFO | Rank 0 | Train Epoch: 1 [56736/250314 (23%)]\tLoss: 0.589811\tData (t) 0.264\tBatch (t) 0.475\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:13 | INFO | Rank 0 | Train Epoch: 1 [56768/250314 (23%)]\tLoss: 0.374598\tData (t) 0.279\tBatch (t) 0.491\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:13 | INFO | Rank 0 | Train Epoch: 1 [56800/250314 (23%)]\tLoss: 0.198363\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:13 | INFO | Rank 0 | Train Epoch: 1 [56832/250314 (23%)]\tLoss: 0.187155\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:14 | INFO | Rank 0 | Train Epoch: 1 [56864/250314 (23%)]\tLoss: 0.314249\tData (t) 0.277\tBatch (t) 0.489\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:14 | INFO | Rank 0 | Train Epoch: 1 [56896/250314 (23%)]\tLoss: 0.414357\tData (t) 0.265\tBatch (t) 0.477\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:15 | INFO | Rank 0 | Train Epoch: 1 [56928/250314 (23%)]\tLoss: 0.557319\tData (t) 0.269\tBatch (t) 0.481\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:15 | INFO | Rank 0 | Train Epoch: 1 [56960/250314 (23%)]\tLoss: 0.513371\tData (t) 0.236\tBatch (t) 0.448\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:16 | INFO | Rank 0 | Train Epoch: 1 [56992/250314 (23%)]\tLoss: 0.492641\tData (t) 0.244\tBatch (t) 0.457\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:16 | INFO | Rank 0 | Train Epoch: 1 [57024/250314 (23%)]\tLoss: 0.363298\tData (t) 0.204\tBatch (t) 0.416\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:17 | INFO | Rank 0 | Train Epoch: 1 [57056/250314 (23%)]\tLoss: 0.496245\tData (t) 0.302\tBatch (t) 0.513\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:17 | INFO | Rank 0 | Train Epoch: 1 [57088/250314 (23%)]\tLoss: 0.335423\tData (t) 0.227\tBatch (t) 0.439\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:18 | INFO | Rank 0 | Train Epoch: 1 [57120/250314 (23%)]\tLoss: 0.480214\tData (t) 0.297\tBatch (t) 0.509\tLR: 0.000010\tlogit_scale 4.586\n",
      "2022-11-09,14:34:18 | INFO | Rank 0 | Train Epoch: 1 [57152/250314 (23%)]\tLoss: 0.519530\tData (t) 0.291\tBatch (t) 0.503\tLR: 0.000010\tlogit_scale 4.586\n"
     ]
    }
   ],
   "source": [
    "!python3 -u src/training/main.py \\\n",
    "    --save-frequency 2 \\\n",
    "    --train-data=\"./data/Multimodal_Retrieval/MR_train_queries.jsonl\"  \\\n",
    "    --train-img=\"/data/nxy/Multimodal_Retrieval/train/\"  \\\n",
    "    --val-data=\"./data/Multimodal_Retrieval/MR_valid_queries.jsonl\"  \\\n",
    "    --val-img=\"/data/nxy/Multimodal_Retrieval/valid/\"  \\\n",
    "    --clip-weight-path=\"./weights/ViT-B-16.state_dict.pt\" \\\n",
    "    --bert-weight-path=\"./weights/pytorch_model.bin\" \\\n",
    "    --warmup 500 \\\n",
    "    --batch-size=32 \\\n",
    "    --lr=1e-5 \\\n",
    "    --wd=0.001 \\\n",
    "    --epochs=10 \\\n",
    "    --model ViT-B-16 \\\n",
    "    --gpu 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b7387-95b6-48d7-b356-739fbcacf1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
