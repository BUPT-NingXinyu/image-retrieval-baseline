{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting numpy==1.19.2\n",
      "  Downloading numpy-1.19.2-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 12.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch==1.7.1\n",
      "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 776.8 MB 10.3 MB/s eta 0:00:01     |████▊                           | 114.0 MB 12.0 MB/s eta 0:00:56     |███████▎                        | 176.4 MB 10.5 MB/s eta 0:00:58     |█████████▉                      | 239.4 MB 12.0 MB/s eta 0:00:45     |█████████████████▌              | 425.8 MB 11.2 MB/s eta 0:00:32     |█████████████████▋              | 427.6 MB 11.2 MB/s eta 0:00:32     |███████████████████████▉        | 579.0 MB 10.2 MB/s eta 0:00:20     |██████████████████████████▊     | 648.7 MB 10.2 MB/s eta 0:00:13     |██████████████████████████▊     | 649.9 MB 10.2 MB/s eta 0:00:13     |███████████████████████████▊    | 672.3 MB 12.0 MB/s eta 0:00:09\n",
      "\u001b[?25hCollecting torchvision==0.8.2\n",
      "  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 12.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/nxy/anaconda3/envs/open-mmlab/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (4.64.0)\n",
      "Requirement already satisfied: six in /home/nxy/anaconda3/envs/open-mmlab/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions in /home/nxy/anaconda3/envs/open-mmlab/lib/python3.7/site-packages (from torch==1.7.1->-r requirements.txt (line 2)) (4.1.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/nxy/anaconda3/envs/open-mmlab/lib/python3.7/site-packages (from torchvision==0.8.2->-r requirements.txt (line 3)) (9.0.1)\n",
      "Installing collected packages: numpy, torch, torchvision\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0\n",
      "    Uninstalling torch-1.11.0:\n",
      "      Successfully uninstalled torch-1.11.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.12.0\n",
      "    Uninstalling torchvision-0.12.0:\n",
      "      Successfully uninstalled torchvision-0.12.0\n",
      "Successfully installed numpy-1.19.2 torch-1.7.1 torchvision-0.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "***不要下openai的CLIP，baseline代码已经把CLIP打包好了，如果有问题要注意一下是不是相对路径的问题***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ftfy regex tqdm\n",
    "#!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解压数据集和权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./Multimodal_Retrieval.zip\n",
      "   creating: ./data/Multimodal_Retrieval/\n",
      "  inflating: ./data/__MACOSX/._Multimodal_Retrieval  \n",
      "  inflating: ./data/Multimodal_Retrieval/MR_train_imgs.tsv  \n",
      "  inflating: ./data/Multimodal_Retrieval/MR_test_queries.jsonl  \n",
      "  inflating: ./data/__MACOSX/Multimodal_Retrieval/._MR_test_queries.jsonl  \n",
      "  inflating: ./data/Multimodal_Retrieval/MR_train_queries.jsonl  \n",
      "  inflating: ./data/Multimodal_Retrieval/MR_valid_queries.jsonl  \n",
      "  inflating: ./data/Multimodal_Retrieval/README.txt  \n",
      "  inflating: ./data/Multimodal_Retrieval/example_pred.jsonl  \n",
      "  inflating: ./data/Multimodal_Retrieval/MR_valid_imgs.tsv  \n",
      "  inflating: ./data/Multimodal_Retrieval/MR_test_imgs.tsv  \n"
     ]
    }
   ],
   "source": [
    "!unzip -d ./data ./Multimodal_Retrieval.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./weights/chinese_roberta_wwm_large_ext_pytorch.zip\n",
      "  inflating: ./weights/pytorch_model.bin  \n",
      "  inflating: ./weights/vocab.txt     \n",
      "  inflating: ./weights/bert_config.json  \n"
     ]
    }
   ],
   "source": [
    "!unzip -d ./weights ./weights/chinese_roberta_wwm_large_ext_pytorch.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备 CLIP 和 BERT 权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params:\n",
      "  new_ckpt_path: ./weights/ViT-B-16.state_dict.pt\n",
      "  raw_ckpt_path: ./weights/ViT-B-16.pt\n",
      "Transformed openai ckpt ./weights/ViT-B-16.pt to ./weights/ViT-B-16.state_dict.pt!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python3 src/preprocess/transform_openai_pretrain_weights.py --raw-ckpt-path ./weights/ViT-B-16.pt --new-ckpt-path ./weights/ViT-B-16.state_dict.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备图片数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to transform train split\n",
      "12000it [00:13, 888.18it/s]\n",
      "finished transforming 12000 images for train split, the output is saved at ./data/Multimodal_Retrieval/MR_train_imgs.224.npz\n",
      "begin to transform valid split\n",
      "12000it [00:15, 798.21it/s]\n",
      "finished transforming 12000 images for valid split, the output is saved at ./data/Multimodal_Retrieval/MR_valid_imgs.224.npz\n",
      "begin to transform test split\n",
      "12000it [00:16, 713.72it/s]\n",
      "finished transforming 12000 images for test split, the output is saved at ./data/Multimodal_Retrieval/MR_test_imgs.224.npz\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "!python3 src/preprocess/transform_images.py --data_dir ./data/Multimodal_Retrieval --image_resolution 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total train imgs is  129380\n",
      "The total val imgs is  29806\n",
      "The total test imgs is  30399\n"
     ]
    }
   ],
   "source": [
    "filename='./data/Multimodal_Retrieval/MR_train_imgs.tsv'   #文件路径\n",
    "total = len(open(filename).readlines())\n",
    "print('The total train imgs is ',total)\n",
    "\n",
    "filename='./data/Multimodal_Retrieval/MR_valid_imgs.tsv'   #文件路径\n",
    "total = len(open(filename).readlines())\n",
    "print('The total val imgs is ',total)\n",
    "\n",
    "filename='./data/Multimodal_Retrieval/MR_test_imgs.tsv'   #文件路径\n",
    "total = len(open(filename).readlines())\n",
    "print('The total test imgs is ',total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 由于我们使用的是不完全数据集，所以要把标注文件和不完全数据集对齐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "248786it [00:57, 4301.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小数据集的query-相关商品对数量： 23481\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "img_filename = \"./data/Multimodal_Retrieval/MR_train_imgs.224.npz\"\n",
    "jsonl_filename = \"./data/Multimodal_Retrieval/MR_train_queries.jsonl\"\n",
    "tiny_jsonl_filename = \"./data/Multimodal_Retrieval/MR_train_queries_tiny.jsonl\"\n",
    "\n",
    "imgs = np.load(img_filename, \"r\")\n",
    "\n",
    "all_new_json = []\n",
    "\n",
    "with open(jsonl_filename, \"r\") as fin:\n",
    "    for line in tqdm(fin):\n",
    "        new_json_line = {}\n",
    "        obj = json.loads(line.strip())\n",
    "        new_json_line['query_id'] = obj['query_id']\n",
    "        new_json_line['query_text'] = obj['query_text']\n",
    "        new_json_line['item_ids'] = []\n",
    "        for target in obj['item_ids']:\n",
    "            #print(imgs[str(img_id)])\n",
    "            if(str(target) in imgs):\n",
    "                new_json_line['item_ids'].append(target)\n",
    "        if(len(new_json_line['item_ids'])>0):\n",
    "            all_new_json.append(new_json_line)\n",
    "    \n",
    "print('小数据集的query-相关商品对数量：',len(all_new_json))\n",
    "\n",
    "with open(tiny_jsonl_filename,'w') as f:\n",
    "    for i in range(len(all_new_json)):\n",
    "        f.write(json.dumps(all_new_json[i], ensure_ascii=False))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5008it [00:12, 416.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小数据集的query-相关商品对数量： 4750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 验证集\n",
    "img_filename = \"./data/Multimodal_Retrieval/MR_valid_imgs.224.npz\"\n",
    "jsonl_filename = \"./data/Multimodal_Retrieval/MR_valid_queries.jsonl\"\n",
    "tiny_jsonl_filename = \"./data/Multimodal_Retrieval/MR_valid_queries_tiny.jsonl\"\n",
    "\n",
    "imgs = np.load(img_filename, \"r\")\n",
    "\n",
    "all_new_json = []\n",
    "\n",
    "with open(jsonl_filename, \"r\") as fin:\n",
    "    for line in tqdm(fin):\n",
    "        new_json_line = {}\n",
    "        obj = json.loads(line.strip())\n",
    "        new_json_line['query_id'] = obj['query_id']\n",
    "        new_json_line['query_text'] = obj['query_text']\n",
    "        new_json_line['item_ids'] = []\n",
    "        for target in obj['item_ids']:\n",
    "            #print(imgs[str(img_id)])\n",
    "            if(str(target) in imgs):\n",
    "                new_json_line['item_ids'].append(target)\n",
    "        if(len(new_json_line['item_ids'])>0):\n",
    "            all_new_json.append(new_json_line)\n",
    "    \n",
    "print('小数据集的query-相关商品对数量：',len(all_new_json))\n",
    "\n",
    "with open(tiny_jsonl_filename,'w') as f:\n",
    "    for i in range(len(all_new_json)):\n",
    "        #f.write(str(all_new_json[i]))\n",
    "        f.write(json.dumps(all_new_json[i], ensure_ascii=False))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from src/training/model_configs/ViT-B-16.json\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 | Params:\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   aggregate: True\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   batch_size: 32\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   bert_weight_path: ./weights/pytorch_model.bin\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   beta1: 0.9\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   beta2: 0.98\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   checkpoint_path: ./logs/lr=8e-05_wd=0.001_agg=True_model=ViT-B-16_batchsize=32_date=2022-11-08-05-23-55/checkpoints\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   clip_weight_path: ./weights/ViT-B-16.state_dict.pt\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   copy_codebase: False\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   debug: False\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   dist_backend: nccl\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   dist_url: tcp://127.0.0.1:6100\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   distributed: False\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   dp: False\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   epochs: 10\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   eps: 1e-06\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   gpu: 0\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   log_level: 20\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   log_path: ./logs/lr=8e-05_wd=0.001_agg=True_model=ViT-B-16_batchsize=32_date=2022-11-08-05-23-55/out.log\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   logs: ./logs/\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   lr: 8e-05\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   model: ViT-B-16\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   multigpu: None\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   name: lr=8e-05_wd=0.001_agg=True_model=ViT-B-16_batchsize=32_date=2022-11-08-05-23-55\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   ngpus_per_node: 1\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   precision: amp\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   rank: 0\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   resume: None\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   save_frequency: 5\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   save_most_recent: False\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   skip_aggregate: False\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   skip_scheduler: False\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   train_data: ./data/Multimodal_Retrieval/MR_train_queries_tiny.jsonl\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   train_img: ./data/Multimodal_Retrieval/MR_train_imgs.224.npz\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   use_bn_sync: False\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   val_data: ./data/Multimodal_Retrieval/MR_valid_queries_tiny.jsonl\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   val_img: ./data/Multimodal_Retrieval/MR_valid_imgs.224.npz\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   warmup: 500\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   wd: 0.001\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 |   world_size: 1\n",
      "2022-11-08,05:23:55 | INFO | Rank 0 | Use GPU: 0 for training\n",
      "2022-11-08,05:24:01 | INFO | Rank 0 | Start epoch 0\n",
      "2022-11-08,05:24:03 | INFO | Rank 0 | Train Epoch: 0 [0/23491 (0%)]\tLoss: 5.642319\tData (t) 0.044\tBatch (t) 2.054\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-08,05:24:04 | INFO | Rank 0 | Train Epoch: 0 [32/23491 (0%)]\tLoss: 5.912613\tData (t) 0.049\tBatch (t) 0.218\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-08,05:24:04 | INFO | Rank 0 | Train Epoch: 0 [64/23491 (0%)]\tLoss: 4.783478\tData (t) 0.037\tBatch (t) 0.203\tLR: 0.000000\tlogit_scale 4.605\n",
      "2022-11-08,05:24:04 | INFO | Rank 0 | Train Epoch: 0 [96/23491 (0%)]\tLoss: 5.184380\tData (t) 0.035\tBatch (t) 0.201\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-08,05:24:04 | INFO | Rank 0 | Train Epoch: 0 [128/23491 (1%)]\tLoss: 5.985443\tData (t) 0.035\tBatch (t) 0.201\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-08,05:24:05 | INFO | Rank 0 | Train Epoch: 0 [160/23491 (1%)]\tLoss: 5.150528\tData (t) 0.035\tBatch (t) 0.251\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-08,05:24:05 | INFO | Rank 0 | Train Epoch: 0 [192/23491 (1%)]\tLoss: 5.347046\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-08,05:24:05 | INFO | Rank 0 | Train Epoch: 0 [224/23491 (1%)]\tLoss: 5.655273\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-08,05:24:05 | INFO | Rank 0 | Train Epoch: 0 [256/23491 (1%)]\tLoss: 5.302368\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000001\tlogit_scale 4.605\n",
      "2022-11-08,05:24:06 | INFO | Rank 0 | Train Epoch: 0 [288/23491 (1%)]\tLoss: 5.037308\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-08,05:24:06 | INFO | Rank 0 | Train Epoch: 0 [320/23491 (1%)]\tLoss: 5.388290\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-08,05:24:06 | INFO | Rank 0 | Train Epoch: 0 [352/23491 (1%)]\tLoss: 5.182285\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-08,05:24:06 | INFO | Rank 0 | Train Epoch: 0 [384/23491 (2%)]\tLoss: 4.966568\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-08,05:24:07 | INFO | Rank 0 | Train Epoch: 0 [416/23491 (2%)]\tLoss: 5.070984\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-08,05:24:07 | INFO | Rank 0 | Train Epoch: 0 [448/23491 (2%)]\tLoss: 5.307590\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000002\tlogit_scale 4.605\n",
      "2022-11-08,05:24:07 | INFO | Rank 0 | Train Epoch: 0 [480/23491 (2%)]\tLoss: 5.039108\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-08,05:24:07 | INFO | Rank 0 | Train Epoch: 0 [512/23491 (2%)]\tLoss: 5.874115\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-08,05:24:08 | INFO | Rank 0 | Train Epoch: 0 [544/23491 (2%)]\tLoss: 4.328861\tData (t) 0.053\tBatch (t) 0.260\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-08,05:24:08 | INFO | Rank 0 | Train Epoch: 0 [576/23491 (2%)]\tLoss: 4.356865\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-08,05:24:08 | INFO | Rank 0 | Train Epoch: 0 [608/23491 (3%)]\tLoss: 4.625679\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-08,05:24:08 | INFO | Rank 0 | Train Epoch: 0 [640/23491 (3%)]\tLoss: 5.135585\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000003\tlogit_scale 4.605\n",
      "2022-11-08,05:24:09 | INFO | Rank 0 | Train Epoch: 0 [672/23491 (3%)]\tLoss: 4.530441\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-08,05:24:09 | INFO | Rank 0 | Train Epoch: 0 [704/23491 (3%)]\tLoss: 4.546352\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-08,05:24:09 | INFO | Rank 0 | Train Epoch: 0 [736/23491 (3%)]\tLoss: 4.557945\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-08,05:24:09 | INFO | Rank 0 | Train Epoch: 0 [768/23491 (3%)]\tLoss: 4.402100\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-08,05:24:10 | INFO | Rank 0 | Train Epoch: 0 [800/23491 (3%)]\tLoss: 4.706306\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-08,05:24:10 | INFO | Rank 0 | Train Epoch: 0 [832/23491 (4%)]\tLoss: 4.204819\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-08,05:24:10 | INFO | Rank 0 | Train Epoch: 0 [864/23491 (4%)]\tLoss: 4.324944\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000004\tlogit_scale 4.605\n",
      "2022-11-08,05:24:11 | INFO | Rank 0 | Train Epoch: 0 [896/23491 (4%)]\tLoss: 4.382706\tData (t) 0.053\tBatch (t) 0.260\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-08,05:24:11 | INFO | Rank 0 | Train Epoch: 0 [928/23491 (4%)]\tLoss: 4.426979\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-08,05:24:11 | INFO | Rank 0 | Train Epoch: 0 [960/23491 (4%)]\tLoss: 4.107506\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-08,05:24:11 | INFO | Rank 0 | Train Epoch: 0 [992/23491 (4%)]\tLoss: 4.076294\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-08,05:24:12 | INFO | Rank 0 | Train Epoch: 0 [1024/23491 (4%)]\tLoss: 4.267799\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-08,05:24:12 | INFO | Rank 0 | Train Epoch: 0 [1056/23491 (4%)]\tLoss: 3.920410\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000005\tlogit_scale 4.605\n",
      "2022-11-08,05:24:12 | INFO | Rank 0 | Train Epoch: 0 [1088/23491 (5%)]\tLoss: 4.226776\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-08,05:24:12 | INFO | Rank 0 | Train Epoch: 0 [1120/23491 (5%)]\tLoss: 3.967041\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-08,05:24:13 | INFO | Rank 0 | Train Epoch: 0 [1152/23491 (5%)]\tLoss: 3.883568\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-08,05:24:13 | INFO | Rank 0 | Train Epoch: 0 [1184/23491 (5%)]\tLoss: 3.908791\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-08,05:24:13 | INFO | Rank 0 | Train Epoch: 0 [1216/23491 (5%)]\tLoss: 3.815430\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-08,05:24:13 | INFO | Rank 0 | Train Epoch: 0 [1248/23491 (5%)]\tLoss: 3.813309\tData (t) 0.053\tBatch (t) 0.260\tLR: 0.000006\tlogit_scale 4.605\n",
      "2022-11-08,05:24:14 | INFO | Rank 0 | Train Epoch: 0 [1280/23491 (5%)]\tLoss: 3.519226\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-08,05:24:14 | INFO | Rank 0 | Train Epoch: 0 [1312/23491 (6%)]\tLoss: 3.707932\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-08,05:24:14 | INFO | Rank 0 | Train Epoch: 0 [1344/23491 (6%)]\tLoss: 3.723511\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-08,05:24:14 | INFO | Rank 0 | Train Epoch: 0 [1376/23491 (6%)]\tLoss: 3.377975\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-08,05:24:15 | INFO | Rank 0 | Train Epoch: 0 [1408/23491 (6%)]\tLoss: 3.401169\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-08,05:24:15 | INFO | Rank 0 | Train Epoch: 0 [1440/23491 (6%)]\tLoss: 3.422012\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000007\tlogit_scale 4.605\n",
      "2022-11-08,05:24:15 | INFO | Rank 0 | Train Epoch: 0 [1472/23491 (6%)]\tLoss: 3.429970\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000008\tlogit_scale 4.605\n",
      "2022-11-08,05:24:15 | INFO | Rank 0 | Train Epoch: 0 [1504/23491 (6%)]\tLoss: 3.449356\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000008\tlogit_scale 4.605\n",
      "2022-11-08,05:24:16 | INFO | Rank 0 | Train Epoch: 0 [1536/23491 (7%)]\tLoss: 3.510513\tData (t) 0.052\tBatch (t) 0.261\tLR: 0.000008\tlogit_scale 4.605\n",
      "2022-11-08,05:24:16 | INFO | Rank 0 | Train Epoch: 0 [1568/23491 (7%)]\tLoss: 3.522186\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000008\tlogit_scale 4.605\n",
      "2022-11-08,05:24:16 | INFO | Rank 0 | Train Epoch: 0 [1600/23491 (7%)]\tLoss: 3.453186\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000008\tlogit_scale 4.605\n",
      "2022-11-08,05:24:17 | INFO | Rank 0 | Train Epoch: 0 [1632/23491 (7%)]\tLoss: 3.201462\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000008\tlogit_scale 4.605\n",
      "2022-11-08,05:24:17 | INFO | Rank 0 | Train Epoch: 0 [1664/23491 (7%)]\tLoss: 3.288383\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000008\tlogit_scale 4.605\n",
      "2022-11-08,05:24:17 | INFO | Rank 0 | Train Epoch: 0 [1696/23491 (7%)]\tLoss: 3.215958\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000009\tlogit_scale 4.605\n",
      "2022-11-08,05:24:17 | INFO | Rank 0 | Train Epoch: 0 [1728/23491 (7%)]\tLoss: 3.195709\tData (t) 0.052\tBatch (t) 0.261\tLR: 0.000009\tlogit_scale 4.605\n",
      "2022-11-08,05:24:18 | INFO | Rank 0 | Train Epoch: 0 [1760/23491 (7%)]\tLoss: 3.330799\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000009\tlogit_scale 4.605\n",
      "2022-11-08,05:24:18 | INFO | Rank 0 | Train Epoch: 0 [1792/23491 (8%)]\tLoss: 3.284042\tData (t) 0.055\tBatch (t) 0.264\tLR: 0.000009\tlogit_scale 4.605\n",
      "2022-11-08,05:24:18 | INFO | Rank 0 | Train Epoch: 0 [1824/23491 (8%)]\tLoss: 3.291443\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000009\tlogit_scale 4.605\n",
      "2022-11-08,05:24:18 | INFO | Rank 0 | Train Epoch: 0 [1856/23491 (8%)]\tLoss: 3.156921\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000009\tlogit_scale 4.605\n",
      "2022-11-08,05:24:19 | INFO | Rank 0 | Train Epoch: 0 [1888/23491 (8%)]\tLoss: 3.035797\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000010\tlogit_scale 4.605\n",
      "2022-11-08,05:24:19 | INFO | Rank 0 | Train Epoch: 0 [1920/23491 (8%)]\tLoss: 2.876251\tData (t) 0.056\tBatch (t) 0.265\tLR: 0.000010\tlogit_scale 4.605\n",
      "2022-11-08,05:24:19 | INFO | Rank 0 | Train Epoch: 0 [1952/23491 (8%)]\tLoss: 3.259411\tData (t) 0.055\tBatch (t) 0.264\tLR: 0.000010\tlogit_scale 4.605\n",
      "2022-11-08,05:24:19 | INFO | Rank 0 | Train Epoch: 0 [1984/23491 (8%)]\tLoss: 3.156494\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000010\tlogit_scale 4.605\n",
      "2022-11-08,05:24:20 | INFO | Rank 0 | Train Epoch: 0 [2016/23491 (9%)]\tLoss: 2.856918\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000010\tlogit_scale 4.605\n",
      "2022-11-08,05:24:20 | INFO | Rank 0 | Train Epoch: 0 [2048/23491 (9%)]\tLoss: 3.209534\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000010\tlogit_scale 4.605\n",
      "2022-11-08,05:24:20 | INFO | Rank 0 | Train Epoch: 0 [2080/23491 (9%)]\tLoss: 3.162170\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000011\tlogit_scale 4.605\n",
      "2022-11-08,05:24:20 | INFO | Rank 0 | Train Epoch: 0 [2112/23491 (9%)]\tLoss: 3.212753\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000011\tlogit_scale 4.605\n",
      "2022-11-08,05:24:21 | INFO | Rank 0 | Train Epoch: 0 [2144/23491 (9%)]\tLoss: 3.018188\tData (t) 0.052\tBatch (t) 0.262\tLR: 0.000011\tlogit_scale 4.605\n",
      "2022-11-08,05:24:21 | INFO | Rank 0 | Train Epoch: 0 [2176/23491 (9%)]\tLoss: 3.008118\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000011\tlogit_scale 4.605\n",
      "2022-11-08,05:24:21 | INFO | Rank 0 | Train Epoch: 0 [2208/23491 (9%)]\tLoss: 3.257454\tData (t) 0.054\tBatch (t) 0.263\tLR: 0.000011\tlogit_scale 4.605\n",
      "2022-11-08,05:24:21 | INFO | Rank 0 | Train Epoch: 0 [2240/23491 (10%)]\tLoss: 2.903023\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000011\tlogit_scale 4.605\n",
      "2022-11-08,05:24:22 | INFO | Rank 0 | Train Epoch: 0 [2272/23491 (10%)]\tLoss: 3.081955\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000012\tlogit_scale 4.605\n",
      "2022-11-08,05:24:22 | INFO | Rank 0 | Train Epoch: 0 [2304/23491 (10%)]\tLoss: 2.608269\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000012\tlogit_scale 4.605\n",
      "2022-11-08,05:24:22 | INFO | Rank 0 | Train Epoch: 0 [2336/23491 (10%)]\tLoss: 2.968948\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000012\tlogit_scale 4.605\n",
      "2022-11-08,05:24:23 | INFO | Rank 0 | Train Epoch: 0 [2368/23491 (10%)]\tLoss: 2.997131\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000012\tlogit_scale 4.605\n",
      "2022-11-08,05:24:23 | INFO | Rank 0 | Train Epoch: 0 [2400/23491 (10%)]\tLoss: 2.892944\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000012\tlogit_scale 4.605\n",
      "2022-11-08,05:24:23 | INFO | Rank 0 | Train Epoch: 0 [2432/23491 (10%)]\tLoss: 2.712975\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000012\tlogit_scale 4.605\n",
      "2022-11-08,05:24:23 | INFO | Rank 0 | Train Epoch: 0 [2464/23491 (10%)]\tLoss: 2.720711\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000012\tlogit_scale 4.605\n",
      "2022-11-08,05:24:24 | INFO | Rank 0 | Train Epoch: 0 [2496/23491 (11%)]\tLoss: 2.757792\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000013\tlogit_scale 4.605\n",
      "2022-11-08,05:24:24 | INFO | Rank 0 | Train Epoch: 0 [2528/23491 (11%)]\tLoss: 2.565517\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000013\tlogit_scale 4.605\n",
      "2022-11-08,05:24:24 | INFO | Rank 0 | Train Epoch: 0 [2560/23491 (11%)]\tLoss: 2.876587\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000013\tlogit_scale 4.605\n",
      "2022-11-08,05:24:24 | INFO | Rank 0 | Train Epoch: 0 [2592/23491 (11%)]\tLoss: 2.766487\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000013\tlogit_scale 4.605\n",
      "2022-11-08,05:24:25 | INFO | Rank 0 | Train Epoch: 0 [2624/23491 (11%)]\tLoss: 2.983192\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000013\tlogit_scale 4.605\n",
      "2022-11-08,05:24:25 | INFO | Rank 0 | Train Epoch: 0 [2656/23491 (11%)]\tLoss: 2.807690\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000013\tlogit_scale 4.605\n",
      "2022-11-08,05:24:25 | INFO | Rank 0 | Train Epoch: 0 [2688/23491 (11%)]\tLoss: 2.752586\tData (t) 0.052\tBatch (t) 0.261\tLR: 0.000014\tlogit_scale 4.605\n",
      "2022-11-08,05:24:25 | INFO | Rank 0 | Train Epoch: 0 [2720/23491 (12%)]\tLoss: 2.459885\tData (t) 0.052\tBatch (t) 0.261\tLR: 0.000014\tlogit_scale 4.605\n",
      "2022-11-08,05:24:26 | INFO | Rank 0 | Train Epoch: 0 [2752/23491 (12%)]\tLoss: 2.477995\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000014\tlogit_scale 4.605\n",
      "2022-11-08,05:24:26 | INFO | Rank 0 | Train Epoch: 0 [2784/23491 (12%)]\tLoss: 2.585934\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000014\tlogit_scale 4.605\n",
      "2022-11-08,05:24:26 | INFO | Rank 0 | Train Epoch: 0 [2816/23491 (12%)]\tLoss: 2.389385\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000014\tlogit_scale 4.605\n",
      "2022-11-08,05:24:26 | INFO | Rank 0 | Train Epoch: 0 [2848/23491 (12%)]\tLoss: 2.432270\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000014\tlogit_scale 4.605\n",
      "2022-11-08,05:24:27 | INFO | Rank 0 | Train Epoch: 0 [2880/23491 (12%)]\tLoss: 2.802254\tData (t) 0.052\tBatch (t) 0.261\tLR: 0.000015\tlogit_scale 4.605\n",
      "2022-11-08,05:24:27 | INFO | Rank 0 | Train Epoch: 0 [2912/23491 (12%)]\tLoss: 2.468254\tData (t) 0.052\tBatch (t) 0.261\tLR: 0.000015\tlogit_scale 4.605\n",
      "2022-11-08,05:24:27 | INFO | Rank 0 | Train Epoch: 0 [2944/23491 (13%)]\tLoss: 2.752701\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000015\tlogit_scale 4.605\n",
      "2022-11-08,05:24:28 | INFO | Rank 0 | Train Epoch: 0 [2976/23491 (13%)]\tLoss: 2.665707\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000015\tlogit_scale 4.605\n",
      "2022-11-08,05:24:28 | INFO | Rank 0 | Train Epoch: 0 [3008/23491 (13%)]\tLoss: 2.531471\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000015\tlogit_scale 4.605\n",
      "2022-11-08,05:24:28 | INFO | Rank 0 | Train Epoch: 0 [3040/23491 (13%)]\tLoss: 2.168857\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000015\tlogit_scale 4.605\n",
      "2022-11-08,05:24:28 | INFO | Rank 0 | Train Epoch: 0 [3072/23491 (13%)]\tLoss: 2.284463\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000016\tlogit_scale 4.605\n",
      "2022-11-08,05:24:29 | INFO | Rank 0 | Train Epoch: 0 [3104/23491 (13%)]\tLoss: 2.143051\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000016\tlogit_scale 4.605\n",
      "2022-11-08,05:24:29 | INFO | Rank 0 | Train Epoch: 0 [3136/23491 (13%)]\tLoss: 2.217045\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000016\tlogit_scale 4.605\n",
      "2022-11-08,05:24:29 | INFO | Rank 0 | Train Epoch: 0 [3168/23491 (13%)]\tLoss: 2.750364\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000016\tlogit_scale 4.605\n",
      "2022-11-08,05:24:29 | INFO | Rank 0 | Train Epoch: 0 [3200/23491 (14%)]\tLoss: 2.578850\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000016\tlogit_scale 4.605\n",
      "2022-11-08,05:24:30 | INFO | Rank 0 | Train Epoch: 0 [3232/23491 (14%)]\tLoss: 1.965759\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000016\tlogit_scale 4.605\n",
      "2022-11-08,05:24:30 | INFO | Rank 0 | Train Epoch: 0 [3264/23491 (14%)]\tLoss: 2.262366\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000016\tlogit_scale 4.605\n",
      "2022-11-08,05:24:30 | INFO | Rank 0 | Train Epoch: 0 [3296/23491 (14%)]\tLoss: 2.121611\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000017\tlogit_scale 4.605\n",
      "2022-11-08,05:24:30 | INFO | Rank 0 | Train Epoch: 0 [3328/23491 (14%)]\tLoss: 2.135715\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000017\tlogit_scale 4.605\n",
      "2022-11-08,05:24:31 | INFO | Rank 0 | Train Epoch: 0 [3360/23491 (14%)]\tLoss: 2.448362\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000017\tlogit_scale 4.605\n",
      "2022-11-08,05:24:31 | INFO | Rank 0 | Train Epoch: 0 [3392/23491 (14%)]\tLoss: 2.006029\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000017\tlogit_scale 4.605\n",
      "2022-11-08,05:24:31 | INFO | Rank 0 | Train Epoch: 0 [3424/23491 (15%)]\tLoss: 2.209229\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000017\tlogit_scale 4.605\n",
      "2022-11-08,05:24:31 | INFO | Rank 0 | Train Epoch: 0 [3456/23491 (15%)]\tLoss: 2.566274\tData (t) 0.052\tBatch (t) 0.262\tLR: 0.000017\tlogit_scale 4.605\n",
      "2022-11-08,05:24:32 | INFO | Rank 0 | Train Epoch: 0 [3488/23491 (15%)]\tLoss: 2.054794\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000018\tlogit_scale 4.605\n",
      "2022-11-08,05:24:32 | INFO | Rank 0 | Train Epoch: 0 [3520/23491 (15%)]\tLoss: 2.287556\tData (t) 0.052\tBatch (t) 0.262\tLR: 0.000018\tlogit_scale 4.605\n",
      "2022-11-08,05:24:32 | INFO | Rank 0 | Train Epoch: 0 [3552/23491 (15%)]\tLoss: 2.206863\tData (t) 0.055\tBatch (t) 0.263\tLR: 0.000018\tlogit_scale 4.605\n",
      "2022-11-08,05:24:32 | INFO | Rank 0 | Train Epoch: 0 [3584/23491 (15%)]\tLoss: 2.375973\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000018\tlogit_scale 4.605\n",
      "2022-11-08,05:24:33 | INFO | Rank 0 | Train Epoch: 0 [3616/23491 (15%)]\tLoss: 2.386255\tData (t) 0.056\tBatch (t) 0.265\tLR: 0.000018\tlogit_scale 4.605\n",
      "2022-11-08,05:24:33 | INFO | Rank 0 | Train Epoch: 0 [3648/23491 (16%)]\tLoss: 2.607923\tData (t) 0.056\tBatch (t) 0.265\tLR: 0.000018\tlogit_scale 4.605\n",
      "2022-11-08,05:24:33 | INFO | Rank 0 | Train Epoch: 0 [3680/23491 (16%)]\tLoss: 1.872804\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000019\tlogit_scale 4.605\n",
      "2022-11-08,05:24:34 | INFO | Rank 0 | Train Epoch: 0 [3712/23491 (16%)]\tLoss: 2.901947\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000019\tlogit_scale 4.605\n",
      "2022-11-08,05:24:34 | INFO | Rank 0 | Train Epoch: 0 [3744/23491 (16%)]\tLoss: 2.195990\tData (t) 0.054\tBatch (t) 0.263\tLR: 0.000019\tlogit_scale 4.605\n",
      "2022-11-08,05:24:34 | INFO | Rank 0 | Train Epoch: 0 [3776/23491 (16%)]\tLoss: 2.009066\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000019\tlogit_scale 4.605\n",
      "2022-11-08,05:24:34 | INFO | Rank 0 | Train Epoch: 0 [3808/23491 (16%)]\tLoss: 2.487779\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000019\tlogit_scale 4.605\n",
      "2022-11-08,05:24:35 | INFO | Rank 0 | Train Epoch: 0 [3840/23491 (16%)]\tLoss: 2.146088\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000019\tlogit_scale 4.605\n",
      "2022-11-08,05:24:35 | INFO | Rank 0 | Train Epoch: 0 [3872/23491 (16%)]\tLoss: 1.902854\tData (t) 0.054\tBatch (t) 0.263\tLR: 0.000020\tlogit_scale 4.605\n",
      "2022-11-08,05:24:35 | INFO | Rank 0 | Train Epoch: 0 [3904/23491 (17%)]\tLoss: 2.455960\tData (t) 0.054\tBatch (t) 0.263\tLR: 0.000020\tlogit_scale 4.605\n",
      "2022-11-08,05:24:35 | INFO | Rank 0 | Train Epoch: 0 [3936/23491 (17%)]\tLoss: 2.502462\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000020\tlogit_scale 4.605\n",
      "2022-11-08,05:24:36 | INFO | Rank 0 | Train Epoch: 0 [3968/23491 (17%)]\tLoss: 2.047850\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000020\tlogit_scale 4.605\n",
      "2022-11-08,05:24:36 | INFO | Rank 0 | Train Epoch: 0 [4000/23491 (17%)]\tLoss: 2.287000\tData (t) 0.055\tBatch (t) 0.264\tLR: 0.000020\tlogit_scale 4.605\n",
      "2022-11-08,05:24:36 | INFO | Rank 0 | Train Epoch: 0 [4032/23491 (17%)]\tLoss: 2.107643\tData (t) 0.053\tBatch (t) 0.261\tLR: 0.000020\tlogit_scale 4.605\n",
      "2022-11-08,05:24:36 | INFO | Rank 0 | Train Epoch: 0 [4064/23491 (17%)]\tLoss: 1.950920\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000020\tlogit_scale 4.605\n",
      "2022-11-08,05:24:37 | INFO | Rank 0 | Train Epoch: 0 [4096/23491 (17%)]\tLoss: 1.917321\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000021\tlogit_scale 4.605\n",
      "2022-11-08,05:24:37 | INFO | Rank 0 | Train Epoch: 0 [4128/23491 (18%)]\tLoss: 2.019750\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000021\tlogit_scale 4.605\n",
      "2022-11-08,05:24:37 | INFO | Rank 0 | Train Epoch: 0 [4160/23491 (18%)]\tLoss: 2.157673\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000021\tlogit_scale 4.605\n",
      "2022-11-08,05:24:37 | INFO | Rank 0 | Train Epoch: 0 [4192/23491 (18%)]\tLoss: 2.609677\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000021\tlogit_scale 4.605\n",
      "2022-11-08,05:24:38 | INFO | Rank 0 | Train Epoch: 0 [4224/23491 (18%)]\tLoss: 2.512858\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000021\tlogit_scale 4.605\n",
      "2022-11-08,05:24:38 | INFO | Rank 0 | Train Epoch: 0 [4256/23491 (18%)]\tLoss: 1.730774\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000021\tlogit_scale 4.605\n",
      "2022-11-08,05:24:38 | INFO | Rank 0 | Train Epoch: 0 [4288/23491 (18%)]\tLoss: 1.953197\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000022\tlogit_scale 4.605\n",
      "2022-11-08,05:24:39 | INFO | Rank 0 | Train Epoch: 0 [4320/23491 (18%)]\tLoss: 2.540720\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000022\tlogit_scale 4.605\n",
      "2022-11-08,05:24:39 | INFO | Rank 0 | Train Epoch: 0 [4352/23491 (19%)]\tLoss: 1.950029\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000022\tlogit_scale 4.605\n",
      "2022-11-08,05:24:39 | INFO | Rank 0 | Train Epoch: 0 [4384/23491 (19%)]\tLoss: 1.785313\tData (t) 0.054\tBatch (t) 0.263\tLR: 0.000022\tlogit_scale 4.605\n",
      "2022-11-08,05:24:39 | INFO | Rank 0 | Train Epoch: 0 [4416/23491 (19%)]\tLoss: 1.977903\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000022\tlogit_scale 4.605\n",
      "2022-11-08,05:24:40 | INFO | Rank 0 | Train Epoch: 0 [4448/23491 (19%)]\tLoss: 1.624380\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000022\tlogit_scale 4.605\n",
      "2022-11-08,05:24:40 | INFO | Rank 0 | Train Epoch: 0 [4480/23491 (19%)]\tLoss: 1.764797\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000023\tlogit_scale 4.605\n",
      "2022-11-08,05:24:40 | INFO | Rank 0 | Train Epoch: 0 [4512/23491 (19%)]\tLoss: 2.061579\tData (t) 0.056\tBatch (t) 0.265\tLR: 0.000023\tlogit_scale 4.605\n",
      "2022-11-08,05:24:40 | INFO | Rank 0 | Train Epoch: 0 [4544/23491 (19%)]\tLoss: 2.273387\tData (t) 0.055\tBatch (t) 0.264\tLR: 0.000023\tlogit_scale 4.605\n",
      "2022-11-08,05:24:41 | INFO | Rank 0 | Train Epoch: 0 [4576/23491 (19%)]\tLoss: 1.668942\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000023\tlogit_scale 4.605\n",
      "2022-11-08,05:24:41 | INFO | Rank 0 | Train Epoch: 0 [4608/23491 (20%)]\tLoss: 1.860460\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000023\tlogit_scale 4.605\n",
      "2022-11-08,05:24:41 | INFO | Rank 0 | Train Epoch: 0 [4640/23491 (20%)]\tLoss: 1.929593\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000023\tlogit_scale 4.605\n",
      "2022-11-08,05:24:41 | INFO | Rank 0 | Train Epoch: 0 [4672/23491 (20%)]\tLoss: 2.257370\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000024\tlogit_scale 4.604\n",
      "2022-11-08,05:24:42 | INFO | Rank 0 | Train Epoch: 0 [4704/23491 (20%)]\tLoss: 1.838172\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000024\tlogit_scale 4.604\n",
      "2022-11-08,05:24:42 | INFO | Rank 0 | Train Epoch: 0 [4736/23491 (20%)]\tLoss: 2.374653\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000024\tlogit_scale 4.604\n",
      "2022-11-08,05:24:42 | INFO | Rank 0 | Train Epoch: 0 [4768/23491 (20%)]\tLoss: 1.692918\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000024\tlogit_scale 4.604\n",
      "2022-11-08,05:24:42 | INFO | Rank 0 | Train Epoch: 0 [4800/23491 (20%)]\tLoss: 1.719671\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000024\tlogit_scale 4.604\n",
      "2022-11-08,05:24:43 | INFO | Rank 0 | Train Epoch: 0 [4832/23491 (21%)]\tLoss: 1.872006\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000024\tlogit_scale 4.604\n",
      "2022-11-08,05:24:43 | INFO | Rank 0 | Train Epoch: 0 [4864/23491 (21%)]\tLoss: 1.984554\tData (t) 0.054\tBatch (t) 0.263\tLR: 0.000024\tlogit_scale 4.604\n",
      "2022-11-08,05:24:43 | INFO | Rank 0 | Train Epoch: 0 [4896/23491 (21%)]\tLoss: 1.963378\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000025\tlogit_scale 4.604\n",
      "2022-11-08,05:24:44 | INFO | Rank 0 | Train Epoch: 0 [4928/23491 (21%)]\tLoss: 1.853758\tData (t) 0.052\tBatch (t) 0.262\tLR: 0.000025\tlogit_scale 4.604\n",
      "2022-11-08,05:24:44 | INFO | Rank 0 | Train Epoch: 0 [4960/23491 (21%)]\tLoss: 1.776119\tData (t) 0.052\tBatch (t) 0.262\tLR: 0.000025\tlogit_scale 4.604\n",
      "2022-11-08,05:24:44 | INFO | Rank 0 | Train Epoch: 0 [4992/23491 (21%)]\tLoss: 2.052745\tData (t) 0.052\tBatch (t) 0.261\tLR: 0.000025\tlogit_scale 4.604\n",
      "2022-11-08,05:24:44 | INFO | Rank 0 | Train Epoch: 0 [5024/23491 (21%)]\tLoss: 2.238837\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000025\tlogit_scale 4.604\n",
      "2022-11-08,05:24:45 | INFO | Rank 0 | Train Epoch: 0 [5056/23491 (22%)]\tLoss: 2.219700\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000025\tlogit_scale 4.604\n",
      "2022-11-08,05:24:45 | INFO | Rank 0 | Train Epoch: 0 [5088/23491 (22%)]\tLoss: 1.572809\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000026\tlogit_scale 4.604\n",
      "2022-11-08,05:24:45 | INFO | Rank 0 | Train Epoch: 0 [5120/23491 (22%)]\tLoss: 1.810483\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000026\tlogit_scale 4.604\n",
      "2022-11-08,05:24:45 | INFO | Rank 0 | Train Epoch: 0 [5152/23491 (22%)]\tLoss: 1.923147\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000026\tlogit_scale 4.604\n",
      "2022-11-08,05:24:46 | INFO | Rank 0 | Train Epoch: 0 [5184/23491 (22%)]\tLoss: 1.578644\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000026\tlogit_scale 4.604\n",
      "2022-11-08,05:24:46 | INFO | Rank 0 | Train Epoch: 0 [5216/23491 (22%)]\tLoss: 1.712556\tData (t) 0.054\tBatch (t) 0.263\tLR: 0.000026\tlogit_scale 4.604\n",
      "2022-11-08,05:24:46 | INFO | Rank 0 | Train Epoch: 0 [5248/23491 (22%)]\tLoss: 1.840196\tData (t) 0.055\tBatch (t) 0.264\tLR: 0.000026\tlogit_scale 4.604\n",
      "2022-11-08,05:24:46 | INFO | Rank 0 | Train Epoch: 0 [5280/23491 (22%)]\tLoss: 1.470813\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000027\tlogit_scale 4.604\n",
      "2022-11-08,05:24:47 | INFO | Rank 0 | Train Epoch: 0 [5312/23491 (23%)]\tLoss: 1.601817\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000027\tlogit_scale 4.604\n",
      "2022-11-08,05:24:47 | INFO | Rank 0 | Train Epoch: 0 [5344/23491 (23%)]\tLoss: 2.208370\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000027\tlogit_scale 4.604\n",
      "2022-11-08,05:24:47 | INFO | Rank 0 | Train Epoch: 0 [5376/23491 (23%)]\tLoss: 2.056365\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000027\tlogit_scale 4.604\n",
      "2022-11-08,05:24:47 | INFO | Rank 0 | Train Epoch: 0 [5408/23491 (23%)]\tLoss: 2.199107\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000027\tlogit_scale 4.604\n",
      "2022-11-08,05:24:48 | INFO | Rank 0 | Train Epoch: 0 [5440/23491 (23%)]\tLoss: 1.921772\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000027\tlogit_scale 4.604\n",
      "2022-11-08,05:24:48 | INFO | Rank 0 | Train Epoch: 0 [5472/23491 (23%)]\tLoss: 1.598123\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000028\tlogit_scale 4.604\n",
      "2022-11-08,05:24:48 | INFO | Rank 0 | Train Epoch: 0 [5504/23491 (23%)]\tLoss: 2.287394\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000028\tlogit_scale 4.604\n",
      "2022-11-08,05:24:49 | INFO | Rank 0 | Train Epoch: 0 [5536/23491 (24%)]\tLoss: 1.497880\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000028\tlogit_scale 4.604\n",
      "2022-11-08,05:24:49 | INFO | Rank 0 | Train Epoch: 0 [5568/23491 (24%)]\tLoss: 2.261954\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000028\tlogit_scale 4.604\n",
      "2022-11-08,05:24:49 | INFO | Rank 0 | Train Epoch: 0 [5600/23491 (24%)]\tLoss: 1.883096\tData (t) 0.061\tBatch (t) 0.273\tLR: 0.000028\tlogit_scale 4.604\n",
      "2022-11-08,05:24:49 | INFO | Rank 0 | Train Epoch: 0 [5632/23491 (24%)]\tLoss: 1.359537\tData (t) 0.060\tBatch (t) 0.272\tLR: 0.000028\tlogit_scale 4.604\n",
      "2022-11-08,05:24:50 | INFO | Rank 0 | Train Epoch: 0 [5664/23491 (24%)]\tLoss: 1.535798\tData (t) 0.061\tBatch (t) 0.272\tLR: 0.000028\tlogit_scale 4.604\n",
      "2022-11-08,05:24:50 | INFO | Rank 0 | Train Epoch: 0 [5696/23491 (24%)]\tLoss: 2.155514\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000029\tlogit_scale 4.604\n",
      "2022-11-08,05:24:50 | INFO | Rank 0 | Train Epoch: 0 [5728/23491 (24%)]\tLoss: 1.963884\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000029\tlogit_scale 4.604\n",
      "2022-11-08,05:24:50 | INFO | Rank 0 | Train Epoch: 0 [5760/23491 (25%)]\tLoss: 1.801700\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000029\tlogit_scale 4.604\n",
      "2022-11-08,05:24:51 | INFO | Rank 0 | Train Epoch: 0 [5792/23491 (25%)]\tLoss: 1.618087\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000029\tlogit_scale 4.604\n",
      "2022-11-08,05:24:51 | INFO | Rank 0 | Train Epoch: 0 [5824/23491 (25%)]\tLoss: 1.773607\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000029\tlogit_scale 4.604\n",
      "2022-11-08,05:24:51 | INFO | Rank 0 | Train Epoch: 0 [5856/23491 (25%)]\tLoss: 1.565145\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000029\tlogit_scale 4.604\n",
      "2022-11-08,05:24:51 | INFO | Rank 0 | Train Epoch: 0 [5888/23491 (25%)]\tLoss: 2.021543\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000030\tlogit_scale 4.604\n",
      "2022-11-08,05:24:52 | INFO | Rank 0 | Train Epoch: 0 [5920/23491 (25%)]\tLoss: 1.955361\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000030\tlogit_scale 4.604\n",
      "2022-11-08,05:24:52 | INFO | Rank 0 | Train Epoch: 0 [5952/23491 (25%)]\tLoss: 1.705321\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000030\tlogit_scale 4.604\n",
      "2022-11-08,05:24:52 | INFO | Rank 0 | Train Epoch: 0 [5984/23491 (25%)]\tLoss: 1.872264\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000030\tlogit_scale 4.604\n",
      "2022-11-08,05:24:52 | INFO | Rank 0 | Train Epoch: 0 [6016/23491 (26%)]\tLoss: 1.630812\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000030\tlogit_scale 4.604\n",
      "2022-11-08,05:24:53 | INFO | Rank 0 | Train Epoch: 0 [6048/23491 (26%)]\tLoss: 1.365870\tData (t) 0.055\tBatch (t) 0.265\tLR: 0.000030\tlogit_scale 4.604\n",
      "2022-11-08,05:24:53 | INFO | Rank 0 | Train Epoch: 0 [6080/23491 (26%)]\tLoss: 1.665149\tData (t) 0.056\tBatch (t) 0.265\tLR: 0.000031\tlogit_scale 4.604\n",
      "2022-11-08,05:24:53 | INFO | Rank 0 | Train Epoch: 0 [6112/23491 (26%)]\tLoss: 2.113273\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000031\tlogit_scale 4.604\n",
      "2022-11-08,05:24:54 | INFO | Rank 0 | Train Epoch: 0 [6144/23491 (26%)]\tLoss: 1.989252\tData (t) 0.054\tBatch (t) 0.263\tLR: 0.000031\tlogit_scale 4.604\n",
      "2022-11-08,05:24:54 | INFO | Rank 0 | Train Epoch: 0 [6176/23491 (26%)]\tLoss: 1.628479\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000031\tlogit_scale 4.604\n",
      "2022-11-08,05:24:54 | INFO | Rank 0 | Train Epoch: 0 [6208/23491 (26%)]\tLoss: 1.408821\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000031\tlogit_scale 4.604\n",
      "2022-11-08,05:24:54 | INFO | Rank 0 | Train Epoch: 0 [6240/23491 (27%)]\tLoss: 1.941085\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000031\tlogit_scale 4.604\n",
      "2022-11-08,05:24:55 | INFO | Rank 0 | Train Epoch: 0 [6272/23491 (27%)]\tLoss: 1.806499\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000032\tlogit_scale 4.604\n",
      "2022-11-08,05:24:55 | INFO | Rank 0 | Train Epoch: 0 [6304/23491 (27%)]\tLoss: 1.859310\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000032\tlogit_scale 4.604\n",
      "2022-11-08,05:24:55 | INFO | Rank 0 | Train Epoch: 0 [6336/23491 (27%)]\tLoss: 1.838057\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000032\tlogit_scale 4.604\n",
      "2022-11-08,05:24:55 | INFO | Rank 0 | Train Epoch: 0 [6368/23491 (27%)]\tLoss: 1.542760\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000032\tlogit_scale 4.604\n",
      "2022-11-08,05:24:56 | INFO | Rank 0 | Train Epoch: 0 [6400/23491 (27%)]\tLoss: 2.224495\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000032\tlogit_scale 4.604\n",
      "2022-11-08,05:24:56 | INFO | Rank 0 | Train Epoch: 0 [6432/23491 (27%)]\tLoss: 1.762895\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000032\tlogit_scale 4.604\n",
      "2022-11-08,05:24:56 | INFO | Rank 0 | Train Epoch: 0 [6464/23491 (28%)]\tLoss: 1.652587\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000032\tlogit_scale 4.604\n",
      "2022-11-08,05:24:56 | INFO | Rank 0 | Train Epoch: 0 [6496/23491 (28%)]\tLoss: 1.430198\tData (t) 0.054\tBatch (t) 0.264\tLR: 0.000033\tlogit_scale 4.604\n",
      "2022-11-08,05:24:57 | INFO | Rank 0 | Train Epoch: 0 [6528/23491 (28%)]\tLoss: 1.714206\tData (t) 0.054\tBatch (t) 0.263\tLR: 0.000033\tlogit_scale 4.604\n",
      "2022-11-08,05:24:57 | INFO | Rank 0 | Train Epoch: 0 [6560/23491 (28%)]\tLoss: 1.803987\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000033\tlogit_scale 4.604\n",
      "2022-11-08,05:24:57 | INFO | Rank 0 | Train Epoch: 0 [6592/23491 (28%)]\tLoss: 1.983436\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000033\tlogit_scale 4.604\n",
      "2022-11-08,05:24:57 | INFO | Rank 0 | Train Epoch: 0 [6624/23491 (28%)]\tLoss: 1.829392\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000033\tlogit_scale 4.604\n",
      "2022-11-08,05:24:58 | INFO | Rank 0 | Train Epoch: 0 [6656/23491 (28%)]\tLoss: 1.763757\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000033\tlogit_scale 4.604\n",
      "2022-11-08,05:24:58 | INFO | Rank 0 | Train Epoch: 0 [6688/23491 (28%)]\tLoss: 1.890766\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000034\tlogit_scale 4.604\n",
      "2022-11-08,05:24:58 | INFO | Rank 0 | Train Epoch: 0 [6720/23491 (29%)]\tLoss: 1.652594\tData (t) 0.054\tBatch (t) 0.264\tLR: 0.000034\tlogit_scale 4.604\n",
      "2022-11-08,05:24:59 | INFO | Rank 0 | Train Epoch: 0 [6752/23491 (29%)]\tLoss: 1.613679\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000034\tlogit_scale 4.604\n",
      "2022-11-08,05:24:59 | INFO | Rank 0 | Train Epoch: 0 [6784/23491 (29%)]\tLoss: 1.328134\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000034\tlogit_scale 4.604\n",
      "2022-11-08,05:24:59 | INFO | Rank 0 | Train Epoch: 0 [6816/23491 (29%)]\tLoss: 1.678795\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000034\tlogit_scale 4.604\n",
      "2022-11-08,05:24:59 | INFO | Rank 0 | Train Epoch: 0 [6848/23491 (29%)]\tLoss: 1.649861\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000034\tlogit_scale 4.604\n",
      "2022-11-08,05:25:00 | INFO | Rank 0 | Train Epoch: 0 [6880/23491 (29%)]\tLoss: 1.629498\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000035\tlogit_scale 4.604\n",
      "2022-11-08,05:25:00 | INFO | Rank 0 | Train Epoch: 0 [6912/23491 (29%)]\tLoss: 1.648744\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000035\tlogit_scale 4.603\n",
      "2022-11-08,05:25:00 | INFO | Rank 0 | Train Epoch: 0 [6944/23491 (30%)]\tLoss: 1.591407\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000035\tlogit_scale 4.603\n",
      "2022-11-08,05:25:00 | INFO | Rank 0 | Train Epoch: 0 [6976/23491 (30%)]\tLoss: 1.794958\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000035\tlogit_scale 4.603\n",
      "2022-11-08,05:25:01 | INFO | Rank 0 | Train Epoch: 0 [7008/23491 (30%)]\tLoss: 1.591853\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000035\tlogit_scale 4.603\n",
      "2022-11-08,05:25:01 | INFO | Rank 0 | Train Epoch: 0 [7040/23491 (30%)]\tLoss: 1.229617\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000035\tlogit_scale 4.603\n",
      "2022-11-08,05:25:01 | INFO | Rank 0 | Train Epoch: 0 [7072/23491 (30%)]\tLoss: 1.730342\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000036\tlogit_scale 4.603\n",
      "2022-11-08,05:25:01 | INFO | Rank 0 | Train Epoch: 0 [7104/23491 (30%)]\tLoss: 1.422955\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000036\tlogit_scale 4.603\n",
      "2022-11-08,05:25:02 | INFO | Rank 0 | Train Epoch: 0 [7136/23491 (30%)]\tLoss: 2.030229\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000036\tlogit_scale 4.603\n",
      "2022-11-08,05:25:02 | INFO | Rank 0 | Train Epoch: 0 [7168/23491 (31%)]\tLoss: 1.340857\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000036\tlogit_scale 4.603\n",
      "2022-11-08,05:25:02 | INFO | Rank 0 | Train Epoch: 0 [7200/23491 (31%)]\tLoss: 1.753627\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000036\tlogit_scale 4.603\n",
      "2022-11-08,05:25:02 | INFO | Rank 0 | Train Epoch: 0 [7232/23491 (31%)]\tLoss: 2.099276\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000036\tlogit_scale 4.603\n",
      "2022-11-08,05:25:03 | INFO | Rank 0 | Train Epoch: 0 [7264/23491 (31%)]\tLoss: 1.767385\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000036\tlogit_scale 4.603\n",
      "2022-11-08,05:25:03 | INFO | Rank 0 | Train Epoch: 0 [7296/23491 (31%)]\tLoss: 1.578040\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000037\tlogit_scale 4.603\n",
      "2022-11-08,05:25:03 | INFO | Rank 0 | Train Epoch: 0 [7328/23491 (31%)]\tLoss: 1.829080\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000037\tlogit_scale 4.603\n",
      "2022-11-08,05:25:04 | INFO | Rank 0 | Train Epoch: 0 [7360/23491 (31%)]\tLoss: 1.626858\tData (t) 0.054\tBatch (t) 0.264\tLR: 0.000037\tlogit_scale 4.603\n",
      "2022-11-08,05:25:04 | INFO | Rank 0 | Train Epoch: 0 [7392/23491 (31%)]\tLoss: 2.118992\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000037\tlogit_scale 4.603\n",
      "2022-11-08,05:25:04 | INFO | Rank 0 | Train Epoch: 0 [7424/23491 (32%)]\tLoss: 1.707056\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000037\tlogit_scale 4.603\n",
      "2022-11-08,05:25:04 | INFO | Rank 0 | Train Epoch: 0 [7456/23491 (32%)]\tLoss: 1.854581\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000037\tlogit_scale 4.603\n",
      "2022-11-08,05:25:05 | INFO | Rank 0 | Train Epoch: 0 [7488/23491 (32%)]\tLoss: 1.716083\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000038\tlogit_scale 4.603\n",
      "2022-11-08,05:25:05 | INFO | Rank 0 | Train Epoch: 0 [7520/23491 (32%)]\tLoss: 1.676847\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000038\tlogit_scale 4.603\n",
      "2022-11-08,05:25:05 | INFO | Rank 0 | Train Epoch: 0 [7552/23491 (32%)]\tLoss: 2.551897\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000038\tlogit_scale 4.603\n",
      "2022-11-08,05:25:05 | INFO | Rank 0 | Train Epoch: 0 [7584/23491 (32%)]\tLoss: 1.834101\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000038\tlogit_scale 4.603\n",
      "2022-11-08,05:25:06 | INFO | Rank 0 | Train Epoch: 0 [7616/23491 (32%)]\tLoss: 2.063953\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000038\tlogit_scale 4.603\n",
      "2022-11-08,05:25:06 | INFO | Rank 0 | Train Epoch: 0 [7648/23491 (33%)]\tLoss: 1.892738\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000038\tlogit_scale 4.603\n",
      "2022-11-08,05:25:06 | INFO | Rank 0 | Train Epoch: 0 [7680/23491 (33%)]\tLoss: 1.931194\tData (t) 0.053\tBatch (t) 0.262\tLR: 0.000039\tlogit_scale 4.603\n",
      "2022-11-08,05:25:06 | INFO | Rank 0 | Train Epoch: 0 [7712/23491 (33%)]\tLoss: 1.877148\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000039\tlogit_scale 4.603\n",
      "2022-11-08,05:25:07 | INFO | Rank 0 | Train Epoch: 0 [7744/23491 (33%)]\tLoss: 1.398014\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000039\tlogit_scale 4.603\n",
      "2022-11-08,05:25:07 | INFO | Rank 0 | Train Epoch: 0 [7776/23491 (33%)]\tLoss: 2.049881\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000039\tlogit_scale 4.603\n",
      "2022-11-08,05:25:07 | INFO | Rank 0 | Train Epoch: 0 [7808/23491 (33%)]\tLoss: 1.992156\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000039\tlogit_scale 4.603\n",
      "2022-11-08,05:25:08 | INFO | Rank 0 | Train Epoch: 0 [7840/23491 (33%)]\tLoss: 1.577565\tData (t) 0.056\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.603\n",
      "2022-11-08,05:25:08 | INFO | Rank 0 | Train Epoch: 0 [7872/23491 (34%)]\tLoss: 1.852038\tData (t) 0.056\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.603\n",
      "2022-11-08,05:25:08 | INFO | Rank 0 | Train Epoch: 0 [7904/23491 (34%)]\tLoss: 2.014147\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000040\tlogit_scale 4.603\n",
      "2022-11-08,05:25:08 | INFO | Rank 0 | Train Epoch: 0 [7936/23491 (34%)]\tLoss: 1.434152\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000040\tlogit_scale 4.603\n",
      "2022-11-08,05:25:09 | INFO | Rank 0 | Train Epoch: 0 [7968/23491 (34%)]\tLoss: 1.368651\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000040\tlogit_scale 4.603\n",
      "2022-11-08,05:25:09 | INFO | Rank 0 | Train Epoch: 0 [8000/23491 (34%)]\tLoss: 2.010993\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000040\tlogit_scale 4.603\n",
      "2022-11-08,05:25:09 | INFO | Rank 0 | Train Epoch: 0 [8032/23491 (34%)]\tLoss: 1.683811\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000040\tlogit_scale 4.603\n",
      "2022-11-08,05:25:09 | INFO | Rank 0 | Train Epoch: 0 [8064/23491 (34%)]\tLoss: 1.911516\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000040\tlogit_scale 4.603\n",
      "2022-11-08,05:25:10 | INFO | Rank 0 | Train Epoch: 0 [8096/23491 (34%)]\tLoss: 1.905296\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000041\tlogit_scale 4.603\n",
      "2022-11-08,05:25:10 | INFO | Rank 0 | Train Epoch: 0 [8128/23491 (35%)]\tLoss: 2.059941\tData (t) 0.054\tBatch (t) 0.264\tLR: 0.000041\tlogit_scale 4.603\n",
      "2022-11-08,05:25:10 | INFO | Rank 0 | Train Epoch: 0 [8160/23491 (35%)]\tLoss: 1.998115\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000041\tlogit_scale 4.603\n",
      "2022-11-08,05:25:10 | INFO | Rank 0 | Train Epoch: 0 [8192/23491 (35%)]\tLoss: 1.628753\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000041\tlogit_scale 4.603\n",
      "2022-11-08,05:25:11 | INFO | Rank 0 | Train Epoch: 0 [8224/23491 (35%)]\tLoss: 2.094038\tData (t) 0.054\tBatch (t) 0.264\tLR: 0.000041\tlogit_scale 4.603\n",
      "2022-11-08,05:25:11 | INFO | Rank 0 | Train Epoch: 0 [8256/23491 (35%)]\tLoss: 1.746375\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000041\tlogit_scale 4.603\n",
      "2022-11-08,05:25:11 | INFO | Rank 0 | Train Epoch: 0 [8288/23491 (35%)]\tLoss: 2.096998\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000042\tlogit_scale 4.602\n",
      "2022-11-08,05:25:11 | INFO | Rank 0 | Train Epoch: 0 [8320/23491 (35%)]\tLoss: 1.574872\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000042\tlogit_scale 4.602\n",
      "2022-11-08,05:25:12 | INFO | Rank 0 | Train Epoch: 0 [8352/23491 (36%)]\tLoss: 1.806801\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000042\tlogit_scale 4.602\n",
      "2022-11-08,05:25:12 | INFO | Rank 0 | Train Epoch: 0 [8384/23491 (36%)]\tLoss: 1.709539\tData (t) 0.055\tBatch (t) 0.265\tLR: 0.000042\tlogit_scale 4.602\n",
      "2022-11-08,05:25:12 | INFO | Rank 0 | Train Epoch: 0 [8416/23491 (36%)]\tLoss: 1.567096\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000042\tlogit_scale 4.602\n",
      "2022-11-08,05:25:13 | INFO | Rank 0 | Train Epoch: 0 [8448/23491 (36%)]\tLoss: 1.106308\tData (t) 0.056\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.602\n",
      "2022-11-08,05:25:13 | INFO | Rank 0 | Train Epoch: 0 [8480/23491 (36%)]\tLoss: 2.039874\tData (t) 0.055\tBatch (t) 0.265\tLR: 0.000043\tlogit_scale 4.602\n",
      "2022-11-08,05:25:13 | INFO | Rank 0 | Train Epoch: 0 [8512/23491 (36%)]\tLoss: 2.395411\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000043\tlogit_scale 4.602\n",
      "2022-11-08,05:25:13 | INFO | Rank 0 | Train Epoch: 0 [8544/23491 (36%)]\tLoss: 1.951001\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000043\tlogit_scale 4.602\n",
      "2022-11-08,05:25:14 | INFO | Rank 0 | Train Epoch: 0 [8576/23491 (37%)]\tLoss: 1.963852\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000043\tlogit_scale 4.602\n",
      "2022-11-08,05:25:14 | INFO | Rank 0 | Train Epoch: 0 [8608/23491 (37%)]\tLoss: 1.691379\tData (t) 0.055\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.602\n",
      "2022-11-08,05:25:14 | INFO | Rank 0 | Train Epoch: 0 [8640/23491 (37%)]\tLoss: 1.527737\tData (t) 0.054\tBatch (t) 0.264\tLR: 0.000043\tlogit_scale 4.602\n",
      "2022-11-08,05:25:14 | INFO | Rank 0 | Train Epoch: 0 [8672/23491 (37%)]\tLoss: 2.280537\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000044\tlogit_scale 4.602\n",
      "2022-11-08,05:25:15 | INFO | Rank 0 | Train Epoch: 0 [8704/23491 (37%)]\tLoss: 1.586930\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000044\tlogit_scale 4.602\n",
      "2022-11-08,05:25:15 | INFO | Rank 0 | Train Epoch: 0 [8736/23491 (37%)]\tLoss: 1.506238\tData (t) 0.052\tBatch (t) 0.263\tLR: 0.000044\tlogit_scale 4.602\n",
      "2022-11-08,05:25:15 | INFO | Rank 0 | Train Epoch: 0 [8768/23491 (37%)]\tLoss: 1.682797\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000044\tlogit_scale 4.602\n",
      "2022-11-08,05:25:15 | INFO | Rank 0 | Train Epoch: 0 [8800/23491 (37%)]\tLoss: 2.097672\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000044\tlogit_scale 4.602\n",
      "2022-11-08,05:25:16 | INFO | Rank 0 | Train Epoch: 0 [8832/23491 (38%)]\tLoss: 1.882256\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000044\tlogit_scale 4.602\n",
      "2022-11-08,05:25:16 | INFO | Rank 0 | Train Epoch: 0 [8864/23491 (38%)]\tLoss: 1.317954\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000044\tlogit_scale 4.602\n",
      "2022-11-08,05:25:16 | INFO | Rank 0 | Train Epoch: 0 [8896/23491 (38%)]\tLoss: 1.399402\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000045\tlogit_scale 4.602\n",
      "2022-11-08,05:25:16 | INFO | Rank 0 | Train Epoch: 0 [8928/23491 (38%)]\tLoss: 1.640670\tData (t) 0.054\tBatch (t) 0.264\tLR: 0.000045\tlogit_scale 4.602\n",
      "2022-11-08,05:25:17 | INFO | Rank 0 | Train Epoch: 0 [8960/23491 (38%)]\tLoss: 1.730011\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000045\tlogit_scale 4.602\n",
      "2022-11-08,05:25:17 | INFO | Rank 0 | Train Epoch: 0 [8992/23491 (38%)]\tLoss: 1.367960\tData (t) 0.056\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.602\n",
      "2022-11-08,05:25:17 | INFO | Rank 0 | Train Epoch: 0 [9024/23491 (38%)]\tLoss: 1.341201\tData (t) 0.055\tBatch (t) 0.265\tLR: 0.000045\tlogit_scale 4.602\n",
      "2022-11-08,05:25:18 | INFO | Rank 0 | Train Epoch: 0 [9056/23491 (39%)]\tLoss: 1.786094\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000045\tlogit_scale 4.602\n",
      "2022-11-08,05:25:18 | INFO | Rank 0 | Train Epoch: 0 [9088/23491 (39%)]\tLoss: 1.887746\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000046\tlogit_scale 4.602\n",
      "2022-11-08,05:25:18 | INFO | Rank 0 | Train Epoch: 0 [9120/23491 (39%)]\tLoss: 1.761198\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000046\tlogit_scale 4.602\n",
      "2022-11-08,05:25:18 | INFO | Rank 0 | Train Epoch: 0 [9152/23491 (39%)]\tLoss: 1.458885\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000046\tlogit_scale 4.602\n",
      "2022-11-08,05:25:19 | INFO | Rank 0 | Train Epoch: 0 [9184/23491 (39%)]\tLoss: 1.804051\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000046\tlogit_scale 4.602\n",
      "2022-11-08,05:25:19 | INFO | Rank 0 | Train Epoch: 0 [9216/23491 (39%)]\tLoss: 2.107869\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000046\tlogit_scale 4.602\n",
      "2022-11-08,05:25:19 | INFO | Rank 0 | Train Epoch: 0 [9248/23491 (39%)]\tLoss: 1.993358\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000046\tlogit_scale 4.602\n",
      "2022-11-08,05:25:19 | INFO | Rank 0 | Train Epoch: 0 [9280/23491 (40%)]\tLoss: 1.481845\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000047\tlogit_scale 4.602\n",
      "2022-11-08,05:25:20 | INFO | Rank 0 | Train Epoch: 0 [9312/23491 (40%)]\tLoss: 2.237498\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000047\tlogit_scale 4.602\n",
      "2022-11-08,05:25:20 | INFO | Rank 0 | Train Epoch: 0 [9344/23491 (40%)]\tLoss: 2.082600\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000047\tlogit_scale 4.602\n",
      "2022-11-08,05:25:20 | INFO | Rank 0 | Train Epoch: 0 [9376/23491 (40%)]\tLoss: 2.054652\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000047\tlogit_scale 4.602\n",
      "2022-11-08,05:25:20 | INFO | Rank 0 | Train Epoch: 0 [9408/23491 (40%)]\tLoss: 2.470684\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000047\tlogit_scale 4.602\n",
      "2022-11-08,05:25:21 | INFO | Rank 0 | Train Epoch: 0 [9440/23491 (40%)]\tLoss: 1.524870\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000047\tlogit_scale 4.602\n",
      "2022-11-08,05:25:21 | INFO | Rank 0 | Train Epoch: 0 [9472/23491 (40%)]\tLoss: 1.507143\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.601\n",
      "2022-11-08,05:25:21 | INFO | Rank 0 | Train Epoch: 0 [9504/23491 (40%)]\tLoss: 2.032318\tData (t) 0.054\tBatch (t) 0.264\tLR: 0.000048\tlogit_scale 4.601\n",
      "2022-11-08,05:25:21 | INFO | Rank 0 | Train Epoch: 0 [9536/23491 (41%)]\tLoss: 2.076353\tData (t) 0.054\tBatch (t) 0.264\tLR: 0.000048\tlogit_scale 4.601\n",
      "2022-11-08,05:25:22 | INFO | Rank 0 | Train Epoch: 0 [9568/23491 (41%)]\tLoss: 1.594949\tData (t) 0.054\tBatch (t) 0.264\tLR: 0.000048\tlogit_scale 4.601\n",
      "2022-11-08,05:25:22 | INFO | Rank 0 | Train Epoch: 0 [9600/23491 (41%)]\tLoss: 2.114773\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000048\tlogit_scale 4.601\n",
      "2022-11-08,05:25:22 | INFO | Rank 0 | Train Epoch: 0 [9632/23491 (41%)]\tLoss: 1.556554\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000048\tlogit_scale 4.601\n",
      "2022-11-08,05:25:23 | INFO | Rank 0 | Train Epoch: 0 [9664/23491 (41%)]\tLoss: 1.921132\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000048\tlogit_scale 4.601\n",
      "2022-11-08,05:25:23 | INFO | Rank 0 | Train Epoch: 0 [9696/23491 (41%)]\tLoss: 1.691252\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000049\tlogit_scale 4.601\n",
      "2022-11-08,05:25:23 | INFO | Rank 0 | Train Epoch: 0 [9728/23491 (41%)]\tLoss: 2.122376\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000049\tlogit_scale 4.601\n",
      "2022-11-08,05:25:23 | INFO | Rank 0 | Train Epoch: 0 [9760/23491 (42%)]\tLoss: 1.394873\tData (t) 0.052\tBatch (t) 0.263\tLR: 0.000049\tlogit_scale 4.601\n",
      "2022-11-08,05:25:24 | INFO | Rank 0 | Train Epoch: 0 [9792/23491 (42%)]\tLoss: 1.733976\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000049\tlogit_scale 4.601\n",
      "2022-11-08,05:25:24 | INFO | Rank 0 | Train Epoch: 0 [9824/23491 (42%)]\tLoss: 1.205851\tData (t) 0.054\tBatch (t) 0.264\tLR: 0.000049\tlogit_scale 4.601\n",
      "2022-11-08,05:25:24 | INFO | Rank 0 | Train Epoch: 0 [9856/23491 (42%)]\tLoss: 2.305860\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000049\tlogit_scale 4.601\n",
      "2022-11-08,05:25:24 | INFO | Rank 0 | Train Epoch: 0 [9888/23491 (42%)]\tLoss: 1.850327\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000050\tlogit_scale 4.601\n",
      "2022-11-08,05:25:25 | INFO | Rank 0 | Train Epoch: 0 [9920/23491 (42%)]\tLoss: 1.759830\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000050\tlogit_scale 4.601\n",
      "2022-11-08,05:25:25 | INFO | Rank 0 | Train Epoch: 0 [9952/23491 (42%)]\tLoss: 1.869274\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000050\tlogit_scale 4.601\n",
      "2022-11-08,05:25:25 | INFO | Rank 0 | Train Epoch: 0 [9984/23491 (43%)]\tLoss: 2.051513\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000050\tlogit_scale 4.601\n",
      "2022-11-08,05:25:25 | INFO | Rank 0 | Train Epoch: 0 [10016/23491 (43%)]\tLoss: 1.873966\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000050\tlogit_scale 4.601\n",
      "2022-11-08,05:25:26 | INFO | Rank 0 | Train Epoch: 0 [10048/23491 (43%)]\tLoss: 2.523380\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000050\tlogit_scale 4.601\n",
      "2022-11-08,05:25:26 | INFO | Rank 0 | Train Epoch: 0 [10080/23491 (43%)]\tLoss: 1.825489\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000051\tlogit_scale 4.601\n",
      "2022-11-08,05:25:26 | INFO | Rank 0 | Train Epoch: 0 [10112/23491 (43%)]\tLoss: 1.981849\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000051\tlogit_scale 4.601\n",
      "2022-11-08,05:25:26 | INFO | Rank 0 | Train Epoch: 0 [10144/23491 (43%)]\tLoss: 1.731552\tData (t) 0.055\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.601\n",
      "2022-11-08,05:25:27 | INFO | Rank 0 | Train Epoch: 0 [10176/23491 (43%)]\tLoss: 1.496204\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000051\tlogit_scale 4.601\n",
      "2022-11-08,05:25:27 | INFO | Rank 0 | Train Epoch: 0 [10208/23491 (43%)]\tLoss: 2.102402\tData (t) 0.056\tBatch (t) 0.267\tLR: 0.000051\tlogit_scale 4.601\n",
      "2022-11-08,05:25:27 | INFO | Rank 0 | Train Epoch: 0 [10240/23491 (44%)]\tLoss: 1.844952\tData (t) 0.055\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.601\n",
      "2022-11-08,05:25:28 | INFO | Rank 0 | Train Epoch: 0 [10272/23491 (44%)]\tLoss: 1.759670\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000052\tlogit_scale 4.601\n",
      "2022-11-08,05:25:28 | INFO | Rank 0 | Train Epoch: 0 [10304/23491 (44%)]\tLoss: 1.995661\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000052\tlogit_scale 4.601\n",
      "2022-11-08,05:25:28 | INFO | Rank 0 | Train Epoch: 0 [10336/23491 (44%)]\tLoss: 1.786881\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000052\tlogit_scale 4.601\n",
      "2022-11-08,05:25:28 | INFO | Rank 0 | Train Epoch: 0 [10368/23491 (44%)]\tLoss: 1.554440\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000052\tlogit_scale 4.601\n",
      "2022-11-08,05:25:29 | INFO | Rank 0 | Train Epoch: 0 [10400/23491 (44%)]\tLoss: 1.840221\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000052\tlogit_scale 4.601\n",
      "2022-11-08,05:25:29 | INFO | Rank 0 | Train Epoch: 0 [10432/23491 (44%)]\tLoss: 1.824969\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000052\tlogit_scale 4.601\n",
      "2022-11-08,05:25:29 | INFO | Rank 0 | Train Epoch: 0 [10464/23491 (45%)]\tLoss: 1.851542\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000052\tlogit_scale 4.601\n",
      "2022-11-08,05:25:29 | INFO | Rank 0 | Train Epoch: 0 [10496/23491 (45%)]\tLoss: 1.530806\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000053\tlogit_scale 4.601\n",
      "2022-11-08,05:25:30 | INFO | Rank 0 | Train Epoch: 0 [10528/23491 (45%)]\tLoss: 2.071009\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000053\tlogit_scale 4.601\n",
      "2022-11-08,05:25:30 | INFO | Rank 0 | Train Epoch: 0 [10560/23491 (45%)]\tLoss: 1.738176\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000053\tlogit_scale 4.600\n",
      "2022-11-08,05:25:30 | INFO | Rank 0 | Train Epoch: 0 [10592/23491 (45%)]\tLoss: 1.742313\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000053\tlogit_scale 4.600\n",
      "2022-11-08,05:25:30 | INFO | Rank 0 | Train Epoch: 0 [10624/23491 (45%)]\tLoss: 1.870804\tData (t) 0.052\tBatch (t) 0.263\tLR: 0.000053\tlogit_scale 4.600\n",
      "2022-11-08,05:25:31 | INFO | Rank 0 | Train Epoch: 0 [10656/23491 (45%)]\tLoss: 2.162289\tData (t) 0.054\tBatch (t) 0.264\tLR: 0.000053\tlogit_scale 4.600\n",
      "2022-11-08,05:25:31 | INFO | Rank 0 | Train Epoch: 0 [10688/23491 (46%)]\tLoss: 1.214707\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000054\tlogit_scale 4.600\n",
      "2022-11-08,05:25:31 | INFO | Rank 0 | Train Epoch: 0 [10720/23491 (46%)]\tLoss: 2.137046\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000054\tlogit_scale 4.600\n",
      "2022-11-08,05:25:32 | INFO | Rank 0 | Train Epoch: 0 [10752/23491 (46%)]\tLoss: 2.094119\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000054\tlogit_scale 4.600\n",
      "2022-11-08,05:25:32 | INFO | Rank 0 | Train Epoch: 0 [10784/23491 (46%)]\tLoss: 1.664309\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000054\tlogit_scale 4.600\n",
      "2022-11-08,05:25:32 | INFO | Rank 0 | Train Epoch: 0 [10816/23491 (46%)]\tLoss: 1.464034\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000054\tlogit_scale 4.600\n",
      "2022-11-08,05:25:32 | INFO | Rank 0 | Train Epoch: 0 [10848/23491 (46%)]\tLoss: 1.745198\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000054\tlogit_scale 4.600\n",
      "2022-11-08,05:25:33 | INFO | Rank 0 | Train Epoch: 0 [10880/23491 (46%)]\tLoss: 1.370091\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000055\tlogit_scale 4.600\n",
      "2022-11-08,05:25:33 | INFO | Rank 0 | Train Epoch: 0 [10912/23491 (46%)]\tLoss: 1.866472\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000055\tlogit_scale 4.600\n",
      "2022-11-08,05:25:33 | INFO | Rank 0 | Train Epoch: 0 [10944/23491 (47%)]\tLoss: 1.721488\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000055\tlogit_scale 4.600\n",
      "2022-11-08,05:25:33 | INFO | Rank 0 | Train Epoch: 0 [10976/23491 (47%)]\tLoss: 1.369909\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000055\tlogit_scale 4.600\n",
      "2022-11-08,05:25:34 | INFO | Rank 0 | Train Epoch: 0 [11008/23491 (47%)]\tLoss: 1.669633\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000055\tlogit_scale 4.600\n",
      "2022-11-08,05:25:34 | INFO | Rank 0 | Train Epoch: 0 [11040/23491 (47%)]\tLoss: 1.554222\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000055\tlogit_scale 4.600\n",
      "2022-11-08,05:25:34 | INFO | Rank 0 | Train Epoch: 0 [11072/23491 (47%)]\tLoss: 1.535287\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000056\tlogit_scale 4.600\n",
      "2022-11-08,05:25:34 | INFO | Rank 0 | Train Epoch: 0 [11104/23491 (47%)]\tLoss: 2.204393\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000056\tlogit_scale 4.600\n",
      "2022-11-08,05:25:35 | INFO | Rank 0 | Train Epoch: 0 [11136/23491 (47%)]\tLoss: 1.869214\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000056\tlogit_scale 4.600\n",
      "2022-11-08,05:25:35 | INFO | Rank 0 | Train Epoch: 0 [11168/23491 (48%)]\tLoss: 1.818280\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000056\tlogit_scale 4.600\n",
      "2022-11-08,05:25:35 | INFO | Rank 0 | Train Epoch: 0 [11200/23491 (48%)]\tLoss: 1.852170\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000056\tlogit_scale 4.600\n",
      "2022-11-08,05:25:35 | INFO | Rank 0 | Train Epoch: 0 [11232/23491 (48%)]\tLoss: 1.712171\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000056\tlogit_scale 4.600\n",
      "2022-11-08,05:25:36 | INFO | Rank 0 | Train Epoch: 0 [11264/23491 (48%)]\tLoss: 1.755707\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000056\tlogit_scale 4.600\n",
      "2022-11-08,05:25:36 | INFO | Rank 0 | Train Epoch: 0 [11296/23491 (48%)]\tLoss: 1.866615\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000057\tlogit_scale 4.600\n",
      "2022-11-08,05:25:36 | INFO | Rank 0 | Train Epoch: 0 [11328/23491 (48%)]\tLoss: 1.421764\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000057\tlogit_scale 4.600\n",
      "2022-11-08,05:25:37 | INFO | Rank 0 | Train Epoch: 0 [11360/23491 (48%)]\tLoss: 1.704145\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000057\tlogit_scale 4.600\n",
      "2022-11-08,05:25:37 | INFO | Rank 0 | Train Epoch: 0 [11392/23491 (49%)]\tLoss: 1.779020\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.600\n",
      "2022-11-08,05:25:37 | INFO | Rank 0 | Train Epoch: 0 [11424/23491 (49%)]\tLoss: 1.568388\tData (t) 0.055\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.600\n",
      "2022-11-08,05:25:37 | INFO | Rank 0 | Train Epoch: 0 [11456/23491 (49%)]\tLoss: 2.372557\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000057\tlogit_scale 4.600\n",
      "2022-11-08,05:25:38 | INFO | Rank 0 | Train Epoch: 0 [11488/23491 (49%)]\tLoss: 2.009706\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.600\n",
      "2022-11-08,05:25:38 | INFO | Rank 0 | Train Epoch: 0 [11520/23491 (49%)]\tLoss: 1.955243\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000058\tlogit_scale 4.600\n",
      "2022-11-08,05:25:38 | INFO | Rank 0 | Train Epoch: 0 [11552/23491 (49%)]\tLoss: 1.935927\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000058\tlogit_scale 4.599\n",
      "2022-11-08,05:25:38 | INFO | Rank 0 | Train Epoch: 0 [11584/23491 (49%)]\tLoss: 2.296264\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000058\tlogit_scale 4.599\n",
      "2022-11-08,05:25:39 | INFO | Rank 0 | Train Epoch: 0 [11616/23491 (49%)]\tLoss: 1.999525\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000058\tlogit_scale 4.599\n",
      "2022-11-08,05:25:39 | INFO | Rank 0 | Train Epoch: 0 [11648/23491 (50%)]\tLoss: 1.604835\tData (t) 0.052\tBatch (t) 0.263\tLR: 0.000058\tlogit_scale 4.599\n",
      "2022-11-08,05:25:39 | INFO | Rank 0 | Train Epoch: 0 [11680/23491 (50%)]\tLoss: 1.925287\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000059\tlogit_scale 4.599\n",
      "2022-11-08,05:25:39 | INFO | Rank 0 | Train Epoch: 0 [11712/23491 (50%)]\tLoss: 1.777337\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000059\tlogit_scale 4.599\n",
      "2022-11-08,05:25:40 | INFO | Rank 0 | Train Epoch: 0 [11744/23491 (50%)]\tLoss: 1.230772\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000059\tlogit_scale 4.599\n",
      "2022-11-08,05:25:40 | INFO | Rank 0 | Train Epoch: 0 [11776/23491 (50%)]\tLoss: 2.008406\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000059\tlogit_scale 4.599\n",
      "2022-11-08,05:25:40 | INFO | Rank 0 | Train Epoch: 0 [11808/23491 (50%)]\tLoss: 1.510062\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000059\tlogit_scale 4.599\n",
      "2022-11-08,05:25:40 | INFO | Rank 0 | Train Epoch: 0 [11840/23491 (50%)]\tLoss: 2.046419\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000059\tlogit_scale 4.599\n",
      "2022-11-08,05:25:41 | INFO | Rank 0 | Train Epoch: 0 [11872/23491 (51%)]\tLoss: 1.995469\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000060\tlogit_scale 4.599\n",
      "2022-11-08,05:25:41 | INFO | Rank 0 | Train Epoch: 0 [11904/23491 (51%)]\tLoss: 1.963741\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000060\tlogit_scale 4.599\n",
      "2022-11-08,05:25:41 | INFO | Rank 0 | Train Epoch: 0 [11936/23491 (51%)]\tLoss: 1.878606\tData (t) 0.052\tBatch (t) 0.263\tLR: 0.000060\tlogit_scale 4.599\n",
      "2022-11-08,05:25:42 | INFO | Rank 0 | Train Epoch: 0 [11968/23491 (51%)]\tLoss: 1.707492\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000060\tlogit_scale 4.599\n",
      "2022-11-08,05:25:42 | INFO | Rank 0 | Train Epoch: 0 [12000/23491 (51%)]\tLoss: 2.530530\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000060\tlogit_scale 4.599\n",
      "2022-11-08,05:25:42 | INFO | Rank 0 | Train Epoch: 0 [12032/23491 (51%)]\tLoss: 1.860544\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000060\tlogit_scale 4.599\n",
      "2022-11-08,05:25:42 | INFO | Rank 0 | Train Epoch: 0 [12064/23491 (51%)]\tLoss: 1.614184\tData (t) 0.054\tBatch (t) 0.264\tLR: 0.000060\tlogit_scale 4.599\n",
      "2022-11-08,05:25:43 | INFO | Rank 0 | Train Epoch: 0 [12096/23491 (51%)]\tLoss: 1.778414\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000061\tlogit_scale 4.599\n",
      "2022-11-08,05:25:43 | INFO | Rank 0 | Train Epoch: 0 [12128/23491 (52%)]\tLoss: 2.200077\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000061\tlogit_scale 4.599\n",
      "2022-11-08,05:25:43 | INFO | Rank 0 | Train Epoch: 0 [12160/23491 (52%)]\tLoss: 1.942363\tData (t) 0.052\tBatch (t) 0.263\tLR: 0.000061\tlogit_scale 4.599\n",
      "2022-11-08,05:25:43 | INFO | Rank 0 | Train Epoch: 0 [12192/23491 (52%)]\tLoss: 2.176033\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000061\tlogit_scale 4.599\n",
      "2022-11-08,05:25:44 | INFO | Rank 0 | Train Epoch: 0 [12224/23491 (52%)]\tLoss: 1.491635\tData (t) 0.052\tBatch (t) 0.263\tLR: 0.000061\tlogit_scale 4.599\n",
      "2022-11-08,05:25:44 | INFO | Rank 0 | Train Epoch: 0 [12256/23491 (52%)]\tLoss: 1.721054\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000061\tlogit_scale 4.599\n",
      "2022-11-08,05:25:44 | INFO | Rank 0 | Train Epoch: 0 [12288/23491 (52%)]\tLoss: 1.665644\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000062\tlogit_scale 4.599\n",
      "2022-11-08,05:25:44 | INFO | Rank 0 | Train Epoch: 0 [12320/23491 (52%)]\tLoss: 2.013947\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000062\tlogit_scale 4.599\n",
      "2022-11-08,05:25:45 | INFO | Rank 0 | Train Epoch: 0 [12352/23491 (53%)]\tLoss: 1.950453\tData (t) 0.052\tBatch (t) 0.263\tLR: 0.000062\tlogit_scale 4.599\n",
      "2022-11-08,05:25:45 | INFO | Rank 0 | Train Epoch: 0 [12384/23491 (53%)]\tLoss: 2.148117\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000062\tlogit_scale 4.598\n",
      "2022-11-08,05:25:45 | INFO | Rank 0 | Train Epoch: 0 [12416/23491 (53%)]\tLoss: 1.869075\tData (t) 0.052\tBatch (t) 0.263\tLR: 0.000062\tlogit_scale 4.598\n",
      "2022-11-08,05:25:45 | INFO | Rank 0 | Train Epoch: 0 [12448/23491 (53%)]\tLoss: 2.093671\tData (t) 0.055\tBatch (t) 0.265\tLR: 0.000062\tlogit_scale 4.598\n",
      "2022-11-08,05:25:46 | INFO | Rank 0 | Train Epoch: 0 [12480/23491 (53%)]\tLoss: 1.901728\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000063\tlogit_scale 4.598\n",
      "2022-11-08,05:25:46 | INFO | Rank 0 | Train Epoch: 0 [12512/23491 (53%)]\tLoss: 1.697992\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000063\tlogit_scale 4.598\n",
      "2022-11-08,05:25:46 | INFO | Rank 0 | Train Epoch: 0 [12544/23491 (53%)]\tLoss: 2.453886\tData (t) 0.052\tBatch (t) 0.263\tLR: 0.000063\tlogit_scale 4.598\n",
      "2022-11-08,05:25:47 | INFO | Rank 0 | Train Epoch: 0 [12576/23491 (54%)]\tLoss: 1.788532\tData (t) 0.055\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.598\n",
      "2022-11-08,05:25:47 | INFO | Rank 0 | Train Epoch: 0 [12608/23491 (54%)]\tLoss: 1.889538\tData (t) 0.055\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.598\n",
      "2022-11-08,05:25:47 | INFO | Rank 0 | Train Epoch: 0 [12640/23491 (54%)]\tLoss: 1.843105\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000063\tlogit_scale 4.598\n",
      "2022-11-08,05:25:47 | INFO | Rank 0 | Train Epoch: 0 [12672/23491 (54%)]\tLoss: 1.704279\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000064\tlogit_scale 4.598\n",
      "2022-11-08,05:25:48 | INFO | Rank 0 | Train Epoch: 0 [12704/23491 (54%)]\tLoss: 1.821022\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000064\tlogit_scale 4.598\n",
      "2022-11-08,05:25:48 | INFO | Rank 0 | Train Epoch: 0 [12736/23491 (54%)]\tLoss: 1.781517\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000064\tlogit_scale 4.598\n",
      "2022-11-08,05:25:48 | INFO | Rank 0 | Train Epoch: 0 [12768/23491 (54%)]\tLoss: 2.426634\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000064\tlogit_scale 4.598\n",
      "2022-11-08,05:25:48 | INFO | Rank 0 | Train Epoch: 0 [12800/23491 (54%)]\tLoss: 2.560700\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000064\tlogit_scale 4.598\n",
      "2022-11-08,05:25:49 | INFO | Rank 0 | Train Epoch: 0 [12832/23491 (55%)]\tLoss: 2.467725\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000064\tlogit_scale 4.598\n",
      "2022-11-08,05:25:49 | INFO | Rank 0 | Train Epoch: 0 [12864/23491 (55%)]\tLoss: 2.005998\tData (t) 0.052\tBatch (t) 0.263\tLR: 0.000064\tlogit_scale 4.598\n",
      "2022-11-08,05:25:49 | INFO | Rank 0 | Train Epoch: 0 [12896/23491 (55%)]\tLoss: 1.458222\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000065\tlogit_scale 4.598\n",
      "2022-11-08,05:25:49 | INFO | Rank 0 | Train Epoch: 0 [12928/23491 (55%)]\tLoss: 1.615115\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000065\tlogit_scale 4.598\n",
      "2022-11-08,05:25:50 | INFO | Rank 0 | Train Epoch: 0 [12960/23491 (55%)]\tLoss: 1.939190\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000065\tlogit_scale 4.598\n",
      "2022-11-08,05:25:50 | INFO | Rank 0 | Train Epoch: 0 [12992/23491 (55%)]\tLoss: 1.594841\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000065\tlogit_scale 4.598\n",
      "2022-11-08,05:25:50 | INFO | Rank 0 | Train Epoch: 0 [13024/23491 (55%)]\tLoss: 1.839789\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000065\tlogit_scale 4.598\n",
      "2022-11-08,05:25:50 | INFO | Rank 0 | Train Epoch: 0 [13056/23491 (56%)]\tLoss: 1.961483\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000065\tlogit_scale 4.598\n",
      "2022-11-08,05:25:51 | INFO | Rank 0 | Train Epoch: 0 [13088/23491 (56%)]\tLoss: 1.878264\tData (t) 0.052\tBatch (t) 0.264\tLR: 0.000066\tlogit_scale 4.598\n",
      "2022-11-08,05:25:51 | INFO | Rank 0 | Train Epoch: 0 [13120/23491 (56%)]\tLoss: 1.843537\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000066\tlogit_scale 4.598\n",
      "2022-11-08,05:25:51 | INFO | Rank 0 | Train Epoch: 0 [13152/23491 (56%)]\tLoss: 2.077892\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000066\tlogit_scale 4.598\n",
      "2022-11-08,05:25:52 | INFO | Rank 0 | Train Epoch: 0 [13184/23491 (56%)]\tLoss: 1.861837\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000066\tlogit_scale 4.598\n",
      "2022-11-08,05:25:52 | INFO | Rank 0 | Train Epoch: 0 [13216/23491 (56%)]\tLoss: 1.859425\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000066\tlogit_scale 4.598\n",
      "2022-11-08,05:25:52 | INFO | Rank 0 | Train Epoch: 0 [13248/23491 (56%)]\tLoss: 1.404068\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000066\tlogit_scale 4.598\n",
      "2022-11-08,05:25:52 | INFO | Rank 0 | Train Epoch: 0 [13280/23491 (57%)]\tLoss: 1.970602\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000067\tlogit_scale 4.598\n",
      "2022-11-08,05:25:53 | INFO | Rank 0 | Train Epoch: 0 [13312/23491 (57%)]\tLoss: 2.020700\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000067\tlogit_scale 4.598\n",
      "2022-11-08,05:25:53 | INFO | Rank 0 | Train Epoch: 0 [13344/23491 (57%)]\tLoss: 2.121981\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000067\tlogit_scale 4.598\n",
      "2022-11-08,05:25:53 | INFO | Rank 0 | Train Epoch: 0 [13376/23491 (57%)]\tLoss: 1.377051\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000067\tlogit_scale 4.598\n",
      "2022-11-08,05:25:53 | INFO | Rank 0 | Train Epoch: 0 [13408/23491 (57%)]\tLoss: 1.704690\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000067\tlogit_scale 4.597\n",
      "2022-11-08,05:25:54 | INFO | Rank 0 | Train Epoch: 0 [13440/23491 (57%)]\tLoss: 1.864068\tData (t) 0.052\tBatch (t) 0.264\tLR: 0.000067\tlogit_scale 4.597\n",
      "2022-11-08,05:25:54 | INFO | Rank 0 | Train Epoch: 0 [13472/23491 (57%)]\tLoss: 1.829595\tData (t) 0.054\tBatch (t) 0.264\tLR: 0.000068\tlogit_scale 4.597\n",
      "2022-11-08,05:25:54 | INFO | Rank 0 | Train Epoch: 0 [13504/23491 (57%)]\tLoss: 1.857971\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000068\tlogit_scale 4.597\n",
      "2022-11-08,05:25:54 | INFO | Rank 0 | Train Epoch: 0 [13536/23491 (58%)]\tLoss: 2.437663\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000068\tlogit_scale 4.597\n",
      "2022-11-08,05:25:55 | INFO | Rank 0 | Train Epoch: 0 [13568/23491 (58%)]\tLoss: 2.066752\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000068\tlogit_scale 4.597\n",
      "2022-11-08,05:25:55 | INFO | Rank 0 | Train Epoch: 0 [13600/23491 (58%)]\tLoss: 1.406745\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000068\tlogit_scale 4.597\n",
      "2022-11-08,05:25:55 | INFO | Rank 0 | Train Epoch: 0 [13632/23491 (58%)]\tLoss: 2.101459\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000068\tlogit_scale 4.597\n",
      "2022-11-08,05:25:55 | INFO | Rank 0 | Train Epoch: 0 [13664/23491 (58%)]\tLoss: 1.999555\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000068\tlogit_scale 4.597\n",
      "2022-11-08,05:25:56 | INFO | Rank 0 | Train Epoch: 0 [13696/23491 (58%)]\tLoss: 1.790735\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.597\n",
      "2022-11-08,05:25:56 | INFO | Rank 0 | Train Epoch: 0 [13728/23491 (58%)]\tLoss: 1.779187\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000069\tlogit_scale 4.597\n",
      "2022-11-08,05:25:56 | INFO | Rank 0 | Train Epoch: 0 [13760/23491 (59%)]\tLoss: 1.529428\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000069\tlogit_scale 4.597\n",
      "2022-11-08,05:25:57 | INFO | Rank 0 | Train Epoch: 0 [13792/23491 (59%)]\tLoss: 2.048852\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000069\tlogit_scale 4.597\n",
      "2022-11-08,05:25:57 | INFO | Rank 0 | Train Epoch: 0 [13824/23491 (59%)]\tLoss: 1.723375\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000069\tlogit_scale 4.597\n",
      "2022-11-08,05:25:57 | INFO | Rank 0 | Train Epoch: 0 [13856/23491 (59%)]\tLoss: 2.103057\tData (t) 0.055\tBatch (t) 0.267\tLR: 0.000069\tlogit_scale 4.597\n",
      "2022-11-08,05:25:57 | INFO | Rank 0 | Train Epoch: 0 [13888/23491 (59%)]\tLoss: 1.870910\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000070\tlogit_scale 4.597\n",
      "2022-11-08,05:25:58 | INFO | Rank 0 | Train Epoch: 0 [13920/23491 (59%)]\tLoss: 1.880071\tData (t) 0.056\tBatch (t) 0.267\tLR: 0.000070\tlogit_scale 4.597\n",
      "2022-11-08,05:25:58 | INFO | Rank 0 | Train Epoch: 0 [13952/23491 (59%)]\tLoss: 1.907103\tData (t) 0.056\tBatch (t) 0.267\tLR: 0.000070\tlogit_scale 4.597\n",
      "2022-11-08,05:25:58 | INFO | Rank 0 | Train Epoch: 0 [13984/23491 (60%)]\tLoss: 1.338431\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000070\tlogit_scale 4.597\n",
      "2022-11-08,05:25:58 | INFO | Rank 0 | Train Epoch: 0 [14016/23491 (60%)]\tLoss: 1.706764\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000070\tlogit_scale 4.597\n",
      "2022-11-08,05:25:59 | INFO | Rank 0 | Train Epoch: 0 [14048/23491 (60%)]\tLoss: 1.982273\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000070\tlogit_scale 4.597\n",
      "2022-11-08,05:25:59 | INFO | Rank 0 | Train Epoch: 0 [14080/23491 (60%)]\tLoss: 1.884206\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.597\n",
      "2022-11-08,05:25:59 | INFO | Rank 0 | Train Epoch: 0 [14112/23491 (60%)]\tLoss: 2.773520\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000071\tlogit_scale 4.597\n",
      "2022-11-08,05:25:59 | INFO | Rank 0 | Train Epoch: 0 [14144/23491 (60%)]\tLoss: 1.799423\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000071\tlogit_scale 4.597\n",
      "2022-11-08,05:26:00 | INFO | Rank 0 | Train Epoch: 0 [14176/23491 (60%)]\tLoss: 1.861534\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000071\tlogit_scale 4.597\n",
      "2022-11-08,05:26:00 | INFO | Rank 0 | Train Epoch: 0 [14208/23491 (60%)]\tLoss: 1.606984\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.597\n",
      "2022-11-08,05:26:00 | INFO | Rank 0 | Train Epoch: 0 [14240/23491 (61%)]\tLoss: 1.489029\tData (t) 0.052\tBatch (t) 0.264\tLR: 0.000071\tlogit_scale 4.597\n",
      "2022-11-08,05:26:01 | INFO | Rank 0 | Train Epoch: 0 [14272/23491 (61%)]\tLoss: 1.475806\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000072\tlogit_scale 4.597\n",
      "2022-11-08,05:26:01 | INFO | Rank 0 | Train Epoch: 0 [14304/23491 (61%)]\tLoss: 2.199459\tData (t) 0.052\tBatch (t) 0.263\tLR: 0.000072\tlogit_scale 4.597\n",
      "2022-11-08,05:26:01 | INFO | Rank 0 | Train Epoch: 0 [14336/23491 (61%)]\tLoss: 2.037361\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000072\tlogit_scale 4.597\n",
      "2022-11-08,05:26:01 | INFO | Rank 0 | Train Epoch: 0 [14368/23491 (61%)]\tLoss: 2.130641\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000072\tlogit_scale 4.597\n",
      "2022-11-08,05:26:02 | INFO | Rank 0 | Train Epoch: 0 [14400/23491 (61%)]\tLoss: 1.886697\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.597\n",
      "2022-11-08,05:26:02 | INFO | Rank 0 | Train Epoch: 0 [14432/23491 (61%)]\tLoss: 1.868417\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000072\tlogit_scale 4.596\n",
      "2022-11-08,05:26:02 | INFO | Rank 0 | Train Epoch: 0 [14464/23491 (62%)]\tLoss: 1.795279\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000072\tlogit_scale 4.596\n",
      "2022-11-08,05:26:02 | INFO | Rank 0 | Train Epoch: 0 [14496/23491 (62%)]\tLoss: 1.702105\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000073\tlogit_scale 4.596\n",
      "2022-11-08,05:26:03 | INFO | Rank 0 | Train Epoch: 0 [14528/23491 (62%)]\tLoss: 2.145905\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.596\n",
      "2022-11-08,05:26:03 | INFO | Rank 0 | Train Epoch: 0 [14560/23491 (62%)]\tLoss: 2.620217\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.596\n",
      "2022-11-08,05:26:03 | INFO | Rank 0 | Train Epoch: 0 [14592/23491 (62%)]\tLoss: 1.893016\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000073\tlogit_scale 4.596\n",
      "2022-11-08,05:26:03 | INFO | Rank 0 | Train Epoch: 0 [14624/23491 (62%)]\tLoss: 1.722946\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000073\tlogit_scale 4.596\n",
      "2022-11-08,05:26:04 | INFO | Rank 0 | Train Epoch: 0 [14656/23491 (62%)]\tLoss: 1.796750\tData (t) 0.052\tBatch (t) 0.263\tLR: 0.000073\tlogit_scale 4.596\n",
      "2022-11-08,05:26:04 | INFO | Rank 0 | Train Epoch: 0 [14688/23491 (63%)]\tLoss: 1.835683\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000074\tlogit_scale 4.596\n",
      "2022-11-08,05:26:04 | INFO | Rank 0 | Train Epoch: 0 [14720/23491 (63%)]\tLoss: 1.868607\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.596\n",
      "2022-11-08,05:26:04 | INFO | Rank 0 | Train Epoch: 0 [14752/23491 (63%)]\tLoss: 2.356052\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000074\tlogit_scale 4.596\n",
      "2022-11-08,05:26:05 | INFO | Rank 0 | Train Epoch: 0 [14784/23491 (63%)]\tLoss: 1.851135\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000074\tlogit_scale 4.596\n",
      "2022-11-08,05:26:05 | INFO | Rank 0 | Train Epoch: 0 [14816/23491 (63%)]\tLoss: 2.005346\tData (t) 0.052\tBatch (t) 0.263\tLR: 0.000074\tlogit_scale 4.596\n",
      "2022-11-08,05:26:05 | INFO | Rank 0 | Train Epoch: 0 [14848/23491 (63%)]\tLoss: 1.556720\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.596\n",
      "2022-11-08,05:26:06 | INFO | Rank 0 | Train Epoch: 0 [14880/23491 (63%)]\tLoss: 2.094682\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000075\tlogit_scale 4.596\n",
      "2022-11-08,05:26:06 | INFO | Rank 0 | Train Epoch: 0 [14912/23491 (63%)]\tLoss: 1.797046\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000075\tlogit_scale 4.596\n",
      "2022-11-08,05:26:06 | INFO | Rank 0 | Train Epoch: 0 [14944/23491 (64%)]\tLoss: 2.034633\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000075\tlogit_scale 4.596\n",
      "2022-11-08,05:26:06 | INFO | Rank 0 | Train Epoch: 0 [14976/23491 (64%)]\tLoss: 2.207449\tData (t) 0.053\tBatch (t) 0.263\tLR: 0.000075\tlogit_scale 4.596\n",
      "2022-11-08,05:26:07 | INFO | Rank 0 | Train Epoch: 0 [15008/23491 (64%)]\tLoss: 1.925266\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000075\tlogit_scale 4.596\n",
      "2022-11-08,05:26:07 | INFO | Rank 0 | Train Epoch: 0 [15040/23491 (64%)]\tLoss: 2.127318\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000075\tlogit_scale 4.596\n",
      "2022-11-08,05:26:07 | INFO | Rank 0 | Train Epoch: 0 [15072/23491 (64%)]\tLoss: 1.666934\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000076\tlogit_scale 4.596\n",
      "2022-11-08,05:26:07 | INFO | Rank 0 | Train Epoch: 0 [15104/23491 (64%)]\tLoss: 1.806461\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000076\tlogit_scale 4.596\n",
      "2022-11-08,05:26:08 | INFO | Rank 0 | Train Epoch: 0 [15136/23491 (64%)]\tLoss: 2.244930\tData (t) 0.052\tBatch (t) 0.264\tLR: 0.000076\tlogit_scale 4.596\n",
      "2022-11-08,05:26:08 | INFO | Rank 0 | Train Epoch: 0 [15168/23491 (65%)]\tLoss: 2.408432\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000076\tlogit_scale 4.596\n",
      "2022-11-08,05:26:08 | INFO | Rank 0 | Train Epoch: 0 [15200/23491 (65%)]\tLoss: 2.103068\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000076\tlogit_scale 4.596\n",
      "2022-11-08,05:26:08 | INFO | Rank 0 | Train Epoch: 0 [15232/23491 (65%)]\tLoss: 2.214824\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000076\tlogit_scale 4.596\n",
      "2022-11-08,05:26:09 | INFO | Rank 0 | Train Epoch: 0 [15264/23491 (65%)]\tLoss: 1.833817\tData (t) 0.052\tBatch (t) 0.264\tLR: 0.000076\tlogit_scale 4.596\n",
      "2022-11-08,05:26:09 | INFO | Rank 0 | Train Epoch: 0 [15296/23491 (65%)]\tLoss: 1.884859\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000077\tlogit_scale 4.595\n",
      "2022-11-08,05:26:09 | INFO | Rank 0 | Train Epoch: 0 [15328/23491 (65%)]\tLoss: 2.429003\tData (t) 0.055\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.595\n",
      "2022-11-08,05:26:10 | INFO | Rank 0 | Train Epoch: 0 [15360/23491 (65%)]\tLoss: 2.128384\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000077\tlogit_scale 4.595\n",
      "2022-11-08,05:26:10 | INFO | Rank 0 | Train Epoch: 0 [15392/23491 (66%)]\tLoss: 1.689093\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000077\tlogit_scale 4.595\n",
      "2022-11-08,05:26:10 | INFO | Rank 0 | Train Epoch: 0 [15424/23491 (66%)]\tLoss: 2.142283\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000077\tlogit_scale 4.595\n",
      "2022-11-08,05:26:10 | INFO | Rank 0 | Train Epoch: 0 [15456/23491 (66%)]\tLoss: 1.749887\tData (t) 0.056\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.595\n",
      "2022-11-08,05:26:11 | INFO | Rank 0 | Train Epoch: 0 [15488/23491 (66%)]\tLoss: 1.915249\tData (t) 0.055\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.595\n",
      "2022-11-08,05:26:11 | INFO | Rank 0 | Train Epoch: 0 [15520/23491 (66%)]\tLoss: 2.031443\tData (t) 0.052\tBatch (t) 0.264\tLR: 0.000078\tlogit_scale 4.595\n",
      "2022-11-08,05:26:11 | INFO | Rank 0 | Train Epoch: 0 [15552/23491 (66%)]\tLoss: 1.952468\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.595\n",
      "2022-11-08,05:26:11 | INFO | Rank 0 | Train Epoch: 0 [15584/23491 (66%)]\tLoss: 1.708209\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.595\n",
      "2022-11-08,05:26:12 | INFO | Rank 0 | Train Epoch: 0 [15616/23491 (66%)]\tLoss: 2.146343\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000078\tlogit_scale 4.595\n",
      "2022-11-08,05:26:12 | INFO | Rank 0 | Train Epoch: 0 [15648/23491 (67%)]\tLoss: 2.251558\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.595\n",
      "2022-11-08,05:26:12 | INFO | Rank 0 | Train Epoch: 0 [15680/23491 (67%)]\tLoss: 1.760544\tData (t) 0.055\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.595\n",
      "2022-11-08,05:26:12 | INFO | Rank 0 | Train Epoch: 0 [15712/23491 (67%)]\tLoss: 1.834145\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.595\n",
      "2022-11-08,05:26:13 | INFO | Rank 0 | Train Epoch: 0 [15744/23491 (67%)]\tLoss: 2.084057\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000079\tlogit_scale 4.595\n",
      "2022-11-08,05:26:13 | INFO | Rank 0 | Train Epoch: 0 [15776/23491 (67%)]\tLoss: 2.159907\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000079\tlogit_scale 4.595\n",
      "2022-11-08,05:26:13 | INFO | Rank 0 | Train Epoch: 0 [15808/23491 (67%)]\tLoss: 1.755901\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000079\tlogit_scale 4.595\n",
      "2022-11-08,05:26:13 | INFO | Rank 0 | Train Epoch: 0 [15840/23491 (67%)]\tLoss: 2.193480\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.595\n",
      "2022-11-08,05:26:14 | INFO | Rank 0 | Train Epoch: 0 [15872/23491 (68%)]\tLoss: 2.044408\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000080\tlogit_scale 4.595\n",
      "2022-11-08,05:26:14 | INFO | Rank 0 | Train Epoch: 0 [15904/23491 (68%)]\tLoss: 2.039397\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000080\tlogit_scale 4.595\n",
      "2022-11-08,05:26:14 | INFO | Rank 0 | Train Epoch: 0 [15936/23491 (68%)]\tLoss: 2.121854\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000080\tlogit_scale 4.595\n",
      "2022-11-08,05:26:15 | INFO | Rank 0 | Train Epoch: 0 [15968/23491 (68%)]\tLoss: 2.148401\tData (t) 0.056\tBatch (t) 0.267\tLR: 0.000080\tlogit_scale 4.595\n",
      "2022-11-08,05:26:15 | INFO | Rank 0 | Train Epoch: 0 [16000/23491 (68%)]\tLoss: 1.940356\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000080\tlogit_scale 4.595\n",
      "2022-11-08,05:26:15 | INFO | Rank 0 | Train Epoch: 0 [16032/23491 (68%)]\tLoss: 2.059552\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.595\n",
      "2022-11-08,05:26:15 | INFO | Rank 0 | Train Epoch: 0 [16064/23491 (68%)]\tLoss: 1.863067\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.595\n",
      "2022-11-08,05:26:16 | INFO | Rank 0 | Train Epoch: 0 [16096/23491 (69%)]\tLoss: 1.921450\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.595\n",
      "2022-11-08,05:26:16 | INFO | Rank 0 | Train Epoch: 0 [16128/23491 (69%)]\tLoss: 2.096201\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.595\n",
      "2022-11-08,05:26:16 | INFO | Rank 0 | Train Epoch: 0 [16160/23491 (69%)]\tLoss: 2.104750\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:16 | INFO | Rank 0 | Train Epoch: 0 [16192/23491 (69%)]\tLoss: 1.826161\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:17 | INFO | Rank 0 | Train Epoch: 0 [16224/23491 (69%)]\tLoss: 1.907495\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:17 | INFO | Rank 0 | Train Epoch: 0 [16256/23491 (69%)]\tLoss: 2.437664\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:17 | INFO | Rank 0 | Train Epoch: 0 [16288/23491 (69%)]\tLoss: 1.955036\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:17 | INFO | Rank 0 | Train Epoch: 0 [16320/23491 (69%)]\tLoss: 1.920008\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:18 | INFO | Rank 0 | Train Epoch: 0 [16352/23491 (70%)]\tLoss: 1.747351\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:18 | INFO | Rank 0 | Train Epoch: 0 [16384/23491 (70%)]\tLoss: 2.039183\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:18 | INFO | Rank 0 | Train Epoch: 0 [16416/23491 (70%)]\tLoss: 2.117524\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:19 | INFO | Rank 0 | Train Epoch: 0 [16448/23491 (70%)]\tLoss: 1.764757\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:19 | INFO | Rank 0 | Train Epoch: 0 [16480/23491 (70%)]\tLoss: 1.794093\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:19 | INFO | Rank 0 | Train Epoch: 0 [16512/23491 (70%)]\tLoss: 2.383119\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:19 | INFO | Rank 0 | Train Epoch: 0 [16544/23491 (70%)]\tLoss: 2.043741\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:20 | INFO | Rank 0 | Train Epoch: 0 [16576/23491 (71%)]\tLoss: 2.157736\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:20 | INFO | Rank 0 | Train Epoch: 0 [16608/23491 (71%)]\tLoss: 1.954544\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:20 | INFO | Rank 0 | Train Epoch: 0 [16640/23491 (71%)]\tLoss: 2.330947\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:20 | INFO | Rank 0 | Train Epoch: 0 [16672/23491 (71%)]\tLoss: 2.107189\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:21 | INFO | Rank 0 | Train Epoch: 0 [16704/23491 (71%)]\tLoss: 2.093594\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:21 | INFO | Rank 0 | Train Epoch: 0 [16736/23491 (71%)]\tLoss: 1.610017\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:21 | INFO | Rank 0 | Train Epoch: 0 [16768/23491 (71%)]\tLoss: 2.501229\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:21 | INFO | Rank 0 | Train Epoch: 0 [16800/23491 (72%)]\tLoss: 2.225214\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:22 | INFO | Rank 0 | Train Epoch: 0 [16832/23491 (72%)]\tLoss: 2.045909\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.594\n",
      "2022-11-08,05:26:22 | INFO | Rank 0 | Train Epoch: 0 [16864/23491 (72%)]\tLoss: 1.949057\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:22 | INFO | Rank 0 | Train Epoch: 0 [16896/23491 (72%)]\tLoss: 1.791313\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:23 | INFO | Rank 0 | Train Epoch: 0 [16928/23491 (72%)]\tLoss: 1.901736\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:23 | INFO | Rank 0 | Train Epoch: 0 [16960/23491 (72%)]\tLoss: 1.781400\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:23 | INFO | Rank 0 | Train Epoch: 0 [16992/23491 (72%)]\tLoss: 1.731276\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:23 | INFO | Rank 0 | Train Epoch: 0 [17024/23491 (72%)]\tLoss: 1.913880\tData (t) 0.056\tBatch (t) 0.268\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:24 | INFO | Rank 0 | Train Epoch: 0 [17056/23491 (73%)]\tLoss: 2.147710\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:24 | INFO | Rank 0 | Train Epoch: 0 [17088/23491 (73%)]\tLoss: 1.744324\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:24 | INFO | Rank 0 | Train Epoch: 0 [17120/23491 (73%)]\tLoss: 1.715017\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:24 | INFO | Rank 0 | Train Epoch: 0 [17152/23491 (73%)]\tLoss: 2.156459\tData (t) 0.056\tBatch (t) 0.269\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:25 | INFO | Rank 0 | Train Epoch: 0 [17184/23491 (73%)]\tLoss: 1.917841\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:25 | INFO | Rank 0 | Train Epoch: 0 [17216/23491 (73%)]\tLoss: 1.533196\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:25 | INFO | Rank 0 | Train Epoch: 0 [17248/23491 (73%)]\tLoss: 2.044899\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:25 | INFO | Rank 0 | Train Epoch: 0 [17280/23491 (74%)]\tLoss: 1.670383\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:26 | INFO | Rank 0 | Train Epoch: 0 [17312/23491 (74%)]\tLoss: 2.058204\tData (t) 0.055\tBatch (t) 0.267\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:26 | INFO | Rank 0 | Train Epoch: 0 [17344/23491 (74%)]\tLoss: 2.061698\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:26 | INFO | Rank 0 | Train Epoch: 0 [17376/23491 (74%)]\tLoss: 2.388016\tData (t) 0.056\tBatch (t) 0.268\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:27 | INFO | Rank 0 | Train Epoch: 0 [17408/23491 (74%)]\tLoss: 2.169348\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:27 | INFO | Rank 0 | Train Epoch: 0 [17440/23491 (74%)]\tLoss: 2.135914\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:27 | INFO | Rank 0 | Train Epoch: 0 [17472/23491 (74%)]\tLoss: 2.321783\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:27 | INFO | Rank 0 | Train Epoch: 0 [17504/23491 (75%)]\tLoss: 1.721380\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:28 | INFO | Rank 0 | Train Epoch: 0 [17536/23491 (75%)]\tLoss: 2.546255\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:28 | INFO | Rank 0 | Train Epoch: 0 [17568/23491 (75%)]\tLoss: 2.166207\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.593\n",
      "2022-11-08,05:26:28 | INFO | Rank 0 | Train Epoch: 0 [17600/23491 (75%)]\tLoss: 2.220213\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:28 | INFO | Rank 0 | Train Epoch: 0 [17632/23491 (75%)]\tLoss: 2.193724\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:29 | INFO | Rank 0 | Train Epoch: 0 [17664/23491 (75%)]\tLoss: 2.492392\tData (t) 0.055\tBatch (t) 0.267\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:29 | INFO | Rank 0 | Train Epoch: 0 [17696/23491 (75%)]\tLoss: 1.871078\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:29 | INFO | Rank 0 | Train Epoch: 0 [17728/23491 (75%)]\tLoss: 1.979895\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:29 | INFO | Rank 0 | Train Epoch: 0 [17760/23491 (76%)]\tLoss: 2.091171\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:30 | INFO | Rank 0 | Train Epoch: 0 [17792/23491 (76%)]\tLoss: 1.671383\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:30 | INFO | Rank 0 | Train Epoch: 0 [17824/23491 (76%)]\tLoss: 2.145028\tData (t) 0.055\tBatch (t) 0.267\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:30 | INFO | Rank 0 | Train Epoch: 0 [17856/23491 (76%)]\tLoss: 1.496874\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:30 | INFO | Rank 0 | Train Epoch: 0 [17888/23491 (76%)]\tLoss: 2.058020\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:31 | INFO | Rank 0 | Train Epoch: 0 [17920/23491 (76%)]\tLoss: 1.954918\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:31 | INFO | Rank 0 | Train Epoch: 0 [17952/23491 (76%)]\tLoss: 1.702693\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:31 | INFO | Rank 0 | Train Epoch: 0 [17984/23491 (77%)]\tLoss: 1.998261\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:32 | INFO | Rank 0 | Train Epoch: 0 [18016/23491 (77%)]\tLoss: 1.459455\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:32 | INFO | Rank 0 | Train Epoch: 0 [18048/23491 (77%)]\tLoss: 1.618050\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:32 | INFO | Rank 0 | Train Epoch: 0 [18080/23491 (77%)]\tLoss: 1.359707\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:32 | INFO | Rank 0 | Train Epoch: 0 [18112/23491 (77%)]\tLoss: 2.053544\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:33 | INFO | Rank 0 | Train Epoch: 0 [18144/23491 (77%)]\tLoss: 2.040828\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:33 | INFO | Rank 0 | Train Epoch: 0 [18176/23491 (77%)]\tLoss: 2.828961\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:33 | INFO | Rank 0 | Train Epoch: 0 [18208/23491 (78%)]\tLoss: 2.213434\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:33 | INFO | Rank 0 | Train Epoch: 0 [18240/23491 (78%)]\tLoss: 1.889282\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:34 | INFO | Rank 0 | Train Epoch: 0 [18272/23491 (78%)]\tLoss: 2.202026\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:34 | INFO | Rank 0 | Train Epoch: 0 [18304/23491 (78%)]\tLoss: 1.884814\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:34 | INFO | Rank 0 | Train Epoch: 0 [18336/23491 (78%)]\tLoss: 1.757675\tData (t) 0.056\tBatch (t) 0.269\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:34 | INFO | Rank 0 | Train Epoch: 0 [18368/23491 (78%)]\tLoss: 2.049629\tData (t) 0.055\tBatch (t) 0.267\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:35 | INFO | Rank 0 | Train Epoch: 0 [18400/23491 (78%)]\tLoss: 1.636836\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:35 | INFO | Rank 0 | Train Epoch: 0 [18432/23491 (78%)]\tLoss: 1.898336\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:35 | INFO | Rank 0 | Train Epoch: 0 [18464/23491 (79%)]\tLoss: 1.389351\tData (t) 0.056\tBatch (t) 0.269\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:36 | INFO | Rank 0 | Train Epoch: 0 [18496/23491 (79%)]\tLoss: 1.701401\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:36 | INFO | Rank 0 | Train Epoch: 0 [18528/23491 (79%)]\tLoss: 2.021113\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:36 | INFO | Rank 0 | Train Epoch: 0 [18560/23491 (79%)]\tLoss: 1.595495\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:36 | INFO | Rank 0 | Train Epoch: 0 [18592/23491 (79%)]\tLoss: 1.517549\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:37 | INFO | Rank 0 | Train Epoch: 0 [18624/23491 (79%)]\tLoss: 1.969781\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:37 | INFO | Rank 0 | Train Epoch: 0 [18656/23491 (79%)]\tLoss: 1.988121\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:37 | INFO | Rank 0 | Train Epoch: 0 [18688/23491 (80%)]\tLoss: 1.636444\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:37 | INFO | Rank 0 | Train Epoch: 0 [18720/23491 (80%)]\tLoss: 1.675086\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.592\n",
      "2022-11-08,05:26:38 | INFO | Rank 0 | Train Epoch: 0 [18752/23491 (80%)]\tLoss: 2.533092\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:38 | INFO | Rank 0 | Train Epoch: 0 [18784/23491 (80%)]\tLoss: 2.495738\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:38 | INFO | Rank 0 | Train Epoch: 0 [18816/23491 (80%)]\tLoss: 1.736697\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:38 | INFO | Rank 0 | Train Epoch: 0 [18848/23491 (80%)]\tLoss: 1.779638\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:39 | INFO | Rank 0 | Train Epoch: 0 [18880/23491 (80%)]\tLoss: 1.509306\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:39 | INFO | Rank 0 | Train Epoch: 0 [18912/23491 (81%)]\tLoss: 1.845660\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:39 | INFO | Rank 0 | Train Epoch: 0 [18944/23491 (81%)]\tLoss: 1.672118\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:40 | INFO | Rank 0 | Train Epoch: 0 [18976/23491 (81%)]\tLoss: 1.664766\tData (t) 0.052\tBatch (t) 0.264\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:40 | INFO | Rank 0 | Train Epoch: 0 [19008/23491 (81%)]\tLoss: 1.844029\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:40 | INFO | Rank 0 | Train Epoch: 0 [19040/23491 (81%)]\tLoss: 1.388302\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:40 | INFO | Rank 0 | Train Epoch: 0 [19072/23491 (81%)]\tLoss: 1.057440\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:41 | INFO | Rank 0 | Train Epoch: 0 [19104/23491 (81%)]\tLoss: 1.503997\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:41 | INFO | Rank 0 | Train Epoch: 0 [19136/23491 (81%)]\tLoss: 1.719023\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:41 | INFO | Rank 0 | Train Epoch: 0 [19168/23491 (82%)]\tLoss: 2.384744\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:41 | INFO | Rank 0 | Train Epoch: 0 [19200/23491 (82%)]\tLoss: 2.093506\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:42 | INFO | Rank 0 | Train Epoch: 0 [19232/23491 (82%)]\tLoss: 1.573021\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:42 | INFO | Rank 0 | Train Epoch: 0 [19264/23491 (82%)]\tLoss: 2.271718\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:42 | INFO | Rank 0 | Train Epoch: 0 [19296/23491 (82%)]\tLoss: 1.580930\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:42 | INFO | Rank 0 | Train Epoch: 0 [19328/23491 (82%)]\tLoss: 1.927547\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:43 | INFO | Rank 0 | Train Epoch: 0 [19360/23491 (82%)]\tLoss: 2.067082\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:43 | INFO | Rank 0 | Train Epoch: 0 [19392/23491 (83%)]\tLoss: 1.946754\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:43 | INFO | Rank 0 | Train Epoch: 0 [19424/23491 (83%)]\tLoss: 2.044132\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:44 | INFO | Rank 0 | Train Epoch: 0 [19456/23491 (83%)]\tLoss: 2.276182\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:44 | INFO | Rank 0 | Train Epoch: 0 [19488/23491 (83%)]\tLoss: 1.562241\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:44 | INFO | Rank 0 | Train Epoch: 0 [19520/23491 (83%)]\tLoss: 1.598217\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:44 | INFO | Rank 0 | Train Epoch: 0 [19552/23491 (83%)]\tLoss: 1.774466\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:45 | INFO | Rank 0 | Train Epoch: 0 [19584/23491 (83%)]\tLoss: 1.818542\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:45 | INFO | Rank 0 | Train Epoch: 0 [19616/23491 (84%)]\tLoss: 1.548532\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:45 | INFO | Rank 0 | Train Epoch: 0 [19648/23491 (84%)]\tLoss: 1.982757\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:45 | INFO | Rank 0 | Train Epoch: 0 [19680/23491 (84%)]\tLoss: 1.782878\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:46 | INFO | Rank 0 | Train Epoch: 0 [19712/23491 (84%)]\tLoss: 1.915519\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:46 | INFO | Rank 0 | Train Epoch: 0 [19744/23491 (84%)]\tLoss: 2.090282\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:46 | INFO | Rank 0 | Train Epoch: 0 [19776/23491 (84%)]\tLoss: 2.198071\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.591\n",
      "2022-11-08,05:26:46 | INFO | Rank 0 | Train Epoch: 0 [19808/23491 (84%)]\tLoss: 2.114417\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:47 | INFO | Rank 0 | Train Epoch: 0 [19840/23491 (84%)]\tLoss: 2.448619\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:47 | INFO | Rank 0 | Train Epoch: 0 [19872/23491 (85%)]\tLoss: 1.930995\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:47 | INFO | Rank 0 | Train Epoch: 0 [19904/23491 (85%)]\tLoss: 2.096144\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:47 | INFO | Rank 0 | Train Epoch: 0 [19936/23491 (85%)]\tLoss: 2.066112\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:48 | INFO | Rank 0 | Train Epoch: 0 [19968/23491 (85%)]\tLoss: 2.228370\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:48 | INFO | Rank 0 | Train Epoch: 0 [20000/23491 (85%)]\tLoss: 2.225755\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:48 | INFO | Rank 0 | Train Epoch: 0 [20032/23491 (85%)]\tLoss: 1.726063\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:49 | INFO | Rank 0 | Train Epoch: 0 [20064/23491 (85%)]\tLoss: 1.847496\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:49 | INFO | Rank 0 | Train Epoch: 0 [20096/23491 (86%)]\tLoss: 1.682937\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:49 | INFO | Rank 0 | Train Epoch: 0 [20128/23491 (86%)]\tLoss: 2.264251\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:49 | INFO | Rank 0 | Train Epoch: 0 [20160/23491 (86%)]\tLoss: 1.794987\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:50 | INFO | Rank 0 | Train Epoch: 0 [20192/23491 (86%)]\tLoss: 2.142418\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:50 | INFO | Rank 0 | Train Epoch: 0 [20224/23491 (86%)]\tLoss: 1.948903\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:50 | INFO | Rank 0 | Train Epoch: 0 [20256/23491 (86%)]\tLoss: 2.282892\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:50 | INFO | Rank 0 | Train Epoch: 0 [20288/23491 (86%)]\tLoss: 2.012418\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:51 | INFO | Rank 0 | Train Epoch: 0 [20320/23491 (87%)]\tLoss: 1.899218\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:51 | INFO | Rank 0 | Train Epoch: 0 [20352/23491 (87%)]\tLoss: 2.222775\tData (t) 0.055\tBatch (t) 0.267\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:51 | INFO | Rank 0 | Train Epoch: 0 [20384/23491 (87%)]\tLoss: 1.917557\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:51 | INFO | Rank 0 | Train Epoch: 0 [20416/23491 (87%)]\tLoss: 1.742880\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:52 | INFO | Rank 0 | Train Epoch: 0 [20448/23491 (87%)]\tLoss: 1.639744\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:52 | INFO | Rank 0 | Train Epoch: 0 [20480/23491 (87%)]\tLoss: 2.155266\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:52 | INFO | Rank 0 | Train Epoch: 0 [20512/23491 (87%)]\tLoss: 2.340014\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:53 | INFO | Rank 0 | Train Epoch: 0 [20544/23491 (87%)]\tLoss: 2.071983\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:53 | INFO | Rank 0 | Train Epoch: 0 [20576/23491 (88%)]\tLoss: 2.036614\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:53 | INFO | Rank 0 | Train Epoch: 0 [20608/23491 (88%)]\tLoss: 2.003698\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:53 | INFO | Rank 0 | Train Epoch: 0 [20640/23491 (88%)]\tLoss: 1.695107\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:54 | INFO | Rank 0 | Train Epoch: 0 [20672/23491 (88%)]\tLoss: 1.957097\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:54 | INFO | Rank 0 | Train Epoch: 0 [20704/23491 (88%)]\tLoss: 2.362350\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.590\n",
      "2022-11-08,05:26:54 | INFO | Rank 0 | Train Epoch: 0 [20736/23491 (88%)]\tLoss: 1.995990\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:54 | INFO | Rank 0 | Train Epoch: 0 [20768/23491 (88%)]\tLoss: 2.115014\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:55 | INFO | Rank 0 | Train Epoch: 0 [20800/23491 (89%)]\tLoss: 1.846795\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:55 | INFO | Rank 0 | Train Epoch: 0 [20832/23491 (89%)]\tLoss: 2.005614\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:55 | INFO | Rank 0 | Train Epoch: 0 [20864/23491 (89%)]\tLoss: 1.434666\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:55 | INFO | Rank 0 | Train Epoch: 0 [20896/23491 (89%)]\tLoss: 1.968829\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:56 | INFO | Rank 0 | Train Epoch: 0 [20928/23491 (89%)]\tLoss: 1.895380\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:56 | INFO | Rank 0 | Train Epoch: 0 [20960/23491 (89%)]\tLoss: 1.790979\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:56 | INFO | Rank 0 | Train Epoch: 0 [20992/23491 (89%)]\tLoss: 1.639862\tData (t) 0.056\tBatch (t) 0.268\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:57 | INFO | Rank 0 | Train Epoch: 0 [21024/23491 (90%)]\tLoss: 1.615498\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:57 | INFO | Rank 0 | Train Epoch: 0 [21056/23491 (90%)]\tLoss: 1.649709\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:57 | INFO | Rank 0 | Train Epoch: 0 [21088/23491 (90%)]\tLoss: 1.967455\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:57 | INFO | Rank 0 | Train Epoch: 0 [21120/23491 (90%)]\tLoss: 1.799173\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:58 | INFO | Rank 0 | Train Epoch: 0 [21152/23491 (90%)]\tLoss: 1.412596\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:58 | INFO | Rank 0 | Train Epoch: 0 [21184/23491 (90%)]\tLoss: 2.640386\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:58 | INFO | Rank 0 | Train Epoch: 0 [21216/23491 (90%)]\tLoss: 1.561771\tData (t) 0.052\tBatch (t) 0.264\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:58 | INFO | Rank 0 | Train Epoch: 0 [21248/23491 (90%)]\tLoss: 2.555979\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:59 | INFO | Rank 0 | Train Epoch: 0 [21280/23491 (91%)]\tLoss: 1.852128\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:59 | INFO | Rank 0 | Train Epoch: 0 [21312/23491 (91%)]\tLoss: 1.780549\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:59 | INFO | Rank 0 | Train Epoch: 0 [21344/23491 (91%)]\tLoss: 1.749512\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:26:59 | INFO | Rank 0 | Train Epoch: 0 [21376/23491 (91%)]\tLoss: 1.854352\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:27:00 | INFO | Rank 0 | Train Epoch: 0 [21408/23491 (91%)]\tLoss: 2.129211\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:27:00 | INFO | Rank 0 | Train Epoch: 0 [21440/23491 (91%)]\tLoss: 2.238781\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:27:00 | INFO | Rank 0 | Train Epoch: 0 [21472/23491 (91%)]\tLoss: 1.822952\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:27:01 | INFO | Rank 0 | Train Epoch: 0 [21504/23491 (92%)]\tLoss: 2.664607\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:27:01 | INFO | Rank 0 | Train Epoch: 0 [21536/23491 (92%)]\tLoss: 2.269896\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:27:01 | INFO | Rank 0 | Train Epoch: 0 [21568/23491 (92%)]\tLoss: 1.900217\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:27:01 | INFO | Rank 0 | Train Epoch: 0 [21600/23491 (92%)]\tLoss: 1.822014\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:27:02 | INFO | Rank 0 | Train Epoch: 0 [21632/23491 (92%)]\tLoss: 2.070197\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:27:02 | INFO | Rank 0 | Train Epoch: 0 [21664/23491 (92%)]\tLoss: 2.395248\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:27:02 | INFO | Rank 0 | Train Epoch: 0 [21696/23491 (92%)]\tLoss: 1.651071\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:27:02 | INFO | Rank 0 | Train Epoch: 0 [21728/23491 (93%)]\tLoss: 1.998146\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:27:03 | INFO | Rank 0 | Train Epoch: 0 [21760/23491 (93%)]\tLoss: 1.782141\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.589\n",
      "2022-11-08,05:27:03 | INFO | Rank 0 | Train Epoch: 0 [21792/23491 (93%)]\tLoss: 1.586903\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:03 | INFO | Rank 0 | Train Epoch: 0 [21824/23491 (93%)]\tLoss: 1.827246\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:03 | INFO | Rank 0 | Train Epoch: 0 [21856/23491 (93%)]\tLoss: 1.431336\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:04 | INFO | Rank 0 | Train Epoch: 0 [21888/23491 (93%)]\tLoss: 2.066607\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:04 | INFO | Rank 0 | Train Epoch: 0 [21920/23491 (93%)]\tLoss: 1.358299\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:04 | INFO | Rank 0 | Train Epoch: 0 [21952/23491 (93%)]\tLoss: 2.094968\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:04 | INFO | Rank 0 | Train Epoch: 0 [21984/23491 (94%)]\tLoss: 1.923281\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:05 | INFO | Rank 0 | Train Epoch: 0 [22016/23491 (94%)]\tLoss: 2.024909\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:05 | INFO | Rank 0 | Train Epoch: 0 [22048/23491 (94%)]\tLoss: 2.143965\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:05 | INFO | Rank 0 | Train Epoch: 0 [22080/23491 (94%)]\tLoss: 1.877882\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:06 | INFO | Rank 0 | Train Epoch: 0 [22112/23491 (94%)]\tLoss: 1.886188\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:06 | INFO | Rank 0 | Train Epoch: 0 [22144/23491 (94%)]\tLoss: 1.516087\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:06 | INFO | Rank 0 | Train Epoch: 0 [22176/23491 (94%)]\tLoss: 1.855040\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:06 | INFO | Rank 0 | Train Epoch: 0 [22208/23491 (95%)]\tLoss: 1.669552\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:07 | INFO | Rank 0 | Train Epoch: 0 [22240/23491 (95%)]\tLoss: 1.840838\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:07 | INFO | Rank 0 | Train Epoch: 0 [22272/23491 (95%)]\tLoss: 2.328106\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:07 | INFO | Rank 0 | Train Epoch: 0 [22304/23491 (95%)]\tLoss: 1.478827\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:07 | INFO | Rank 0 | Train Epoch: 0 [22336/23491 (95%)]\tLoss: 2.194728\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:08 | INFO | Rank 0 | Train Epoch: 0 [22368/23491 (95%)]\tLoss: 1.940707\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:08 | INFO | Rank 0 | Train Epoch: 0 [22400/23491 (95%)]\tLoss: 1.856950\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:08 | INFO | Rank 0 | Train Epoch: 0 [22432/23491 (96%)]\tLoss: 2.060231\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:08 | INFO | Rank 0 | Train Epoch: 0 [22464/23491 (96%)]\tLoss: 1.566968\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:09 | INFO | Rank 0 | Train Epoch: 0 [22496/23491 (96%)]\tLoss: 1.648767\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:09 | INFO | Rank 0 | Train Epoch: 0 [22528/23491 (96%)]\tLoss: 2.022400\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:09 | INFO | Rank 0 | Train Epoch: 0 [22560/23491 (96%)]\tLoss: 1.674303\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:10 | INFO | Rank 0 | Train Epoch: 0 [22592/23491 (96%)]\tLoss: 1.995365\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:10 | INFO | Rank 0 | Train Epoch: 0 [22624/23491 (96%)]\tLoss: 2.170192\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:10 | INFO | Rank 0 | Train Epoch: 0 [22656/23491 (96%)]\tLoss: 2.398653\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:10 | INFO | Rank 0 | Train Epoch: 0 [22688/23491 (97%)]\tLoss: 1.722058\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:11 | INFO | Rank 0 | Train Epoch: 0 [22720/23491 (97%)]\tLoss: 1.289569\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:11 | INFO | Rank 0 | Train Epoch: 0 [22752/23491 (97%)]\tLoss: 1.697816\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:11 | INFO | Rank 0 | Train Epoch: 0 [22784/23491 (97%)]\tLoss: 1.347188\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:11 | INFO | Rank 0 | Train Epoch: 0 [22816/23491 (97%)]\tLoss: 1.737359\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.588\n",
      "2022-11-08,05:27:12 | INFO | Rank 0 | Train Epoch: 0 [22848/23491 (97%)]\tLoss: 2.257456\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:12 | INFO | Rank 0 | Train Epoch: 0 [22880/23491 (97%)]\tLoss: 2.219264\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:12 | INFO | Rank 0 | Train Epoch: 0 [22912/23491 (98%)]\tLoss: 2.036206\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:12 | INFO | Rank 0 | Train Epoch: 0 [22944/23491 (98%)]\tLoss: 2.127967\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:13 | INFO | Rank 0 | Train Epoch: 0 [22976/23491 (98%)]\tLoss: 1.609470\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:13 | INFO | Rank 0 | Train Epoch: 0 [23008/23491 (98%)]\tLoss: 1.703533\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:13 | INFO | Rank 0 | Train Epoch: 0 [23040/23491 (98%)]\tLoss: 1.858595\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:14 | INFO | Rank 0 | Train Epoch: 0 [23072/23491 (98%)]\tLoss: 2.337899\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:14 | INFO | Rank 0 | Train Epoch: 0 [23104/23491 (98%)]\tLoss: 1.953218\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:14 | INFO | Rank 0 | Train Epoch: 0 [23136/23491 (99%)]\tLoss: 1.815663\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:14 | INFO | Rank 0 | Train Epoch: 0 [23168/23491 (99%)]\tLoss: 1.766278\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:15 | INFO | Rank 0 | Train Epoch: 0 [23200/23491 (99%)]\tLoss: 2.074623\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:15 | INFO | Rank 0 | Train Epoch: 0 [23232/23491 (99%)]\tLoss: 2.079352\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:15 | INFO | Rank 0 | Train Epoch: 0 [23264/23491 (99%)]\tLoss: 1.700794\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:15 | INFO | Rank 0 | Train Epoch: 0 [23296/23491 (99%)]\tLoss: 1.673276\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:16 | INFO | Rank 0 | Train Epoch: 0 [23328/23491 (99%)]\tLoss: 2.154892\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:16 | INFO | Rank 0 | Train Epoch: 0 [23360/23491 (99%)]\tLoss: 1.753170\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:16 | INFO | Rank 0 | Train Epoch: 0 [23392/23491 (100%)]\tLoss: 2.369095\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:16 | INFO | Rank 0 | Train Epoch: 0 [23424/23491 (100%)]\tLoss: 2.038995\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:17 | INFO | Rank 0 | Train Epoch: 0 [23456/23491 (100%)]\tLoss: 1.505024\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:27:17 | INFO | Rank 0 | Begin to eval epoch: 1...\n",
      "100%|█████████████████████████████████████████| 386/386 [00:46<00:00,  8.35it/s]\n",
      "2022-11-08,05:28:03 | INFO | Rank 0 | Eval Epoch: 1 val_loss: 2.5215\tepoch: 1.0000\tnum_elements: 12328.0000\n",
      "2022-11-08,05:28:03 | INFO | Rank 0 | Start epoch 1\n",
      "2022-11-08,05:28:03 | INFO | Rank 0 | Train Epoch: 1 [0/23491 (0%)]\tLoss: 1.495345\tData (t) 0.036\tBatch (t) 0.256\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:28:03 | INFO | Rank 0 | Train Epoch: 1 [32/23491 (0%)]\tLoss: 1.507572\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:28:04 | INFO | Rank 0 | Train Epoch: 1 [64/23491 (0%)]\tLoss: 1.837002\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:28:04 | INFO | Rank 0 | Train Epoch: 1 [96/23491 (0%)]\tLoss: 1.493619\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:28:04 | INFO | Rank 0 | Train Epoch: 1 [128/23491 (1%)]\tLoss: 1.621188\tData (t) 0.053\tBatch (t) 0.264\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:28:05 | INFO | Rank 0 | Train Epoch: 1 [160/23491 (1%)]\tLoss: 1.919336\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:28:05 | INFO | Rank 0 | Train Epoch: 1 [192/23491 (1%)]\tLoss: 1.822783\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:28:05 | INFO | Rank 0 | Train Epoch: 1 [224/23491 (1%)]\tLoss: 1.447383\tData (t) 0.059\tBatch (t) 0.274\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:28:05 | INFO | Rank 0 | Train Epoch: 1 [256/23491 (1%)]\tLoss: 1.218132\tData (t) 0.057\tBatch (t) 0.272\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:28:06 | INFO | Rank 0 | Train Epoch: 1 [288/23491 (1%)]\tLoss: 1.580279\tData (t) 0.058\tBatch (t) 0.273\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:28:06 | INFO | Rank 0 | Train Epoch: 1 [320/23491 (1%)]\tLoss: 1.329837\tData (t) 0.058\tBatch (t) 0.273\tLR: 0.000080\tlogit_scale 4.587\n",
      "2022-11-08,05:28:06 | INFO | Rank 0 | Train Epoch: 1 [352/23491 (1%)]\tLoss: 1.833767\tData (t) 0.058\tBatch (t) 0.273\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:06 | INFO | Rank 0 | Train Epoch: 1 [384/23491 (2%)]\tLoss: 1.724274\tData (t) 0.058\tBatch (t) 0.273\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:07 | INFO | Rank 0 | Train Epoch: 1 [416/23491 (2%)]\tLoss: 1.765149\tData (t) 0.058\tBatch (t) 0.274\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:07 | INFO | Rank 0 | Train Epoch: 1 [448/23491 (2%)]\tLoss: 0.876014\tData (t) 0.058\tBatch (t) 0.272\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:07 | INFO | Rank 0 | Train Epoch: 1 [480/23491 (2%)]\tLoss: 1.337030\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:08 | INFO | Rank 0 | Train Epoch: 1 [512/23491 (2%)]\tLoss: 2.012685\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:08 | INFO | Rank 0 | Train Epoch: 1 [544/23491 (2%)]\tLoss: 1.699473\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:08 | INFO | Rank 0 | Train Epoch: 1 [576/23491 (2%)]\tLoss: 1.304205\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:08 | INFO | Rank 0 | Train Epoch: 1 [608/23491 (3%)]\tLoss: 1.327516\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:09 | INFO | Rank 0 | Train Epoch: 1 [640/23491 (3%)]\tLoss: 1.968654\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:09 | INFO | Rank 0 | Train Epoch: 1 [672/23491 (3%)]\tLoss: 1.680495\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:09 | INFO | Rank 0 | Train Epoch: 1 [704/23491 (3%)]\tLoss: 1.540693\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:09 | INFO | Rank 0 | Train Epoch: 1 [736/23491 (3%)]\tLoss: 1.511990\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:10 | INFO | Rank 0 | Train Epoch: 1 [768/23491 (3%)]\tLoss: 1.286111\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:10 | INFO | Rank 0 | Train Epoch: 1 [800/23491 (3%)]\tLoss: 1.328102\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:10 | INFO | Rank 0 | Train Epoch: 1 [832/23491 (4%)]\tLoss: 1.912629\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:10 | INFO | Rank 0 | Train Epoch: 1 [864/23491 (4%)]\tLoss: 1.629243\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:11 | INFO | Rank 0 | Train Epoch: 1 [896/23491 (4%)]\tLoss: 1.781038\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:11 | INFO | Rank 0 | Train Epoch: 1 [928/23491 (4%)]\tLoss: 1.185907\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:11 | INFO | Rank 0 | Train Epoch: 1 [960/23491 (4%)]\tLoss: 1.616918\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:12 | INFO | Rank 0 | Train Epoch: 1 [992/23491 (4%)]\tLoss: 1.257842\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:12 | INFO | Rank 0 | Train Epoch: 1 [1024/23491 (4%)]\tLoss: 1.714846\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:12 | INFO | Rank 0 | Train Epoch: 1 [1056/23491 (4%)]\tLoss: 1.862161\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:12 | INFO | Rank 0 | Train Epoch: 1 [1088/23491 (5%)]\tLoss: 1.583240\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:13 | INFO | Rank 0 | Train Epoch: 1 [1120/23491 (5%)]\tLoss: 1.443632\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:13 | INFO | Rank 0 | Train Epoch: 1 [1152/23491 (5%)]\tLoss: 1.134885\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:13 | INFO | Rank 0 | Train Epoch: 1 [1184/23491 (5%)]\tLoss: 1.368995\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:13 | INFO | Rank 0 | Train Epoch: 1 [1216/23491 (5%)]\tLoss: 1.768258\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:14 | INFO | Rank 0 | Train Epoch: 1 [1248/23491 (5%)]\tLoss: 1.839779\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:14 | INFO | Rank 0 | Train Epoch: 1 [1280/23491 (5%)]\tLoss: 1.935682\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:14 | INFO | Rank 0 | Train Epoch: 1 [1312/23491 (6%)]\tLoss: 1.691274\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:14 | INFO | Rank 0 | Train Epoch: 1 [1344/23491 (6%)]\tLoss: 1.675290\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:15 | INFO | Rank 0 | Train Epoch: 1 [1376/23491 (6%)]\tLoss: 1.321419\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:15 | INFO | Rank 0 | Train Epoch: 1 [1408/23491 (6%)]\tLoss: 1.246505\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:15 | INFO | Rank 0 | Train Epoch: 1 [1440/23491 (6%)]\tLoss: 1.160435\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:15 | INFO | Rank 0 | Train Epoch: 1 [1472/23491 (6%)]\tLoss: 1.982774\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:16 | INFO | Rank 0 | Train Epoch: 1 [1504/23491 (6%)]\tLoss: 1.766021\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:16 | INFO | Rank 0 | Train Epoch: 1 [1536/23491 (7%)]\tLoss: 1.478233\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:16 | INFO | Rank 0 | Train Epoch: 1 [1568/23491 (7%)]\tLoss: 1.601025\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:17 | INFO | Rank 0 | Train Epoch: 1 [1600/23491 (7%)]\tLoss: 1.750261\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:17 | INFO | Rank 0 | Train Epoch: 1 [1632/23491 (7%)]\tLoss: 1.475453\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.586\n",
      "2022-11-08,05:28:17 | INFO | Rank 0 | Train Epoch: 1 [1664/23491 (7%)]\tLoss: 1.365378\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:17 | INFO | Rank 0 | Train Epoch: 1 [1696/23491 (7%)]\tLoss: 1.746395\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:18 | INFO | Rank 0 | Train Epoch: 1 [1728/23491 (7%)]\tLoss: 1.530964\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:18 | INFO | Rank 0 | Train Epoch: 1 [1760/23491 (7%)]\tLoss: 1.530064\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:18 | INFO | Rank 0 | Train Epoch: 1 [1792/23491 (8%)]\tLoss: 1.509019\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:18 | INFO | Rank 0 | Train Epoch: 1 [1824/23491 (8%)]\tLoss: 1.585453\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:19 | INFO | Rank 0 | Train Epoch: 1 [1856/23491 (8%)]\tLoss: 1.639441\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:19 | INFO | Rank 0 | Train Epoch: 1 [1888/23491 (8%)]\tLoss: 1.708338\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:19 | INFO | Rank 0 | Train Epoch: 1 [1920/23491 (8%)]\tLoss: 1.389555\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:19 | INFO | Rank 0 | Train Epoch: 1 [1952/23491 (8%)]\tLoss: 1.362807\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:20 | INFO | Rank 0 | Train Epoch: 1 [1984/23491 (8%)]\tLoss: 1.827557\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:20 | INFO | Rank 0 | Train Epoch: 1 [2016/23491 (9%)]\tLoss: 1.946545\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:20 | INFO | Rank 0 | Train Epoch: 1 [2048/23491 (9%)]\tLoss: 1.427224\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:21 | INFO | Rank 0 | Train Epoch: 1 [2080/23491 (9%)]\tLoss: 1.601640\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:21 | INFO | Rank 0 | Train Epoch: 1 [2112/23491 (9%)]\tLoss: 1.733986\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:21 | INFO | Rank 0 | Train Epoch: 1 [2144/23491 (9%)]\tLoss: 1.542232\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:21 | INFO | Rank 0 | Train Epoch: 1 [2176/23491 (9%)]\tLoss: 1.754220\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:22 | INFO | Rank 0 | Train Epoch: 1 [2208/23491 (9%)]\tLoss: 1.315156\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:22 | INFO | Rank 0 | Train Epoch: 1 [2240/23491 (10%)]\tLoss: 2.196683\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:22 | INFO | Rank 0 | Train Epoch: 1 [2272/23491 (10%)]\tLoss: 1.449026\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:22 | INFO | Rank 0 | Train Epoch: 1 [2304/23491 (10%)]\tLoss: 1.575372\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:23 | INFO | Rank 0 | Train Epoch: 1 [2336/23491 (10%)]\tLoss: 1.339287\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:23 | INFO | Rank 0 | Train Epoch: 1 [2368/23491 (10%)]\tLoss: 1.668995\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:23 | INFO | Rank 0 | Train Epoch: 1 [2400/23491 (10%)]\tLoss: 1.210787\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:23 | INFO | Rank 0 | Train Epoch: 1 [2432/23491 (10%)]\tLoss: 1.438174\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:24 | INFO | Rank 0 | Train Epoch: 1 [2464/23491 (10%)]\tLoss: 1.733715\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:24 | INFO | Rank 0 | Train Epoch: 1 [2496/23491 (11%)]\tLoss: 1.916510\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:24 | INFO | Rank 0 | Train Epoch: 1 [2528/23491 (11%)]\tLoss: 1.673953\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:25 | INFO | Rank 0 | Train Epoch: 1 [2560/23491 (11%)]\tLoss: 1.547492\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:25 | INFO | Rank 0 | Train Epoch: 1 [2592/23491 (11%)]\tLoss: 1.456696\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:25 | INFO | Rank 0 | Train Epoch: 1 [2624/23491 (11%)]\tLoss: 1.575653\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:25 | INFO | Rank 0 | Train Epoch: 1 [2656/23491 (11%)]\tLoss: 1.262641\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:26 | INFO | Rank 0 | Train Epoch: 1 [2688/23491 (11%)]\tLoss: 1.538837\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:26 | INFO | Rank 0 | Train Epoch: 1 [2720/23491 (12%)]\tLoss: 1.510930\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:26 | INFO | Rank 0 | Train Epoch: 1 [2752/23491 (12%)]\tLoss: 1.438986\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:26 | INFO | Rank 0 | Train Epoch: 1 [2784/23491 (12%)]\tLoss: 1.487188\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:27 | INFO | Rank 0 | Train Epoch: 1 [2816/23491 (12%)]\tLoss: 0.926365\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:27 | INFO | Rank 0 | Train Epoch: 1 [2848/23491 (12%)]\tLoss: 1.679241\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:27 | INFO | Rank 0 | Train Epoch: 1 [2880/23491 (12%)]\tLoss: 1.872586\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:27 | INFO | Rank 0 | Train Epoch: 1 [2912/23491 (12%)]\tLoss: 1.487548\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:28 | INFO | Rank 0 | Train Epoch: 1 [2944/23491 (13%)]\tLoss: 1.876624\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:28 | INFO | Rank 0 | Train Epoch: 1 [2976/23491 (13%)]\tLoss: 1.759636\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.585\n",
      "2022-11-08,05:28:28 | INFO | Rank 0 | Train Epoch: 1 [3008/23491 (13%)]\tLoss: 1.625006\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:29 | INFO | Rank 0 | Train Epoch: 1 [3040/23491 (13%)]\tLoss: 1.413436\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:29 | INFO | Rank 0 | Train Epoch: 1 [3072/23491 (13%)]\tLoss: 2.120078\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:29 | INFO | Rank 0 | Train Epoch: 1 [3104/23491 (13%)]\tLoss: 1.424683\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:29 | INFO | Rank 0 | Train Epoch: 1 [3136/23491 (13%)]\tLoss: 1.154763\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:30 | INFO | Rank 0 | Train Epoch: 1 [3168/23491 (13%)]\tLoss: 1.715834\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:30 | INFO | Rank 0 | Train Epoch: 1 [3200/23491 (14%)]\tLoss: 1.735218\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:30 | INFO | Rank 0 | Train Epoch: 1 [3232/23491 (14%)]\tLoss: 1.865198\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:30 | INFO | Rank 0 | Train Epoch: 1 [3264/23491 (14%)]\tLoss: 1.697416\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:31 | INFO | Rank 0 | Train Epoch: 1 [3296/23491 (14%)]\tLoss: 1.567221\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:31 | INFO | Rank 0 | Train Epoch: 1 [3328/23491 (14%)]\tLoss: 1.496125\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:31 | INFO | Rank 0 | Train Epoch: 1 [3360/23491 (14%)]\tLoss: 1.609867\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:31 | INFO | Rank 0 | Train Epoch: 1 [3392/23491 (14%)]\tLoss: 1.296106\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:32 | INFO | Rank 0 | Train Epoch: 1 [3424/23491 (15%)]\tLoss: 1.646046\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:32 | INFO | Rank 0 | Train Epoch: 1 [3456/23491 (15%)]\tLoss: 1.876938\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:32 | INFO | Rank 0 | Train Epoch: 1 [3488/23491 (15%)]\tLoss: 2.028626\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:32 | INFO | Rank 0 | Train Epoch: 1 [3520/23491 (15%)]\tLoss: 1.664306\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000080\tlogit_scale 4.584\n",
      "2022-11-08,05:28:33 | INFO | Rank 0 | Train Epoch: 1 [3552/23491 (15%)]\tLoss: 1.322540\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:33 | INFO | Rank 0 | Train Epoch: 1 [3584/23491 (15%)]\tLoss: 1.764586\tData (t) 0.056\tBatch (t) 0.271\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:33 | INFO | Rank 0 | Train Epoch: 1 [3616/23491 (15%)]\tLoss: 1.781344\tData (t) 0.058\tBatch (t) 0.272\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:34 | INFO | Rank 0 | Train Epoch: 1 [3648/23491 (16%)]\tLoss: 1.341109\tData (t) 0.058\tBatch (t) 0.273\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:34 | INFO | Rank 0 | Train Epoch: 1 [3680/23491 (16%)]\tLoss: 1.690870\tData (t) 0.058\tBatch (t) 0.273\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:34 | INFO | Rank 0 | Train Epoch: 1 [3712/23491 (16%)]\tLoss: 1.802297\tData (t) 0.059\tBatch (t) 0.274\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:34 | INFO | Rank 0 | Train Epoch: 1 [3744/23491 (16%)]\tLoss: 1.717244\tData (t) 0.058\tBatch (t) 0.273\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:35 | INFO | Rank 0 | Train Epoch: 1 [3776/23491 (16%)]\tLoss: 1.599302\tData (t) 0.057\tBatch (t) 0.272\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:35 | INFO | Rank 0 | Train Epoch: 1 [3808/23491 (16%)]\tLoss: 1.883791\tData (t) 0.058\tBatch (t) 0.273\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:35 | INFO | Rank 0 | Train Epoch: 1 [3840/23491 (16%)]\tLoss: 1.456664\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:35 | INFO | Rank 0 | Train Epoch: 1 [3872/23491 (16%)]\tLoss: 1.460520\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:36 | INFO | Rank 0 | Train Epoch: 1 [3904/23491 (17%)]\tLoss: 1.281953\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:36 | INFO | Rank 0 | Train Epoch: 1 [3936/23491 (17%)]\tLoss: 1.495456\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:36 | INFO | Rank 0 | Train Epoch: 1 [3968/23491 (17%)]\tLoss: 1.696451\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:37 | INFO | Rank 0 | Train Epoch: 1 [4000/23491 (17%)]\tLoss: 1.861843\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:37 | INFO | Rank 0 | Train Epoch: 1 [4032/23491 (17%)]\tLoss: 1.776457\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:37 | INFO | Rank 0 | Train Epoch: 1 [4064/23491 (17%)]\tLoss: 1.596931\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:37 | INFO | Rank 0 | Train Epoch: 1 [4096/23491 (17%)]\tLoss: 1.660905\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:38 | INFO | Rank 0 | Train Epoch: 1 [4128/23491 (18%)]\tLoss: 1.570511\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:38 | INFO | Rank 0 | Train Epoch: 1 [4160/23491 (18%)]\tLoss: 1.183900\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:38 | INFO | Rank 0 | Train Epoch: 1 [4192/23491 (18%)]\tLoss: 1.742659\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:38 | INFO | Rank 0 | Train Epoch: 1 [4224/23491 (18%)]\tLoss: 2.003270\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:39 | INFO | Rank 0 | Train Epoch: 1 [4256/23491 (18%)]\tLoss: 1.886506\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.584\n",
      "2022-11-08,05:28:39 | INFO | Rank 0 | Train Epoch: 1 [4288/23491 (18%)]\tLoss: 1.425683\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:39 | INFO | Rank 0 | Train Epoch: 1 [4320/23491 (18%)]\tLoss: 1.275082\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:39 | INFO | Rank 0 | Train Epoch: 1 [4352/23491 (19%)]\tLoss: 1.846381\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:40 | INFO | Rank 0 | Train Epoch: 1 [4384/23491 (19%)]\tLoss: 1.748610\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:40 | INFO | Rank 0 | Train Epoch: 1 [4416/23491 (19%)]\tLoss: 1.481095\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:40 | INFO | Rank 0 | Train Epoch: 1 [4448/23491 (19%)]\tLoss: 1.718247\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:41 | INFO | Rank 0 | Train Epoch: 1 [4480/23491 (19%)]\tLoss: 1.475214\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:41 | INFO | Rank 0 | Train Epoch: 1 [4512/23491 (19%)]\tLoss: 1.385425\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:41 | INFO | Rank 0 | Train Epoch: 1 [4544/23491 (19%)]\tLoss: 1.453316\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:41 | INFO | Rank 0 | Train Epoch: 1 [4576/23491 (19%)]\tLoss: 1.805558\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:42 | INFO | Rank 0 | Train Epoch: 1 [4608/23491 (20%)]\tLoss: 1.306842\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:42 | INFO | Rank 0 | Train Epoch: 1 [4640/23491 (20%)]\tLoss: 1.119011\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:42 | INFO | Rank 0 | Train Epoch: 1 [4672/23491 (20%)]\tLoss: 1.305948\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:42 | INFO | Rank 0 | Train Epoch: 1 [4704/23491 (20%)]\tLoss: 1.383594\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:43 | INFO | Rank 0 | Train Epoch: 1 [4736/23491 (20%)]\tLoss: 1.857154\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:43 | INFO | Rank 0 | Train Epoch: 1 [4768/23491 (20%)]\tLoss: 1.463178\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:43 | INFO | Rank 0 | Train Epoch: 1 [4800/23491 (20%)]\tLoss: 1.705822\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:43 | INFO | Rank 0 | Train Epoch: 1 [4832/23491 (21%)]\tLoss: 1.776035\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:44 | INFO | Rank 0 | Train Epoch: 1 [4864/23491 (21%)]\tLoss: 1.470943\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:44 | INFO | Rank 0 | Train Epoch: 1 [4896/23491 (21%)]\tLoss: 1.180794\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:44 | INFO | Rank 0 | Train Epoch: 1 [4928/23491 (21%)]\tLoss: 1.931392\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:45 | INFO | Rank 0 | Train Epoch: 1 [4960/23491 (21%)]\tLoss: 1.488137\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:45 | INFO | Rank 0 | Train Epoch: 1 [4992/23491 (21%)]\tLoss: 1.494807\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:45 | INFO | Rank 0 | Train Epoch: 1 [5024/23491 (21%)]\tLoss: 1.682434\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:45 | INFO | Rank 0 | Train Epoch: 1 [5056/23491 (22%)]\tLoss: 1.449842\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:46 | INFO | Rank 0 | Train Epoch: 1 [5088/23491 (22%)]\tLoss: 1.301819\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:46 | INFO | Rank 0 | Train Epoch: 1 [5120/23491 (22%)]\tLoss: 1.083500\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:46 | INFO | Rank 0 | Train Epoch: 1 [5152/23491 (22%)]\tLoss: 1.681648\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:46 | INFO | Rank 0 | Train Epoch: 1 [5184/23491 (22%)]\tLoss: 1.712936\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:47 | INFO | Rank 0 | Train Epoch: 1 [5216/23491 (22%)]\tLoss: 1.309089\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:47 | INFO | Rank 0 | Train Epoch: 1 [5248/23491 (22%)]\tLoss: 2.034695\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:47 | INFO | Rank 0 | Train Epoch: 1 [5280/23491 (22%)]\tLoss: 1.811744\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:47 | INFO | Rank 0 | Train Epoch: 1 [5312/23491 (23%)]\tLoss: 1.470538\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:48 | INFO | Rank 0 | Train Epoch: 1 [5344/23491 (23%)]\tLoss: 1.913227\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:48 | INFO | Rank 0 | Train Epoch: 1 [5376/23491 (23%)]\tLoss: 1.738953\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.583\n",
      "2022-11-08,05:28:48 | INFO | Rank 0 | Train Epoch: 1 [5408/23491 (23%)]\tLoss: 1.911672\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:49 | INFO | Rank 0 | Train Epoch: 1 [5440/23491 (23%)]\tLoss: 1.476383\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:49 | INFO | Rank 0 | Train Epoch: 1 [5472/23491 (23%)]\tLoss: 1.370992\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:49 | INFO | Rank 0 | Train Epoch: 1 [5504/23491 (23%)]\tLoss: 1.424834\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:49 | INFO | Rank 0 | Train Epoch: 1 [5536/23491 (24%)]\tLoss: 1.535071\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:50 | INFO | Rank 0 | Train Epoch: 1 [5568/23491 (24%)]\tLoss: 1.422694\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:50 | INFO | Rank 0 | Train Epoch: 1 [5600/23491 (24%)]\tLoss: 1.621571\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:50 | INFO | Rank 0 | Train Epoch: 1 [5632/23491 (24%)]\tLoss: 1.388821\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:50 | INFO | Rank 0 | Train Epoch: 1 [5664/23491 (24%)]\tLoss: 1.746571\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:51 | INFO | Rank 0 | Train Epoch: 1 [5696/23491 (24%)]\tLoss: 1.419489\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:51 | INFO | Rank 0 | Train Epoch: 1 [5728/23491 (24%)]\tLoss: 1.890625\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:51 | INFO | Rank 0 | Train Epoch: 1 [5760/23491 (25%)]\tLoss: 2.004819\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:51 | INFO | Rank 0 | Train Epoch: 1 [5792/23491 (25%)]\tLoss: 1.585241\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:52 | INFO | Rank 0 | Train Epoch: 1 [5824/23491 (25%)]\tLoss: 2.051009\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:52 | INFO | Rank 0 | Train Epoch: 1 [5856/23491 (25%)]\tLoss: 1.537013\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:52 | INFO | Rank 0 | Train Epoch: 1 [5888/23491 (25%)]\tLoss: 1.130560\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:52 | INFO | Rank 0 | Train Epoch: 1 [5920/23491 (25%)]\tLoss: 2.130344\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:53 | INFO | Rank 0 | Train Epoch: 1 [5952/23491 (25%)]\tLoss: 1.662236\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:53 | INFO | Rank 0 | Train Epoch: 1 [5984/23491 (25%)]\tLoss: 1.330065\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:53 | INFO | Rank 0 | Train Epoch: 1 [6016/23491 (26%)]\tLoss: 2.061255\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:54 | INFO | Rank 0 | Train Epoch: 1 [6048/23491 (26%)]\tLoss: 1.488880\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:54 | INFO | Rank 0 | Train Epoch: 1 [6080/23491 (26%)]\tLoss: 1.385927\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:54 | INFO | Rank 0 | Train Epoch: 1 [6112/23491 (26%)]\tLoss: 1.451501\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:54 | INFO | Rank 0 | Train Epoch: 1 [6144/23491 (26%)]\tLoss: 1.170519\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:55 | INFO | Rank 0 | Train Epoch: 1 [6176/23491 (26%)]\tLoss: 1.543068\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:55 | INFO | Rank 0 | Train Epoch: 1 [6208/23491 (26%)]\tLoss: 1.421026\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:55 | INFO | Rank 0 | Train Epoch: 1 [6240/23491 (27%)]\tLoss: 1.136816\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:55 | INFO | Rank 0 | Train Epoch: 1 [6272/23491 (27%)]\tLoss: 1.338184\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:56 | INFO | Rank 0 | Train Epoch: 1 [6304/23491 (27%)]\tLoss: 1.264352\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:56 | INFO | Rank 0 | Train Epoch: 1 [6336/23491 (27%)]\tLoss: 1.591937\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:56 | INFO | Rank 0 | Train Epoch: 1 [6368/23491 (27%)]\tLoss: 1.826060\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:56 | INFO | Rank 0 | Train Epoch: 1 [6400/23491 (27%)]\tLoss: 1.419043\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:57 | INFO | Rank 0 | Train Epoch: 1 [6432/23491 (27%)]\tLoss: 2.044780\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:57 | INFO | Rank 0 | Train Epoch: 1 [6464/23491 (28%)]\tLoss: 1.406513\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:57 | INFO | Rank 0 | Train Epoch: 1 [6496/23491 (28%)]\tLoss: 1.226362\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:58 | INFO | Rank 0 | Train Epoch: 1 [6528/23491 (28%)]\tLoss: 1.443840\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:58 | INFO | Rank 0 | Train Epoch: 1 [6560/23491 (28%)]\tLoss: 1.792840\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:58 | INFO | Rank 0 | Train Epoch: 1 [6592/23491 (28%)]\tLoss: 1.862080\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:58 | INFO | Rank 0 | Train Epoch: 1 [6624/23491 (28%)]\tLoss: 1.362451\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:59 | INFO | Rank 0 | Train Epoch: 1 [6656/23491 (28%)]\tLoss: 1.626750\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:59 | INFO | Rank 0 | Train Epoch: 1 [6688/23491 (28%)]\tLoss: 1.484131\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:59 | INFO | Rank 0 | Train Epoch: 1 [6720/23491 (29%)]\tLoss: 1.580275\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:28:59 | INFO | Rank 0 | Train Epoch: 1 [6752/23491 (29%)]\tLoss: 1.482894\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.582\n",
      "2022-11-08,05:29:00 | INFO | Rank 0 | Train Epoch: 1 [6784/23491 (29%)]\tLoss: 1.505491\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:00 | INFO | Rank 0 | Train Epoch: 1 [6816/23491 (29%)]\tLoss: 1.394462\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:00 | INFO | Rank 0 | Train Epoch: 1 [6848/23491 (29%)]\tLoss: 1.738405\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:00 | INFO | Rank 0 | Train Epoch: 1 [6880/23491 (29%)]\tLoss: 1.623597\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:01 | INFO | Rank 0 | Train Epoch: 1 [6912/23491 (29%)]\tLoss: 1.431697\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:01 | INFO | Rank 0 | Train Epoch: 1 [6944/23491 (30%)]\tLoss: 1.386408\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:01 | INFO | Rank 0 | Train Epoch: 1 [6976/23491 (30%)]\tLoss: 1.685198\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:02 | INFO | Rank 0 | Train Epoch: 1 [7008/23491 (30%)]\tLoss: 1.704491\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:02 | INFO | Rank 0 | Train Epoch: 1 [7040/23491 (30%)]\tLoss: 1.746702\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:02 | INFO | Rank 0 | Train Epoch: 1 [7072/23491 (30%)]\tLoss: 1.819934\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:02 | INFO | Rank 0 | Train Epoch: 1 [7104/23491 (30%)]\tLoss: 1.823292\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:03 | INFO | Rank 0 | Train Epoch: 1 [7136/23491 (30%)]\tLoss: 2.147444\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:03 | INFO | Rank 0 | Train Epoch: 1 [7168/23491 (31%)]\tLoss: 1.790985\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:03 | INFO | Rank 0 | Train Epoch: 1 [7200/23491 (31%)]\tLoss: 1.560263\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:03 | INFO | Rank 0 | Train Epoch: 1 [7232/23491 (31%)]\tLoss: 1.659890\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:04 | INFO | Rank 0 | Train Epoch: 1 [7264/23491 (31%)]\tLoss: 1.460838\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:04 | INFO | Rank 0 | Train Epoch: 1 [7296/23491 (31%)]\tLoss: 1.441751\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:04 | INFO | Rank 0 | Train Epoch: 1 [7328/23491 (31%)]\tLoss: 1.931285\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:04 | INFO | Rank 0 | Train Epoch: 1 [7360/23491 (31%)]\tLoss: 1.605661\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:05 | INFO | Rank 0 | Train Epoch: 1 [7392/23491 (31%)]\tLoss: 1.731594\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:05 | INFO | Rank 0 | Train Epoch: 1 [7424/23491 (32%)]\tLoss: 1.662737\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:05 | INFO | Rank 0 | Train Epoch: 1 [7456/23491 (32%)]\tLoss: 1.250662\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:06 | INFO | Rank 0 | Train Epoch: 1 [7488/23491 (32%)]\tLoss: 1.221826\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:06 | INFO | Rank 0 | Train Epoch: 1 [7520/23491 (32%)]\tLoss: 1.609320\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:06 | INFO | Rank 0 | Train Epoch: 1 [7552/23491 (32%)]\tLoss: 1.701467\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:06 | INFO | Rank 0 | Train Epoch: 1 [7584/23491 (32%)]\tLoss: 1.431686\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:07 | INFO | Rank 0 | Train Epoch: 1 [7616/23491 (32%)]\tLoss: 1.224937\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:07 | INFO | Rank 0 | Train Epoch: 1 [7648/23491 (33%)]\tLoss: 1.397971\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:07 | INFO | Rank 0 | Train Epoch: 1 [7680/23491 (33%)]\tLoss: 1.884827\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:07 | INFO | Rank 0 | Train Epoch: 1 [7712/23491 (33%)]\tLoss: 1.643956\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:08 | INFO | Rank 0 | Train Epoch: 1 [7744/23491 (33%)]\tLoss: 1.873513\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:08 | INFO | Rank 0 | Train Epoch: 1 [7776/23491 (33%)]\tLoss: 1.273587\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:08 | INFO | Rank 0 | Train Epoch: 1 [7808/23491 (33%)]\tLoss: 1.680682\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:08 | INFO | Rank 0 | Train Epoch: 1 [7840/23491 (33%)]\tLoss: 1.385540\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:09 | INFO | Rank 0 | Train Epoch: 1 [7872/23491 (34%)]\tLoss: 1.670304\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.581\n",
      "2022-11-08,05:29:09 | INFO | Rank 0 | Train Epoch: 1 [7904/23491 (34%)]\tLoss: 1.663667\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:09 | INFO | Rank 0 | Train Epoch: 1 [7936/23491 (34%)]\tLoss: 1.736339\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:10 | INFO | Rank 0 | Train Epoch: 1 [7968/23491 (34%)]\tLoss: 1.750391\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:10 | INFO | Rank 0 | Train Epoch: 1 [8000/23491 (34%)]\tLoss: 1.584669\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:10 | INFO | Rank 0 | Train Epoch: 1 [8032/23491 (34%)]\tLoss: 1.076214\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:10 | INFO | Rank 0 | Train Epoch: 1 [8064/23491 (34%)]\tLoss: 1.602541\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:11 | INFO | Rank 0 | Train Epoch: 1 [8096/23491 (34%)]\tLoss: 1.740232\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:11 | INFO | Rank 0 | Train Epoch: 1 [8128/23491 (35%)]\tLoss: 1.571995\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:11 | INFO | Rank 0 | Train Epoch: 1 [8160/23491 (35%)]\tLoss: 1.828741\tData (t) 0.053\tBatch (t) 0.268\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:11 | INFO | Rank 0 | Train Epoch: 1 [8192/23491 (35%)]\tLoss: 1.384151\tData (t) 0.054\tBatch (t) 0.269\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:12 | INFO | Rank 0 | Train Epoch: 1 [8224/23491 (35%)]\tLoss: 1.359547\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:12 | INFO | Rank 0 | Train Epoch: 1 [8256/23491 (35%)]\tLoss: 1.642726\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:12 | INFO | Rank 0 | Train Epoch: 1 [8288/23491 (35%)]\tLoss: 1.734028\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:12 | INFO | Rank 0 | Train Epoch: 1 [8320/23491 (35%)]\tLoss: 1.568808\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:13 | INFO | Rank 0 | Train Epoch: 1 [8352/23491 (36%)]\tLoss: 1.840220\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:13 | INFO | Rank 0 | Train Epoch: 1 [8384/23491 (36%)]\tLoss: 1.788202\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:13 | INFO | Rank 0 | Train Epoch: 1 [8416/23491 (36%)]\tLoss: 1.681369\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:14 | INFO | Rank 0 | Train Epoch: 1 [8448/23491 (36%)]\tLoss: 1.506934\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:14 | INFO | Rank 0 | Train Epoch: 1 [8480/23491 (36%)]\tLoss: 1.581558\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:14 | INFO | Rank 0 | Train Epoch: 1 [8512/23491 (36%)]\tLoss: 1.522238\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:14 | INFO | Rank 0 | Train Epoch: 1 [8544/23491 (36%)]\tLoss: 1.525823\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:15 | INFO | Rank 0 | Train Epoch: 1 [8576/23491 (37%)]\tLoss: 1.630064\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:15 | INFO | Rank 0 | Train Epoch: 1 [8608/23491 (37%)]\tLoss: 1.929025\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:15 | INFO | Rank 0 | Train Epoch: 1 [8640/23491 (37%)]\tLoss: 1.337284\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:15 | INFO | Rank 0 | Train Epoch: 1 [8672/23491 (37%)]\tLoss: 1.541908\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:16 | INFO | Rank 0 | Train Epoch: 1 [8704/23491 (37%)]\tLoss: 1.798675\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:16 | INFO | Rank 0 | Train Epoch: 1 [8736/23491 (37%)]\tLoss: 1.867783\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:16 | INFO | Rank 0 | Train Epoch: 1 [8768/23491 (37%)]\tLoss: 1.458611\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:16 | INFO | Rank 0 | Train Epoch: 1 [8800/23491 (37%)]\tLoss: 1.413431\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:17 | INFO | Rank 0 | Train Epoch: 1 [8832/23491 (38%)]\tLoss: 1.425246\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:17 | INFO | Rank 0 | Train Epoch: 1 [8864/23491 (38%)]\tLoss: 1.295940\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:17 | INFO | Rank 0 | Train Epoch: 1 [8896/23491 (38%)]\tLoss: 1.557320\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:17 | INFO | Rank 0 | Train Epoch: 1 [8928/23491 (38%)]\tLoss: 2.049575\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:18 | INFO | Rank 0 | Train Epoch: 1 [8960/23491 (38%)]\tLoss: 1.631368\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.580\n",
      "2022-11-08,05:29:18 | INFO | Rank 0 | Train Epoch: 1 [8992/23491 (38%)]\tLoss: 1.450686\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:18 | INFO | Rank 0 | Train Epoch: 1 [9024/23491 (38%)]\tLoss: 1.432646\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:19 | INFO | Rank 0 | Train Epoch: 1 [9056/23491 (39%)]\tLoss: 1.346046\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:19 | INFO | Rank 0 | Train Epoch: 1 [9088/23491 (39%)]\tLoss: 1.607140\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:19 | INFO | Rank 0 | Train Epoch: 1 [9120/23491 (39%)]\tLoss: 2.017729\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:19 | INFO | Rank 0 | Train Epoch: 1 [9152/23491 (39%)]\tLoss: 1.353219\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:20 | INFO | Rank 0 | Train Epoch: 1 [9184/23491 (39%)]\tLoss: 1.376519\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:20 | INFO | Rank 0 | Train Epoch: 1 [9216/23491 (39%)]\tLoss: 1.106590\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:20 | INFO | Rank 0 | Train Epoch: 1 [9248/23491 (39%)]\tLoss: 1.814990\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:20 | INFO | Rank 0 | Train Epoch: 1 [9280/23491 (40%)]\tLoss: 1.555710\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:21 | INFO | Rank 0 | Train Epoch: 1 [9312/23491 (40%)]\tLoss: 1.420778\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:21 | INFO | Rank 0 | Train Epoch: 1 [9344/23491 (40%)]\tLoss: 1.363162\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:21 | INFO | Rank 0 | Train Epoch: 1 [9376/23491 (40%)]\tLoss: 1.311752\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:21 | INFO | Rank 0 | Train Epoch: 1 [9408/23491 (40%)]\tLoss: 1.155515\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:22 | INFO | Rank 0 | Train Epoch: 1 [9440/23491 (40%)]\tLoss: 1.758534\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:22 | INFO | Rank 0 | Train Epoch: 1 [9472/23491 (40%)]\tLoss: 1.818635\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:22 | INFO | Rank 0 | Train Epoch: 1 [9504/23491 (40%)]\tLoss: 1.935380\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:23 | INFO | Rank 0 | Train Epoch: 1 [9536/23491 (41%)]\tLoss: 1.305393\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:23 | INFO | Rank 0 | Train Epoch: 1 [9568/23491 (41%)]\tLoss: 1.430098\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:23 | INFO | Rank 0 | Train Epoch: 1 [9600/23491 (41%)]\tLoss: 1.866127\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:23 | INFO | Rank 0 | Train Epoch: 1 [9632/23491 (41%)]\tLoss: 1.751197\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:24 | INFO | Rank 0 | Train Epoch: 1 [9664/23491 (41%)]\tLoss: 1.769087\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:24 | INFO | Rank 0 | Train Epoch: 1 [9696/23491 (41%)]\tLoss: 1.886708\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:24 | INFO | Rank 0 | Train Epoch: 1 [9728/23491 (41%)]\tLoss: 1.623869\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:24 | INFO | Rank 0 | Train Epoch: 1 [9760/23491 (42%)]\tLoss: 1.509604\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:25 | INFO | Rank 0 | Train Epoch: 1 [9792/23491 (42%)]\tLoss: 1.451075\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:25 | INFO | Rank 0 | Train Epoch: 1 [9824/23491 (42%)]\tLoss: 1.392616\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:25 | INFO | Rank 0 | Train Epoch: 1 [9856/23491 (42%)]\tLoss: 1.333411\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:25 | INFO | Rank 0 | Train Epoch: 1 [9888/23491 (42%)]\tLoss: 1.316016\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:26 | INFO | Rank 0 | Train Epoch: 1 [9920/23491 (42%)]\tLoss: 1.803228\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:26 | INFO | Rank 0 | Train Epoch: 1 [9952/23491 (42%)]\tLoss: 0.907620\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:26 | INFO | Rank 0 | Train Epoch: 1 [9984/23491 (43%)]\tLoss: 1.232419\tData (t) 0.052\tBatch (t) 0.264\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:27 | INFO | Rank 0 | Train Epoch: 1 [10016/23491 (43%)]\tLoss: 1.467667\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:27 | INFO | Rank 0 | Train Epoch: 1 [10048/23491 (43%)]\tLoss: 1.507493\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:27 | INFO | Rank 0 | Train Epoch: 1 [10080/23491 (43%)]\tLoss: 1.500588\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:27 | INFO | Rank 0 | Train Epoch: 1 [10112/23491 (43%)]\tLoss: 1.052955\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:28 | INFO | Rank 0 | Train Epoch: 1 [10144/23491 (43%)]\tLoss: 2.175754\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:28 | INFO | Rank 0 | Train Epoch: 1 [10176/23491 (43%)]\tLoss: 1.447193\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:28 | INFO | Rank 0 | Train Epoch: 1 [10208/23491 (43%)]\tLoss: 1.665116\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:28 | INFO | Rank 0 | Train Epoch: 1 [10240/23491 (44%)]\tLoss: 1.630418\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:29 | INFO | Rank 0 | Train Epoch: 1 [10272/23491 (44%)]\tLoss: 1.427533\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.579\n",
      "2022-11-08,05:29:29 | INFO | Rank 0 | Train Epoch: 1 [10304/23491 (44%)]\tLoss: 1.778582\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:29 | INFO | Rank 0 | Train Epoch: 1 [10336/23491 (44%)]\tLoss: 1.568611\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:29 | INFO | Rank 0 | Train Epoch: 1 [10368/23491 (44%)]\tLoss: 1.837646\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:30 | INFO | Rank 0 | Train Epoch: 1 [10400/23491 (44%)]\tLoss: 1.616340\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:30 | INFO | Rank 0 | Train Epoch: 1 [10432/23491 (44%)]\tLoss: 1.457923\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:30 | INFO | Rank 0 | Train Epoch: 1 [10464/23491 (45%)]\tLoss: 1.150059\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:31 | INFO | Rank 0 | Train Epoch: 1 [10496/23491 (45%)]\tLoss: 1.656039\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:31 | INFO | Rank 0 | Train Epoch: 1 [10528/23491 (45%)]\tLoss: 1.413554\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:31 | INFO | Rank 0 | Train Epoch: 1 [10560/23491 (45%)]\tLoss: 1.743226\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:31 | INFO | Rank 0 | Train Epoch: 1 [10592/23491 (45%)]\tLoss: 1.384064\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:32 | INFO | Rank 0 | Train Epoch: 1 [10624/23491 (45%)]\tLoss: 1.829960\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:32 | INFO | Rank 0 | Train Epoch: 1 [10656/23491 (45%)]\tLoss: 1.727034\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:32 | INFO | Rank 0 | Train Epoch: 1 [10688/23491 (46%)]\tLoss: 1.589984\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:32 | INFO | Rank 0 | Train Epoch: 1 [10720/23491 (46%)]\tLoss: 1.385002\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:33 | INFO | Rank 0 | Train Epoch: 1 [10752/23491 (46%)]\tLoss: 1.099375\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:33 | INFO | Rank 0 | Train Epoch: 1 [10784/23491 (46%)]\tLoss: 1.911793\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:33 | INFO | Rank 0 | Train Epoch: 1 [10816/23491 (46%)]\tLoss: 1.516715\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:33 | INFO | Rank 0 | Train Epoch: 1 [10848/23491 (46%)]\tLoss: 1.294789\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:34 | INFO | Rank 0 | Train Epoch: 1 [10880/23491 (46%)]\tLoss: 1.961009\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:34 | INFO | Rank 0 | Train Epoch: 1 [10912/23491 (46%)]\tLoss: 1.529591\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:34 | INFO | Rank 0 | Train Epoch: 1 [10944/23491 (47%)]\tLoss: 1.296235\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:35 | INFO | Rank 0 | Train Epoch: 1 [10976/23491 (47%)]\tLoss: 2.099798\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:35 | INFO | Rank 0 | Train Epoch: 1 [11008/23491 (47%)]\tLoss: 1.726372\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:35 | INFO | Rank 0 | Train Epoch: 1 [11040/23491 (47%)]\tLoss: 1.742660\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:35 | INFO | Rank 0 | Train Epoch: 1 [11072/23491 (47%)]\tLoss: 1.529898\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:36 | INFO | Rank 0 | Train Epoch: 1 [11104/23491 (47%)]\tLoss: 1.985919\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:36 | INFO | Rank 0 | Train Epoch: 1 [11136/23491 (47%)]\tLoss: 1.185989\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:36 | INFO | Rank 0 | Train Epoch: 1 [11168/23491 (48%)]\tLoss: 2.004599\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:36 | INFO | Rank 0 | Train Epoch: 1 [11200/23491 (48%)]\tLoss: 1.774953\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:37 | INFO | Rank 0 | Train Epoch: 1 [11232/23491 (48%)]\tLoss: 1.354858\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:37 | INFO | Rank 0 | Train Epoch: 1 [11264/23491 (48%)]\tLoss: 1.672230\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:37 | INFO | Rank 0 | Train Epoch: 1 [11296/23491 (48%)]\tLoss: 1.455982\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:37 | INFO | Rank 0 | Train Epoch: 1 [11328/23491 (48%)]\tLoss: 1.478497\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:38 | INFO | Rank 0 | Train Epoch: 1 [11360/23491 (48%)]\tLoss: 1.524831\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:38 | INFO | Rank 0 | Train Epoch: 1 [11392/23491 (49%)]\tLoss: 1.430284\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:38 | INFO | Rank 0 | Train Epoch: 1 [11424/23491 (49%)]\tLoss: 1.653461\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:38 | INFO | Rank 0 | Train Epoch: 1 [11456/23491 (49%)]\tLoss: 1.799621\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:39 | INFO | Rank 0 | Train Epoch: 1 [11488/23491 (49%)]\tLoss: 1.746648\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:39 | INFO | Rank 0 | Train Epoch: 1 [11520/23491 (49%)]\tLoss: 1.742482\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:39 | INFO | Rank 0 | Train Epoch: 1 [11552/23491 (49%)]\tLoss: 1.657855\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:40 | INFO | Rank 0 | Train Epoch: 1 [11584/23491 (49%)]\tLoss: 1.340808\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.578\n",
      "2022-11-08,05:29:40 | INFO | Rank 0 | Train Epoch: 1 [11616/23491 (49%)]\tLoss: 1.565304\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.577\n",
      "2022-11-08,05:29:40 | INFO | Rank 0 | Train Epoch: 1 [11648/23491 (50%)]\tLoss: 1.519896\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000079\tlogit_scale 4.577\n",
      "2022-11-08,05:29:40 | INFO | Rank 0 | Train Epoch: 1 [11680/23491 (50%)]\tLoss: 1.513342\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:41 | INFO | Rank 0 | Train Epoch: 1 [11712/23491 (50%)]\tLoss: 1.906731\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:41 | INFO | Rank 0 | Train Epoch: 1 [11744/23491 (50%)]\tLoss: 1.414426\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:41 | INFO | Rank 0 | Train Epoch: 1 [11776/23491 (50%)]\tLoss: 1.625084\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:41 | INFO | Rank 0 | Train Epoch: 1 [11808/23491 (50%)]\tLoss: 1.855068\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:42 | INFO | Rank 0 | Train Epoch: 1 [11840/23491 (50%)]\tLoss: 1.918100\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:42 | INFO | Rank 0 | Train Epoch: 1 [11872/23491 (51%)]\tLoss: 1.352703\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:42 | INFO | Rank 0 | Train Epoch: 1 [11904/23491 (51%)]\tLoss: 2.081469\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:42 | INFO | Rank 0 | Train Epoch: 1 [11936/23491 (51%)]\tLoss: 1.630830\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:43 | INFO | Rank 0 | Train Epoch: 1 [11968/23491 (51%)]\tLoss: 1.591352\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:43 | INFO | Rank 0 | Train Epoch: 1 [12000/23491 (51%)]\tLoss: 2.064049\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:43 | INFO | Rank 0 | Train Epoch: 1 [12032/23491 (51%)]\tLoss: 1.395964\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:44 | INFO | Rank 0 | Train Epoch: 1 [12064/23491 (51%)]\tLoss: 1.568871\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:44 | INFO | Rank 0 | Train Epoch: 1 [12096/23491 (51%)]\tLoss: 1.688875\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:44 | INFO | Rank 0 | Train Epoch: 1 [12128/23491 (52%)]\tLoss: 1.639053\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:44 | INFO | Rank 0 | Train Epoch: 1 [12160/23491 (52%)]\tLoss: 1.294505\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:45 | INFO | Rank 0 | Train Epoch: 1 [12192/23491 (52%)]\tLoss: 1.414052\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:45 | INFO | Rank 0 | Train Epoch: 1 [12224/23491 (52%)]\tLoss: 1.527905\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:45 | INFO | Rank 0 | Train Epoch: 1 [12256/23491 (52%)]\tLoss: 1.856182\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:45 | INFO | Rank 0 | Train Epoch: 1 [12288/23491 (52%)]\tLoss: 1.431385\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:46 | INFO | Rank 0 | Train Epoch: 1 [12320/23491 (52%)]\tLoss: 1.389791\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:46 | INFO | Rank 0 | Train Epoch: 1 [12352/23491 (53%)]\tLoss: 1.525432\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:46 | INFO | Rank 0 | Train Epoch: 1 [12384/23491 (53%)]\tLoss: 1.830483\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:46 | INFO | Rank 0 | Train Epoch: 1 [12416/23491 (53%)]\tLoss: 1.788940\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:47 | INFO | Rank 0 | Train Epoch: 1 [12448/23491 (53%)]\tLoss: 1.582361\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:47 | INFO | Rank 0 | Train Epoch: 1 [12480/23491 (53%)]\tLoss: 1.805123\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:47 | INFO | Rank 0 | Train Epoch: 1 [12512/23491 (53%)]\tLoss: 1.453834\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:48 | INFO | Rank 0 | Train Epoch: 1 [12544/23491 (53%)]\tLoss: 1.724739\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:48 | INFO | Rank 0 | Train Epoch: 1 [12576/23491 (54%)]\tLoss: 1.520604\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.577\n",
      "2022-11-08,05:29:48 | INFO | Rank 0 | Train Epoch: 1 [12608/23491 (54%)]\tLoss: 1.553177\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:48 | INFO | Rank 0 | Train Epoch: 1 [12640/23491 (54%)]\tLoss: 1.746490\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:49 | INFO | Rank 0 | Train Epoch: 1 [12672/23491 (54%)]\tLoss: 2.178921\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:49 | INFO | Rank 0 | Train Epoch: 1 [12704/23491 (54%)]\tLoss: 1.336378\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:49 | INFO | Rank 0 | Train Epoch: 1 [12736/23491 (54%)]\tLoss: 1.710026\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:49 | INFO | Rank 0 | Train Epoch: 1 [12768/23491 (54%)]\tLoss: 1.467955\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:50 | INFO | Rank 0 | Train Epoch: 1 [12800/23491 (54%)]\tLoss: 1.763273\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:50 | INFO | Rank 0 | Train Epoch: 1 [12832/23491 (55%)]\tLoss: 1.228863\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:50 | INFO | Rank 0 | Train Epoch: 1 [12864/23491 (55%)]\tLoss: 1.910802\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:50 | INFO | Rank 0 | Train Epoch: 1 [12896/23491 (55%)]\tLoss: 1.171498\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:51 | INFO | Rank 0 | Train Epoch: 1 [12928/23491 (55%)]\tLoss: 1.558349\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:51 | INFO | Rank 0 | Train Epoch: 1 [12960/23491 (55%)]\tLoss: 1.667504\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:51 | INFO | Rank 0 | Train Epoch: 1 [12992/23491 (55%)]\tLoss: 1.689203\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:52 | INFO | Rank 0 | Train Epoch: 1 [13024/23491 (55%)]\tLoss: 1.937124\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:52 | INFO | Rank 0 | Train Epoch: 1 [13056/23491 (56%)]\tLoss: 1.523232\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:52 | INFO | Rank 0 | Train Epoch: 1 [13088/23491 (56%)]\tLoss: 1.646369\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:52 | INFO | Rank 0 | Train Epoch: 1 [13120/23491 (56%)]\tLoss: 1.253291\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:53 | INFO | Rank 0 | Train Epoch: 1 [13152/23491 (56%)]\tLoss: 1.305372\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:53 | INFO | Rank 0 | Train Epoch: 1 [13184/23491 (56%)]\tLoss: 1.817724\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:53 | INFO | Rank 0 | Train Epoch: 1 [13216/23491 (56%)]\tLoss: 1.632744\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:53 | INFO | Rank 0 | Train Epoch: 1 [13248/23491 (56%)]\tLoss: 2.568763\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:54 | INFO | Rank 0 | Train Epoch: 1 [13280/23491 (57%)]\tLoss: 1.468437\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:54 | INFO | Rank 0 | Train Epoch: 1 [13312/23491 (57%)]\tLoss: 1.538182\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:54 | INFO | Rank 0 | Train Epoch: 1 [13344/23491 (57%)]\tLoss: 1.302289\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:54 | INFO | Rank 0 | Train Epoch: 1 [13376/23491 (57%)]\tLoss: 1.541990\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:55 | INFO | Rank 0 | Train Epoch: 1 [13408/23491 (57%)]\tLoss: 1.885820\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:55 | INFO | Rank 0 | Train Epoch: 1 [13440/23491 (57%)]\tLoss: 0.946425\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:55 | INFO | Rank 0 | Train Epoch: 1 [13472/23491 (57%)]\tLoss: 1.216427\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:56 | INFO | Rank 0 | Train Epoch: 1 [13504/23491 (57%)]\tLoss: 1.525905\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:56 | INFO | Rank 0 | Train Epoch: 1 [13536/23491 (58%)]\tLoss: 1.786514\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:56 | INFO | Rank 0 | Train Epoch: 1 [13568/23491 (58%)]\tLoss: 1.295924\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:56 | INFO | Rank 0 | Train Epoch: 1 [13600/23491 (58%)]\tLoss: 1.493466\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:57 | INFO | Rank 0 | Train Epoch: 1 [13632/23491 (58%)]\tLoss: 2.106201\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:57 | INFO | Rank 0 | Train Epoch: 1 [13664/23491 (58%)]\tLoss: 1.545989\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:57 | INFO | Rank 0 | Train Epoch: 1 [13696/23491 (58%)]\tLoss: 1.620419\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:57 | INFO | Rank 0 | Train Epoch: 1 [13728/23491 (58%)]\tLoss: 2.222966\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:58 | INFO | Rank 0 | Train Epoch: 1 [13760/23491 (59%)]\tLoss: 1.163987\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:58 | INFO | Rank 0 | Train Epoch: 1 [13792/23491 (59%)]\tLoss: 1.207744\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:58 | INFO | Rank 0 | Train Epoch: 1 [13824/23491 (59%)]\tLoss: 1.411953\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:58 | INFO | Rank 0 | Train Epoch: 1 [13856/23491 (59%)]\tLoss: 1.562447\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:59 | INFO | Rank 0 | Train Epoch: 1 [13888/23491 (59%)]\tLoss: 1.548419\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:59 | INFO | Rank 0 | Train Epoch: 1 [13920/23491 (59%)]\tLoss: 1.286580\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:29:59 | INFO | Rank 0 | Train Epoch: 1 [13952/23491 (59%)]\tLoss: 1.457635\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:00 | INFO | Rank 0 | Train Epoch: 1 [13984/23491 (60%)]\tLoss: 1.351946\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:00 | INFO | Rank 0 | Train Epoch: 1 [14016/23491 (60%)]\tLoss: 1.273147\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:00 | INFO | Rank 0 | Train Epoch: 1 [14048/23491 (60%)]\tLoss: 1.194112\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:00 | INFO | Rank 0 | Train Epoch: 1 [14080/23491 (60%)]\tLoss: 1.430896\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:01 | INFO | Rank 0 | Train Epoch: 1 [14112/23491 (60%)]\tLoss: 1.099019\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:01 | INFO | Rank 0 | Train Epoch: 1 [14144/23491 (60%)]\tLoss: 1.587218\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:01 | INFO | Rank 0 | Train Epoch: 1 [14176/23491 (60%)]\tLoss: 1.769120\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:01 | INFO | Rank 0 | Train Epoch: 1 [14208/23491 (60%)]\tLoss: 1.459342\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:02 | INFO | Rank 0 | Train Epoch: 1 [14240/23491 (61%)]\tLoss: 1.365783\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:02 | INFO | Rank 0 | Train Epoch: 1 [14272/23491 (61%)]\tLoss: 1.032162\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:02 | INFO | Rank 0 | Train Epoch: 1 [14304/23491 (61%)]\tLoss: 1.482394\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:02 | INFO | Rank 0 | Train Epoch: 1 [14336/23491 (61%)]\tLoss: 1.673731\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:03 | INFO | Rank 0 | Train Epoch: 1 [14368/23491 (61%)]\tLoss: 1.063671\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:03 | INFO | Rank 0 | Train Epoch: 1 [14400/23491 (61%)]\tLoss: 1.699504\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:03 | INFO | Rank 0 | Train Epoch: 1 [14432/23491 (61%)]\tLoss: 1.682483\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:03 | INFO | Rank 0 | Train Epoch: 1 [14464/23491 (62%)]\tLoss: 1.106008\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.576\n",
      "2022-11-08,05:30:04 | INFO | Rank 0 | Train Epoch: 1 [14496/23491 (62%)]\tLoss: 1.066543\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:04 | INFO | Rank 0 | Train Epoch: 1 [14528/23491 (62%)]\tLoss: 1.116640\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:04 | INFO | Rank 0 | Train Epoch: 1 [14560/23491 (62%)]\tLoss: 1.633544\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:05 | INFO | Rank 0 | Train Epoch: 1 [14592/23491 (62%)]\tLoss: 1.219283\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:05 | INFO | Rank 0 | Train Epoch: 1 [14624/23491 (62%)]\tLoss: 1.549243\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:05 | INFO | Rank 0 | Train Epoch: 1 [14656/23491 (62%)]\tLoss: 1.444199\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:05 | INFO | Rank 0 | Train Epoch: 1 [14688/23491 (63%)]\tLoss: 1.858496\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:06 | INFO | Rank 0 | Train Epoch: 1 [14720/23491 (63%)]\tLoss: 1.705917\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:06 | INFO | Rank 0 | Train Epoch: 1 [14752/23491 (63%)]\tLoss: 1.567384\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:06 | INFO | Rank 0 | Train Epoch: 1 [14784/23491 (63%)]\tLoss: 1.307333\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:06 | INFO | Rank 0 | Train Epoch: 1 [14816/23491 (63%)]\tLoss: 1.716162\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:07 | INFO | Rank 0 | Train Epoch: 1 [14848/23491 (63%)]\tLoss: 1.555440\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:07 | INFO | Rank 0 | Train Epoch: 1 [14880/23491 (63%)]\tLoss: 2.233246\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:07 | INFO | Rank 0 | Train Epoch: 1 [14912/23491 (63%)]\tLoss: 1.515104\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:07 | INFO | Rank 0 | Train Epoch: 1 [14944/23491 (64%)]\tLoss: 1.542359\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:08 | INFO | Rank 0 | Train Epoch: 1 [14976/23491 (64%)]\tLoss: 1.723511\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:08 | INFO | Rank 0 | Train Epoch: 1 [15008/23491 (64%)]\tLoss: 1.429414\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:08 | INFO | Rank 0 | Train Epoch: 1 [15040/23491 (64%)]\tLoss: 1.494493\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:09 | INFO | Rank 0 | Train Epoch: 1 [15072/23491 (64%)]\tLoss: 1.487972\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:09 | INFO | Rank 0 | Train Epoch: 1 [15104/23491 (64%)]\tLoss: 1.654489\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:09 | INFO | Rank 0 | Train Epoch: 1 [15136/23491 (64%)]\tLoss: 1.852934\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:09 | INFO | Rank 0 | Train Epoch: 1 [15168/23491 (65%)]\tLoss: 1.493062\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:10 | INFO | Rank 0 | Train Epoch: 1 [15200/23491 (65%)]\tLoss: 1.626124\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:10 | INFO | Rank 0 | Train Epoch: 1 [15232/23491 (65%)]\tLoss: 1.590926\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:10 | INFO | Rank 0 | Train Epoch: 1 [15264/23491 (65%)]\tLoss: 2.168594\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:10 | INFO | Rank 0 | Train Epoch: 1 [15296/23491 (65%)]\tLoss: 1.710793\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:11 | INFO | Rank 0 | Train Epoch: 1 [15328/23491 (65%)]\tLoss: 1.294422\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:11 | INFO | Rank 0 | Train Epoch: 1 [15360/23491 (65%)]\tLoss: 1.338797\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:11 | INFO | Rank 0 | Train Epoch: 1 [15392/23491 (66%)]\tLoss: 1.551337\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:11 | INFO | Rank 0 | Train Epoch: 1 [15424/23491 (66%)]\tLoss: 1.343417\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:12 | INFO | Rank 0 | Train Epoch: 1 [15456/23491 (66%)]\tLoss: 1.632288\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:12 | INFO | Rank 0 | Train Epoch: 1 [15488/23491 (66%)]\tLoss: 1.886518\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:12 | INFO | Rank 0 | Train Epoch: 1 [15520/23491 (66%)]\tLoss: 1.551562\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:13 | INFO | Rank 0 | Train Epoch: 1 [15552/23491 (66%)]\tLoss: 1.479662\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:13 | INFO | Rank 0 | Train Epoch: 1 [15584/23491 (66%)]\tLoss: 1.495688\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:13 | INFO | Rank 0 | Train Epoch: 1 [15616/23491 (66%)]\tLoss: 1.346943\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:13 | INFO | Rank 0 | Train Epoch: 1 [15648/23491 (67%)]\tLoss: 1.649608\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:14 | INFO | Rank 0 | Train Epoch: 1 [15680/23491 (67%)]\tLoss: 1.722076\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:14 | INFO | Rank 0 | Train Epoch: 1 [15712/23491 (67%)]\tLoss: 1.676667\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:14 | INFO | Rank 0 | Train Epoch: 1 [15744/23491 (67%)]\tLoss: 1.342102\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:14 | INFO | Rank 0 | Train Epoch: 1 [15776/23491 (67%)]\tLoss: 1.382567\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.575\n",
      "2022-11-08,05:30:15 | INFO | Rank 0 | Train Epoch: 1 [15808/23491 (67%)]\tLoss: 1.524830\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:15 | INFO | Rank 0 | Train Epoch: 1 [15840/23491 (67%)]\tLoss: 1.814350\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:15 | INFO | Rank 0 | Train Epoch: 1 [15872/23491 (68%)]\tLoss: 1.370926\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:15 | INFO | Rank 0 | Train Epoch: 1 [15904/23491 (68%)]\tLoss: 1.714441\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:16 | INFO | Rank 0 | Train Epoch: 1 [15936/23491 (68%)]\tLoss: 1.587946\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:16 | INFO | Rank 0 | Train Epoch: 1 [15968/23491 (68%)]\tLoss: 1.366646\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:16 | INFO | Rank 0 | Train Epoch: 1 [16000/23491 (68%)]\tLoss: 1.276568\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:17 | INFO | Rank 0 | Train Epoch: 1 [16032/23491 (68%)]\tLoss: 1.447955\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:17 | INFO | Rank 0 | Train Epoch: 1 [16064/23491 (68%)]\tLoss: 1.328830\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:17 | INFO | Rank 0 | Train Epoch: 1 [16096/23491 (69%)]\tLoss: 1.493524\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:17 | INFO | Rank 0 | Train Epoch: 1 [16128/23491 (69%)]\tLoss: 1.632396\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:18 | INFO | Rank 0 | Train Epoch: 1 [16160/23491 (69%)]\tLoss: 1.720941\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:18 | INFO | Rank 0 | Train Epoch: 1 [16192/23491 (69%)]\tLoss: 1.359322\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:18 | INFO | Rank 0 | Train Epoch: 1 [16224/23491 (69%)]\tLoss: 1.130764\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:18 | INFO | Rank 0 | Train Epoch: 1 [16256/23491 (69%)]\tLoss: 2.000982\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:19 | INFO | Rank 0 | Train Epoch: 1 [16288/23491 (69%)]\tLoss: 1.020021\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:19 | INFO | Rank 0 | Train Epoch: 1 [16320/23491 (69%)]\tLoss: 1.312158\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:19 | INFO | Rank 0 | Train Epoch: 1 [16352/23491 (70%)]\tLoss: 1.535783\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:19 | INFO | Rank 0 | Train Epoch: 1 [16384/23491 (70%)]\tLoss: 1.481884\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:20 | INFO | Rank 0 | Train Epoch: 1 [16416/23491 (70%)]\tLoss: 1.789589\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:20 | INFO | Rank 0 | Train Epoch: 1 [16448/23491 (70%)]\tLoss: 1.376034\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:20 | INFO | Rank 0 | Train Epoch: 1 [16480/23491 (70%)]\tLoss: 1.482247\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:21 | INFO | Rank 0 | Train Epoch: 1 [16512/23491 (70%)]\tLoss: 1.810091\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:21 | INFO | Rank 0 | Train Epoch: 1 [16544/23491 (70%)]\tLoss: 1.486337\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:21 | INFO | Rank 0 | Train Epoch: 1 [16576/23491 (71%)]\tLoss: 1.432719\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:21 | INFO | Rank 0 | Train Epoch: 1 [16608/23491 (71%)]\tLoss: 1.749629\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:22 | INFO | Rank 0 | Train Epoch: 1 [16640/23491 (71%)]\tLoss: 1.113963\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:22 | INFO | Rank 0 | Train Epoch: 1 [16672/23491 (71%)]\tLoss: 1.309364\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:22 | INFO | Rank 0 | Train Epoch: 1 [16704/23491 (71%)]\tLoss: 1.498398\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:22 | INFO | Rank 0 | Train Epoch: 1 [16736/23491 (71%)]\tLoss: 1.701483\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:23 | INFO | Rank 0 | Train Epoch: 1 [16768/23491 (71%)]\tLoss: 1.266436\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:23 | INFO | Rank 0 | Train Epoch: 1 [16800/23491 (72%)]\tLoss: 1.728276\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:23 | INFO | Rank 0 | Train Epoch: 1 [16832/23491 (72%)]\tLoss: 1.279676\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:23 | INFO | Rank 0 | Train Epoch: 1 [16864/23491 (72%)]\tLoss: 1.623333\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:24 | INFO | Rank 0 | Train Epoch: 1 [16896/23491 (72%)]\tLoss: 1.480964\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:24 | INFO | Rank 0 | Train Epoch: 1 [16928/23491 (72%)]\tLoss: 1.692366\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:24 | INFO | Rank 0 | Train Epoch: 1 [16960/23491 (72%)]\tLoss: 1.554337\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:25 | INFO | Rank 0 | Train Epoch: 1 [16992/23491 (72%)]\tLoss: 1.479660\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:25 | INFO | Rank 0 | Train Epoch: 1 [17024/23491 (72%)]\tLoss: 1.438317\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:25 | INFO | Rank 0 | Train Epoch: 1 [17056/23491 (73%)]\tLoss: 1.387553\tData (t) 0.059\tBatch (t) 0.274\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:25 | INFO | Rank 0 | Train Epoch: 1 [17088/23491 (73%)]\tLoss: 1.628752\tData (t) 0.058\tBatch (t) 0.273\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:26 | INFO | Rank 0 | Train Epoch: 1 [17120/23491 (73%)]\tLoss: 1.460007\tData (t) 0.058\tBatch (t) 0.273\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:26 | INFO | Rank 0 | Train Epoch: 1 [17152/23491 (73%)]\tLoss: 1.319017\tData (t) 0.058\tBatch (t) 0.273\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:26 | INFO | Rank 0 | Train Epoch: 1 [17184/23491 (73%)]\tLoss: 1.262346\tData (t) 0.059\tBatch (t) 0.274\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:26 | INFO | Rank 0 | Train Epoch: 1 [17216/23491 (73%)]\tLoss: 1.040515\tData (t) 0.058\tBatch (t) 0.272\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:27 | INFO | Rank 0 | Train Epoch: 1 [17248/23491 (73%)]\tLoss: 1.336259\tData (t) 0.059\tBatch (t) 0.274\tLR: 0.000078\tlogit_scale 4.574\n",
      "2022-11-08,05:30:27 | INFO | Rank 0 | Train Epoch: 1 [17280/23491 (74%)]\tLoss: 1.650921\tData (t) 0.059\tBatch (t) 0.274\tLR: 0.000077\tlogit_scale 4.574\n",
      "2022-11-08,05:30:27 | INFO | Rank 0 | Train Epoch: 1 [17312/23491 (74%)]\tLoss: 1.583848\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.574\n",
      "2022-11-08,05:30:27 | INFO | Rank 0 | Train Epoch: 1 [17344/23491 (74%)]\tLoss: 1.471978\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.574\n",
      "2022-11-08,05:30:28 | INFO | Rank 0 | Train Epoch: 1 [17376/23491 (74%)]\tLoss: 1.403361\tData (t) 0.054\tBatch (t) 0.282\tLR: 0.000077\tlogit_scale 4.574\n",
      "2022-11-08,05:30:28 | INFO | Rank 0 | Train Epoch: 1 [17408/23491 (74%)]\tLoss: 1.732440\tData (t) 0.056\tBatch (t) 0.270\tLR: 0.000077\tlogit_scale 4.574\n",
      "2022-11-08,05:30:28 | INFO | Rank 0 | Train Epoch: 1 [17440/23491 (74%)]\tLoss: 1.337044\tData (t) 0.055\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.574\n",
      "2022-11-08,05:30:29 | INFO | Rank 0 | Train Epoch: 1 [17472/23491 (74%)]\tLoss: 1.485685\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.574\n",
      "2022-11-08,05:30:29 | INFO | Rank 0 | Train Epoch: 1 [17504/23491 (75%)]\tLoss: 1.154295\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.574\n",
      "2022-11-08,05:30:29 | INFO | Rank 0 | Train Epoch: 1 [17536/23491 (75%)]\tLoss: 1.060420\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.574\n",
      "2022-11-08,05:30:29 | INFO | Rank 0 | Train Epoch: 1 [17568/23491 (75%)]\tLoss: 0.960297\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.574\n",
      "2022-11-08,05:30:30 | INFO | Rank 0 | Train Epoch: 1 [17600/23491 (75%)]\tLoss: 1.312960\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.574\n",
      "2022-11-08,05:30:30 | INFO | Rank 0 | Train Epoch: 1 [17632/23491 (75%)]\tLoss: 1.471772\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.574\n",
      "2022-11-08,05:30:30 | INFO | Rank 0 | Train Epoch: 1 [17664/23491 (75%)]\tLoss: 1.412876\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:30 | INFO | Rank 0 | Train Epoch: 1 [17696/23491 (75%)]\tLoss: 1.580019\tData (t) 0.055\tBatch (t) 0.269\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:31 | INFO | Rank 0 | Train Epoch: 1 [17728/23491 (75%)]\tLoss: 1.437132\tData (t) 0.055\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:31 | INFO | Rank 0 | Train Epoch: 1 [17760/23491 (76%)]\tLoss: 1.848590\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:31 | INFO | Rank 0 | Train Epoch: 1 [17792/23491 (76%)]\tLoss: 1.552275\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:32 | INFO | Rank 0 | Train Epoch: 1 [17824/23491 (76%)]\tLoss: 1.645601\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:32 | INFO | Rank 0 | Train Epoch: 1 [17856/23491 (76%)]\tLoss: 1.382028\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:32 | INFO | Rank 0 | Train Epoch: 1 [17888/23491 (76%)]\tLoss: 1.451642\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:32 | INFO | Rank 0 | Train Epoch: 1 [17920/23491 (76%)]\tLoss: 1.456137\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:33 | INFO | Rank 0 | Train Epoch: 1 [17952/23491 (76%)]\tLoss: 1.348137\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:33 | INFO | Rank 0 | Train Epoch: 1 [17984/23491 (77%)]\tLoss: 1.288206\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:33 | INFO | Rank 0 | Train Epoch: 1 [18016/23491 (77%)]\tLoss: 1.750333\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:33 | INFO | Rank 0 | Train Epoch: 1 [18048/23491 (77%)]\tLoss: 1.390264\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:34 | INFO | Rank 0 | Train Epoch: 1 [18080/23491 (77%)]\tLoss: 1.142610\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:34 | INFO | Rank 0 | Train Epoch: 1 [18112/23491 (77%)]\tLoss: 1.703441\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:34 | INFO | Rank 0 | Train Epoch: 1 [18144/23491 (77%)]\tLoss: 1.990471\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:34 | INFO | Rank 0 | Train Epoch: 1 [18176/23491 (77%)]\tLoss: 1.980796\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:35 | INFO | Rank 0 | Train Epoch: 1 [18208/23491 (78%)]\tLoss: 1.353561\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:35 | INFO | Rank 0 | Train Epoch: 1 [18240/23491 (78%)]\tLoss: 2.021541\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:35 | INFO | Rank 0 | Train Epoch: 1 [18272/23491 (78%)]\tLoss: 1.278585\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:36 | INFO | Rank 0 | Train Epoch: 1 [18304/23491 (78%)]\tLoss: 1.303802\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:36 | INFO | Rank 0 | Train Epoch: 1 [18336/23491 (78%)]\tLoss: 1.498725\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:36 | INFO | Rank 0 | Train Epoch: 1 [18368/23491 (78%)]\tLoss: 1.458749\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:36 | INFO | Rank 0 | Train Epoch: 1 [18400/23491 (78%)]\tLoss: 1.640673\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:37 | INFO | Rank 0 | Train Epoch: 1 [18432/23491 (78%)]\tLoss: 1.427598\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:37 | INFO | Rank 0 | Train Epoch: 1 [18464/23491 (79%)]\tLoss: 1.272569\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:37 | INFO | Rank 0 | Train Epoch: 1 [18496/23491 (79%)]\tLoss: 1.829647\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:37 | INFO | Rank 0 | Train Epoch: 1 [18528/23491 (79%)]\tLoss: 1.789484\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:38 | INFO | Rank 0 | Train Epoch: 1 [18560/23491 (79%)]\tLoss: 1.610322\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:38 | INFO | Rank 0 | Train Epoch: 1 [18592/23491 (79%)]\tLoss: 1.364751\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:38 | INFO | Rank 0 | Train Epoch: 1 [18624/23491 (79%)]\tLoss: 1.198270\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:38 | INFO | Rank 0 | Train Epoch: 1 [18656/23491 (79%)]\tLoss: 2.455986\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:39 | INFO | Rank 0 | Train Epoch: 1 [18688/23491 (80%)]\tLoss: 1.312596\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:39 | INFO | Rank 0 | Train Epoch: 1 [18720/23491 (80%)]\tLoss: 1.604025\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:39 | INFO | Rank 0 | Train Epoch: 1 [18752/23491 (80%)]\tLoss: 0.928595\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:39 | INFO | Rank 0 | Train Epoch: 1 [18784/23491 (80%)]\tLoss: 1.300010\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:40 | INFO | Rank 0 | Train Epoch: 1 [18816/23491 (80%)]\tLoss: 1.726342\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:40 | INFO | Rank 0 | Train Epoch: 1 [18848/23491 (80%)]\tLoss: 1.667989\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:40 | INFO | Rank 0 | Train Epoch: 1 [18880/23491 (80%)]\tLoss: 1.294719\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:41 | INFO | Rank 0 | Train Epoch: 1 [18912/23491 (81%)]\tLoss: 1.436321\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:41 | INFO | Rank 0 | Train Epoch: 1 [18944/23491 (81%)]\tLoss: 1.382830\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:41 | INFO | Rank 0 | Train Epoch: 1 [18976/23491 (81%)]\tLoss: 1.392757\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.573\n",
      "2022-11-08,05:30:41 | INFO | Rank 0 | Train Epoch: 1 [19008/23491 (81%)]\tLoss: 1.734879\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:42 | INFO | Rank 0 | Train Epoch: 1 [19040/23491 (81%)]\tLoss: 1.732685\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:42 | INFO | Rank 0 | Train Epoch: 1 [19072/23491 (81%)]\tLoss: 1.224431\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:42 | INFO | Rank 0 | Train Epoch: 1 [19104/23491 (81%)]\tLoss: 1.554559\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:42 | INFO | Rank 0 | Train Epoch: 1 [19136/23491 (81%)]\tLoss: 1.039567\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:43 | INFO | Rank 0 | Train Epoch: 1 [19168/23491 (82%)]\tLoss: 1.088991\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:43 | INFO | Rank 0 | Train Epoch: 1 [19200/23491 (82%)]\tLoss: 0.855978\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:43 | INFO | Rank 0 | Train Epoch: 1 [19232/23491 (82%)]\tLoss: 1.178505\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:43 | INFO | Rank 0 | Train Epoch: 1 [19264/23491 (82%)]\tLoss: 0.735175\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:44 | INFO | Rank 0 | Train Epoch: 1 [19296/23491 (82%)]\tLoss: 1.545778\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:44 | INFO | Rank 0 | Train Epoch: 1 [19328/23491 (82%)]\tLoss: 0.942592\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:44 | INFO | Rank 0 | Train Epoch: 1 [19360/23491 (82%)]\tLoss: 0.973642\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:45 | INFO | Rank 0 | Train Epoch: 1 [19392/23491 (83%)]\tLoss: 2.156980\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:45 | INFO | Rank 0 | Train Epoch: 1 [19424/23491 (83%)]\tLoss: 1.332089\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:45 | INFO | Rank 0 | Train Epoch: 1 [19456/23491 (83%)]\tLoss: 1.502273\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:45 | INFO | Rank 0 | Train Epoch: 1 [19488/23491 (83%)]\tLoss: 1.464054\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:46 | INFO | Rank 0 | Train Epoch: 1 [19520/23491 (83%)]\tLoss: 1.014987\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:46 | INFO | Rank 0 | Train Epoch: 1 [19552/23491 (83%)]\tLoss: 1.204748\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:46 | INFO | Rank 0 | Train Epoch: 1 [19584/23491 (83%)]\tLoss: 1.595887\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:46 | INFO | Rank 0 | Train Epoch: 1 [19616/23491 (84%)]\tLoss: 1.947157\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:47 | INFO | Rank 0 | Train Epoch: 1 [19648/23491 (84%)]\tLoss: 1.356854\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:47 | INFO | Rank 0 | Train Epoch: 1 [19680/23491 (84%)]\tLoss: 1.774981\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:47 | INFO | Rank 0 | Train Epoch: 1 [19712/23491 (84%)]\tLoss: 1.260903\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:47 | INFO | Rank 0 | Train Epoch: 1 [19744/23491 (84%)]\tLoss: 1.472686\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:48 | INFO | Rank 0 | Train Epoch: 1 [19776/23491 (84%)]\tLoss: 1.491937\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:48 | INFO | Rank 0 | Train Epoch: 1 [19808/23491 (84%)]\tLoss: 1.508053\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:48 | INFO | Rank 0 | Train Epoch: 1 [19840/23491 (84%)]\tLoss: 0.765108\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:49 | INFO | Rank 0 | Train Epoch: 1 [19872/23491 (85%)]\tLoss: 1.556972\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:49 | INFO | Rank 0 | Train Epoch: 1 [19904/23491 (85%)]\tLoss: 1.441549\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:49 | INFO | Rank 0 | Train Epoch: 1 [19936/23491 (85%)]\tLoss: 1.596549\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:49 | INFO | Rank 0 | Train Epoch: 1 [19968/23491 (85%)]\tLoss: 1.086431\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:50 | INFO | Rank 0 | Train Epoch: 1 [20000/23491 (85%)]\tLoss: 1.673237\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:50 | INFO | Rank 0 | Train Epoch: 1 [20032/23491 (85%)]\tLoss: 1.817865\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:50 | INFO | Rank 0 | Train Epoch: 1 [20064/23491 (85%)]\tLoss: 1.413993\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:50 | INFO | Rank 0 | Train Epoch: 1 [20096/23491 (86%)]\tLoss: 1.263237\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:51 | INFO | Rank 0 | Train Epoch: 1 [20128/23491 (86%)]\tLoss: 1.611238\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:51 | INFO | Rank 0 | Train Epoch: 1 [20160/23491 (86%)]\tLoss: 1.420699\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:51 | INFO | Rank 0 | Train Epoch: 1 [20192/23491 (86%)]\tLoss: 1.141720\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:51 | INFO | Rank 0 | Train Epoch: 1 [20224/23491 (86%)]\tLoss: 1.543486\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:52 | INFO | Rank 0 | Train Epoch: 1 [20256/23491 (86%)]\tLoss: 1.738396\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:52 | INFO | Rank 0 | Train Epoch: 1 [20288/23491 (86%)]\tLoss: 1.285488\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:52 | INFO | Rank 0 | Train Epoch: 1 [20320/23491 (87%)]\tLoss: 1.441251\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:53 | INFO | Rank 0 | Train Epoch: 1 [20352/23491 (87%)]\tLoss: 1.900017\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:53 | INFO | Rank 0 | Train Epoch: 1 [20384/23491 (87%)]\tLoss: 1.110442\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:53 | INFO | Rank 0 | Train Epoch: 1 [20416/23491 (87%)]\tLoss: 1.176113\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:53 | INFO | Rank 0 | Train Epoch: 1 [20448/23491 (87%)]\tLoss: 1.557127\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:54 | INFO | Rank 0 | Train Epoch: 1 [20480/23491 (87%)]\tLoss: 1.739130\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:54 | INFO | Rank 0 | Train Epoch: 1 [20512/23491 (87%)]\tLoss: 1.666772\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:54 | INFO | Rank 0 | Train Epoch: 1 [20544/23491 (87%)]\tLoss: 1.515004\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:54 | INFO | Rank 0 | Train Epoch: 1 [20576/23491 (88%)]\tLoss: 1.734371\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:55 | INFO | Rank 0 | Train Epoch: 1 [20608/23491 (88%)]\tLoss: 1.021251\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.572\n",
      "2022-11-08,05:30:55 | INFO | Rank 0 | Train Epoch: 1 [20640/23491 (88%)]\tLoss: 1.329168\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:55 | INFO | Rank 0 | Train Epoch: 1 [20672/23491 (88%)]\tLoss: 1.549618\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:55 | INFO | Rank 0 | Train Epoch: 1 [20704/23491 (88%)]\tLoss: 1.433825\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:56 | INFO | Rank 0 | Train Epoch: 1 [20736/23491 (88%)]\tLoss: 1.469612\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:56 | INFO | Rank 0 | Train Epoch: 1 [20768/23491 (88%)]\tLoss: 1.477090\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:56 | INFO | Rank 0 | Train Epoch: 1 [20800/23491 (89%)]\tLoss: 1.534763\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:57 | INFO | Rank 0 | Train Epoch: 1 [20832/23491 (89%)]\tLoss: 1.381116\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:57 | INFO | Rank 0 | Train Epoch: 1 [20864/23491 (89%)]\tLoss: 1.527743\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:57 | INFO | Rank 0 | Train Epoch: 1 [20896/23491 (89%)]\tLoss: 1.304253\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:57 | INFO | Rank 0 | Train Epoch: 1 [20928/23491 (89%)]\tLoss: 1.277636\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:58 | INFO | Rank 0 | Train Epoch: 1 [20960/23491 (89%)]\tLoss: 1.650409\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:58 | INFO | Rank 0 | Train Epoch: 1 [20992/23491 (89%)]\tLoss: 1.005054\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:58 | INFO | Rank 0 | Train Epoch: 1 [21024/23491 (90%)]\tLoss: 1.205574\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:58 | INFO | Rank 0 | Train Epoch: 1 [21056/23491 (90%)]\tLoss: 1.413935\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:59 | INFO | Rank 0 | Train Epoch: 1 [21088/23491 (90%)]\tLoss: 1.287112\tData (t) 0.055\tBatch (t) 0.269\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:59 | INFO | Rank 0 | Train Epoch: 1 [21120/23491 (90%)]\tLoss: 1.305202\tData (t) 0.057\tBatch (t) 0.270\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:59 | INFO | Rank 0 | Train Epoch: 1 [21152/23491 (90%)]\tLoss: 1.741533\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:30:59 | INFO | Rank 0 | Train Epoch: 1 [21184/23491 (90%)]\tLoss: 1.389685\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:00 | INFO | Rank 0 | Train Epoch: 1 [21216/23491 (90%)]\tLoss: 1.266192\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:00 | INFO | Rank 0 | Train Epoch: 1 [21248/23491 (90%)]\tLoss: 1.448172\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:00 | INFO | Rank 0 | Train Epoch: 1 [21280/23491 (91%)]\tLoss: 1.811418\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:01 | INFO | Rank 0 | Train Epoch: 1 [21312/23491 (91%)]\tLoss: 1.465569\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:01 | INFO | Rank 0 | Train Epoch: 1 [21344/23491 (91%)]\tLoss: 1.766039\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:01 | INFO | Rank 0 | Train Epoch: 1 [21376/23491 (91%)]\tLoss: 1.421983\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:01 | INFO | Rank 0 | Train Epoch: 1 [21408/23491 (91%)]\tLoss: 0.898064\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:02 | INFO | Rank 0 | Train Epoch: 1 [21440/23491 (91%)]\tLoss: 1.278536\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:02 | INFO | Rank 0 | Train Epoch: 1 [21472/23491 (91%)]\tLoss: 1.499730\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:02 | INFO | Rank 0 | Train Epoch: 1 [21504/23491 (92%)]\tLoss: 1.300017\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:02 | INFO | Rank 0 | Train Epoch: 1 [21536/23491 (92%)]\tLoss: 1.648325\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:03 | INFO | Rank 0 | Train Epoch: 1 [21568/23491 (92%)]\tLoss: 1.951035\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:03 | INFO | Rank 0 | Train Epoch: 1 [21600/23491 (92%)]\tLoss: 1.384542\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:03 | INFO | Rank 0 | Train Epoch: 1 [21632/23491 (92%)]\tLoss: 1.728070\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:03 | INFO | Rank 0 | Train Epoch: 1 [21664/23491 (92%)]\tLoss: 1.317023\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:04 | INFO | Rank 0 | Train Epoch: 1 [21696/23491 (92%)]\tLoss: 2.038182\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:04 | INFO | Rank 0 | Train Epoch: 1 [21728/23491 (93%)]\tLoss: 1.713280\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:04 | INFO | Rank 0 | Train Epoch: 1 [21760/23491 (93%)]\tLoss: 1.934885\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:05 | INFO | Rank 0 | Train Epoch: 1 [21792/23491 (93%)]\tLoss: 1.159476\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:05 | INFO | Rank 0 | Train Epoch: 1 [21824/23491 (93%)]\tLoss: 1.532337\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:05 | INFO | Rank 0 | Train Epoch: 1 [21856/23491 (93%)]\tLoss: 1.491948\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000077\tlogit_scale 4.571\n",
      "2022-11-08,05:31:05 | INFO | Rank 0 | Train Epoch: 1 [21888/23491 (93%)]\tLoss: 1.480752\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:06 | INFO | Rank 0 | Train Epoch: 1 [21920/23491 (93%)]\tLoss: 1.654476\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:06 | INFO | Rank 0 | Train Epoch: 1 [21952/23491 (93%)]\tLoss: 1.355957\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:06 | INFO | Rank 0 | Train Epoch: 1 [21984/23491 (94%)]\tLoss: 1.636139\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:06 | INFO | Rank 0 | Train Epoch: 1 [22016/23491 (94%)]\tLoss: 1.587297\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:07 | INFO | Rank 0 | Train Epoch: 1 [22048/23491 (94%)]\tLoss: 1.379649\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:07 | INFO | Rank 0 | Train Epoch: 1 [22080/23491 (94%)]\tLoss: 1.203732\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:07 | INFO | Rank 0 | Train Epoch: 1 [22112/23491 (94%)]\tLoss: 1.493382\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:07 | INFO | Rank 0 | Train Epoch: 1 [22144/23491 (94%)]\tLoss: 1.569854\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:08 | INFO | Rank 0 | Train Epoch: 1 [22176/23491 (94%)]\tLoss: 1.089485\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:08 | INFO | Rank 0 | Train Epoch: 1 [22208/23491 (95%)]\tLoss: 1.738221\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:08 | INFO | Rank 0 | Train Epoch: 1 [22240/23491 (95%)]\tLoss: 1.122985\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:09 | INFO | Rank 0 | Train Epoch: 1 [22272/23491 (95%)]\tLoss: 1.989408\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:09 | INFO | Rank 0 | Train Epoch: 1 [22304/23491 (95%)]\tLoss: 1.445498\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:09 | INFO | Rank 0 | Train Epoch: 1 [22336/23491 (95%)]\tLoss: 1.582654\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:09 | INFO | Rank 0 | Train Epoch: 1 [22368/23491 (95%)]\tLoss: 1.247957\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:10 | INFO | Rank 0 | Train Epoch: 1 [22400/23491 (95%)]\tLoss: 1.335410\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:10 | INFO | Rank 0 | Train Epoch: 1 [22432/23491 (96%)]\tLoss: 1.228044\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.571\n",
      "2022-11-08,05:31:10 | INFO | Rank 0 | Train Epoch: 1 [22464/23491 (96%)]\tLoss: 2.039696\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:10 | INFO | Rank 0 | Train Epoch: 1 [22496/23491 (96%)]\tLoss: 1.100923\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:11 | INFO | Rank 0 | Train Epoch: 1 [22528/23491 (96%)]\tLoss: 1.767086\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:11 | INFO | Rank 0 | Train Epoch: 1 [22560/23491 (96%)]\tLoss: 1.330264\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:11 | INFO | Rank 0 | Train Epoch: 1 [22592/23491 (96%)]\tLoss: 1.460945\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:11 | INFO | Rank 0 | Train Epoch: 1 [22624/23491 (96%)]\tLoss: 1.276922\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:12 | INFO | Rank 0 | Train Epoch: 1 [22656/23491 (96%)]\tLoss: 1.420847\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:12 | INFO | Rank 0 | Train Epoch: 1 [22688/23491 (97%)]\tLoss: 1.104474\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:12 | INFO | Rank 0 | Train Epoch: 1 [22720/23491 (97%)]\tLoss: 1.623692\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:13 | INFO | Rank 0 | Train Epoch: 1 [22752/23491 (97%)]\tLoss: 1.238484\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:13 | INFO | Rank 0 | Train Epoch: 1 [22784/23491 (97%)]\tLoss: 1.184055\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:13 | INFO | Rank 0 | Train Epoch: 1 [22816/23491 (97%)]\tLoss: 1.091513\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:13 | INFO | Rank 0 | Train Epoch: 1 [22848/23491 (97%)]\tLoss: 1.590834\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:14 | INFO | Rank 0 | Train Epoch: 1 [22880/23491 (97%)]\tLoss: 1.341683\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:14 | INFO | Rank 0 | Train Epoch: 1 [22912/23491 (98%)]\tLoss: 1.210034\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:14 | INFO | Rank 0 | Train Epoch: 1 [22944/23491 (98%)]\tLoss: 1.458548\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:14 | INFO | Rank 0 | Train Epoch: 1 [22976/23491 (98%)]\tLoss: 1.135439\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:15 | INFO | Rank 0 | Train Epoch: 1 [23008/23491 (98%)]\tLoss: 1.190812\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:15 | INFO | Rank 0 | Train Epoch: 1 [23040/23491 (98%)]\tLoss: 1.745094\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:15 | INFO | Rank 0 | Train Epoch: 1 [23072/23491 (98%)]\tLoss: 1.293978\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:15 | INFO | Rank 0 | Train Epoch: 1 [23104/23491 (98%)]\tLoss: 1.224041\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:16 | INFO | Rank 0 | Train Epoch: 1 [23136/23491 (99%)]\tLoss: 2.043562\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:16 | INFO | Rank 0 | Train Epoch: 1 [23168/23491 (99%)]\tLoss: 1.320410\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:16 | INFO | Rank 0 | Train Epoch: 1 [23200/23491 (99%)]\tLoss: 2.326512\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:17 | INFO | Rank 0 | Train Epoch: 1 [23232/23491 (99%)]\tLoss: 1.026332\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:17 | INFO | Rank 0 | Train Epoch: 1 [23264/23491 (99%)]\tLoss: 1.354459\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:17 | INFO | Rank 0 | Train Epoch: 1 [23296/23491 (99%)]\tLoss: 1.051055\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:17 | INFO | Rank 0 | Train Epoch: 1 [23328/23491 (99%)]\tLoss: 1.346669\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:18 | INFO | Rank 0 | Train Epoch: 1 [23360/23491 (99%)]\tLoss: 1.651575\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:18 | INFO | Rank 0 | Train Epoch: 1 [23392/23491 (100%)]\tLoss: 1.336032\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:18 | INFO | Rank 0 | Train Epoch: 1 [23424/23491 (100%)]\tLoss: 1.324642\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:31:18 | INFO | Rank 0 | Train Epoch: 1 [23456/23491 (100%)]\tLoss: 1.664246\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "  0%|                                                   | 0/386 [00:00<?, ?it/s]2022-11-08,05:31:18 | INFO | Rank 0 | Begin to eval epoch: 2...\n",
      "100%|█████████████████████████████████████████| 386/386 [00:46<00:00,  8.37it/s]\n",
      "2022-11-08,05:32:05 | INFO | Rank 0 | Eval Epoch: 2 val_loss: 2.3924\tepoch: 2.0000\tnum_elements: 12328.0000\n",
      "2022-11-08,05:32:05 | INFO | Rank 0 | Start epoch 2\n",
      "2022-11-08,05:32:05 | INFO | Rank 0 | Train Epoch: 2 [0/23491 (0%)]\tLoss: 1.086538\tData (t) 0.034\tBatch (t) 0.248\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:05 | INFO | Rank 0 | Train Epoch: 2 [32/23491 (0%)]\tLoss: 1.079530\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:05 | INFO | Rank 0 | Train Epoch: 2 [64/23491 (0%)]\tLoss: 0.717300\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:06 | INFO | Rank 0 | Train Epoch: 2 [96/23491 (0%)]\tLoss: 0.869627\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:06 | INFO | Rank 0 | Train Epoch: 2 [128/23491 (1%)]\tLoss: 1.042623\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:06 | INFO | Rank 0 | Train Epoch: 2 [160/23491 (1%)]\tLoss: 1.212041\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:06 | INFO | Rank 0 | Train Epoch: 2 [192/23491 (1%)]\tLoss: 0.849352\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:07 | INFO | Rank 0 | Train Epoch: 2 [224/23491 (1%)]\tLoss: 1.184009\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:07 | INFO | Rank 0 | Train Epoch: 2 [256/23491 (1%)]\tLoss: 0.849376\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:07 | INFO | Rank 0 | Train Epoch: 2 [288/23491 (1%)]\tLoss: 1.340802\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:07 | INFO | Rank 0 | Train Epoch: 2 [320/23491 (1%)]\tLoss: 1.173252\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:08 | INFO | Rank 0 | Train Epoch: 2 [352/23491 (1%)]\tLoss: 1.648408\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:08 | INFO | Rank 0 | Train Epoch: 2 [384/23491 (2%)]\tLoss: 1.284661\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:08 | INFO | Rank 0 | Train Epoch: 2 [416/23491 (2%)]\tLoss: 0.688726\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:09 | INFO | Rank 0 | Train Epoch: 2 [448/23491 (2%)]\tLoss: 1.270007\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:09 | INFO | Rank 0 | Train Epoch: 2 [480/23491 (2%)]\tLoss: 1.329794\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:09 | INFO | Rank 0 | Train Epoch: 2 [512/23491 (2%)]\tLoss: 0.778808\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:09 | INFO | Rank 0 | Train Epoch: 2 [544/23491 (2%)]\tLoss: 1.072978\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:10 | INFO | Rank 0 | Train Epoch: 2 [576/23491 (2%)]\tLoss: 0.829706\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:10 | INFO | Rank 0 | Train Epoch: 2 [608/23491 (3%)]\tLoss: 1.314011\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:10 | INFO | Rank 0 | Train Epoch: 2 [640/23491 (3%)]\tLoss: 0.980830\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:10 | INFO | Rank 0 | Train Epoch: 2 [672/23491 (3%)]\tLoss: 1.019204\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:11 | INFO | Rank 0 | Train Epoch: 2 [704/23491 (3%)]\tLoss: 1.118226\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:11 | INFO | Rank 0 | Train Epoch: 2 [736/23491 (3%)]\tLoss: 1.082118\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:11 | INFO | Rank 0 | Train Epoch: 2 [768/23491 (3%)]\tLoss: 0.992987\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:11 | INFO | Rank 0 | Train Epoch: 2 [800/23491 (3%)]\tLoss: 0.884490\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:12 | INFO | Rank 0 | Train Epoch: 2 [832/23491 (4%)]\tLoss: 0.892992\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:12 | INFO | Rank 0 | Train Epoch: 2 [864/23491 (4%)]\tLoss: 0.874122\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:12 | INFO | Rank 0 | Train Epoch: 2 [896/23491 (4%)]\tLoss: 1.123094\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:13 | INFO | Rank 0 | Train Epoch: 2 [928/23491 (4%)]\tLoss: 1.020486\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:13 | INFO | Rank 0 | Train Epoch: 2 [960/23491 (4%)]\tLoss: 0.565998\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:13 | INFO | Rank 0 | Train Epoch: 2 [992/23491 (4%)]\tLoss: 0.910879\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:13 | INFO | Rank 0 | Train Epoch: 2 [1024/23491 (4%)]\tLoss: 1.162955\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:14 | INFO | Rank 0 | Train Epoch: 2 [1056/23491 (4%)]\tLoss: 0.800775\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:14 | INFO | Rank 0 | Train Epoch: 2 [1088/23491 (5%)]\tLoss: 1.182730\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:14 | INFO | Rank 0 | Train Epoch: 2 [1120/23491 (5%)]\tLoss: 1.030253\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:14 | INFO | Rank 0 | Train Epoch: 2 [1152/23491 (5%)]\tLoss: 1.340159\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:15 | INFO | Rank 0 | Train Epoch: 2 [1184/23491 (5%)]\tLoss: 0.966538\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:15 | INFO | Rank 0 | Train Epoch: 2 [1216/23491 (5%)]\tLoss: 1.330950\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:15 | INFO | Rank 0 | Train Epoch: 2 [1248/23491 (5%)]\tLoss: 0.920904\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:15 | INFO | Rank 0 | Train Epoch: 2 [1280/23491 (5%)]\tLoss: 1.302715\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:16 | INFO | Rank 0 | Train Epoch: 2 [1312/23491 (6%)]\tLoss: 0.669103\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:16 | INFO | Rank 0 | Train Epoch: 2 [1344/23491 (6%)]\tLoss: 1.234598\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:16 | INFO | Rank 0 | Train Epoch: 2 [1376/23491 (6%)]\tLoss: 0.875842\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:17 | INFO | Rank 0 | Train Epoch: 2 [1408/23491 (6%)]\tLoss: 1.100517\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.570\n",
      "2022-11-08,05:32:17 | INFO | Rank 0 | Train Epoch: 2 [1440/23491 (6%)]\tLoss: 1.495913\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:17 | INFO | Rank 0 | Train Epoch: 2 [1472/23491 (6%)]\tLoss: 0.777004\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:17 | INFO | Rank 0 | Train Epoch: 2 [1504/23491 (6%)]\tLoss: 0.961358\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:18 | INFO | Rank 0 | Train Epoch: 2 [1536/23491 (7%)]\tLoss: 1.157107\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:18 | INFO | Rank 0 | Train Epoch: 2 [1568/23491 (7%)]\tLoss: 1.008886\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:18 | INFO | Rank 0 | Train Epoch: 2 [1600/23491 (7%)]\tLoss: 0.860245\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:18 | INFO | Rank 0 | Train Epoch: 2 [1632/23491 (7%)]\tLoss: 1.151486\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:19 | INFO | Rank 0 | Train Epoch: 2 [1664/23491 (7%)]\tLoss: 1.046506\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:19 | INFO | Rank 0 | Train Epoch: 2 [1696/23491 (7%)]\tLoss: 1.467522\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:19 | INFO | Rank 0 | Train Epoch: 2 [1728/23491 (7%)]\tLoss: 1.243735\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:19 | INFO | Rank 0 | Train Epoch: 2 [1760/23491 (7%)]\tLoss: 1.263177\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:20 | INFO | Rank 0 | Train Epoch: 2 [1792/23491 (8%)]\tLoss: 1.023641\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:20 | INFO | Rank 0 | Train Epoch: 2 [1824/23491 (8%)]\tLoss: 0.844037\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:20 | INFO | Rank 0 | Train Epoch: 2 [1856/23491 (8%)]\tLoss: 1.127033\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:21 | INFO | Rank 0 | Train Epoch: 2 [1888/23491 (8%)]\tLoss: 1.233589\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:21 | INFO | Rank 0 | Train Epoch: 2 [1920/23491 (8%)]\tLoss: 1.029883\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:21 | INFO | Rank 0 | Train Epoch: 2 [1952/23491 (8%)]\tLoss: 0.885648\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:21 | INFO | Rank 0 | Train Epoch: 2 [1984/23491 (8%)]\tLoss: 1.549460\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:22 | INFO | Rank 0 | Train Epoch: 2 [2016/23491 (9%)]\tLoss: 1.108691\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:22 | INFO | Rank 0 | Train Epoch: 2 [2048/23491 (9%)]\tLoss: 1.279336\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:22 | INFO | Rank 0 | Train Epoch: 2 [2080/23491 (9%)]\tLoss: 0.949781\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:22 | INFO | Rank 0 | Train Epoch: 2 [2112/23491 (9%)]\tLoss: 1.460804\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:23 | INFO | Rank 0 | Train Epoch: 2 [2144/23491 (9%)]\tLoss: 0.920141\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:23 | INFO | Rank 0 | Train Epoch: 2 [2176/23491 (9%)]\tLoss: 1.616072\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:23 | INFO | Rank 0 | Train Epoch: 2 [2208/23491 (9%)]\tLoss: 0.849830\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:23 | INFO | Rank 0 | Train Epoch: 2 [2240/23491 (10%)]\tLoss: 1.089254\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:24 | INFO | Rank 0 | Train Epoch: 2 [2272/23491 (10%)]\tLoss: 1.529048\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:24 | INFO | Rank 0 | Train Epoch: 2 [2304/23491 (10%)]\tLoss: 0.817099\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:24 | INFO | Rank 0 | Train Epoch: 2 [2336/23491 (10%)]\tLoss: 1.194377\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:24 | INFO | Rank 0 | Train Epoch: 2 [2368/23491 (10%)]\tLoss: 0.987616\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000076\tlogit_scale 4.569\n",
      "2022-11-08,05:32:25 | INFO | Rank 0 | Train Epoch: 2 [2400/23491 (10%)]\tLoss: 1.016536\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:25 | INFO | Rank 0 | Train Epoch: 2 [2432/23491 (10%)]\tLoss: 1.103512\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:25 | INFO | Rank 0 | Train Epoch: 2 [2464/23491 (10%)]\tLoss: 1.292310\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:26 | INFO | Rank 0 | Train Epoch: 2 [2496/23491 (11%)]\tLoss: 0.632369\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:26 | INFO | Rank 0 | Train Epoch: 2 [2528/23491 (11%)]\tLoss: 0.947507\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:26 | INFO | Rank 0 | Train Epoch: 2 [2560/23491 (11%)]\tLoss: 0.974503\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:26 | INFO | Rank 0 | Train Epoch: 2 [2592/23491 (11%)]\tLoss: 1.162757\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:27 | INFO | Rank 0 | Train Epoch: 2 [2624/23491 (11%)]\tLoss: 1.079124\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:27 | INFO | Rank 0 | Train Epoch: 2 [2656/23491 (11%)]\tLoss: 1.113709\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:27 | INFO | Rank 0 | Train Epoch: 2 [2688/23491 (11%)]\tLoss: 1.349307\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:27 | INFO | Rank 0 | Train Epoch: 2 [2720/23491 (12%)]\tLoss: 1.711824\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:28 | INFO | Rank 0 | Train Epoch: 2 [2752/23491 (12%)]\tLoss: 0.922001\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:28 | INFO | Rank 0 | Train Epoch: 2 [2784/23491 (12%)]\tLoss: 0.945965\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:28 | INFO | Rank 0 | Train Epoch: 2 [2816/23491 (12%)]\tLoss: 1.277784\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:28 | INFO | Rank 0 | Train Epoch: 2 [2848/23491 (12%)]\tLoss: 1.296468\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:29 | INFO | Rank 0 | Train Epoch: 2 [2880/23491 (12%)]\tLoss: 1.130281\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:29 | INFO | Rank 0 | Train Epoch: 2 [2912/23491 (12%)]\tLoss: 1.242154\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:29 | INFO | Rank 0 | Train Epoch: 2 [2944/23491 (13%)]\tLoss: 1.380737\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.569\n",
      "2022-11-08,05:32:30 | INFO | Rank 0 | Train Epoch: 2 [2976/23491 (13%)]\tLoss: 1.384616\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:30 | INFO | Rank 0 | Train Epoch: 2 [3008/23491 (13%)]\tLoss: 1.053598\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:30 | INFO | Rank 0 | Train Epoch: 2 [3040/23491 (13%)]\tLoss: 1.093311\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:30 | INFO | Rank 0 | Train Epoch: 2 [3072/23491 (13%)]\tLoss: 0.771439\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:31 | INFO | Rank 0 | Train Epoch: 2 [3104/23491 (13%)]\tLoss: 0.839163\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:31 | INFO | Rank 0 | Train Epoch: 2 [3136/23491 (13%)]\tLoss: 1.102776\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:31 | INFO | Rank 0 | Train Epoch: 2 [3168/23491 (13%)]\tLoss: 1.018479\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:31 | INFO | Rank 0 | Train Epoch: 2 [3200/23491 (14%)]\tLoss: 1.164547\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:32 | INFO | Rank 0 | Train Epoch: 2 [3232/23491 (14%)]\tLoss: 0.933506\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:32 | INFO | Rank 0 | Train Epoch: 2 [3264/23491 (14%)]\tLoss: 1.247853\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:32 | INFO | Rank 0 | Train Epoch: 2 [3296/23491 (14%)]\tLoss: 0.938631\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:32 | INFO | Rank 0 | Train Epoch: 2 [3328/23491 (14%)]\tLoss: 0.556705\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:33 | INFO | Rank 0 | Train Epoch: 2 [3360/23491 (14%)]\tLoss: 1.264991\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:33 | INFO | Rank 0 | Train Epoch: 2 [3392/23491 (14%)]\tLoss: 1.202135\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:33 | INFO | Rank 0 | Train Epoch: 2 [3424/23491 (15%)]\tLoss: 0.975652\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:34 | INFO | Rank 0 | Train Epoch: 2 [3456/23491 (15%)]\tLoss: 1.052384\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:34 | INFO | Rank 0 | Train Epoch: 2 [3488/23491 (15%)]\tLoss: 1.183124\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:34 | INFO | Rank 0 | Train Epoch: 2 [3520/23491 (15%)]\tLoss: 1.007626\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:34 | INFO | Rank 0 | Train Epoch: 2 [3552/23491 (15%)]\tLoss: 0.918683\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:35 | INFO | Rank 0 | Train Epoch: 2 [3584/23491 (15%)]\tLoss: 0.886971\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:35 | INFO | Rank 0 | Train Epoch: 2 [3616/23491 (15%)]\tLoss: 1.295130\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:35 | INFO | Rank 0 | Train Epoch: 2 [3648/23491 (16%)]\tLoss: 1.102268\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:35 | INFO | Rank 0 | Train Epoch: 2 [3680/23491 (16%)]\tLoss: 1.041313\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:36 | INFO | Rank 0 | Train Epoch: 2 [3712/23491 (16%)]\tLoss: 1.393754\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:36 | INFO | Rank 0 | Train Epoch: 2 [3744/23491 (16%)]\tLoss: 0.815140\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:36 | INFO | Rank 0 | Train Epoch: 2 [3776/23491 (16%)]\tLoss: 1.220225\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:36 | INFO | Rank 0 | Train Epoch: 2 [3808/23491 (16%)]\tLoss: 0.656234\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:37 | INFO | Rank 0 | Train Epoch: 2 [3840/23491 (16%)]\tLoss: 1.260385\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:37 | INFO | Rank 0 | Train Epoch: 2 [3872/23491 (16%)]\tLoss: 1.466171\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:37 | INFO | Rank 0 | Train Epoch: 2 [3904/23491 (17%)]\tLoss: 1.188284\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:38 | INFO | Rank 0 | Train Epoch: 2 [3936/23491 (17%)]\tLoss: 1.084250\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:38 | INFO | Rank 0 | Train Epoch: 2 [3968/23491 (17%)]\tLoss: 1.241585\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:38 | INFO | Rank 0 | Train Epoch: 2 [4000/23491 (17%)]\tLoss: 1.290805\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:38 | INFO | Rank 0 | Train Epoch: 2 [4032/23491 (17%)]\tLoss: 0.989848\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:39 | INFO | Rank 0 | Train Epoch: 2 [4064/23491 (17%)]\tLoss: 1.325188\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:39 | INFO | Rank 0 | Train Epoch: 2 [4096/23491 (17%)]\tLoss: 1.213738\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:39 | INFO | Rank 0 | Train Epoch: 2 [4128/23491 (18%)]\tLoss: 1.178410\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:39 | INFO | Rank 0 | Train Epoch: 2 [4160/23491 (18%)]\tLoss: 1.762702\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:40 | INFO | Rank 0 | Train Epoch: 2 [4192/23491 (18%)]\tLoss: 1.010029\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:40 | INFO | Rank 0 | Train Epoch: 2 [4224/23491 (18%)]\tLoss: 1.747557\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:40 | INFO | Rank 0 | Train Epoch: 2 [4256/23491 (18%)]\tLoss: 1.201420\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:40 | INFO | Rank 0 | Train Epoch: 2 [4288/23491 (18%)]\tLoss: 1.059652\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:41 | INFO | Rank 0 | Train Epoch: 2 [4320/23491 (18%)]\tLoss: 1.174632\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:41 | INFO | Rank 0 | Train Epoch: 2 [4352/23491 (19%)]\tLoss: 1.261678\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:41 | INFO | Rank 0 | Train Epoch: 2 [4384/23491 (19%)]\tLoss: 1.326265\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:41 | INFO | Rank 0 | Train Epoch: 2 [4416/23491 (19%)]\tLoss: 1.356725\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:42 | INFO | Rank 0 | Train Epoch: 2 [4448/23491 (19%)]\tLoss: 0.824844\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:42 | INFO | Rank 0 | Train Epoch: 2 [4480/23491 (19%)]\tLoss: 0.659293\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:42 | INFO | Rank 0 | Train Epoch: 2 [4512/23491 (19%)]\tLoss: 1.189324\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:43 | INFO | Rank 0 | Train Epoch: 2 [4544/23491 (19%)]\tLoss: 0.800957\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:43 | INFO | Rank 0 | Train Epoch: 2 [4576/23491 (19%)]\tLoss: 1.064834\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:43 | INFO | Rank 0 | Train Epoch: 2 [4608/23491 (20%)]\tLoss: 1.344006\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:43 | INFO | Rank 0 | Train Epoch: 2 [4640/23491 (20%)]\tLoss: 1.170065\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:44 | INFO | Rank 0 | Train Epoch: 2 [4672/23491 (20%)]\tLoss: 0.698637\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:44 | INFO | Rank 0 | Train Epoch: 2 [4704/23491 (20%)]\tLoss: 0.738995\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:44 | INFO | Rank 0 | Train Epoch: 2 [4736/23491 (20%)]\tLoss: 0.934204\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:44 | INFO | Rank 0 | Train Epoch: 2 [4768/23491 (20%)]\tLoss: 1.308765\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:45 | INFO | Rank 0 | Train Epoch: 2 [4800/23491 (20%)]\tLoss: 1.381965\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:45 | INFO | Rank 0 | Train Epoch: 2 [4832/23491 (21%)]\tLoss: 1.015523\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:45 | INFO | Rank 0 | Train Epoch: 2 [4864/23491 (21%)]\tLoss: 0.906203\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.568\n",
      "2022-11-08,05:32:45 | INFO | Rank 0 | Train Epoch: 2 [4896/23491 (21%)]\tLoss: 1.030763\tData (t) 0.052\tBatch (t) 0.267\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:46 | INFO | Rank 0 | Train Epoch: 2 [4928/23491 (21%)]\tLoss: 1.280073\tData (t) 0.055\tBatch (t) 0.271\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:46 | INFO | Rank 0 | Train Epoch: 2 [4960/23491 (21%)]\tLoss: 1.040622\tData (t) 0.056\tBatch (t) 0.271\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:46 | INFO | Rank 0 | Train Epoch: 2 [4992/23491 (21%)]\tLoss: 0.853409\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:47 | INFO | Rank 0 | Train Epoch: 2 [5024/23491 (21%)]\tLoss: 1.099487\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:47 | INFO | Rank 0 | Train Epoch: 2 [5056/23491 (22%)]\tLoss: 0.914284\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:47 | INFO | Rank 0 | Train Epoch: 2 [5088/23491 (22%)]\tLoss: 0.787388\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:47 | INFO | Rank 0 | Train Epoch: 2 [5120/23491 (22%)]\tLoss: 1.197837\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:48 | INFO | Rank 0 | Train Epoch: 2 [5152/23491 (22%)]\tLoss: 0.929368\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:48 | INFO | Rank 0 | Train Epoch: 2 [5184/23491 (22%)]\tLoss: 1.115689\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:48 | INFO | Rank 0 | Train Epoch: 2 [5216/23491 (22%)]\tLoss: 1.305453\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:48 | INFO | Rank 0 | Train Epoch: 2 [5248/23491 (22%)]\tLoss: 0.706969\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:49 | INFO | Rank 0 | Train Epoch: 2 [5280/23491 (22%)]\tLoss: 1.180622\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:49 | INFO | Rank 0 | Train Epoch: 2 [5312/23491 (23%)]\tLoss: 0.945696\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:49 | INFO | Rank 0 | Train Epoch: 2 [5344/23491 (23%)]\tLoss: 0.621984\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:49 | INFO | Rank 0 | Train Epoch: 2 [5376/23491 (23%)]\tLoss: 0.854240\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:50 | INFO | Rank 0 | Train Epoch: 2 [5408/23491 (23%)]\tLoss: 1.202508\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:50 | INFO | Rank 0 | Train Epoch: 2 [5440/23491 (23%)]\tLoss: 1.494767\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:50 | INFO | Rank 0 | Train Epoch: 2 [5472/23491 (23%)]\tLoss: 1.222693\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:51 | INFO | Rank 0 | Train Epoch: 2 [5504/23491 (23%)]\tLoss: 1.336397\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:51 | INFO | Rank 0 | Train Epoch: 2 [5536/23491 (24%)]\tLoss: 1.025577\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:51 | INFO | Rank 0 | Train Epoch: 2 [5568/23491 (24%)]\tLoss: 1.442784\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:51 | INFO | Rank 0 | Train Epoch: 2 [5600/23491 (24%)]\tLoss: 0.963292\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:52 | INFO | Rank 0 | Train Epoch: 2 [5632/23491 (24%)]\tLoss: 0.907820\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:52 | INFO | Rank 0 | Train Epoch: 2 [5664/23491 (24%)]\tLoss: 1.669033\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:52 | INFO | Rank 0 | Train Epoch: 2 [5696/23491 (24%)]\tLoss: 1.256691\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:52 | INFO | Rank 0 | Train Epoch: 2 [5728/23491 (24%)]\tLoss: 1.122266\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:53 | INFO | Rank 0 | Train Epoch: 2 [5760/23491 (25%)]\tLoss: 1.107803\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:53 | INFO | Rank 0 | Train Epoch: 2 [5792/23491 (25%)]\tLoss: 1.370618\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:53 | INFO | Rank 0 | Train Epoch: 2 [5824/23491 (25%)]\tLoss: 1.074381\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:53 | INFO | Rank 0 | Train Epoch: 2 [5856/23491 (25%)]\tLoss: 1.049598\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:54 | INFO | Rank 0 | Train Epoch: 2 [5888/23491 (25%)]\tLoss: 0.996088\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:54 | INFO | Rank 0 | Train Epoch: 2 [5920/23491 (25%)]\tLoss: 0.974502\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:54 | INFO | Rank 0 | Train Epoch: 2 [5952/23491 (25%)]\tLoss: 1.086359\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:55 | INFO | Rank 0 | Train Epoch: 2 [5984/23491 (25%)]\tLoss: 1.194281\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000075\tlogit_scale 4.567\n",
      "2022-11-08,05:32:55 | INFO | Rank 0 | Train Epoch: 2 [6016/23491 (26%)]\tLoss: 1.131109\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000074\tlogit_scale 4.567\n",
      "2022-11-08,05:32:55 | INFO | Rank 0 | Train Epoch: 2 [6048/23491 (26%)]\tLoss: 1.167722\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.567\n",
      "2022-11-08,05:32:55 | INFO | Rank 0 | Train Epoch: 2 [6080/23491 (26%)]\tLoss: 1.144259\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.567\n",
      "2022-11-08,05:32:56 | INFO | Rank 0 | Train Epoch: 2 [6112/23491 (26%)]\tLoss: 1.314715\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.567\n",
      "2022-11-08,05:32:56 | INFO | Rank 0 | Train Epoch: 2 [6144/23491 (26%)]\tLoss: 1.233140\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000074\tlogit_scale 4.567\n",
      "2022-11-08,05:32:56 | INFO | Rank 0 | Train Epoch: 2 [6176/23491 (26%)]\tLoss: 1.136844\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.567\n",
      "2022-11-08,05:32:56 | INFO | Rank 0 | Train Epoch: 2 [6208/23491 (26%)]\tLoss: 1.503430\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.567\n",
      "2022-11-08,05:32:57 | INFO | Rank 0 | Train Epoch: 2 [6240/23491 (27%)]\tLoss: 1.709594\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.567\n",
      "2022-11-08,05:32:57 | INFO | Rank 0 | Train Epoch: 2 [6272/23491 (27%)]\tLoss: 1.144474\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.567\n",
      "2022-11-08,05:32:57 | INFO | Rank 0 | Train Epoch: 2 [6304/23491 (27%)]\tLoss: 1.159880\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:32:57 | INFO | Rank 0 | Train Epoch: 2 [6336/23491 (27%)]\tLoss: 1.222369\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:32:58 | INFO | Rank 0 | Train Epoch: 2 [6368/23491 (27%)]\tLoss: 0.803453\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:32:58 | INFO | Rank 0 | Train Epoch: 2 [6400/23491 (27%)]\tLoss: 1.366123\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:32:58 | INFO | Rank 0 | Train Epoch: 2 [6432/23491 (27%)]\tLoss: 1.148252\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:32:59 | INFO | Rank 0 | Train Epoch: 2 [6464/23491 (28%)]\tLoss: 1.070808\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:32:59 | INFO | Rank 0 | Train Epoch: 2 [6496/23491 (28%)]\tLoss: 1.118036\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:32:59 | INFO | Rank 0 | Train Epoch: 2 [6528/23491 (28%)]\tLoss: 0.604903\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:32:59 | INFO | Rank 0 | Train Epoch: 2 [6560/23491 (28%)]\tLoss: 0.975348\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:00 | INFO | Rank 0 | Train Epoch: 2 [6592/23491 (28%)]\tLoss: 1.604124\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:00 | INFO | Rank 0 | Train Epoch: 2 [6624/23491 (28%)]\tLoss: 1.385084\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:00 | INFO | Rank 0 | Train Epoch: 2 [6656/23491 (28%)]\tLoss: 0.754433\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:00 | INFO | Rank 0 | Train Epoch: 2 [6688/23491 (28%)]\tLoss: 1.398690\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:01 | INFO | Rank 0 | Train Epoch: 2 [6720/23491 (29%)]\tLoss: 1.063788\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:01 | INFO | Rank 0 | Train Epoch: 2 [6752/23491 (29%)]\tLoss: 1.602501\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:01 | INFO | Rank 0 | Train Epoch: 2 [6784/23491 (29%)]\tLoss: 1.233456\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:01 | INFO | Rank 0 | Train Epoch: 2 [6816/23491 (29%)]\tLoss: 1.050467\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:02 | INFO | Rank 0 | Train Epoch: 2 [6848/23491 (29%)]\tLoss: 1.599808\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:02 | INFO | Rank 0 | Train Epoch: 2 [6880/23491 (29%)]\tLoss: 0.686287\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:02 | INFO | Rank 0 | Train Epoch: 2 [6912/23491 (29%)]\tLoss: 0.812886\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:03 | INFO | Rank 0 | Train Epoch: 2 [6944/23491 (30%)]\tLoss: 1.114710\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:03 | INFO | Rank 0 | Train Epoch: 2 [6976/23491 (30%)]\tLoss: 0.896079\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:03 | INFO | Rank 0 | Train Epoch: 2 [7008/23491 (30%)]\tLoss: 1.021780\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:03 | INFO | Rank 0 | Train Epoch: 2 [7040/23491 (30%)]\tLoss: 1.321027\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:04 | INFO | Rank 0 | Train Epoch: 2 [7072/23491 (30%)]\tLoss: 0.733135\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:04 | INFO | Rank 0 | Train Epoch: 2 [7104/23491 (30%)]\tLoss: 1.345037\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:04 | INFO | Rank 0 | Train Epoch: 2 [7136/23491 (30%)]\tLoss: 0.937871\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:04 | INFO | Rank 0 | Train Epoch: 2 [7168/23491 (31%)]\tLoss: 0.867866\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:05 | INFO | Rank 0 | Train Epoch: 2 [7200/23491 (31%)]\tLoss: 1.014797\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:05 | INFO | Rank 0 | Train Epoch: 2 [7232/23491 (31%)]\tLoss: 1.020961\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:05 | INFO | Rank 0 | Train Epoch: 2 [7264/23491 (31%)]\tLoss: 0.920142\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:05 | INFO | Rank 0 | Train Epoch: 2 [7296/23491 (31%)]\tLoss: 1.111116\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:06 | INFO | Rank 0 | Train Epoch: 2 [7328/23491 (31%)]\tLoss: 0.628612\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:06 | INFO | Rank 0 | Train Epoch: 2 [7360/23491 (31%)]\tLoss: 1.082964\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:06 | INFO | Rank 0 | Train Epoch: 2 [7392/23491 (31%)]\tLoss: 1.053572\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:06 | INFO | Rank 0 | Train Epoch: 2 [7424/23491 (32%)]\tLoss: 1.419220\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:07 | INFO | Rank 0 | Train Epoch: 2 [7456/23491 (32%)]\tLoss: 1.089676\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:07 | INFO | Rank 0 | Train Epoch: 2 [7488/23491 (32%)]\tLoss: 1.404238\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:07 | INFO | Rank 0 | Train Epoch: 2 [7520/23491 (32%)]\tLoss: 1.070074\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:08 | INFO | Rank 0 | Train Epoch: 2 [7552/23491 (32%)]\tLoss: 0.984651\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:08 | INFO | Rank 0 | Train Epoch: 2 [7584/23491 (32%)]\tLoss: 0.996694\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:08 | INFO | Rank 0 | Train Epoch: 2 [7616/23491 (32%)]\tLoss: 1.325610\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:08 | INFO | Rank 0 | Train Epoch: 2 [7648/23491 (33%)]\tLoss: 0.808108\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:09 | INFO | Rank 0 | Train Epoch: 2 [7680/23491 (33%)]\tLoss: 0.780724\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:09 | INFO | Rank 0 | Train Epoch: 2 [7712/23491 (33%)]\tLoss: 0.704129\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:09 | INFO | Rank 0 | Train Epoch: 2 [7744/23491 (33%)]\tLoss: 1.346078\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:09 | INFO | Rank 0 | Train Epoch: 2 [7776/23491 (33%)]\tLoss: 1.573411\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:10 | INFO | Rank 0 | Train Epoch: 2 [7808/23491 (33%)]\tLoss: 0.762670\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:10 | INFO | Rank 0 | Train Epoch: 2 [7840/23491 (33%)]\tLoss: 1.172836\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:10 | INFO | Rank 0 | Train Epoch: 2 [7872/23491 (34%)]\tLoss: 1.604069\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:10 | INFO | Rank 0 | Train Epoch: 2 [7904/23491 (34%)]\tLoss: 1.000281\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:11 | INFO | Rank 0 | Train Epoch: 2 [7936/23491 (34%)]\tLoss: 1.007280\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:11 | INFO | Rank 0 | Train Epoch: 2 [7968/23491 (34%)]\tLoss: 1.458556\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:11 | INFO | Rank 0 | Train Epoch: 2 [8000/23491 (34%)]\tLoss: 1.263496\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:12 | INFO | Rank 0 | Train Epoch: 2 [8032/23491 (34%)]\tLoss: 1.768173\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:12 | INFO | Rank 0 | Train Epoch: 2 [8064/23491 (34%)]\tLoss: 1.075788\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:12 | INFO | Rank 0 | Train Epoch: 2 [8096/23491 (34%)]\tLoss: 1.046891\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:12 | INFO | Rank 0 | Train Epoch: 2 [8128/23491 (35%)]\tLoss: 0.842366\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:13 | INFO | Rank 0 | Train Epoch: 2 [8160/23491 (35%)]\tLoss: 1.042181\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:13 | INFO | Rank 0 | Train Epoch: 2 [8192/23491 (35%)]\tLoss: 1.509254\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:13 | INFO | Rank 0 | Train Epoch: 2 [8224/23491 (35%)]\tLoss: 0.983294\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:13 | INFO | Rank 0 | Train Epoch: 2 [8256/23491 (35%)]\tLoss: 1.135122\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:14 | INFO | Rank 0 | Train Epoch: 2 [8288/23491 (35%)]\tLoss: 0.737187\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:14 | INFO | Rank 0 | Train Epoch: 2 [8320/23491 (35%)]\tLoss: 1.026750\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:14 | INFO | Rank 0 | Train Epoch: 2 [8352/23491 (36%)]\tLoss: 0.958839\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.566\n",
      "2022-11-08,05:33:14 | INFO | Rank 0 | Train Epoch: 2 [8384/23491 (36%)]\tLoss: 1.010498\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:15 | INFO | Rank 0 | Train Epoch: 2 [8416/23491 (36%)]\tLoss: 1.329489\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:15 | INFO | Rank 0 | Train Epoch: 2 [8448/23491 (36%)]\tLoss: 1.256095\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:15 | INFO | Rank 0 | Train Epoch: 2 [8480/23491 (36%)]\tLoss: 1.328600\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:16 | INFO | Rank 0 | Train Epoch: 2 [8512/23491 (36%)]\tLoss: 1.512921\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:16 | INFO | Rank 0 | Train Epoch: 2 [8544/23491 (36%)]\tLoss: 0.979475\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:16 | INFO | Rank 0 | Train Epoch: 2 [8576/23491 (37%)]\tLoss: 0.891221\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:16 | INFO | Rank 0 | Train Epoch: 2 [8608/23491 (37%)]\tLoss: 1.171896\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:17 | INFO | Rank 0 | Train Epoch: 2 [8640/23491 (37%)]\tLoss: 0.899593\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:17 | INFO | Rank 0 | Train Epoch: 2 [8672/23491 (37%)]\tLoss: 1.173418\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:17 | INFO | Rank 0 | Train Epoch: 2 [8704/23491 (37%)]\tLoss: 0.878248\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:17 | INFO | Rank 0 | Train Epoch: 2 [8736/23491 (37%)]\tLoss: 0.475527\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:18 | INFO | Rank 0 | Train Epoch: 2 [8768/23491 (37%)]\tLoss: 1.028194\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:18 | INFO | Rank 0 | Train Epoch: 2 [8800/23491 (37%)]\tLoss: 1.239762\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:18 | INFO | Rank 0 | Train Epoch: 2 [8832/23491 (38%)]\tLoss: 0.936548\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:18 | INFO | Rank 0 | Train Epoch: 2 [8864/23491 (38%)]\tLoss: 1.175639\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:19 | INFO | Rank 0 | Train Epoch: 2 [8896/23491 (38%)]\tLoss: 1.196073\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:19 | INFO | Rank 0 | Train Epoch: 2 [8928/23491 (38%)]\tLoss: 1.256806\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:19 | INFO | Rank 0 | Train Epoch: 2 [8960/23491 (38%)]\tLoss: 1.017087\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:20 | INFO | Rank 0 | Train Epoch: 2 [8992/23491 (38%)]\tLoss: 1.163573\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:20 | INFO | Rank 0 | Train Epoch: 2 [9024/23491 (38%)]\tLoss: 0.837653\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:20 | INFO | Rank 0 | Train Epoch: 2 [9056/23491 (39%)]\tLoss: 1.146454\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:20 | INFO | Rank 0 | Train Epoch: 2 [9088/23491 (39%)]\tLoss: 1.254382\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:21 | INFO | Rank 0 | Train Epoch: 2 [9120/23491 (39%)]\tLoss: 1.180214\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:21 | INFO | Rank 0 | Train Epoch: 2 [9152/23491 (39%)]\tLoss: 0.962507\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:21 | INFO | Rank 0 | Train Epoch: 2 [9184/23491 (39%)]\tLoss: 0.939047\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:21 | INFO | Rank 0 | Train Epoch: 2 [9216/23491 (39%)]\tLoss: 1.277347\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:22 | INFO | Rank 0 | Train Epoch: 2 [9248/23491 (39%)]\tLoss: 0.956208\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:22 | INFO | Rank 0 | Train Epoch: 2 [9280/23491 (40%)]\tLoss: 1.481686\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000074\tlogit_scale 4.565\n",
      "2022-11-08,05:33:22 | INFO | Rank 0 | Train Epoch: 2 [9312/23491 (40%)]\tLoss: 1.392945\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:22 | INFO | Rank 0 | Train Epoch: 2 [9344/23491 (40%)]\tLoss: 1.625804\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:23 | INFO | Rank 0 | Train Epoch: 2 [9376/23491 (40%)]\tLoss: 0.968711\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:23 | INFO | Rank 0 | Train Epoch: 2 [9408/23491 (40%)]\tLoss: 0.784475\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:23 | INFO | Rank 0 | Train Epoch: 2 [9440/23491 (40%)]\tLoss: 1.014450\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:24 | INFO | Rank 0 | Train Epoch: 2 [9472/23491 (40%)]\tLoss: 1.291219\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:24 | INFO | Rank 0 | Train Epoch: 2 [9504/23491 (40%)]\tLoss: 1.228004\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:24 | INFO | Rank 0 | Train Epoch: 2 [9536/23491 (41%)]\tLoss: 0.700509\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:24 | INFO | Rank 0 | Train Epoch: 2 [9568/23491 (41%)]\tLoss: 1.162530\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:25 | INFO | Rank 0 | Train Epoch: 2 [9600/23491 (41%)]\tLoss: 1.063434\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:25 | INFO | Rank 0 | Train Epoch: 2 [9632/23491 (41%)]\tLoss: 1.103876\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:25 | INFO | Rank 0 | Train Epoch: 2 [9664/23491 (41%)]\tLoss: 1.060141\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:25 | INFO | Rank 0 | Train Epoch: 2 [9696/23491 (41%)]\tLoss: 1.065144\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:26 | INFO | Rank 0 | Train Epoch: 2 [9728/23491 (41%)]\tLoss: 1.230317\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:26 | INFO | Rank 0 | Train Epoch: 2 [9760/23491 (42%)]\tLoss: 0.990978\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:26 | INFO | Rank 0 | Train Epoch: 2 [9792/23491 (42%)]\tLoss: 1.137498\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:26 | INFO | Rank 0 | Train Epoch: 2 [9824/23491 (42%)]\tLoss: 0.987171\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:27 | INFO | Rank 0 | Train Epoch: 2 [9856/23491 (42%)]\tLoss: 0.926338\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:27 | INFO | Rank 0 | Train Epoch: 2 [9888/23491 (42%)]\tLoss: 1.322611\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:27 | INFO | Rank 0 | Train Epoch: 2 [9920/23491 (42%)]\tLoss: 1.201416\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:27 | INFO | Rank 0 | Train Epoch: 2 [9952/23491 (42%)]\tLoss: 1.145199\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:28 | INFO | Rank 0 | Train Epoch: 2 [9984/23491 (43%)]\tLoss: 0.614708\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:28 | INFO | Rank 0 | Train Epoch: 2 [10016/23491 (43%)]\tLoss: 0.863496\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:28 | INFO | Rank 0 | Train Epoch: 2 [10048/23491 (43%)]\tLoss: 0.938769\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:29 | INFO | Rank 0 | Train Epoch: 2 [10080/23491 (43%)]\tLoss: 0.958259\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:29 | INFO | Rank 0 | Train Epoch: 2 [10112/23491 (43%)]\tLoss: 0.632657\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:29 | INFO | Rank 0 | Train Epoch: 2 [10144/23491 (43%)]\tLoss: 0.894158\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:29 | INFO | Rank 0 | Train Epoch: 2 [10176/23491 (43%)]\tLoss: 1.221565\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:30 | INFO | Rank 0 | Train Epoch: 2 [10208/23491 (43%)]\tLoss: 0.848551\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:30 | INFO | Rank 0 | Train Epoch: 2 [10240/23491 (44%)]\tLoss: 0.916134\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:30 | INFO | Rank 0 | Train Epoch: 2 [10272/23491 (44%)]\tLoss: 0.867745\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:30 | INFO | Rank 0 | Train Epoch: 2 [10304/23491 (44%)]\tLoss: 0.786824\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:31 | INFO | Rank 0 | Train Epoch: 2 [10336/23491 (44%)]\tLoss: 0.941835\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:31 | INFO | Rank 0 | Train Epoch: 2 [10368/23491 (44%)]\tLoss: 1.229171\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:31 | INFO | Rank 0 | Train Epoch: 2 [10400/23491 (44%)]\tLoss: 0.937424\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:31 | INFO | Rank 0 | Train Epoch: 2 [10432/23491 (44%)]\tLoss: 1.215804\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:32 | INFO | Rank 0 | Train Epoch: 2 [10464/23491 (45%)]\tLoss: 0.917520\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:32 | INFO | Rank 0 | Train Epoch: 2 [10496/23491 (45%)]\tLoss: 1.428563\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:32 | INFO | Rank 0 | Train Epoch: 2 [10528/23491 (45%)]\tLoss: 0.814995\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:33 | INFO | Rank 0 | Train Epoch: 2 [10560/23491 (45%)]\tLoss: 0.987048\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.565\n",
      "2022-11-08,05:33:33 | INFO | Rank 0 | Train Epoch: 2 [10592/23491 (45%)]\tLoss: 1.334559\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:33 | INFO | Rank 0 | Train Epoch: 2 [10624/23491 (45%)]\tLoss: 0.891140\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:33 | INFO | Rank 0 | Train Epoch: 2 [10656/23491 (45%)]\tLoss: 1.007002\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:34 | INFO | Rank 0 | Train Epoch: 2 [10688/23491 (46%)]\tLoss: 1.334813\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:34 | INFO | Rank 0 | Train Epoch: 2 [10720/23491 (46%)]\tLoss: 1.007416\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:34 | INFO | Rank 0 | Train Epoch: 2 [10752/23491 (46%)]\tLoss: 1.335306\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:34 | INFO | Rank 0 | Train Epoch: 2 [10784/23491 (46%)]\tLoss: 1.047159\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:35 | INFO | Rank 0 | Train Epoch: 2 [10816/23491 (46%)]\tLoss: 1.122459\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:35 | INFO | Rank 0 | Train Epoch: 2 [10848/23491 (46%)]\tLoss: 1.184634\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:35 | INFO | Rank 0 | Train Epoch: 2 [10880/23491 (46%)]\tLoss: 0.797837\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:35 | INFO | Rank 0 | Train Epoch: 2 [10912/23491 (46%)]\tLoss: 1.403574\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:36 | INFO | Rank 0 | Train Epoch: 2 [10944/23491 (47%)]\tLoss: 0.644768\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:36 | INFO | Rank 0 | Train Epoch: 2 [10976/23491 (47%)]\tLoss: 1.378080\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:36 | INFO | Rank 0 | Train Epoch: 2 [11008/23491 (47%)]\tLoss: 1.184236\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:37 | INFO | Rank 0 | Train Epoch: 2 [11040/23491 (47%)]\tLoss: 1.239038\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:37 | INFO | Rank 0 | Train Epoch: 2 [11072/23491 (47%)]\tLoss: 1.182576\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:37 | INFO | Rank 0 | Train Epoch: 2 [11104/23491 (47%)]\tLoss: 0.800831\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:37 | INFO | Rank 0 | Train Epoch: 2 [11136/23491 (47%)]\tLoss: 1.008816\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:38 | INFO | Rank 0 | Train Epoch: 2 [11168/23491 (48%)]\tLoss: 1.054145\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:38 | INFO | Rank 0 | Train Epoch: 2 [11200/23491 (48%)]\tLoss: 1.129362\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:38 | INFO | Rank 0 | Train Epoch: 2 [11232/23491 (48%)]\tLoss: 1.143421\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:38 | INFO | Rank 0 | Train Epoch: 2 [11264/23491 (48%)]\tLoss: 1.105691\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:39 | INFO | Rank 0 | Train Epoch: 2 [11296/23491 (48%)]\tLoss: 1.088912\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:39 | INFO | Rank 0 | Train Epoch: 2 [11328/23491 (48%)]\tLoss: 1.034966\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:39 | INFO | Rank 0 | Train Epoch: 2 [11360/23491 (48%)]\tLoss: 1.606064\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:39 | INFO | Rank 0 | Train Epoch: 2 [11392/23491 (49%)]\tLoss: 1.536017\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:40 | INFO | Rank 0 | Train Epoch: 2 [11424/23491 (49%)]\tLoss: 1.592147\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:40 | INFO | Rank 0 | Train Epoch: 2 [11456/23491 (49%)]\tLoss: 1.616771\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:40 | INFO | Rank 0 | Train Epoch: 2 [11488/23491 (49%)]\tLoss: 1.433617\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:41 | INFO | Rank 0 | Train Epoch: 2 [11520/23491 (49%)]\tLoss: 1.327469\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:41 | INFO | Rank 0 | Train Epoch: 2 [11552/23491 (49%)]\tLoss: 1.790941\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:41 | INFO | Rank 0 | Train Epoch: 2 [11584/23491 (49%)]\tLoss: 0.972021\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:41 | INFO | Rank 0 | Train Epoch: 2 [11616/23491 (49%)]\tLoss: 1.276084\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.564\n",
      "2022-11-08,05:33:42 | INFO | Rank 0 | Train Epoch: 2 [11648/23491 (50%)]\tLoss: 0.964299\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:42 | INFO | Rank 0 | Train Epoch: 2 [11680/23491 (50%)]\tLoss: 1.225238\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:42 | INFO | Rank 0 | Train Epoch: 2 [11712/23491 (50%)]\tLoss: 1.426638\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:42 | INFO | Rank 0 | Train Epoch: 2 [11744/23491 (50%)]\tLoss: 1.499770\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:43 | INFO | Rank 0 | Train Epoch: 2 [11776/23491 (50%)]\tLoss: 1.053003\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:43 | INFO | Rank 0 | Train Epoch: 2 [11808/23491 (50%)]\tLoss: 1.019578\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:43 | INFO | Rank 0 | Train Epoch: 2 [11840/23491 (50%)]\tLoss: 1.133999\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:43 | INFO | Rank 0 | Train Epoch: 2 [11872/23491 (51%)]\tLoss: 0.710648\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:44 | INFO | Rank 0 | Train Epoch: 2 [11904/23491 (51%)]\tLoss: 1.213311\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:44 | INFO | Rank 0 | Train Epoch: 2 [11936/23491 (51%)]\tLoss: 1.232661\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:44 | INFO | Rank 0 | Train Epoch: 2 [11968/23491 (51%)]\tLoss: 0.895491\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:44 | INFO | Rank 0 | Train Epoch: 2 [12000/23491 (51%)]\tLoss: 1.700287\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:45 | INFO | Rank 0 | Train Epoch: 2 [12032/23491 (51%)]\tLoss: 1.142097\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:45 | INFO | Rank 0 | Train Epoch: 2 [12064/23491 (51%)]\tLoss: 1.370416\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:45 | INFO | Rank 0 | Train Epoch: 2 [12096/23491 (51%)]\tLoss: 0.939531\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:46 | INFO | Rank 0 | Train Epoch: 2 [12128/23491 (52%)]\tLoss: 1.109713\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:46 | INFO | Rank 0 | Train Epoch: 2 [12160/23491 (52%)]\tLoss: 0.802771\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:46 | INFO | Rank 0 | Train Epoch: 2 [12192/23491 (52%)]\tLoss: 1.198372\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:46 | INFO | Rank 0 | Train Epoch: 2 [12224/23491 (52%)]\tLoss: 1.056961\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:47 | INFO | Rank 0 | Train Epoch: 2 [12256/23491 (52%)]\tLoss: 0.873061\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:47 | INFO | Rank 0 | Train Epoch: 2 [12288/23491 (52%)]\tLoss: 0.861555\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:47 | INFO | Rank 0 | Train Epoch: 2 [12320/23491 (52%)]\tLoss: 1.168732\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:47 | INFO | Rank 0 | Train Epoch: 2 [12352/23491 (53%)]\tLoss: 1.073703\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:48 | INFO | Rank 0 | Train Epoch: 2 [12384/23491 (53%)]\tLoss: 1.088047\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000073\tlogit_scale 4.563\n",
      "2022-11-08,05:33:48 | INFO | Rank 0 | Train Epoch: 2 [12416/23491 (53%)]\tLoss: 1.728552\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:48 | INFO | Rank 0 | Train Epoch: 2 [12448/23491 (53%)]\tLoss: 0.934800\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:48 | INFO | Rank 0 | Train Epoch: 2 [12480/23491 (53%)]\tLoss: 0.833037\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:49 | INFO | Rank 0 | Train Epoch: 2 [12512/23491 (53%)]\tLoss: 1.074547\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:49 | INFO | Rank 0 | Train Epoch: 2 [12544/23491 (53%)]\tLoss: 0.992678\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:49 | INFO | Rank 0 | Train Epoch: 2 [12576/23491 (54%)]\tLoss: 0.883696\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:50 | INFO | Rank 0 | Train Epoch: 2 [12608/23491 (54%)]\tLoss: 1.311476\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:50 | INFO | Rank 0 | Train Epoch: 2 [12640/23491 (54%)]\tLoss: 1.488832\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:50 | INFO | Rank 0 | Train Epoch: 2 [12672/23491 (54%)]\tLoss: 1.217532\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:50 | INFO | Rank 0 | Train Epoch: 2 [12704/23491 (54%)]\tLoss: 1.252396\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:51 | INFO | Rank 0 | Train Epoch: 2 [12736/23491 (54%)]\tLoss: 1.360492\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:51 | INFO | Rank 0 | Train Epoch: 2 [12768/23491 (54%)]\tLoss: 1.250737\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:51 | INFO | Rank 0 | Train Epoch: 2 [12800/23491 (54%)]\tLoss: 0.925170\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:51 | INFO | Rank 0 | Train Epoch: 2 [12832/23491 (55%)]\tLoss: 0.699328\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:52 | INFO | Rank 0 | Train Epoch: 2 [12864/23491 (55%)]\tLoss: 1.290345\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:52 | INFO | Rank 0 | Train Epoch: 2 [12896/23491 (55%)]\tLoss: 0.775540\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:52 | INFO | Rank 0 | Train Epoch: 2 [12928/23491 (55%)]\tLoss: 1.184448\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:52 | INFO | Rank 0 | Train Epoch: 2 [12960/23491 (55%)]\tLoss: 0.959552\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:53 | INFO | Rank 0 | Train Epoch: 2 [12992/23491 (55%)]\tLoss: 1.488055\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:53 | INFO | Rank 0 | Train Epoch: 2 [13024/23491 (55%)]\tLoss: 1.108040\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:53 | INFO | Rank 0 | Train Epoch: 2 [13056/23491 (56%)]\tLoss: 1.449081\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:54 | INFO | Rank 0 | Train Epoch: 2 [13088/23491 (56%)]\tLoss: 0.942116\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:54 | INFO | Rank 0 | Train Epoch: 2 [13120/23491 (56%)]\tLoss: 1.254710\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:54 | INFO | Rank 0 | Train Epoch: 2 [13152/23491 (56%)]\tLoss: 1.169589\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:54 | INFO | Rank 0 | Train Epoch: 2 [13184/23491 (56%)]\tLoss: 1.148523\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:55 | INFO | Rank 0 | Train Epoch: 2 [13216/23491 (56%)]\tLoss: 0.852032\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:55 | INFO | Rank 0 | Train Epoch: 2 [13248/23491 (56%)]\tLoss: 0.569726\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:55 | INFO | Rank 0 | Train Epoch: 2 [13280/23491 (57%)]\tLoss: 1.144435\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:55 | INFO | Rank 0 | Train Epoch: 2 [13312/23491 (57%)]\tLoss: 0.999743\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:56 | INFO | Rank 0 | Train Epoch: 2 [13344/23491 (57%)]\tLoss: 0.895991\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:56 | INFO | Rank 0 | Train Epoch: 2 [13376/23491 (57%)]\tLoss: 0.724116\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:56 | INFO | Rank 0 | Train Epoch: 2 [13408/23491 (57%)]\tLoss: 0.577480\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:56 | INFO | Rank 0 | Train Epoch: 2 [13440/23491 (57%)]\tLoss: 1.267874\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:57 | INFO | Rank 0 | Train Epoch: 2 [13472/23491 (57%)]\tLoss: 0.760217\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:57 | INFO | Rank 0 | Train Epoch: 2 [13504/23491 (57%)]\tLoss: 1.013209\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:57 | INFO | Rank 0 | Train Epoch: 2 [13536/23491 (58%)]\tLoss: 1.479995\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:57 | INFO | Rank 0 | Train Epoch: 2 [13568/23491 (58%)]\tLoss: 0.691475\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:58 | INFO | Rank 0 | Train Epoch: 2 [13600/23491 (58%)]\tLoss: 0.809597\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:58 | INFO | Rank 0 | Train Epoch: 2 [13632/23491 (58%)]\tLoss: 1.048991\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:58 | INFO | Rank 0 | Train Epoch: 2 [13664/23491 (58%)]\tLoss: 0.760587\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:59 | INFO | Rank 0 | Train Epoch: 2 [13696/23491 (58%)]\tLoss: 0.767209\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:59 | INFO | Rank 0 | Train Epoch: 2 [13728/23491 (58%)]\tLoss: 1.510575\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:59 | INFO | Rank 0 | Train Epoch: 2 [13760/23491 (59%)]\tLoss: 1.880565\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.563\n",
      "2022-11-08,05:33:59 | INFO | Rank 0 | Train Epoch: 2 [13792/23491 (59%)]\tLoss: 1.293031\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:00 | INFO | Rank 0 | Train Epoch: 2 [13824/23491 (59%)]\tLoss: 0.671985\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:00 | INFO | Rank 0 | Train Epoch: 2 [13856/23491 (59%)]\tLoss: 0.930847\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:00 | INFO | Rank 0 | Train Epoch: 2 [13888/23491 (59%)]\tLoss: 0.958660\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:00 | INFO | Rank 0 | Train Epoch: 2 [13920/23491 (59%)]\tLoss: 1.103917\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:01 | INFO | Rank 0 | Train Epoch: 2 [13952/23491 (59%)]\tLoss: 1.045166\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:01 | INFO | Rank 0 | Train Epoch: 2 [13984/23491 (60%)]\tLoss: 0.927064\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:01 | INFO | Rank 0 | Train Epoch: 2 [14016/23491 (60%)]\tLoss: 1.074158\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:01 | INFO | Rank 0 | Train Epoch: 2 [14048/23491 (60%)]\tLoss: 1.019862\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:02 | INFO | Rank 0 | Train Epoch: 2 [14080/23491 (60%)]\tLoss: 0.829011\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:02 | INFO | Rank 0 | Train Epoch: 2 [14112/23491 (60%)]\tLoss: 1.297138\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:02 | INFO | Rank 0 | Train Epoch: 2 [14144/23491 (60%)]\tLoss: 0.903971\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:03 | INFO | Rank 0 | Train Epoch: 2 [14176/23491 (60%)]\tLoss: 0.930746\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:03 | INFO | Rank 0 | Train Epoch: 2 [14208/23491 (60%)]\tLoss: 0.643043\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:03 | INFO | Rank 0 | Train Epoch: 2 [14240/23491 (61%)]\tLoss: 0.912505\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:03 | INFO | Rank 0 | Train Epoch: 2 [14272/23491 (61%)]\tLoss: 1.285270\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:04 | INFO | Rank 0 | Train Epoch: 2 [14304/23491 (61%)]\tLoss: 1.453241\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:04 | INFO | Rank 0 | Train Epoch: 2 [14336/23491 (61%)]\tLoss: 1.431012\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:04 | INFO | Rank 0 | Train Epoch: 2 [14368/23491 (61%)]\tLoss: 1.189766\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:04 | INFO | Rank 0 | Train Epoch: 2 [14400/23491 (61%)]\tLoss: 1.106122\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:05 | INFO | Rank 0 | Train Epoch: 2 [14432/23491 (61%)]\tLoss: 0.711214\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:05 | INFO | Rank 0 | Train Epoch: 2 [14464/23491 (62%)]\tLoss: 0.855422\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:05 | INFO | Rank 0 | Train Epoch: 2 [14496/23491 (62%)]\tLoss: 0.698022\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:05 | INFO | Rank 0 | Train Epoch: 2 [14528/23491 (62%)]\tLoss: 0.995263\tData (t) 0.052\tBatch (t) 0.264\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:06 | INFO | Rank 0 | Train Epoch: 2 [14560/23491 (62%)]\tLoss: 0.977150\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:06 | INFO | Rank 0 | Train Epoch: 2 [14592/23491 (62%)]\tLoss: 0.743430\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:06 | INFO | Rank 0 | Train Epoch: 2 [14624/23491 (62%)]\tLoss: 0.807412\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:07 | INFO | Rank 0 | Train Epoch: 2 [14656/23491 (62%)]\tLoss: 0.926861\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:07 | INFO | Rank 0 | Train Epoch: 2 [14688/23491 (63%)]\tLoss: 0.946382\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:07 | INFO | Rank 0 | Train Epoch: 2 [14720/23491 (63%)]\tLoss: 1.232095\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:07 | INFO | Rank 0 | Train Epoch: 2 [14752/23491 (63%)]\tLoss: 0.840043\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:08 | INFO | Rank 0 | Train Epoch: 2 [14784/23491 (63%)]\tLoss: 1.347357\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:08 | INFO | Rank 0 | Train Epoch: 2 [14816/23491 (63%)]\tLoss: 0.795071\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:08 | INFO | Rank 0 | Train Epoch: 2 [14848/23491 (63%)]\tLoss: 0.973576\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:08 | INFO | Rank 0 | Train Epoch: 2 [14880/23491 (63%)]\tLoss: 0.973522\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:09 | INFO | Rank 0 | Train Epoch: 2 [14912/23491 (63%)]\tLoss: 0.778536\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:09 | INFO | Rank 0 | Train Epoch: 2 [14944/23491 (64%)]\tLoss: 1.370998\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:09 | INFO | Rank 0 | Train Epoch: 2 [14976/23491 (64%)]\tLoss: 0.982979\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:09 | INFO | Rank 0 | Train Epoch: 2 [15008/23491 (64%)]\tLoss: 1.228921\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:10 | INFO | Rank 0 | Train Epoch: 2 [15040/23491 (64%)]\tLoss: 1.088932\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:10 | INFO | Rank 0 | Train Epoch: 2 [15072/23491 (64%)]\tLoss: 1.249367\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:10 | INFO | Rank 0 | Train Epoch: 2 [15104/23491 (64%)]\tLoss: 0.962121\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:11 | INFO | Rank 0 | Train Epoch: 2 [15136/23491 (64%)]\tLoss: 1.080317\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:11 | INFO | Rank 0 | Train Epoch: 2 [15168/23491 (65%)]\tLoss: 1.079144\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:11 | INFO | Rank 0 | Train Epoch: 2 [15200/23491 (65%)]\tLoss: 0.860582\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:11 | INFO | Rank 0 | Train Epoch: 2 [15232/23491 (65%)]\tLoss: 1.141547\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:12 | INFO | Rank 0 | Train Epoch: 2 [15264/23491 (65%)]\tLoss: 0.872713\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000072\tlogit_scale 4.562\n",
      "2022-11-08,05:34:12 | INFO | Rank 0 | Train Epoch: 2 [15296/23491 (65%)]\tLoss: 1.214915\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.562\n",
      "2022-11-08,05:34:12 | INFO | Rank 0 | Train Epoch: 2 [15328/23491 (65%)]\tLoss: 1.147177\tData (t) 0.053\tBatch (t) 0.282\tLR: 0.000071\tlogit_scale 4.562\n",
      "2022-11-08,05:34:12 | INFO | Rank 0 | Train Epoch: 2 [15360/23491 (65%)]\tLoss: 1.151695\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.562\n",
      "2022-11-08,05:34:13 | INFO | Rank 0 | Train Epoch: 2 [15392/23491 (66%)]\tLoss: 0.797335\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.562\n",
      "2022-11-08,05:34:13 | INFO | Rank 0 | Train Epoch: 2 [15424/23491 (66%)]\tLoss: 1.228012\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.562\n",
      "2022-11-08,05:34:13 | INFO | Rank 0 | Train Epoch: 2 [15456/23491 (66%)]\tLoss: 0.629602\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.562\n",
      "2022-11-08,05:34:13 | INFO | Rank 0 | Train Epoch: 2 [15488/23491 (66%)]\tLoss: 1.298629\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.562\n",
      "2022-11-08,05:34:14 | INFO | Rank 0 | Train Epoch: 2 [15520/23491 (66%)]\tLoss: 0.957060\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.562\n",
      "2022-11-08,05:34:14 | INFO | Rank 0 | Train Epoch: 2 [15552/23491 (66%)]\tLoss: 1.212646\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.562\n",
      "2022-11-08,05:34:14 | INFO | Rank 0 | Train Epoch: 2 [15584/23491 (66%)]\tLoss: 0.911838\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.562\n",
      "2022-11-08,05:34:15 | INFO | Rank 0 | Train Epoch: 2 [15616/23491 (66%)]\tLoss: 1.394113\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.562\n",
      "2022-11-08,05:34:15 | INFO | Rank 0 | Train Epoch: 2 [15648/23491 (67%)]\tLoss: 0.922419\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.562\n",
      "2022-11-08,05:34:15 | INFO | Rank 0 | Train Epoch: 2 [15680/23491 (67%)]\tLoss: 0.975116\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.562\n",
      "2022-11-08,05:34:15 | INFO | Rank 0 | Train Epoch: 2 [15712/23491 (67%)]\tLoss: 0.913623\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.562\n",
      "2022-11-08,05:34:16 | INFO | Rank 0 | Train Epoch: 2 [15744/23491 (67%)]\tLoss: 1.211964\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.562\n",
      "2022-11-08,05:34:16 | INFO | Rank 0 | Train Epoch: 2 [15776/23491 (67%)]\tLoss: 1.109826\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.562\n",
      "2022-11-08,05:34:16 | INFO | Rank 0 | Train Epoch: 2 [15808/23491 (67%)]\tLoss: 0.575900\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:16 | INFO | Rank 0 | Train Epoch: 2 [15840/23491 (67%)]\tLoss: 1.079286\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:17 | INFO | Rank 0 | Train Epoch: 2 [15872/23491 (68%)]\tLoss: 1.528518\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:17 | INFO | Rank 0 | Train Epoch: 2 [15904/23491 (68%)]\tLoss: 1.460964\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:17 | INFO | Rank 0 | Train Epoch: 2 [15936/23491 (68%)]\tLoss: 1.269770\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:17 | INFO | Rank 0 | Train Epoch: 2 [15968/23491 (68%)]\tLoss: 0.907141\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:18 | INFO | Rank 0 | Train Epoch: 2 [16000/23491 (68%)]\tLoss: 0.966786\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:18 | INFO | Rank 0 | Train Epoch: 2 [16032/23491 (68%)]\tLoss: 1.222229\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:18 | INFO | Rank 0 | Train Epoch: 2 [16064/23491 (68%)]\tLoss: 0.719832\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:18 | INFO | Rank 0 | Train Epoch: 2 [16096/23491 (69%)]\tLoss: 1.268688\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:19 | INFO | Rank 0 | Train Epoch: 2 [16128/23491 (69%)]\tLoss: 1.277088\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:19 | INFO | Rank 0 | Train Epoch: 2 [16160/23491 (69%)]\tLoss: 1.332783\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:19 | INFO | Rank 0 | Train Epoch: 2 [16192/23491 (69%)]\tLoss: 0.830711\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:20 | INFO | Rank 0 | Train Epoch: 2 [16224/23491 (69%)]\tLoss: 1.385064\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:20 | INFO | Rank 0 | Train Epoch: 2 [16256/23491 (69%)]\tLoss: 1.084348\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:20 | INFO | Rank 0 | Train Epoch: 2 [16288/23491 (69%)]\tLoss: 0.829678\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:20 | INFO | Rank 0 | Train Epoch: 2 [16320/23491 (69%)]\tLoss: 1.010741\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:21 | INFO | Rank 0 | Train Epoch: 2 [16352/23491 (70%)]\tLoss: 0.771775\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:21 | INFO | Rank 0 | Train Epoch: 2 [16384/23491 (70%)]\tLoss: 1.312243\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:21 | INFO | Rank 0 | Train Epoch: 2 [16416/23491 (70%)]\tLoss: 1.037588\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:21 | INFO | Rank 0 | Train Epoch: 2 [16448/23491 (70%)]\tLoss: 1.009951\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:22 | INFO | Rank 0 | Train Epoch: 2 [16480/23491 (70%)]\tLoss: 1.023070\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:22 | INFO | Rank 0 | Train Epoch: 2 [16512/23491 (70%)]\tLoss: 0.925534\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:22 | INFO | Rank 0 | Train Epoch: 2 [16544/23491 (70%)]\tLoss: 1.254040\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:22 | INFO | Rank 0 | Train Epoch: 2 [16576/23491 (71%)]\tLoss: 1.053282\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:23 | INFO | Rank 0 | Train Epoch: 2 [16608/23491 (71%)]\tLoss: 0.782732\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:23 | INFO | Rank 0 | Train Epoch: 2 [16640/23491 (71%)]\tLoss: 1.165520\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:23 | INFO | Rank 0 | Train Epoch: 2 [16672/23491 (71%)]\tLoss: 0.609555\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:24 | INFO | Rank 0 | Train Epoch: 2 [16704/23491 (71%)]\tLoss: 1.107331\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:24 | INFO | Rank 0 | Train Epoch: 2 [16736/23491 (71%)]\tLoss: 1.356103\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:24 | INFO | Rank 0 | Train Epoch: 2 [16768/23491 (71%)]\tLoss: 1.051464\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:24 | INFO | Rank 0 | Train Epoch: 2 [16800/23491 (72%)]\tLoss: 0.787337\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:25 | INFO | Rank 0 | Train Epoch: 2 [16832/23491 (72%)]\tLoss: 1.228757\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:25 | INFO | Rank 0 | Train Epoch: 2 [16864/23491 (72%)]\tLoss: 0.943344\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:25 | INFO | Rank 0 | Train Epoch: 2 [16896/23491 (72%)]\tLoss: 1.275390\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:25 | INFO | Rank 0 | Train Epoch: 2 [16928/23491 (72%)]\tLoss: 1.359389\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:26 | INFO | Rank 0 | Train Epoch: 2 [16960/23491 (72%)]\tLoss: 1.238699\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:26 | INFO | Rank 0 | Train Epoch: 2 [16992/23491 (72%)]\tLoss: 0.916278\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:26 | INFO | Rank 0 | Train Epoch: 2 [17024/23491 (72%)]\tLoss: 0.831984\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:26 | INFO | Rank 0 | Train Epoch: 2 [17056/23491 (73%)]\tLoss: 0.648285\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:27 | INFO | Rank 0 | Train Epoch: 2 [17088/23491 (73%)]\tLoss: 0.804631\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:27 | INFO | Rank 0 | Train Epoch: 2 [17120/23491 (73%)]\tLoss: 1.548454\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:27 | INFO | Rank 0 | Train Epoch: 2 [17152/23491 (73%)]\tLoss: 1.187779\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:28 | INFO | Rank 0 | Train Epoch: 2 [17184/23491 (73%)]\tLoss: 1.224248\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:28 | INFO | Rank 0 | Train Epoch: 2 [17216/23491 (73%)]\tLoss: 1.263510\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:28 | INFO | Rank 0 | Train Epoch: 2 [17248/23491 (73%)]\tLoss: 1.338095\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:28 | INFO | Rank 0 | Train Epoch: 2 [17280/23491 (74%)]\tLoss: 1.320932\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:29 | INFO | Rank 0 | Train Epoch: 2 [17312/23491 (74%)]\tLoss: 1.165854\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:29 | INFO | Rank 0 | Train Epoch: 2 [17344/23491 (74%)]\tLoss: 0.899388\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:29 | INFO | Rank 0 | Train Epoch: 2 [17376/23491 (74%)]\tLoss: 1.087688\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.561\n",
      "2022-11-08,05:34:29 | INFO | Rank 0 | Train Epoch: 2 [17408/23491 (74%)]\tLoss: 1.067569\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:30 | INFO | Rank 0 | Train Epoch: 2 [17440/23491 (74%)]\tLoss: 1.164857\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:30 | INFO | Rank 0 | Train Epoch: 2 [17472/23491 (74%)]\tLoss: 0.880230\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:30 | INFO | Rank 0 | Train Epoch: 2 [17504/23491 (75%)]\tLoss: 1.123904\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:30 | INFO | Rank 0 | Train Epoch: 2 [17536/23491 (75%)]\tLoss: 0.477282\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:31 | INFO | Rank 0 | Train Epoch: 2 [17568/23491 (75%)]\tLoss: 1.335610\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:31 | INFO | Rank 0 | Train Epoch: 2 [17600/23491 (75%)]\tLoss: 0.913139\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:31 | INFO | Rank 0 | Train Epoch: 2 [17632/23491 (75%)]\tLoss: 1.057983\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:32 | INFO | Rank 0 | Train Epoch: 2 [17664/23491 (75%)]\tLoss: 1.141959\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:32 | INFO | Rank 0 | Train Epoch: 2 [17696/23491 (75%)]\tLoss: 0.829631\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:32 | INFO | Rank 0 | Train Epoch: 2 [17728/23491 (75%)]\tLoss: 0.929997\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:32 | INFO | Rank 0 | Train Epoch: 2 [17760/23491 (76%)]\tLoss: 1.792060\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:33 | INFO | Rank 0 | Train Epoch: 2 [17792/23491 (76%)]\tLoss: 0.966007\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:33 | INFO | Rank 0 | Train Epoch: 2 [17824/23491 (76%)]\tLoss: 1.159121\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:33 | INFO | Rank 0 | Train Epoch: 2 [17856/23491 (76%)]\tLoss: 1.303704\tData (t) 0.055\tBatch (t) 0.271\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:33 | INFO | Rank 0 | Train Epoch: 2 [17888/23491 (76%)]\tLoss: 0.954589\tData (t) 0.055\tBatch (t) 0.269\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:34 | INFO | Rank 0 | Train Epoch: 2 [17920/23491 (76%)]\tLoss: 1.102338\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:34 | INFO | Rank 0 | Train Epoch: 2 [17952/23491 (76%)]\tLoss: 0.859118\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:34 | INFO | Rank 0 | Train Epoch: 2 [17984/23491 (77%)]\tLoss: 1.056913\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:34 | INFO | Rank 0 | Train Epoch: 2 [18016/23491 (77%)]\tLoss: 1.083605\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000071\tlogit_scale 4.560\n",
      "2022-11-08,05:34:35 | INFO | Rank 0 | Train Epoch: 2 [18048/23491 (77%)]\tLoss: 1.007193\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:35 | INFO | Rank 0 | Train Epoch: 2 [18080/23491 (77%)]\tLoss: 1.101142\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:35 | INFO | Rank 0 | Train Epoch: 2 [18112/23491 (77%)]\tLoss: 1.473143\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:36 | INFO | Rank 0 | Train Epoch: 2 [18144/23491 (77%)]\tLoss: 0.824325\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:36 | INFO | Rank 0 | Train Epoch: 2 [18176/23491 (77%)]\tLoss: 0.577948\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:36 | INFO | Rank 0 | Train Epoch: 2 [18208/23491 (78%)]\tLoss: 0.831817\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:36 | INFO | Rank 0 | Train Epoch: 2 [18240/23491 (78%)]\tLoss: 1.125697\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:37 | INFO | Rank 0 | Train Epoch: 2 [18272/23491 (78%)]\tLoss: 0.986905\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:37 | INFO | Rank 0 | Train Epoch: 2 [18304/23491 (78%)]\tLoss: 0.835337\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:37 | INFO | Rank 0 | Train Epoch: 2 [18336/23491 (78%)]\tLoss: 1.141432\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:37 | INFO | Rank 0 | Train Epoch: 2 [18368/23491 (78%)]\tLoss: 0.847533\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:38 | INFO | Rank 0 | Train Epoch: 2 [18400/23491 (78%)]\tLoss: 1.059397\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:38 | INFO | Rank 0 | Train Epoch: 2 [18432/23491 (78%)]\tLoss: 0.694387\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:38 | INFO | Rank 0 | Train Epoch: 2 [18464/23491 (79%)]\tLoss: 0.819227\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:38 | INFO | Rank 0 | Train Epoch: 2 [18496/23491 (79%)]\tLoss: 1.332199\tData (t) 0.053\tBatch (t) 0.268\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:39 | INFO | Rank 0 | Train Epoch: 2 [18528/23491 (79%)]\tLoss: 1.319162\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:39 | INFO | Rank 0 | Train Epoch: 2 [18560/23491 (79%)]\tLoss: 1.301404\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:39 | INFO | Rank 0 | Train Epoch: 2 [18592/23491 (79%)]\tLoss: 0.945556\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:40 | INFO | Rank 0 | Train Epoch: 2 [18624/23491 (79%)]\tLoss: 1.266631\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:40 | INFO | Rank 0 | Train Epoch: 2 [18656/23491 (79%)]\tLoss: 1.262819\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:40 | INFO | Rank 0 | Train Epoch: 2 [18688/23491 (80%)]\tLoss: 0.993942\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:40 | INFO | Rank 0 | Train Epoch: 2 [18720/23491 (80%)]\tLoss: 1.151603\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:41 | INFO | Rank 0 | Train Epoch: 2 [18752/23491 (80%)]\tLoss: 1.280249\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:41 | INFO | Rank 0 | Train Epoch: 2 [18784/23491 (80%)]\tLoss: 0.939814\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:41 | INFO | Rank 0 | Train Epoch: 2 [18816/23491 (80%)]\tLoss: 0.921815\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:41 | INFO | Rank 0 | Train Epoch: 2 [18848/23491 (80%)]\tLoss: 1.220371\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:42 | INFO | Rank 0 | Train Epoch: 2 [18880/23491 (80%)]\tLoss: 0.901263\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:42 | INFO | Rank 0 | Train Epoch: 2 [18912/23491 (81%)]\tLoss: 0.789362\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:42 | INFO | Rank 0 | Train Epoch: 2 [18944/23491 (81%)]\tLoss: 1.228379\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:42 | INFO | Rank 0 | Train Epoch: 2 [18976/23491 (81%)]\tLoss: 0.811734\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:43 | INFO | Rank 0 | Train Epoch: 2 [19008/23491 (81%)]\tLoss: 1.235854\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:43 | INFO | Rank 0 | Train Epoch: 2 [19040/23491 (81%)]\tLoss: 1.385220\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:43 | INFO | Rank 0 | Train Epoch: 2 [19072/23491 (81%)]\tLoss: 0.698602\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:43 | INFO | Rank 0 | Train Epoch: 2 [19104/23491 (81%)]\tLoss: 1.238797\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:44 | INFO | Rank 0 | Train Epoch: 2 [19136/23491 (81%)]\tLoss: 1.028546\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:44 | INFO | Rank 0 | Train Epoch: 2 [19168/23491 (82%)]\tLoss: 1.257764\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:44 | INFO | Rank 0 | Train Epoch: 2 [19200/23491 (82%)]\tLoss: 0.879235\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:45 | INFO | Rank 0 | Train Epoch: 2 [19232/23491 (82%)]\tLoss: 1.307450\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:45 | INFO | Rank 0 | Train Epoch: 2 [19264/23491 (82%)]\tLoss: 0.935427\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:45 | INFO | Rank 0 | Train Epoch: 2 [19296/23491 (82%)]\tLoss: 0.833079\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:45 | INFO | Rank 0 | Train Epoch: 2 [19328/23491 (82%)]\tLoss: 1.096817\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:46 | INFO | Rank 0 | Train Epoch: 2 [19360/23491 (82%)]\tLoss: 0.609659\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:46 | INFO | Rank 0 | Train Epoch: 2 [19392/23491 (83%)]\tLoss: 1.324588\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:46 | INFO | Rank 0 | Train Epoch: 2 [19424/23491 (83%)]\tLoss: 1.041711\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:46 | INFO | Rank 0 | Train Epoch: 2 [19456/23491 (83%)]\tLoss: 1.122176\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:47 | INFO | Rank 0 | Train Epoch: 2 [19488/23491 (83%)]\tLoss: 0.831576\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:47 | INFO | Rank 0 | Train Epoch: 2 [19520/23491 (83%)]\tLoss: 1.188950\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:47 | INFO | Rank 0 | Train Epoch: 2 [19552/23491 (83%)]\tLoss: 1.291690\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:47 | INFO | Rank 0 | Train Epoch: 2 [19584/23491 (83%)]\tLoss: 0.988070\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:48 | INFO | Rank 0 | Train Epoch: 2 [19616/23491 (84%)]\tLoss: 1.041698\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:48 | INFO | Rank 0 | Train Epoch: 2 [19648/23491 (84%)]\tLoss: 0.524506\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:48 | INFO | Rank 0 | Train Epoch: 2 [19680/23491 (84%)]\tLoss: 1.168124\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:49 | INFO | Rank 0 | Train Epoch: 2 [19712/23491 (84%)]\tLoss: 1.615137\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:49 | INFO | Rank 0 | Train Epoch: 2 [19744/23491 (84%)]\tLoss: 1.106900\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:49 | INFO | Rank 0 | Train Epoch: 2 [19776/23491 (84%)]\tLoss: 0.976148\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:49 | INFO | Rank 0 | Train Epoch: 2 [19808/23491 (84%)]\tLoss: 1.105050\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:50 | INFO | Rank 0 | Train Epoch: 2 [19840/23491 (84%)]\tLoss: 0.813583\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:50 | INFO | Rank 0 | Train Epoch: 2 [19872/23491 (85%)]\tLoss: 0.755775\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:50 | INFO | Rank 0 | Train Epoch: 2 [19904/23491 (85%)]\tLoss: 1.017501\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:50 | INFO | Rank 0 | Train Epoch: 2 [19936/23491 (85%)]\tLoss: 1.188252\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:51 | INFO | Rank 0 | Train Epoch: 2 [19968/23491 (85%)]\tLoss: 0.832865\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:51 | INFO | Rank 0 | Train Epoch: 2 [20000/23491 (85%)]\tLoss: 0.821852\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:51 | INFO | Rank 0 | Train Epoch: 2 [20032/23491 (85%)]\tLoss: 0.697582\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:51 | INFO | Rank 0 | Train Epoch: 2 [20064/23491 (85%)]\tLoss: 1.122301\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:52 | INFO | Rank 0 | Train Epoch: 2 [20096/23491 (86%)]\tLoss: 0.920549\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:52 | INFO | Rank 0 | Train Epoch: 2 [20128/23491 (86%)]\tLoss: 1.276067\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:52 | INFO | Rank 0 | Train Epoch: 2 [20160/23491 (86%)]\tLoss: 0.763473\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000070\tlogit_scale 4.560\n",
      "2022-11-08,05:34:53 | INFO | Rank 0 | Train Epoch: 2 [20192/23491 (86%)]\tLoss: 1.182575\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000070\tlogit_scale 4.559\n",
      "2022-11-08,05:34:53 | INFO | Rank 0 | Train Epoch: 2 [20224/23491 (86%)]\tLoss: 0.972175\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000070\tlogit_scale 4.559\n",
      "2022-11-08,05:34:53 | INFO | Rank 0 | Train Epoch: 2 [20256/23491 (86%)]\tLoss: 1.078240\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000070\tlogit_scale 4.559\n",
      "2022-11-08,05:34:53 | INFO | Rank 0 | Train Epoch: 2 [20288/23491 (86%)]\tLoss: 0.785386\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.559\n",
      "2022-11-08,05:34:54 | INFO | Rank 0 | Train Epoch: 2 [20320/23491 (87%)]\tLoss: 1.406764\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000070\tlogit_scale 4.559\n",
      "2022-11-08,05:34:54 | INFO | Rank 0 | Train Epoch: 2 [20352/23491 (87%)]\tLoss: 1.226468\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.559\n",
      "2022-11-08,05:34:54 | INFO | Rank 0 | Train Epoch: 2 [20384/23491 (87%)]\tLoss: 1.413555\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.559\n",
      "2022-11-08,05:34:54 | INFO | Rank 0 | Train Epoch: 2 [20416/23491 (87%)]\tLoss: 1.172109\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000070\tlogit_scale 4.559\n",
      "2022-11-08,05:34:55 | INFO | Rank 0 | Train Epoch: 2 [20448/23491 (87%)]\tLoss: 1.270851\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.559\n",
      "2022-11-08,05:34:55 | INFO | Rank 0 | Train Epoch: 2 [20480/23491 (87%)]\tLoss: 1.013988\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.559\n",
      "2022-11-08,05:34:55 | INFO | Rank 0 | Train Epoch: 2 [20512/23491 (87%)]\tLoss: 0.893790\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.559\n",
      "2022-11-08,05:34:55 | INFO | Rank 0 | Train Epoch: 2 [20544/23491 (87%)]\tLoss: 0.875201\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000070\tlogit_scale 4.559\n",
      "2022-11-08,05:34:56 | INFO | Rank 0 | Train Epoch: 2 [20576/23491 (88%)]\tLoss: 1.436240\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.559\n",
      "2022-11-08,05:34:56 | INFO | Rank 0 | Train Epoch: 2 [20608/23491 (88%)]\tLoss: 1.246724\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.559\n",
      "2022-11-08,05:34:56 | INFO | Rank 0 | Train Epoch: 2 [20640/23491 (88%)]\tLoss: 0.989348\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.559\n",
      "2022-11-08,05:34:57 | INFO | Rank 0 | Train Epoch: 2 [20672/23491 (88%)]\tLoss: 1.141580\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000070\tlogit_scale 4.559\n",
      "2022-11-08,05:34:57 | INFO | Rank 0 | Train Epoch: 2 [20704/23491 (88%)]\tLoss: 0.878643\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:34:57 | INFO | Rank 0 | Train Epoch: 2 [20736/23491 (88%)]\tLoss: 1.164755\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:34:57 | INFO | Rank 0 | Train Epoch: 2 [20768/23491 (88%)]\tLoss: 1.072255\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:34:58 | INFO | Rank 0 | Train Epoch: 2 [20800/23491 (89%)]\tLoss: 0.994611\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:34:58 | INFO | Rank 0 | Train Epoch: 2 [20832/23491 (89%)]\tLoss: 1.071138\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:34:58 | INFO | Rank 0 | Train Epoch: 2 [20864/23491 (89%)]\tLoss: 0.887443\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:34:58 | INFO | Rank 0 | Train Epoch: 2 [20896/23491 (89%)]\tLoss: 1.197354\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:34:59 | INFO | Rank 0 | Train Epoch: 2 [20928/23491 (89%)]\tLoss: 0.771650\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:34:59 | INFO | Rank 0 | Train Epoch: 2 [20960/23491 (89%)]\tLoss: 0.898227\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:34:59 | INFO | Rank 0 | Train Epoch: 2 [20992/23491 (89%)]\tLoss: 0.756683\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:34:59 | INFO | Rank 0 | Train Epoch: 2 [21024/23491 (90%)]\tLoss: 0.949546\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:00 | INFO | Rank 0 | Train Epoch: 2 [21056/23491 (90%)]\tLoss: 1.187349\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:00 | INFO | Rank 0 | Train Epoch: 2 [21088/23491 (90%)]\tLoss: 1.503484\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:00 | INFO | Rank 0 | Train Epoch: 2 [21120/23491 (90%)]\tLoss: 0.871048\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:01 | INFO | Rank 0 | Train Epoch: 2 [21152/23491 (90%)]\tLoss: 1.136095\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:01 | INFO | Rank 0 | Train Epoch: 2 [21184/23491 (90%)]\tLoss: 0.721217\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:01 | INFO | Rank 0 | Train Epoch: 2 [21216/23491 (90%)]\tLoss: 0.990484\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:01 | INFO | Rank 0 | Train Epoch: 2 [21248/23491 (90%)]\tLoss: 1.141144\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:02 | INFO | Rank 0 | Train Epoch: 2 [21280/23491 (91%)]\tLoss: 0.703307\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:02 | INFO | Rank 0 | Train Epoch: 2 [21312/23491 (91%)]\tLoss: 0.911761\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:02 | INFO | Rank 0 | Train Epoch: 2 [21344/23491 (91%)]\tLoss: 1.111458\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:02 | INFO | Rank 0 | Train Epoch: 2 [21376/23491 (91%)]\tLoss: 0.931424\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:03 | INFO | Rank 0 | Train Epoch: 2 [21408/23491 (91%)]\tLoss: 0.719340\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:03 | INFO | Rank 0 | Train Epoch: 2 [21440/23491 (91%)]\tLoss: 1.347579\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:03 | INFO | Rank 0 | Train Epoch: 2 [21472/23491 (91%)]\tLoss: 0.877167\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:03 | INFO | Rank 0 | Train Epoch: 2 [21504/23491 (92%)]\tLoss: 0.676254\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:04 | INFO | Rank 0 | Train Epoch: 2 [21536/23491 (92%)]\tLoss: 1.138107\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:04 | INFO | Rank 0 | Train Epoch: 2 [21568/23491 (92%)]\tLoss: 1.153543\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:04 | INFO | Rank 0 | Train Epoch: 2 [21600/23491 (92%)]\tLoss: 0.861091\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:05 | INFO | Rank 0 | Train Epoch: 2 [21632/23491 (92%)]\tLoss: 0.800674\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:05 | INFO | Rank 0 | Train Epoch: 2 [21664/23491 (92%)]\tLoss: 1.389209\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:05 | INFO | Rank 0 | Train Epoch: 2 [21696/23491 (92%)]\tLoss: 1.026677\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:05 | INFO | Rank 0 | Train Epoch: 2 [21728/23491 (93%)]\tLoss: 1.336699\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:06 | INFO | Rank 0 | Train Epoch: 2 [21760/23491 (93%)]\tLoss: 0.763398\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:06 | INFO | Rank 0 | Train Epoch: 2 [21792/23491 (93%)]\tLoss: 0.969203\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:06 | INFO | Rank 0 | Train Epoch: 2 [21824/23491 (93%)]\tLoss: 0.744425\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:06 | INFO | Rank 0 | Train Epoch: 2 [21856/23491 (93%)]\tLoss: 1.001869\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:07 | INFO | Rank 0 | Train Epoch: 2 [21888/23491 (93%)]\tLoss: 1.086907\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:07 | INFO | Rank 0 | Train Epoch: 2 [21920/23491 (93%)]\tLoss: 0.982526\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:07 | INFO | Rank 0 | Train Epoch: 2 [21952/23491 (93%)]\tLoss: 1.188956\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:07 | INFO | Rank 0 | Train Epoch: 2 [21984/23491 (94%)]\tLoss: 0.791505\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:08 | INFO | Rank 0 | Train Epoch: 2 [22016/23491 (94%)]\tLoss: 0.544112\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:08 | INFO | Rank 0 | Train Epoch: 2 [22048/23491 (94%)]\tLoss: 1.029109\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:08 | INFO | Rank 0 | Train Epoch: 2 [22080/23491 (94%)]\tLoss: 0.777364\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:08 | INFO | Rank 0 | Train Epoch: 2 [22112/23491 (94%)]\tLoss: 1.080665\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:09 | INFO | Rank 0 | Train Epoch: 2 [22144/23491 (94%)]\tLoss: 1.180926\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:09 | INFO | Rank 0 | Train Epoch: 2 [22176/23491 (94%)]\tLoss: 1.233824\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:09 | INFO | Rank 0 | Train Epoch: 2 [22208/23491 (95%)]\tLoss: 1.187153\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:10 | INFO | Rank 0 | Train Epoch: 2 [22240/23491 (95%)]\tLoss: 1.093277\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:10 | INFO | Rank 0 | Train Epoch: 2 [22272/23491 (95%)]\tLoss: 1.274180\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.559\n",
      "2022-11-08,05:35:10 | INFO | Rank 0 | Train Epoch: 2 [22304/23491 (95%)]\tLoss: 1.153966\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:10 | INFO | Rank 0 | Train Epoch: 2 [22336/23491 (95%)]\tLoss: 1.078808\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:11 | INFO | Rank 0 | Train Epoch: 2 [22368/23491 (95%)]\tLoss: 1.627861\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:11 | INFO | Rank 0 | Train Epoch: 2 [22400/23491 (95%)]\tLoss: 1.011092\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:11 | INFO | Rank 0 | Train Epoch: 2 [22432/23491 (96%)]\tLoss: 1.135898\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:11 | INFO | Rank 0 | Train Epoch: 2 [22464/23491 (96%)]\tLoss: 1.197421\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:12 | INFO | Rank 0 | Train Epoch: 2 [22496/23491 (96%)]\tLoss: 1.120208\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:12 | INFO | Rank 0 | Train Epoch: 2 [22528/23491 (96%)]\tLoss: 1.272095\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:12 | INFO | Rank 0 | Train Epoch: 2 [22560/23491 (96%)]\tLoss: 0.715243\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:12 | INFO | Rank 0 | Train Epoch: 2 [22592/23491 (96%)]\tLoss: 1.053285\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:13 | INFO | Rank 0 | Train Epoch: 2 [22624/23491 (96%)]\tLoss: 0.922546\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:13 | INFO | Rank 0 | Train Epoch: 2 [22656/23491 (96%)]\tLoss: 1.241340\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:13 | INFO | Rank 0 | Train Epoch: 2 [22688/23491 (97%)]\tLoss: 0.755917\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:14 | INFO | Rank 0 | Train Epoch: 2 [22720/23491 (97%)]\tLoss: 1.338725\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:14 | INFO | Rank 0 | Train Epoch: 2 [22752/23491 (97%)]\tLoss: 0.846087\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:14 | INFO | Rank 0 | Train Epoch: 2 [22784/23491 (97%)]\tLoss: 0.985375\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:14 | INFO | Rank 0 | Train Epoch: 2 [22816/23491 (97%)]\tLoss: 1.158926\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:15 | INFO | Rank 0 | Train Epoch: 2 [22848/23491 (97%)]\tLoss: 0.724486\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:15 | INFO | Rank 0 | Train Epoch: 2 [22880/23491 (97%)]\tLoss: 1.269438\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:15 | INFO | Rank 0 | Train Epoch: 2 [22912/23491 (98%)]\tLoss: 1.006551\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:15 | INFO | Rank 0 | Train Epoch: 2 [22944/23491 (98%)]\tLoss: 0.753190\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:16 | INFO | Rank 0 | Train Epoch: 2 [22976/23491 (98%)]\tLoss: 1.032525\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:16 | INFO | Rank 0 | Train Epoch: 2 [23008/23491 (98%)]\tLoss: 1.350863\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:16 | INFO | Rank 0 | Train Epoch: 2 [23040/23491 (98%)]\tLoss: 1.147029\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:16 | INFO | Rank 0 | Train Epoch: 2 [23072/23491 (98%)]\tLoss: 1.105964\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:17 | INFO | Rank 0 | Train Epoch: 2 [23104/23491 (98%)]\tLoss: 0.993338\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:17 | INFO | Rank 0 | Train Epoch: 2 [23136/23491 (99%)]\tLoss: 0.888150\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:17 | INFO | Rank 0 | Train Epoch: 2 [23168/23491 (99%)]\tLoss: 0.877813\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:18 | INFO | Rank 0 | Train Epoch: 2 [23200/23491 (99%)]\tLoss: 0.884401\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000069\tlogit_scale 4.558\n",
      "2022-11-08,05:35:18 | INFO | Rank 0 | Train Epoch: 2 [23232/23491 (99%)]\tLoss: 0.869233\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:35:18 | INFO | Rank 0 | Train Epoch: 2 [23264/23491 (99%)]\tLoss: 0.987495\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:35:18 | INFO | Rank 0 | Train Epoch: 2 [23296/23491 (99%)]\tLoss: 1.049287\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:35:19 | INFO | Rank 0 | Train Epoch: 2 [23328/23491 (99%)]\tLoss: 0.783840\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:35:19 | INFO | Rank 0 | Train Epoch: 2 [23360/23491 (99%)]\tLoss: 1.072649\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:35:19 | INFO | Rank 0 | Train Epoch: 2 [23392/23491 (100%)]\tLoss: 1.206691\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:35:19 | INFO | Rank 0 | Train Epoch: 2 [23424/23491 (100%)]\tLoss: 0.900940\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:35:20 | INFO | Rank 0 | Train Epoch: 2 [23456/23491 (100%)]\tLoss: 0.801577\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000068\tlogit_scale 4.558\n",
      "  0%|                                                   | 0/386 [00:00<?, ?it/s]2022-11-08,05:35:20 | INFO | Rank 0 | Begin to eval epoch: 3...\n",
      "100%|█████████████████████████████████████████| 386/386 [00:46<00:00,  8.36it/s]\n",
      "2022-11-08,05:36:06 | INFO | Rank 0 | Eval Epoch: 3 val_loss: 2.3732\tepoch: 3.0000\tnum_elements: 12328.0000\n",
      "2022-11-08,05:36:06 | INFO | Rank 0 | Start epoch 3\n",
      "2022-11-08,05:36:06 | INFO | Rank 0 | Train Epoch: 3 [0/23491 (0%)]\tLoss: 0.678585\tData (t) 0.034\tBatch (t) 0.248\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:06 | INFO | Rank 0 | Train Epoch: 3 [32/23491 (0%)]\tLoss: 0.587693\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:07 | INFO | Rank 0 | Train Epoch: 3 [64/23491 (0%)]\tLoss: 0.792128\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:07 | INFO | Rank 0 | Train Epoch: 3 [96/23491 (0%)]\tLoss: 0.790778\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:07 | INFO | Rank 0 | Train Epoch: 3 [128/23491 (1%)]\tLoss: 1.088814\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:07 | INFO | Rank 0 | Train Epoch: 3 [160/23491 (1%)]\tLoss: 0.691345\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:08 | INFO | Rank 0 | Train Epoch: 3 [192/23491 (1%)]\tLoss: 0.516333\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:08 | INFO | Rank 0 | Train Epoch: 3 [224/23491 (1%)]\tLoss: 0.557521\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:08 | INFO | Rank 0 | Train Epoch: 3 [256/23491 (1%)]\tLoss: 0.496692\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:09 | INFO | Rank 0 | Train Epoch: 3 [288/23491 (1%)]\tLoss: 0.615804\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:09 | INFO | Rank 0 | Train Epoch: 3 [320/23491 (1%)]\tLoss: 0.780302\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:09 | INFO | Rank 0 | Train Epoch: 3 [352/23491 (1%)]\tLoss: 0.755774\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:09 | INFO | Rank 0 | Train Epoch: 3 [384/23491 (2%)]\tLoss: 0.830300\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:10 | INFO | Rank 0 | Train Epoch: 3 [416/23491 (2%)]\tLoss: 0.719140\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:10 | INFO | Rank 0 | Train Epoch: 3 [448/23491 (2%)]\tLoss: 0.588490\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:10 | INFO | Rank 0 | Train Epoch: 3 [480/23491 (2%)]\tLoss: 0.629737\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:10 | INFO | Rank 0 | Train Epoch: 3 [512/23491 (2%)]\tLoss: 0.688046\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:11 | INFO | Rank 0 | Train Epoch: 3 [544/23491 (2%)]\tLoss: 0.836523\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:11 | INFO | Rank 0 | Train Epoch: 3 [576/23491 (2%)]\tLoss: 0.932444\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:11 | INFO | Rank 0 | Train Epoch: 3 [608/23491 (3%)]\tLoss: 0.901285\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:11 | INFO | Rank 0 | Train Epoch: 3 [640/23491 (3%)]\tLoss: 0.343314\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:12 | INFO | Rank 0 | Train Epoch: 3 [672/23491 (3%)]\tLoss: 0.620737\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:12 | INFO | Rank 0 | Train Epoch: 3 [704/23491 (3%)]\tLoss: 0.680131\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:12 | INFO | Rank 0 | Train Epoch: 3 [736/23491 (3%)]\tLoss: 0.928973\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:13 | INFO | Rank 0 | Train Epoch: 3 [768/23491 (3%)]\tLoss: 0.719002\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:13 | INFO | Rank 0 | Train Epoch: 3 [800/23491 (3%)]\tLoss: 0.467069\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:13 | INFO | Rank 0 | Train Epoch: 3 [832/23491 (4%)]\tLoss: 0.691250\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:13 | INFO | Rank 0 | Train Epoch: 3 [864/23491 (4%)]\tLoss: 0.904236\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:14 | INFO | Rank 0 | Train Epoch: 3 [896/23491 (4%)]\tLoss: 0.655852\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:14 | INFO | Rank 0 | Train Epoch: 3 [928/23491 (4%)]\tLoss: 0.614054\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:14 | INFO | Rank 0 | Train Epoch: 3 [960/23491 (4%)]\tLoss: 1.041007\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:14 | INFO | Rank 0 | Train Epoch: 3 [992/23491 (4%)]\tLoss: 0.505282\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:15 | INFO | Rank 0 | Train Epoch: 3 [1024/23491 (4%)]\tLoss: 0.615375\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:15 | INFO | Rank 0 | Train Epoch: 3 [1056/23491 (4%)]\tLoss: 0.616163\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:15 | INFO | Rank 0 | Train Epoch: 3 [1088/23491 (5%)]\tLoss: 0.449671\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:15 | INFO | Rank 0 | Train Epoch: 3 [1120/23491 (5%)]\tLoss: 0.710288\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:16 | INFO | Rank 0 | Train Epoch: 3 [1152/23491 (5%)]\tLoss: 0.989830\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:16 | INFO | Rank 0 | Train Epoch: 3 [1184/23491 (5%)]\tLoss: 0.849815\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:16 | INFO | Rank 0 | Train Epoch: 3 [1216/23491 (5%)]\tLoss: 0.855010\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:16 | INFO | Rank 0 | Train Epoch: 3 [1248/23491 (5%)]\tLoss: 0.787331\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:17 | INFO | Rank 0 | Train Epoch: 3 [1280/23491 (5%)]\tLoss: 0.804658\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:17 | INFO | Rank 0 | Train Epoch: 3 [1312/23491 (6%)]\tLoss: 0.755404\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:17 | INFO | Rank 0 | Train Epoch: 3 [1344/23491 (6%)]\tLoss: 0.950085\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:18 | INFO | Rank 0 | Train Epoch: 3 [1376/23491 (6%)]\tLoss: 0.832764\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:18 | INFO | Rank 0 | Train Epoch: 3 [1408/23491 (6%)]\tLoss: 0.649567\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:18 | INFO | Rank 0 | Train Epoch: 3 [1440/23491 (6%)]\tLoss: 0.963522\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:18 | INFO | Rank 0 | Train Epoch: 3 [1472/23491 (6%)]\tLoss: 1.231962\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:19 | INFO | Rank 0 | Train Epoch: 3 [1504/23491 (6%)]\tLoss: 0.629020\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:19 | INFO | Rank 0 | Train Epoch: 3 [1536/23491 (7%)]\tLoss: 0.682236\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:19 | INFO | Rank 0 | Train Epoch: 3 [1568/23491 (7%)]\tLoss: 0.681036\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:19 | INFO | Rank 0 | Train Epoch: 3 [1600/23491 (7%)]\tLoss: 0.803241\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:20 | INFO | Rank 0 | Train Epoch: 3 [1632/23491 (7%)]\tLoss: 0.737353\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:20 | INFO | Rank 0 | Train Epoch: 3 [1664/23491 (7%)]\tLoss: 0.856057\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:20 | INFO | Rank 0 | Train Epoch: 3 [1696/23491 (7%)]\tLoss: 0.569619\tData (t) 0.054\tBatch (t) 0.270\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:20 | INFO | Rank 0 | Train Epoch: 3 [1728/23491 (7%)]\tLoss: 0.934229\tData (t) 0.055\tBatch (t) 0.271\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:21 | INFO | Rank 0 | Train Epoch: 3 [1760/23491 (7%)]\tLoss: 0.447875\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:21 | INFO | Rank 0 | Train Epoch: 3 [1792/23491 (8%)]\tLoss: 0.685965\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:21 | INFO | Rank 0 | Train Epoch: 3 [1824/23491 (8%)]\tLoss: 0.647577\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:22 | INFO | Rank 0 | Train Epoch: 3 [1856/23491 (8%)]\tLoss: 0.505658\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:22 | INFO | Rank 0 | Train Epoch: 3 [1888/23491 (8%)]\tLoss: 0.898257\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:22 | INFO | Rank 0 | Train Epoch: 3 [1920/23491 (8%)]\tLoss: 0.634169\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:22 | INFO | Rank 0 | Train Epoch: 3 [1952/23491 (8%)]\tLoss: 0.642870\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:23 | INFO | Rank 0 | Train Epoch: 3 [1984/23491 (8%)]\tLoss: 0.646829\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:23 | INFO | Rank 0 | Train Epoch: 3 [2016/23491 (9%)]\tLoss: 0.634977\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:23 | INFO | Rank 0 | Train Epoch: 3 [2048/23491 (9%)]\tLoss: 0.940412\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:23 | INFO | Rank 0 | Train Epoch: 3 [2080/23491 (9%)]\tLoss: 0.713320\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:24 | INFO | Rank 0 | Train Epoch: 3 [2112/23491 (9%)]\tLoss: 0.884555\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:24 | INFO | Rank 0 | Train Epoch: 3 [2144/23491 (9%)]\tLoss: 1.041661\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000068\tlogit_scale 4.558\n",
      "2022-11-08,05:36:24 | INFO | Rank 0 | Train Epoch: 3 [2176/23491 (9%)]\tLoss: 0.659839\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:24 | INFO | Rank 0 | Train Epoch: 3 [2208/23491 (9%)]\tLoss: 1.029052\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:25 | INFO | Rank 0 | Train Epoch: 3 [2240/23491 (10%)]\tLoss: 0.764506\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:25 | INFO | Rank 0 | Train Epoch: 3 [2272/23491 (10%)]\tLoss: 1.056921\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:25 | INFO | Rank 0 | Train Epoch: 3 [2304/23491 (10%)]\tLoss: 0.904502\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:26 | INFO | Rank 0 | Train Epoch: 3 [2336/23491 (10%)]\tLoss: 0.933196\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:26 | INFO | Rank 0 | Train Epoch: 3 [2368/23491 (10%)]\tLoss: 0.662465\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:26 | INFO | Rank 0 | Train Epoch: 3 [2400/23491 (10%)]\tLoss: 0.804618\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:26 | INFO | Rank 0 | Train Epoch: 3 [2432/23491 (10%)]\tLoss: 0.628492\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:27 | INFO | Rank 0 | Train Epoch: 3 [2464/23491 (10%)]\tLoss: 0.652855\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:27 | INFO | Rank 0 | Train Epoch: 3 [2496/23491 (11%)]\tLoss: 0.693243\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:27 | INFO | Rank 0 | Train Epoch: 3 [2528/23491 (11%)]\tLoss: 0.572279\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:27 | INFO | Rank 0 | Train Epoch: 3 [2560/23491 (11%)]\tLoss: 0.882996\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:28 | INFO | Rank 0 | Train Epoch: 3 [2592/23491 (11%)]\tLoss: 0.546412\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:28 | INFO | Rank 0 | Train Epoch: 3 [2624/23491 (11%)]\tLoss: 1.432853\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:28 | INFO | Rank 0 | Train Epoch: 3 [2656/23491 (11%)]\tLoss: 0.762721\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:28 | INFO | Rank 0 | Train Epoch: 3 [2688/23491 (11%)]\tLoss: 0.975572\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:29 | INFO | Rank 0 | Train Epoch: 3 [2720/23491 (12%)]\tLoss: 1.211365\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:29 | INFO | Rank 0 | Train Epoch: 3 [2752/23491 (12%)]\tLoss: 0.321248\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:29 | INFO | Rank 0 | Train Epoch: 3 [2784/23491 (12%)]\tLoss: 0.927860\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:30 | INFO | Rank 0 | Train Epoch: 3 [2816/23491 (12%)]\tLoss: 0.323628\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:30 | INFO | Rank 0 | Train Epoch: 3 [2848/23491 (12%)]\tLoss: 0.710453\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:30 | INFO | Rank 0 | Train Epoch: 3 [2880/23491 (12%)]\tLoss: 0.880662\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:30 | INFO | Rank 0 | Train Epoch: 3 [2912/23491 (12%)]\tLoss: 0.855092\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:31 | INFO | Rank 0 | Train Epoch: 3 [2944/23491 (13%)]\tLoss: 0.688381\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:31 | INFO | Rank 0 | Train Epoch: 3 [2976/23491 (13%)]\tLoss: 0.931588\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:31 | INFO | Rank 0 | Train Epoch: 3 [3008/23491 (13%)]\tLoss: 0.544815\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:31 | INFO | Rank 0 | Train Epoch: 3 [3040/23491 (13%)]\tLoss: 1.080971\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:32 | INFO | Rank 0 | Train Epoch: 3 [3072/23491 (13%)]\tLoss: 1.140944\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:32 | INFO | Rank 0 | Train Epoch: 3 [3104/23491 (13%)]\tLoss: 0.854511\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:32 | INFO | Rank 0 | Train Epoch: 3 [3136/23491 (13%)]\tLoss: 1.234378\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:32 | INFO | Rank 0 | Train Epoch: 3 [3168/23491 (13%)]\tLoss: 0.725319\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:33 | INFO | Rank 0 | Train Epoch: 3 [3200/23491 (14%)]\tLoss: 0.537454\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:33 | INFO | Rank 0 | Train Epoch: 3 [3232/23491 (14%)]\tLoss: 0.599460\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:33 | INFO | Rank 0 | Train Epoch: 3 [3264/23491 (14%)]\tLoss: 0.736869\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:34 | INFO | Rank 0 | Train Epoch: 3 [3296/23491 (14%)]\tLoss: 0.576961\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:34 | INFO | Rank 0 | Train Epoch: 3 [3328/23491 (14%)]\tLoss: 0.452706\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:34 | INFO | Rank 0 | Train Epoch: 3 [3360/23491 (14%)]\tLoss: 0.810606\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:34 | INFO | Rank 0 | Train Epoch: 3 [3392/23491 (14%)]\tLoss: 0.762138\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:35 | INFO | Rank 0 | Train Epoch: 3 [3424/23491 (15%)]\tLoss: 0.937302\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:35 | INFO | Rank 0 | Train Epoch: 3 [3456/23491 (15%)]\tLoss: 0.846702\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:35 | INFO | Rank 0 | Train Epoch: 3 [3488/23491 (15%)]\tLoss: 0.740342\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:35 | INFO | Rank 0 | Train Epoch: 3 [3520/23491 (15%)]\tLoss: 1.010592\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:36 | INFO | Rank 0 | Train Epoch: 3 [3552/23491 (15%)]\tLoss: 0.587383\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:36 | INFO | Rank 0 | Train Epoch: 3 [3584/23491 (15%)]\tLoss: 0.714687\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:36 | INFO | Rank 0 | Train Epoch: 3 [3616/23491 (15%)]\tLoss: 0.606844\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:36 | INFO | Rank 0 | Train Epoch: 3 [3648/23491 (16%)]\tLoss: 0.712117\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:37 | INFO | Rank 0 | Train Epoch: 3 [3680/23491 (16%)]\tLoss: 0.987051\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:37 | INFO | Rank 0 | Train Epoch: 3 [3712/23491 (16%)]\tLoss: 0.752721\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:37 | INFO | Rank 0 | Train Epoch: 3 [3744/23491 (16%)]\tLoss: 0.875273\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:37 | INFO | Rank 0 | Train Epoch: 3 [3776/23491 (16%)]\tLoss: 0.612067\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:38 | INFO | Rank 0 | Train Epoch: 3 [3808/23491 (16%)]\tLoss: 0.824403\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:38 | INFO | Rank 0 | Train Epoch: 3 [3840/23491 (16%)]\tLoss: 0.720552\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:38 | INFO | Rank 0 | Train Epoch: 3 [3872/23491 (16%)]\tLoss: 0.718109\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:39 | INFO | Rank 0 | Train Epoch: 3 [3904/23491 (17%)]\tLoss: 0.909278\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:39 | INFO | Rank 0 | Train Epoch: 3 [3936/23491 (17%)]\tLoss: 0.890862\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:39 | INFO | Rank 0 | Train Epoch: 3 [3968/23491 (17%)]\tLoss: 0.773788\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:39 | INFO | Rank 0 | Train Epoch: 3 [4000/23491 (17%)]\tLoss: 0.424009\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:40 | INFO | Rank 0 | Train Epoch: 3 [4032/23491 (17%)]\tLoss: 0.981830\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:40 | INFO | Rank 0 | Train Epoch: 3 [4064/23491 (17%)]\tLoss: 0.555068\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:40 | INFO | Rank 0 | Train Epoch: 3 [4096/23491 (17%)]\tLoss: 0.871186\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:40 | INFO | Rank 0 | Train Epoch: 3 [4128/23491 (18%)]\tLoss: 0.685660\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:41 | INFO | Rank 0 | Train Epoch: 3 [4160/23491 (18%)]\tLoss: 0.522721\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:41 | INFO | Rank 0 | Train Epoch: 3 [4192/23491 (18%)]\tLoss: 0.708348\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:41 | INFO | Rank 0 | Train Epoch: 3 [4224/23491 (18%)]\tLoss: 1.196552\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:41 | INFO | Rank 0 | Train Epoch: 3 [4256/23491 (18%)]\tLoss: 0.858304\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:42 | INFO | Rank 0 | Train Epoch: 3 [4288/23491 (18%)]\tLoss: 1.043520\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:42 | INFO | Rank 0 | Train Epoch: 3 [4320/23491 (18%)]\tLoss: 0.479069\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:42 | INFO | Rank 0 | Train Epoch: 3 [4352/23491 (19%)]\tLoss: 0.885510\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:43 | INFO | Rank 0 | Train Epoch: 3 [4384/23491 (19%)]\tLoss: 0.562715\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:43 | INFO | Rank 0 | Train Epoch: 3 [4416/23491 (19%)]\tLoss: 0.521448\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.557\n",
      "2022-11-08,05:36:43 | INFO | Rank 0 | Train Epoch: 3 [4448/23491 (19%)]\tLoss: 0.552686\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.556\n",
      "2022-11-08,05:36:43 | INFO | Rank 0 | Train Epoch: 3 [4480/23491 (19%)]\tLoss: 0.421564\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.556\n",
      "2022-11-08,05:36:44 | INFO | Rank 0 | Train Epoch: 3 [4512/23491 (19%)]\tLoss: 0.581111\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000067\tlogit_scale 4.556\n",
      "2022-11-08,05:36:44 | INFO | Rank 0 | Train Epoch: 3 [4544/23491 (19%)]\tLoss: 0.504594\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:44 | INFO | Rank 0 | Train Epoch: 3 [4576/23491 (19%)]\tLoss: 0.746083\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:44 | INFO | Rank 0 | Train Epoch: 3 [4608/23491 (20%)]\tLoss: 0.798663\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:45 | INFO | Rank 0 | Train Epoch: 3 [4640/23491 (20%)]\tLoss: 0.715430\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:45 | INFO | Rank 0 | Train Epoch: 3 [4672/23491 (20%)]\tLoss: 0.792809\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:45 | INFO | Rank 0 | Train Epoch: 3 [4704/23491 (20%)]\tLoss: 0.493613\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:45 | INFO | Rank 0 | Train Epoch: 3 [4736/23491 (20%)]\tLoss: 0.476607\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:46 | INFO | Rank 0 | Train Epoch: 3 [4768/23491 (20%)]\tLoss: 0.760963\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:46 | INFO | Rank 0 | Train Epoch: 3 [4800/23491 (20%)]\tLoss: 0.968217\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:46 | INFO | Rank 0 | Train Epoch: 3 [4832/23491 (21%)]\tLoss: 0.665384\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:47 | INFO | Rank 0 | Train Epoch: 3 [4864/23491 (21%)]\tLoss: 0.546705\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:47 | INFO | Rank 0 | Train Epoch: 3 [4896/23491 (21%)]\tLoss: 1.193387\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:47 | INFO | Rank 0 | Train Epoch: 3 [4928/23491 (21%)]\tLoss: 0.665713\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:47 | INFO | Rank 0 | Train Epoch: 3 [4960/23491 (21%)]\tLoss: 1.199578\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:48 | INFO | Rank 0 | Train Epoch: 3 [4992/23491 (21%)]\tLoss: 0.909144\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:48 | INFO | Rank 0 | Train Epoch: 3 [5024/23491 (21%)]\tLoss: 1.355340\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:48 | INFO | Rank 0 | Train Epoch: 3 [5056/23491 (22%)]\tLoss: 0.572640\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:48 | INFO | Rank 0 | Train Epoch: 3 [5088/23491 (22%)]\tLoss: 0.697136\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:49 | INFO | Rank 0 | Train Epoch: 3 [5120/23491 (22%)]\tLoss: 0.494515\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:49 | INFO | Rank 0 | Train Epoch: 3 [5152/23491 (22%)]\tLoss: 0.872958\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:49 | INFO | Rank 0 | Train Epoch: 3 [5184/23491 (22%)]\tLoss: 0.785439\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:49 | INFO | Rank 0 | Train Epoch: 3 [5216/23491 (22%)]\tLoss: 0.945948\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:50 | INFO | Rank 0 | Train Epoch: 3 [5248/23491 (22%)]\tLoss: 0.620695\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:50 | INFO | Rank 0 | Train Epoch: 3 [5280/23491 (22%)]\tLoss: 0.751278\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:50 | INFO | Rank 0 | Train Epoch: 3 [5312/23491 (23%)]\tLoss: 0.839530\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:51 | INFO | Rank 0 | Train Epoch: 3 [5344/23491 (23%)]\tLoss: 0.839480\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:51 | INFO | Rank 0 | Train Epoch: 3 [5376/23491 (23%)]\tLoss: 0.821841\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:51 | INFO | Rank 0 | Train Epoch: 3 [5408/23491 (23%)]\tLoss: 1.579325\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:51 | INFO | Rank 0 | Train Epoch: 3 [5440/23491 (23%)]\tLoss: 0.770032\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:52 | INFO | Rank 0 | Train Epoch: 3 [5472/23491 (23%)]\tLoss: 0.442972\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:52 | INFO | Rank 0 | Train Epoch: 3 [5504/23491 (23%)]\tLoss: 0.797775\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:52 | INFO | Rank 0 | Train Epoch: 3 [5536/23491 (24%)]\tLoss: 0.543685\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:52 | INFO | Rank 0 | Train Epoch: 3 [5568/23491 (24%)]\tLoss: 0.732929\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:53 | INFO | Rank 0 | Train Epoch: 3 [5600/23491 (24%)]\tLoss: 0.583582\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:53 | INFO | Rank 0 | Train Epoch: 3 [5632/23491 (24%)]\tLoss: 0.758991\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:53 | INFO | Rank 0 | Train Epoch: 3 [5664/23491 (24%)]\tLoss: 0.586346\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:53 | INFO | Rank 0 | Train Epoch: 3 [5696/23491 (24%)]\tLoss: 0.489634\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:54 | INFO | Rank 0 | Train Epoch: 3 [5728/23491 (24%)]\tLoss: 0.438478\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:54 | INFO | Rank 0 | Train Epoch: 3 [5760/23491 (25%)]\tLoss: 0.477659\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:54 | INFO | Rank 0 | Train Epoch: 3 [5792/23491 (25%)]\tLoss: 0.778860\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:55 | INFO | Rank 0 | Train Epoch: 3 [5824/23491 (25%)]\tLoss: 0.728973\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:55 | INFO | Rank 0 | Train Epoch: 3 [5856/23491 (25%)]\tLoss: 0.533060\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:55 | INFO | Rank 0 | Train Epoch: 3 [5888/23491 (25%)]\tLoss: 0.810847\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:55 | INFO | Rank 0 | Train Epoch: 3 [5920/23491 (25%)]\tLoss: 0.918313\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:56 | INFO | Rank 0 | Train Epoch: 3 [5952/23491 (25%)]\tLoss: 0.887729\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:56 | INFO | Rank 0 | Train Epoch: 3 [5984/23491 (25%)]\tLoss: 0.469528\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:56 | INFO | Rank 0 | Train Epoch: 3 [6016/23491 (26%)]\tLoss: 0.527416\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:56 | INFO | Rank 0 | Train Epoch: 3 [6048/23491 (26%)]\tLoss: 0.820075\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:57 | INFO | Rank 0 | Train Epoch: 3 [6080/23491 (26%)]\tLoss: 0.606189\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:57 | INFO | Rank 0 | Train Epoch: 3 [6112/23491 (26%)]\tLoss: 1.031988\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:57 | INFO | Rank 0 | Train Epoch: 3 [6144/23491 (26%)]\tLoss: 0.816174\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:57 | INFO | Rank 0 | Train Epoch: 3 [6176/23491 (26%)]\tLoss: 0.579157\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:58 | INFO | Rank 0 | Train Epoch: 3 [6208/23491 (26%)]\tLoss: 0.453698\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:58 | INFO | Rank 0 | Train Epoch: 3 [6240/23491 (27%)]\tLoss: 0.884993\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:58 | INFO | Rank 0 | Train Epoch: 3 [6272/23491 (27%)]\tLoss: 0.362202\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:58 | INFO | Rank 0 | Train Epoch: 3 [6304/23491 (27%)]\tLoss: 0.863183\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:59 | INFO | Rank 0 | Train Epoch: 3 [6336/23491 (27%)]\tLoss: 0.589027\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:59 | INFO | Rank 0 | Train Epoch: 3 [6368/23491 (27%)]\tLoss: 0.401191\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:36:59 | INFO | Rank 0 | Train Epoch: 3 [6400/23491 (27%)]\tLoss: 1.068612\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:37:00 | INFO | Rank 0 | Train Epoch: 3 [6432/23491 (27%)]\tLoss: 0.990234\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:37:00 | INFO | Rank 0 | Train Epoch: 3 [6464/23491 (28%)]\tLoss: 0.768867\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:37:00 | INFO | Rank 0 | Train Epoch: 3 [6496/23491 (28%)]\tLoss: 1.087323\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:37:00 | INFO | Rank 0 | Train Epoch: 3 [6528/23491 (28%)]\tLoss: 0.402088\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:37:01 | INFO | Rank 0 | Train Epoch: 3 [6560/23491 (28%)]\tLoss: 0.614362\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:37:01 | INFO | Rank 0 | Train Epoch: 3 [6592/23491 (28%)]\tLoss: 0.746071\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:37:01 | INFO | Rank 0 | Train Epoch: 3 [6624/23491 (28%)]\tLoss: 0.522692\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:37:01 | INFO | Rank 0 | Train Epoch: 3 [6656/23491 (28%)]\tLoss: 0.693973\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:37:02 | INFO | Rank 0 | Train Epoch: 3 [6688/23491 (28%)]\tLoss: 0.855938\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:37:02 | INFO | Rank 0 | Train Epoch: 3 [6720/23491 (29%)]\tLoss: 0.891518\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:37:02 | INFO | Rank 0 | Train Epoch: 3 [6752/23491 (29%)]\tLoss: 0.713671\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:37:02 | INFO | Rank 0 | Train Epoch: 3 [6784/23491 (29%)]\tLoss: 0.766686\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000066\tlogit_scale 4.556\n",
      "2022-11-08,05:37:03 | INFO | Rank 0 | Train Epoch: 3 [6816/23491 (29%)]\tLoss: 0.881533\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.556\n",
      "2022-11-08,05:37:03 | INFO | Rank 0 | Train Epoch: 3 [6848/23491 (29%)]\tLoss: 0.767983\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.556\n",
      "2022-11-08,05:37:03 | INFO | Rank 0 | Train Epoch: 3 [6880/23491 (29%)]\tLoss: 0.775696\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.556\n",
      "2022-11-08,05:37:04 | INFO | Rank 0 | Train Epoch: 3 [6912/23491 (29%)]\tLoss: 0.581419\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.556\n",
      "2022-11-08,05:37:04 | INFO | Rank 0 | Train Epoch: 3 [6944/23491 (30%)]\tLoss: 0.541566\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.556\n",
      "2022-11-08,05:37:04 | INFO | Rank 0 | Train Epoch: 3 [6976/23491 (30%)]\tLoss: 0.569308\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.556\n",
      "2022-11-08,05:37:04 | INFO | Rank 0 | Train Epoch: 3 [7008/23491 (30%)]\tLoss: 0.743831\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.556\n",
      "2022-11-08,05:37:05 | INFO | Rank 0 | Train Epoch: 3 [7040/23491 (30%)]\tLoss: 0.976928\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:05 | INFO | Rank 0 | Train Epoch: 3 [7072/23491 (30%)]\tLoss: 0.862771\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:05 | INFO | Rank 0 | Train Epoch: 3 [7104/23491 (30%)]\tLoss: 0.809812\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:05 | INFO | Rank 0 | Train Epoch: 3 [7136/23491 (30%)]\tLoss: 0.945828\tData (t) 0.052\tBatch (t) 0.264\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:06 | INFO | Rank 0 | Train Epoch: 3 [7168/23491 (31%)]\tLoss: 0.942930\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:06 | INFO | Rank 0 | Train Epoch: 3 [7200/23491 (31%)]\tLoss: 0.779884\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:06 | INFO | Rank 0 | Train Epoch: 3 [7232/23491 (31%)]\tLoss: 0.794319\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:06 | INFO | Rank 0 | Train Epoch: 3 [7264/23491 (31%)]\tLoss: 0.677331\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:07 | INFO | Rank 0 | Train Epoch: 3 [7296/23491 (31%)]\tLoss: 0.527722\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:07 | INFO | Rank 0 | Train Epoch: 3 [7328/23491 (31%)]\tLoss: 0.687023\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:07 | INFO | Rank 0 | Train Epoch: 3 [7360/23491 (31%)]\tLoss: 0.729496\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:08 | INFO | Rank 0 | Train Epoch: 3 [7392/23491 (31%)]\tLoss: 0.674229\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:08 | INFO | Rank 0 | Train Epoch: 3 [7424/23491 (32%)]\tLoss: 0.692695\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:08 | INFO | Rank 0 | Train Epoch: 3 [7456/23491 (32%)]\tLoss: 0.581815\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:08 | INFO | Rank 0 | Train Epoch: 3 [7488/23491 (32%)]\tLoss: 0.637415\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:09 | INFO | Rank 0 | Train Epoch: 3 [7520/23491 (32%)]\tLoss: 0.829392\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:09 | INFO | Rank 0 | Train Epoch: 3 [7552/23491 (32%)]\tLoss: 0.612941\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:09 | INFO | Rank 0 | Train Epoch: 3 [7584/23491 (32%)]\tLoss: 0.861964\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:09 | INFO | Rank 0 | Train Epoch: 3 [7616/23491 (32%)]\tLoss: 0.975295\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:10 | INFO | Rank 0 | Train Epoch: 3 [7648/23491 (33%)]\tLoss: 0.641948\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:10 | INFO | Rank 0 | Train Epoch: 3 [7680/23491 (33%)]\tLoss: 0.812158\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:10 | INFO | Rank 0 | Train Epoch: 3 [7712/23491 (33%)]\tLoss: 1.233513\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:10 | INFO | Rank 0 | Train Epoch: 3 [7744/23491 (33%)]\tLoss: 0.757941\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:11 | INFO | Rank 0 | Train Epoch: 3 [7776/23491 (33%)]\tLoss: 0.515017\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:11 | INFO | Rank 0 | Train Epoch: 3 [7808/23491 (33%)]\tLoss: 1.407897\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:11 | INFO | Rank 0 | Train Epoch: 3 [7840/23491 (33%)]\tLoss: 0.745191\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:12 | INFO | Rank 0 | Train Epoch: 3 [7872/23491 (34%)]\tLoss: 0.794633\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:12 | INFO | Rank 0 | Train Epoch: 3 [7904/23491 (34%)]\tLoss: 0.597586\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:12 | INFO | Rank 0 | Train Epoch: 3 [7936/23491 (34%)]\tLoss: 0.498786\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:12 | INFO | Rank 0 | Train Epoch: 3 [7968/23491 (34%)]\tLoss: 0.841284\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:13 | INFO | Rank 0 | Train Epoch: 3 [8000/23491 (34%)]\tLoss: 0.632804\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:13 | INFO | Rank 0 | Train Epoch: 3 [8032/23491 (34%)]\tLoss: 0.590486\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:13 | INFO | Rank 0 | Train Epoch: 3 [8064/23491 (34%)]\tLoss: 0.919374\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:13 | INFO | Rank 0 | Train Epoch: 3 [8096/23491 (34%)]\tLoss: 0.579053\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:14 | INFO | Rank 0 | Train Epoch: 3 [8128/23491 (35%)]\tLoss: 0.708408\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:14 | INFO | Rank 0 | Train Epoch: 3 [8160/23491 (35%)]\tLoss: 0.775477\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:14 | INFO | Rank 0 | Train Epoch: 3 [8192/23491 (35%)]\tLoss: 0.956629\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:14 | INFO | Rank 0 | Train Epoch: 3 [8224/23491 (35%)]\tLoss: 0.610783\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:15 | INFO | Rank 0 | Train Epoch: 3 [8256/23491 (35%)]\tLoss: 0.690158\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:15 | INFO | Rank 0 | Train Epoch: 3 [8288/23491 (35%)]\tLoss: 0.828303\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:15 | INFO | Rank 0 | Train Epoch: 3 [8320/23491 (35%)]\tLoss: 0.740802\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:15 | INFO | Rank 0 | Train Epoch: 3 [8352/23491 (36%)]\tLoss: 0.447885\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:16 | INFO | Rank 0 | Train Epoch: 3 [8384/23491 (36%)]\tLoss: 0.966553\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:16 | INFO | Rank 0 | Train Epoch: 3 [8416/23491 (36%)]\tLoss: 0.563976\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:16 | INFO | Rank 0 | Train Epoch: 3 [8448/23491 (36%)]\tLoss: 0.927309\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:17 | INFO | Rank 0 | Train Epoch: 3 [8480/23491 (36%)]\tLoss: 0.494059\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:17 | INFO | Rank 0 | Train Epoch: 3 [8512/23491 (36%)]\tLoss: 0.616121\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:17 | INFO | Rank 0 | Train Epoch: 3 [8544/23491 (36%)]\tLoss: 0.905042\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:17 | INFO | Rank 0 | Train Epoch: 3 [8576/23491 (37%)]\tLoss: 0.542112\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:18 | INFO | Rank 0 | Train Epoch: 3 [8608/23491 (37%)]\tLoss: 1.071836\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:18 | INFO | Rank 0 | Train Epoch: 3 [8640/23491 (37%)]\tLoss: 0.429007\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:18 | INFO | Rank 0 | Train Epoch: 3 [8672/23491 (37%)]\tLoss: 0.817300\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:18 | INFO | Rank 0 | Train Epoch: 3 [8704/23491 (37%)]\tLoss: 0.743760\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:19 | INFO | Rank 0 | Train Epoch: 3 [8736/23491 (37%)]\tLoss: 0.698204\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:19 | INFO | Rank 0 | Train Epoch: 3 [8768/23491 (37%)]\tLoss: 0.328840\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:19 | INFO | Rank 0 | Train Epoch: 3 [8800/23491 (37%)]\tLoss: 0.423854\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:19 | INFO | Rank 0 | Train Epoch: 3 [8832/23491 (38%)]\tLoss: 0.429318\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:20 | INFO | Rank 0 | Train Epoch: 3 [8864/23491 (38%)]\tLoss: 0.803314\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:20 | INFO | Rank 0 | Train Epoch: 3 [8896/23491 (38%)]\tLoss: 0.696312\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:20 | INFO | Rank 0 | Train Epoch: 3 [8928/23491 (38%)]\tLoss: 0.928861\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:21 | INFO | Rank 0 | Train Epoch: 3 [8960/23491 (38%)]\tLoss: 0.881732\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:21 | INFO | Rank 0 | Train Epoch: 3 [8992/23491 (38%)]\tLoss: 0.696661\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:21 | INFO | Rank 0 | Train Epoch: 3 [9024/23491 (38%)]\tLoss: 0.956550\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000065\tlogit_scale 4.555\n",
      "2022-11-08,05:37:21 | INFO | Rank 0 | Train Epoch: 3 [9056/23491 (39%)]\tLoss: 0.888679\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.555\n",
      "2022-11-08,05:37:22 | INFO | Rank 0 | Train Epoch: 3 [9088/23491 (39%)]\tLoss: 0.327297\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.555\n",
      "2022-11-08,05:37:22 | INFO | Rank 0 | Train Epoch: 3 [9120/23491 (39%)]\tLoss: 0.624656\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.555\n",
      "2022-11-08,05:37:22 | INFO | Rank 0 | Train Epoch: 3 [9152/23491 (39%)]\tLoss: 0.953775\tData (t) 0.052\tBatch (t) 0.264\tLR: 0.000064\tlogit_scale 4.555\n",
      "2022-11-08,05:37:22 | INFO | Rank 0 | Train Epoch: 3 [9184/23491 (39%)]\tLoss: 0.594114\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.555\n",
      "2022-11-08,05:37:23 | INFO | Rank 0 | Train Epoch: 3 [9216/23491 (39%)]\tLoss: 0.727151\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.555\n",
      "2022-11-08,05:37:23 | INFO | Rank 0 | Train Epoch: 3 [9248/23491 (39%)]\tLoss: 0.617457\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.555\n",
      "2022-11-08,05:37:23 | INFO | Rank 0 | Train Epoch: 3 [9280/23491 (40%)]\tLoss: 0.759353\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.555\n",
      "2022-11-08,05:37:23 | INFO | Rank 0 | Train Epoch: 3 [9312/23491 (40%)]\tLoss: 0.706044\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.555\n",
      "2022-11-08,05:37:24 | INFO | Rank 0 | Train Epoch: 3 [9344/23491 (40%)]\tLoss: 0.887179\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.555\n",
      "2022-11-08,05:37:24 | INFO | Rank 0 | Train Epoch: 3 [9376/23491 (40%)]\tLoss: 1.133702\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.555\n",
      "2022-11-08,05:37:24 | INFO | Rank 0 | Train Epoch: 3 [9408/23491 (40%)]\tLoss: 0.877159\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:25 | INFO | Rank 0 | Train Epoch: 3 [9440/23491 (40%)]\tLoss: 0.854493\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:25 | INFO | Rank 0 | Train Epoch: 3 [9472/23491 (40%)]\tLoss: 1.166778\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:25 | INFO | Rank 0 | Train Epoch: 3 [9504/23491 (40%)]\tLoss: 0.753078\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:25 | INFO | Rank 0 | Train Epoch: 3 [9536/23491 (41%)]\tLoss: 0.733338\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:26 | INFO | Rank 0 | Train Epoch: 3 [9568/23491 (41%)]\tLoss: 0.549557\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:26 | INFO | Rank 0 | Train Epoch: 3 [9600/23491 (41%)]\tLoss: 0.631545\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:26 | INFO | Rank 0 | Train Epoch: 3 [9632/23491 (41%)]\tLoss: 0.597358\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:26 | INFO | Rank 0 | Train Epoch: 3 [9664/23491 (41%)]\tLoss: 0.730633\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:27 | INFO | Rank 0 | Train Epoch: 3 [9696/23491 (41%)]\tLoss: 0.968886\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:27 | INFO | Rank 0 | Train Epoch: 3 [9728/23491 (41%)]\tLoss: 0.645181\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:27 | INFO | Rank 0 | Train Epoch: 3 [9760/23491 (42%)]\tLoss: 0.758620\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:27 | INFO | Rank 0 | Train Epoch: 3 [9792/23491 (42%)]\tLoss: 0.566409\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:28 | INFO | Rank 0 | Train Epoch: 3 [9824/23491 (42%)]\tLoss: 0.912292\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:28 | INFO | Rank 0 | Train Epoch: 3 [9856/23491 (42%)]\tLoss: 0.748607\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:28 | INFO | Rank 0 | Train Epoch: 3 [9888/23491 (42%)]\tLoss: 0.601692\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:29 | INFO | Rank 0 | Train Epoch: 3 [9920/23491 (42%)]\tLoss: 0.577532\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:29 | INFO | Rank 0 | Train Epoch: 3 [9952/23491 (42%)]\tLoss: 0.524710\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:29 | INFO | Rank 0 | Train Epoch: 3 [9984/23491 (43%)]\tLoss: 0.685912\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:29 | INFO | Rank 0 | Train Epoch: 3 [10016/23491 (43%)]\tLoss: 0.740420\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:30 | INFO | Rank 0 | Train Epoch: 3 [10048/23491 (43%)]\tLoss: 0.702430\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:30 | INFO | Rank 0 | Train Epoch: 3 [10080/23491 (43%)]\tLoss: 0.778238\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:30 | INFO | Rank 0 | Train Epoch: 3 [10112/23491 (43%)]\tLoss: 0.533480\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:30 | INFO | Rank 0 | Train Epoch: 3 [10144/23491 (43%)]\tLoss: 0.787256\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:31 | INFO | Rank 0 | Train Epoch: 3 [10176/23491 (43%)]\tLoss: 0.293094\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:31 | INFO | Rank 0 | Train Epoch: 3 [10208/23491 (43%)]\tLoss: 0.545447\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:31 | INFO | Rank 0 | Train Epoch: 3 [10240/23491 (44%)]\tLoss: 1.175698\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:31 | INFO | Rank 0 | Train Epoch: 3 [10272/23491 (44%)]\tLoss: 0.775047\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:32 | INFO | Rank 0 | Train Epoch: 3 [10304/23491 (44%)]\tLoss: 0.639531\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:32 | INFO | Rank 0 | Train Epoch: 3 [10336/23491 (44%)]\tLoss: 0.811469\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:32 | INFO | Rank 0 | Train Epoch: 3 [10368/23491 (44%)]\tLoss: 0.914644\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:32 | INFO | Rank 0 | Train Epoch: 3 [10400/23491 (44%)]\tLoss: 0.367938\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:33 | INFO | Rank 0 | Train Epoch: 3 [10432/23491 (44%)]\tLoss: 0.727495\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:33 | INFO | Rank 0 | Train Epoch: 3 [10464/23491 (45%)]\tLoss: 0.797039\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:33 | INFO | Rank 0 | Train Epoch: 3 [10496/23491 (45%)]\tLoss: 0.659549\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:34 | INFO | Rank 0 | Train Epoch: 3 [10528/23491 (45%)]\tLoss: 0.681930\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:34 | INFO | Rank 0 | Train Epoch: 3 [10560/23491 (45%)]\tLoss: 0.704723\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:34 | INFO | Rank 0 | Train Epoch: 3 [10592/23491 (45%)]\tLoss: 0.855990\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:34 | INFO | Rank 0 | Train Epoch: 3 [10624/23491 (45%)]\tLoss: 0.712730\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:35 | INFO | Rank 0 | Train Epoch: 3 [10656/23491 (45%)]\tLoss: 0.408608\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:35 | INFO | Rank 0 | Train Epoch: 3 [10688/23491 (46%)]\tLoss: 0.727408\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:35 | INFO | Rank 0 | Train Epoch: 3 [10720/23491 (46%)]\tLoss: 0.836039\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:35 | INFO | Rank 0 | Train Epoch: 3 [10752/23491 (46%)]\tLoss: 0.697067\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:36 | INFO | Rank 0 | Train Epoch: 3 [10784/23491 (46%)]\tLoss: 0.541341\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:36 | INFO | Rank 0 | Train Epoch: 3 [10816/23491 (46%)]\tLoss: 0.978173\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:36 | INFO | Rank 0 | Train Epoch: 3 [10848/23491 (46%)]\tLoss: 0.532669\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:36 | INFO | Rank 0 | Train Epoch: 3 [10880/23491 (46%)]\tLoss: 0.636626\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:37 | INFO | Rank 0 | Train Epoch: 3 [10912/23491 (46%)]\tLoss: 0.934652\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:37 | INFO | Rank 0 | Train Epoch: 3 [10944/23491 (47%)]\tLoss: 1.220736\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:37 | INFO | Rank 0 | Train Epoch: 3 [10976/23491 (47%)]\tLoss: 0.807355\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:38 | INFO | Rank 0 | Train Epoch: 3 [11008/23491 (47%)]\tLoss: 1.128299\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:38 | INFO | Rank 0 | Train Epoch: 3 [11040/23491 (47%)]\tLoss: 0.728572\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.554\n",
      "2022-11-08,05:37:38 | INFO | Rank 0 | Train Epoch: 3 [11072/23491 (47%)]\tLoss: 0.629058\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000064\tlogit_scale 4.553\n",
      "2022-11-08,05:37:38 | INFO | Rank 0 | Train Epoch: 3 [11104/23491 (47%)]\tLoss: 0.690164\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.553\n",
      "2022-11-08,05:37:39 | INFO | Rank 0 | Train Epoch: 3 [11136/23491 (47%)]\tLoss: 0.387316\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.553\n",
      "2022-11-08,05:37:39 | INFO | Rank 0 | Train Epoch: 3 [11168/23491 (48%)]\tLoss: 0.395125\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.553\n",
      "2022-11-08,05:37:39 | INFO | Rank 0 | Train Epoch: 3 [11200/23491 (48%)]\tLoss: 0.666077\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000064\tlogit_scale 4.553\n",
      "2022-11-08,05:37:39 | INFO | Rank 0 | Train Epoch: 3 [11232/23491 (48%)]\tLoss: 0.312101\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:40 | INFO | Rank 0 | Train Epoch: 3 [11264/23491 (48%)]\tLoss: 0.730822\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:40 | INFO | Rank 0 | Train Epoch: 3 [11296/23491 (48%)]\tLoss: 0.884290\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:40 | INFO | Rank 0 | Train Epoch: 3 [11328/23491 (48%)]\tLoss: 0.522706\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:40 | INFO | Rank 0 | Train Epoch: 3 [11360/23491 (48%)]\tLoss: 0.519618\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:41 | INFO | Rank 0 | Train Epoch: 3 [11392/23491 (49%)]\tLoss: 0.735975\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:41 | INFO | Rank 0 | Train Epoch: 3 [11424/23491 (49%)]\tLoss: 0.802828\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:41 | INFO | Rank 0 | Train Epoch: 3 [11456/23491 (49%)]\tLoss: 0.992178\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:42 | INFO | Rank 0 | Train Epoch: 3 [11488/23491 (49%)]\tLoss: 0.431639\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:42 | INFO | Rank 0 | Train Epoch: 3 [11520/23491 (49%)]\tLoss: 0.412116\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:42 | INFO | Rank 0 | Train Epoch: 3 [11552/23491 (49%)]\tLoss: 0.614821\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:42 | INFO | Rank 0 | Train Epoch: 3 [11584/23491 (49%)]\tLoss: 0.499444\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:43 | INFO | Rank 0 | Train Epoch: 3 [11616/23491 (49%)]\tLoss: 0.736316\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:43 | INFO | Rank 0 | Train Epoch: 3 [11648/23491 (50%)]\tLoss: 0.830471\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:43 | INFO | Rank 0 | Train Epoch: 3 [11680/23491 (50%)]\tLoss: 0.980301\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:43 | INFO | Rank 0 | Train Epoch: 3 [11712/23491 (50%)]\tLoss: 1.065367\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:44 | INFO | Rank 0 | Train Epoch: 3 [11744/23491 (50%)]\tLoss: 0.529955\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:44 | INFO | Rank 0 | Train Epoch: 3 [11776/23491 (50%)]\tLoss: 0.618304\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:44 | INFO | Rank 0 | Train Epoch: 3 [11808/23491 (50%)]\tLoss: 0.991786\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:44 | INFO | Rank 0 | Train Epoch: 3 [11840/23491 (50%)]\tLoss: 0.733108\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:45 | INFO | Rank 0 | Train Epoch: 3 [11872/23491 (51%)]\tLoss: 0.635996\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:45 | INFO | Rank 0 | Train Epoch: 3 [11904/23491 (51%)]\tLoss: 0.771631\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:45 | INFO | Rank 0 | Train Epoch: 3 [11936/23491 (51%)]\tLoss: 0.725826\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:46 | INFO | Rank 0 | Train Epoch: 3 [11968/23491 (51%)]\tLoss: 0.968622\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:46 | INFO | Rank 0 | Train Epoch: 3 [12000/23491 (51%)]\tLoss: 0.897944\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:46 | INFO | Rank 0 | Train Epoch: 3 [12032/23491 (51%)]\tLoss: 0.579017\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:46 | INFO | Rank 0 | Train Epoch: 3 [12064/23491 (51%)]\tLoss: 0.543963\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:47 | INFO | Rank 0 | Train Epoch: 3 [12096/23491 (51%)]\tLoss: 0.789116\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:47 | INFO | Rank 0 | Train Epoch: 3 [12128/23491 (52%)]\tLoss: 0.581603\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:47 | INFO | Rank 0 | Train Epoch: 3 [12160/23491 (52%)]\tLoss: 0.686480\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:47 | INFO | Rank 0 | Train Epoch: 3 [12192/23491 (52%)]\tLoss: 0.783665\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:48 | INFO | Rank 0 | Train Epoch: 3 [12224/23491 (52%)]\tLoss: 0.606211\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:48 | INFO | Rank 0 | Train Epoch: 3 [12256/23491 (52%)]\tLoss: 0.418407\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:48 | INFO | Rank 0 | Train Epoch: 3 [12288/23491 (52%)]\tLoss: 1.158876\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:48 | INFO | Rank 0 | Train Epoch: 3 [12320/23491 (52%)]\tLoss: 0.807120\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:49 | INFO | Rank 0 | Train Epoch: 3 [12352/23491 (53%)]\tLoss: 0.893191\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:49 | INFO | Rank 0 | Train Epoch: 3 [12384/23491 (53%)]\tLoss: 0.661953\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:49 | INFO | Rank 0 | Train Epoch: 3 [12416/23491 (53%)]\tLoss: 0.934648\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:50 | INFO | Rank 0 | Train Epoch: 3 [12448/23491 (53%)]\tLoss: 0.581957\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:50 | INFO | Rank 0 | Train Epoch: 3 [12480/23491 (53%)]\tLoss: 0.735113\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:50 | INFO | Rank 0 | Train Epoch: 3 [12512/23491 (53%)]\tLoss: 0.645909\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:50 | INFO | Rank 0 | Train Epoch: 3 [12544/23491 (53%)]\tLoss: 0.863598\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:51 | INFO | Rank 0 | Train Epoch: 3 [12576/23491 (54%)]\tLoss: 0.725877\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:51 | INFO | Rank 0 | Train Epoch: 3 [12608/23491 (54%)]\tLoss: 0.515412\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:51 | INFO | Rank 0 | Train Epoch: 3 [12640/23491 (54%)]\tLoss: 0.894284\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:51 | INFO | Rank 0 | Train Epoch: 3 [12672/23491 (54%)]\tLoss: 0.425064\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:52 | INFO | Rank 0 | Train Epoch: 3 [12704/23491 (54%)]\tLoss: 0.976898\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:52 | INFO | Rank 0 | Train Epoch: 3 [12736/23491 (54%)]\tLoss: 0.567083\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:52 | INFO | Rank 0 | Train Epoch: 3 [12768/23491 (54%)]\tLoss: 0.736791\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:52 | INFO | Rank 0 | Train Epoch: 3 [12800/23491 (54%)]\tLoss: 0.442878\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:53 | INFO | Rank 0 | Train Epoch: 3 [12832/23491 (55%)]\tLoss: 0.839485\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:53 | INFO | Rank 0 | Train Epoch: 3 [12864/23491 (55%)]\tLoss: 0.884015\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:53 | INFO | Rank 0 | Train Epoch: 3 [12896/23491 (55%)]\tLoss: 0.575141\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:53 | INFO | Rank 0 | Train Epoch: 3 [12928/23491 (55%)]\tLoss: 0.707773\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:54 | INFO | Rank 0 | Train Epoch: 3 [12960/23491 (55%)]\tLoss: 0.995099\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:54 | INFO | Rank 0 | Train Epoch: 3 [12992/23491 (55%)]\tLoss: 0.793453\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:54 | INFO | Rank 0 | Train Epoch: 3 [13024/23491 (55%)]\tLoss: 0.917893\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:55 | INFO | Rank 0 | Train Epoch: 3 [13056/23491 (56%)]\tLoss: 0.468964\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:55 | INFO | Rank 0 | Train Epoch: 3 [13088/23491 (56%)]\tLoss: 0.719855\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:55 | INFO | Rank 0 | Train Epoch: 3 [13120/23491 (56%)]\tLoss: 1.059642\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:55 | INFO | Rank 0 | Train Epoch: 3 [13152/23491 (56%)]\tLoss: 0.678686\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:56 | INFO | Rank 0 | Train Epoch: 3 [13184/23491 (56%)]\tLoss: 1.037526\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:56 | INFO | Rank 0 | Train Epoch: 3 [13216/23491 (56%)]\tLoss: 0.773797\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:56 | INFO | Rank 0 | Train Epoch: 3 [13248/23491 (56%)]\tLoss: 0.800777\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:56 | INFO | Rank 0 | Train Epoch: 3 [13280/23491 (57%)]\tLoss: 0.882878\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:57 | INFO | Rank 0 | Train Epoch: 3 [13312/23491 (57%)]\tLoss: 0.607198\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:57 | INFO | Rank 0 | Train Epoch: 3 [13344/23491 (57%)]\tLoss: 0.628964\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000063\tlogit_scale 4.553\n",
      "2022-11-08,05:37:57 | INFO | Rank 0 | Train Epoch: 3 [13376/23491 (57%)]\tLoss: 0.747232\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:37:57 | INFO | Rank 0 | Train Epoch: 3 [13408/23491 (57%)]\tLoss: 0.691027\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:37:58 | INFO | Rank 0 | Train Epoch: 3 [13440/23491 (57%)]\tLoss: 0.578229\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:37:58 | INFO | Rank 0 | Train Epoch: 3 [13472/23491 (57%)]\tLoss: 0.616121\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:37:58 | INFO | Rank 0 | Train Epoch: 3 [13504/23491 (57%)]\tLoss: 0.516576\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:37:59 | INFO | Rank 0 | Train Epoch: 3 [13536/23491 (58%)]\tLoss: 0.536280\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:37:59 | INFO | Rank 0 | Train Epoch: 3 [13568/23491 (58%)]\tLoss: 0.364239\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:37:59 | INFO | Rank 0 | Train Epoch: 3 [13600/23491 (58%)]\tLoss: 0.520343\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:37:59 | INFO | Rank 0 | Train Epoch: 3 [13632/23491 (58%)]\tLoss: 0.532464\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:38:00 | INFO | Rank 0 | Train Epoch: 3 [13664/23491 (58%)]\tLoss: 1.121478\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:38:00 | INFO | Rank 0 | Train Epoch: 3 [13696/23491 (58%)]\tLoss: 0.561171\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:38:00 | INFO | Rank 0 | Train Epoch: 3 [13728/23491 (58%)]\tLoss: 0.374300\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:38:00 | INFO | Rank 0 | Train Epoch: 3 [13760/23491 (59%)]\tLoss: 0.785197\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:38:01 | INFO | Rank 0 | Train Epoch: 3 [13792/23491 (59%)]\tLoss: 0.752094\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:38:01 | INFO | Rank 0 | Train Epoch: 3 [13824/23491 (59%)]\tLoss: 1.386773\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:38:01 | INFO | Rank 0 | Train Epoch: 3 [13856/23491 (59%)]\tLoss: 0.972856\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:38:01 | INFO | Rank 0 | Train Epoch: 3 [13888/23491 (59%)]\tLoss: 0.947658\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:38:02 | INFO | Rank 0 | Train Epoch: 3 [13920/23491 (59%)]\tLoss: 0.968565\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.553\n",
      "2022-11-08,05:38:02 | INFO | Rank 0 | Train Epoch: 3 [13952/23491 (59%)]\tLoss: 0.764438\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:02 | INFO | Rank 0 | Train Epoch: 3 [13984/23491 (60%)]\tLoss: 0.901535\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:03 | INFO | Rank 0 | Train Epoch: 3 [14016/23491 (60%)]\tLoss: 0.894853\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:03 | INFO | Rank 0 | Train Epoch: 3 [14048/23491 (60%)]\tLoss: 0.772816\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:03 | INFO | Rank 0 | Train Epoch: 3 [14080/23491 (60%)]\tLoss: 0.718998\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:03 | INFO | Rank 0 | Train Epoch: 3 [14112/23491 (60%)]\tLoss: 0.443642\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:04 | INFO | Rank 0 | Train Epoch: 3 [14144/23491 (60%)]\tLoss: 0.621433\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:04 | INFO | Rank 0 | Train Epoch: 3 [14176/23491 (60%)]\tLoss: 0.859486\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:04 | INFO | Rank 0 | Train Epoch: 3 [14208/23491 (60%)]\tLoss: 0.706506\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:04 | INFO | Rank 0 | Train Epoch: 3 [14240/23491 (61%)]\tLoss: 1.246196\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:05 | INFO | Rank 0 | Train Epoch: 3 [14272/23491 (61%)]\tLoss: 0.753058\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:05 | INFO | Rank 0 | Train Epoch: 3 [14304/23491 (61%)]\tLoss: 0.716662\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:05 | INFO | Rank 0 | Train Epoch: 3 [14336/23491 (61%)]\tLoss: 0.876585\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:05 | INFO | Rank 0 | Train Epoch: 3 [14368/23491 (61%)]\tLoss: 0.928371\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:06 | INFO | Rank 0 | Train Epoch: 3 [14400/23491 (61%)]\tLoss: 0.685003\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:06 | INFO | Rank 0 | Train Epoch: 3 [14432/23491 (61%)]\tLoss: 0.527984\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:06 | INFO | Rank 0 | Train Epoch: 3 [14464/23491 (62%)]\tLoss: 0.822631\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:07 | INFO | Rank 0 | Train Epoch: 3 [14496/23491 (62%)]\tLoss: 0.515253\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:07 | INFO | Rank 0 | Train Epoch: 3 [14528/23491 (62%)]\tLoss: 0.697224\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:07 | INFO | Rank 0 | Train Epoch: 3 [14560/23491 (62%)]\tLoss: 0.390867\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:07 | INFO | Rank 0 | Train Epoch: 3 [14592/23491 (62%)]\tLoss: 0.756946\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:08 | INFO | Rank 0 | Train Epoch: 3 [14624/23491 (62%)]\tLoss: 0.595567\tData (t) 0.056\tBatch (t) 0.271\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:08 | INFO | Rank 0 | Train Epoch: 3 [14656/23491 (62%)]\tLoss: 0.422950\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:08 | INFO | Rank 0 | Train Epoch: 3 [14688/23491 (63%)]\tLoss: 0.792539\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:08 | INFO | Rank 0 | Train Epoch: 3 [14720/23491 (63%)]\tLoss: 0.789411\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:09 | INFO | Rank 0 | Train Epoch: 3 [14752/23491 (63%)]\tLoss: 0.715190\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:09 | INFO | Rank 0 | Train Epoch: 3 [14784/23491 (63%)]\tLoss: 1.109591\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:09 | INFO | Rank 0 | Train Epoch: 3 [14816/23491 (63%)]\tLoss: 0.632107\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:09 | INFO | Rank 0 | Train Epoch: 3 [14848/23491 (63%)]\tLoss: 0.846907\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:10 | INFO | Rank 0 | Train Epoch: 3 [14880/23491 (63%)]\tLoss: 0.788197\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:10 | INFO | Rank 0 | Train Epoch: 3 [14912/23491 (63%)]\tLoss: 0.887798\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:10 | INFO | Rank 0 | Train Epoch: 3 [14944/23491 (64%)]\tLoss: 0.679460\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:11 | INFO | Rank 0 | Train Epoch: 3 [14976/23491 (64%)]\tLoss: 0.955096\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:11 | INFO | Rank 0 | Train Epoch: 3 [15008/23491 (64%)]\tLoss: 0.782260\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:11 | INFO | Rank 0 | Train Epoch: 3 [15040/23491 (64%)]\tLoss: 0.804229\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:11 | INFO | Rank 0 | Train Epoch: 3 [15072/23491 (64%)]\tLoss: 0.795936\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:12 | INFO | Rank 0 | Train Epoch: 3 [15104/23491 (64%)]\tLoss: 0.694382\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:12 | INFO | Rank 0 | Train Epoch: 3 [15136/23491 (64%)]\tLoss: 0.811029\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:12 | INFO | Rank 0 | Train Epoch: 3 [15168/23491 (65%)]\tLoss: 0.858276\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:12 | INFO | Rank 0 | Train Epoch: 3 [15200/23491 (65%)]\tLoss: 0.776333\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:13 | INFO | Rank 0 | Train Epoch: 3 [15232/23491 (65%)]\tLoss: 0.722249\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:13 | INFO | Rank 0 | Train Epoch: 3 [15264/23491 (65%)]\tLoss: 0.744563\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:13 | INFO | Rank 0 | Train Epoch: 3 [15296/23491 (65%)]\tLoss: 0.585680\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:13 | INFO | Rank 0 | Train Epoch: 3 [15328/23491 (65%)]\tLoss: 0.724139\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:14 | INFO | Rank 0 | Train Epoch: 3 [15360/23491 (65%)]\tLoss: 0.551296\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:14 | INFO | Rank 0 | Train Epoch: 3 [15392/23491 (66%)]\tLoss: 0.817108\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:14 | INFO | Rank 0 | Train Epoch: 3 [15424/23491 (66%)]\tLoss: 0.731328\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000062\tlogit_scale 4.552\n",
      "2022-11-08,05:38:15 | INFO | Rank 0 | Train Epoch: 3 [15456/23491 (66%)]\tLoss: 0.581598\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:15 | INFO | Rank 0 | Train Epoch: 3 [15488/23491 (66%)]\tLoss: 0.703921\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:15 | INFO | Rank 0 | Train Epoch: 3 [15520/23491 (66%)]\tLoss: 0.958281\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:15 | INFO | Rank 0 | Train Epoch: 3 [15552/23491 (66%)]\tLoss: 0.787245\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:16 | INFO | Rank 0 | Train Epoch: 3 [15584/23491 (66%)]\tLoss: 0.991069\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:16 | INFO | Rank 0 | Train Epoch: 3 [15616/23491 (66%)]\tLoss: 0.676644\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:16 | INFO | Rank 0 | Train Epoch: 3 [15648/23491 (67%)]\tLoss: 1.069515\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:16 | INFO | Rank 0 | Train Epoch: 3 [15680/23491 (67%)]\tLoss: 0.986289\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:17 | INFO | Rank 0 | Train Epoch: 3 [15712/23491 (67%)]\tLoss: 0.616125\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:17 | INFO | Rank 0 | Train Epoch: 3 [15744/23491 (67%)]\tLoss: 1.135824\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:17 | INFO | Rank 0 | Train Epoch: 3 [15776/23491 (67%)]\tLoss: 0.513224\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:17 | INFO | Rank 0 | Train Epoch: 3 [15808/23491 (67%)]\tLoss: 0.537996\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:18 | INFO | Rank 0 | Train Epoch: 3 [15840/23491 (67%)]\tLoss: 0.970250\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:18 | INFO | Rank 0 | Train Epoch: 3 [15872/23491 (68%)]\tLoss: 0.672273\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:18 | INFO | Rank 0 | Train Epoch: 3 [15904/23491 (68%)]\tLoss: 0.443628\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:18 | INFO | Rank 0 | Train Epoch: 3 [15936/23491 (68%)]\tLoss: 0.718912\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:19 | INFO | Rank 0 | Train Epoch: 3 [15968/23491 (68%)]\tLoss: 0.620286\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:19 | INFO | Rank 0 | Train Epoch: 3 [16000/23491 (68%)]\tLoss: 0.783505\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:19 | INFO | Rank 0 | Train Epoch: 3 [16032/23491 (68%)]\tLoss: 0.784885\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:20 | INFO | Rank 0 | Train Epoch: 3 [16064/23491 (68%)]\tLoss: 0.672641\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:20 | INFO | Rank 0 | Train Epoch: 3 [16096/23491 (69%)]\tLoss: 0.338369\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:20 | INFO | Rank 0 | Train Epoch: 3 [16128/23491 (69%)]\tLoss: 0.652806\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:20 | INFO | Rank 0 | Train Epoch: 3 [16160/23491 (69%)]\tLoss: 0.779488\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:21 | INFO | Rank 0 | Train Epoch: 3 [16192/23491 (69%)]\tLoss: 0.557042\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:21 | INFO | Rank 0 | Train Epoch: 3 [16224/23491 (69%)]\tLoss: 0.505257\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:21 | INFO | Rank 0 | Train Epoch: 3 [16256/23491 (69%)]\tLoss: 0.691281\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:21 | INFO | Rank 0 | Train Epoch: 3 [16288/23491 (69%)]\tLoss: 0.402490\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:22 | INFO | Rank 0 | Train Epoch: 3 [16320/23491 (69%)]\tLoss: 0.895135\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:22 | INFO | Rank 0 | Train Epoch: 3 [16352/23491 (70%)]\tLoss: 0.789133\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:22 | INFO | Rank 0 | Train Epoch: 3 [16384/23491 (70%)]\tLoss: 0.760337\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:22 | INFO | Rank 0 | Train Epoch: 3 [16416/23491 (70%)]\tLoss: 0.688291\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:23 | INFO | Rank 0 | Train Epoch: 3 [16448/23491 (70%)]\tLoss: 0.518366\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:23 | INFO | Rank 0 | Train Epoch: 3 [16480/23491 (70%)]\tLoss: 0.605883\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:23 | INFO | Rank 0 | Train Epoch: 3 [16512/23491 (70%)]\tLoss: 0.961452\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:24 | INFO | Rank 0 | Train Epoch: 3 [16544/23491 (70%)]\tLoss: 0.745146\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:24 | INFO | Rank 0 | Train Epoch: 3 [16576/23491 (71%)]\tLoss: 0.688489\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:24 | INFO | Rank 0 | Train Epoch: 3 [16608/23491 (71%)]\tLoss: 0.749393\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:24 | INFO | Rank 0 | Train Epoch: 3 [16640/23491 (71%)]\tLoss: 0.704713\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:25 | INFO | Rank 0 | Train Epoch: 3 [16672/23491 (71%)]\tLoss: 0.837188\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000061\tlogit_scale 4.552\n",
      "2022-11-08,05:38:25 | INFO | Rank 0 | Train Epoch: 3 [16704/23491 (71%)]\tLoss: 0.744039\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:25 | INFO | Rank 0 | Train Epoch: 3 [16736/23491 (71%)]\tLoss: 0.688212\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:25 | INFO | Rank 0 | Train Epoch: 3 [16768/23491 (71%)]\tLoss: 0.485295\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:26 | INFO | Rank 0 | Train Epoch: 3 [16800/23491 (72%)]\tLoss: 0.727157\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:26 | INFO | Rank 0 | Train Epoch: 3 [16832/23491 (72%)]\tLoss: 0.361301\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:26 | INFO | Rank 0 | Train Epoch: 3 [16864/23491 (72%)]\tLoss: 1.057689\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:26 | INFO | Rank 0 | Train Epoch: 3 [16896/23491 (72%)]\tLoss: 0.616781\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:27 | INFO | Rank 0 | Train Epoch: 3 [16928/23491 (72%)]\tLoss: 1.014894\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:27 | INFO | Rank 0 | Train Epoch: 3 [16960/23491 (72%)]\tLoss: 0.399363\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:27 | INFO | Rank 0 | Train Epoch: 3 [16992/23491 (72%)]\tLoss: 0.679353\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:28 | INFO | Rank 0 | Train Epoch: 3 [17024/23491 (72%)]\tLoss: 0.641436\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:28 | INFO | Rank 0 | Train Epoch: 3 [17056/23491 (73%)]\tLoss: 0.777143\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:28 | INFO | Rank 0 | Train Epoch: 3 [17088/23491 (73%)]\tLoss: 0.997648\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:28 | INFO | Rank 0 | Train Epoch: 3 [17120/23491 (73%)]\tLoss: 0.707489\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:29 | INFO | Rank 0 | Train Epoch: 3 [17152/23491 (73%)]\tLoss: 1.027682\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:29 | INFO | Rank 0 | Train Epoch: 3 [17184/23491 (73%)]\tLoss: 0.826011\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:29 | INFO | Rank 0 | Train Epoch: 3 [17216/23491 (73%)]\tLoss: 0.522670\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:29 | INFO | Rank 0 | Train Epoch: 3 [17248/23491 (73%)]\tLoss: 0.748279\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:30 | INFO | Rank 0 | Train Epoch: 3 [17280/23491 (74%)]\tLoss: 0.711785\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:30 | INFO | Rank 0 | Train Epoch: 3 [17312/23491 (74%)]\tLoss: 0.935332\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:30 | INFO | Rank 0 | Train Epoch: 3 [17344/23491 (74%)]\tLoss: 0.436899\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:30 | INFO | Rank 0 | Train Epoch: 3 [17376/23491 (74%)]\tLoss: 0.731051\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:31 | INFO | Rank 0 | Train Epoch: 3 [17408/23491 (74%)]\tLoss: 0.761412\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:31 | INFO | Rank 0 | Train Epoch: 3 [17440/23491 (74%)]\tLoss: 0.483554\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:31 | INFO | Rank 0 | Train Epoch: 3 [17472/23491 (74%)]\tLoss: 0.430426\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000061\tlogit_scale 4.551\n",
      "2022-11-08,05:38:32 | INFO | Rank 0 | Train Epoch: 3 [17504/23491 (75%)]\tLoss: 0.882272\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:32 | INFO | Rank 0 | Train Epoch: 3 [17536/23491 (75%)]\tLoss: 0.616536\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:32 | INFO | Rank 0 | Train Epoch: 3 [17568/23491 (75%)]\tLoss: 0.488710\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:32 | INFO | Rank 0 | Train Epoch: 3 [17600/23491 (75%)]\tLoss: 0.409444\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:33 | INFO | Rank 0 | Train Epoch: 3 [17632/23491 (75%)]\tLoss: 0.807508\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:33 | INFO | Rank 0 | Train Epoch: 3 [17664/23491 (75%)]\tLoss: 0.471982\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:33 | INFO | Rank 0 | Train Epoch: 3 [17696/23491 (75%)]\tLoss: 0.517418\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:33 | INFO | Rank 0 | Train Epoch: 3 [17728/23491 (75%)]\tLoss: 0.685066\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:34 | INFO | Rank 0 | Train Epoch: 3 [17760/23491 (76%)]\tLoss: 0.443009\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:34 | INFO | Rank 0 | Train Epoch: 3 [17792/23491 (76%)]\tLoss: 0.624596\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:34 | INFO | Rank 0 | Train Epoch: 3 [17824/23491 (76%)]\tLoss: 0.806980\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:34 | INFO | Rank 0 | Train Epoch: 3 [17856/23491 (76%)]\tLoss: 1.055714\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:35 | INFO | Rank 0 | Train Epoch: 3 [17888/23491 (76%)]\tLoss: 1.103713\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:35 | INFO | Rank 0 | Train Epoch: 3 [17920/23491 (76%)]\tLoss: 0.563530\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:35 | INFO | Rank 0 | Train Epoch: 3 [17952/23491 (76%)]\tLoss: 0.790893\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:35 | INFO | Rank 0 | Train Epoch: 3 [17984/23491 (77%)]\tLoss: 0.722019\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:36 | INFO | Rank 0 | Train Epoch: 3 [18016/23491 (77%)]\tLoss: 0.366680\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:36 | INFO | Rank 0 | Train Epoch: 3 [18048/23491 (77%)]\tLoss: 0.759832\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:36 | INFO | Rank 0 | Train Epoch: 3 [18080/23491 (77%)]\tLoss: 0.816732\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:37 | INFO | Rank 0 | Train Epoch: 3 [18112/23491 (77%)]\tLoss: 0.921809\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:37 | INFO | Rank 0 | Train Epoch: 3 [18144/23491 (77%)]\tLoss: 0.579093\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:37 | INFO | Rank 0 | Train Epoch: 3 [18176/23491 (77%)]\tLoss: 0.639905\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:37 | INFO | Rank 0 | Train Epoch: 3 [18208/23491 (78%)]\tLoss: 1.481594\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:38 | INFO | Rank 0 | Train Epoch: 3 [18240/23491 (78%)]\tLoss: 0.722817\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:38 | INFO | Rank 0 | Train Epoch: 3 [18272/23491 (78%)]\tLoss: 0.775992\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:38 | INFO | Rank 0 | Train Epoch: 3 [18304/23491 (78%)]\tLoss: 0.828868\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:38 | INFO | Rank 0 | Train Epoch: 3 [18336/23491 (78%)]\tLoss: 0.851561\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:39 | INFO | Rank 0 | Train Epoch: 3 [18368/23491 (78%)]\tLoss: 0.655633\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:39 | INFO | Rank 0 | Train Epoch: 3 [18400/23491 (78%)]\tLoss: 0.826649\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:39 | INFO | Rank 0 | Train Epoch: 3 [18432/23491 (78%)]\tLoss: 0.668107\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:39 | INFO | Rank 0 | Train Epoch: 3 [18464/23491 (79%)]\tLoss: 0.637678\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:40 | INFO | Rank 0 | Train Epoch: 3 [18496/23491 (79%)]\tLoss: 0.512183\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:40 | INFO | Rank 0 | Train Epoch: 3 [18528/23491 (79%)]\tLoss: 0.677626\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:40 | INFO | Rank 0 | Train Epoch: 3 [18560/23491 (79%)]\tLoss: 0.699865\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:41 | INFO | Rank 0 | Train Epoch: 3 [18592/23491 (79%)]\tLoss: 0.781566\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:41 | INFO | Rank 0 | Train Epoch: 3 [18624/23491 (79%)]\tLoss: 0.477622\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:41 | INFO | Rank 0 | Train Epoch: 3 [18656/23491 (79%)]\tLoss: 0.489464\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:41 | INFO | Rank 0 | Train Epoch: 3 [18688/23491 (80%)]\tLoss: 0.673612\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:42 | INFO | Rank 0 | Train Epoch: 3 [18720/23491 (80%)]\tLoss: 0.529245\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:42 | INFO | Rank 0 | Train Epoch: 3 [18752/23491 (80%)]\tLoss: 0.724045\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:42 | INFO | Rank 0 | Train Epoch: 3 [18784/23491 (80%)]\tLoss: 0.609996\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:42 | INFO | Rank 0 | Train Epoch: 3 [18816/23491 (80%)]\tLoss: 0.738808\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:43 | INFO | Rank 0 | Train Epoch: 3 [18848/23491 (80%)]\tLoss: 0.626773\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:43 | INFO | Rank 0 | Train Epoch: 3 [18880/23491 (80%)]\tLoss: 0.670701\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:43 | INFO | Rank 0 | Train Epoch: 3 [18912/23491 (81%)]\tLoss: 0.880854\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:43 | INFO | Rank 0 | Train Epoch: 3 [18944/23491 (81%)]\tLoss: 0.669527\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:44 | INFO | Rank 0 | Train Epoch: 3 [18976/23491 (81%)]\tLoss: 0.565484\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:44 | INFO | Rank 0 | Train Epoch: 3 [19008/23491 (81%)]\tLoss: 0.581384\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:44 | INFO | Rank 0 | Train Epoch: 3 [19040/23491 (81%)]\tLoss: 0.821859\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:45 | INFO | Rank 0 | Train Epoch: 3 [19072/23491 (81%)]\tLoss: 0.556747\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:45 | INFO | Rank 0 | Train Epoch: 3 [19104/23491 (81%)]\tLoss: 0.708405\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:45 | INFO | Rank 0 | Train Epoch: 3 [19136/23491 (81%)]\tLoss: 1.071429\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:45 | INFO | Rank 0 | Train Epoch: 3 [19168/23491 (82%)]\tLoss: 0.527108\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:46 | INFO | Rank 0 | Train Epoch: 3 [19200/23491 (82%)]\tLoss: 0.825509\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:46 | INFO | Rank 0 | Train Epoch: 3 [19232/23491 (82%)]\tLoss: 0.600998\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.551\n",
      "2022-11-08,05:38:46 | INFO | Rank 0 | Train Epoch: 3 [19264/23491 (82%)]\tLoss: 1.324545\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000060\tlogit_scale 4.550\n",
      "2022-11-08,05:38:46 | INFO | Rank 0 | Train Epoch: 3 [19296/23491 (82%)]\tLoss: 0.891802\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.550\n",
      "2022-11-08,05:38:47 | INFO | Rank 0 | Train Epoch: 3 [19328/23491 (82%)]\tLoss: 0.888258\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000060\tlogit_scale 4.550\n",
      "2022-11-08,05:38:47 | INFO | Rank 0 | Train Epoch: 3 [19360/23491 (82%)]\tLoss: 0.801336\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000060\tlogit_scale 4.550\n",
      "2022-11-08,05:38:47 | INFO | Rank 0 | Train Epoch: 3 [19392/23491 (83%)]\tLoss: 0.368531\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.550\n",
      "2022-11-08,05:38:47 | INFO | Rank 0 | Train Epoch: 3 [19424/23491 (83%)]\tLoss: 0.888202\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.550\n",
      "2022-11-08,05:38:48 | INFO | Rank 0 | Train Epoch: 3 [19456/23491 (83%)]\tLoss: 0.902112\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.550\n",
      "2022-11-08,05:38:48 | INFO | Rank 0 | Train Epoch: 3 [19488/23491 (83%)]\tLoss: 0.949394\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000060\tlogit_scale 4.550\n",
      "2022-11-08,05:38:48 | INFO | Rank 0 | Train Epoch: 3 [19520/23491 (83%)]\tLoss: 0.746542\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:49 | INFO | Rank 0 | Train Epoch: 3 [19552/23491 (83%)]\tLoss: 0.885049\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:49 | INFO | Rank 0 | Train Epoch: 3 [19584/23491 (83%)]\tLoss: 0.708505\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:49 | INFO | Rank 0 | Train Epoch: 3 [19616/23491 (84%)]\tLoss: 0.436124\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:49 | INFO | Rank 0 | Train Epoch: 3 [19648/23491 (84%)]\tLoss: 0.370574\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:50 | INFO | Rank 0 | Train Epoch: 3 [19680/23491 (84%)]\tLoss: 0.851691\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:50 | INFO | Rank 0 | Train Epoch: 3 [19712/23491 (84%)]\tLoss: 0.448503\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:50 | INFO | Rank 0 | Train Epoch: 3 [19744/23491 (84%)]\tLoss: 0.655453\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:50 | INFO | Rank 0 | Train Epoch: 3 [19776/23491 (84%)]\tLoss: 0.700289\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:51 | INFO | Rank 0 | Train Epoch: 3 [19808/23491 (84%)]\tLoss: 0.638256\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:51 | INFO | Rank 0 | Train Epoch: 3 [19840/23491 (84%)]\tLoss: 0.591544\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:51 | INFO | Rank 0 | Train Epoch: 3 [19872/23491 (85%)]\tLoss: 0.707339\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:51 | INFO | Rank 0 | Train Epoch: 3 [19904/23491 (85%)]\tLoss: 0.504988\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:52 | INFO | Rank 0 | Train Epoch: 3 [19936/23491 (85%)]\tLoss: 0.786821\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:52 | INFO | Rank 0 | Train Epoch: 3 [19968/23491 (85%)]\tLoss: 0.641067\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:52 | INFO | Rank 0 | Train Epoch: 3 [20000/23491 (85%)]\tLoss: 0.871829\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:53 | INFO | Rank 0 | Train Epoch: 3 [20032/23491 (85%)]\tLoss: 0.933495\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:53 | INFO | Rank 0 | Train Epoch: 3 [20064/23491 (85%)]\tLoss: 0.847462\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:53 | INFO | Rank 0 | Train Epoch: 3 [20096/23491 (86%)]\tLoss: 0.344005\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:53 | INFO | Rank 0 | Train Epoch: 3 [20128/23491 (86%)]\tLoss: 1.021379\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:54 | INFO | Rank 0 | Train Epoch: 3 [20160/23491 (86%)]\tLoss: 1.070728\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:54 | INFO | Rank 0 | Train Epoch: 3 [20192/23491 (86%)]\tLoss: 0.763183\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:54 | INFO | Rank 0 | Train Epoch: 3 [20224/23491 (86%)]\tLoss: 0.830103\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:54 | INFO | Rank 0 | Train Epoch: 3 [20256/23491 (86%)]\tLoss: 0.953588\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:55 | INFO | Rank 0 | Train Epoch: 3 [20288/23491 (86%)]\tLoss: 0.854048\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:55 | INFO | Rank 0 | Train Epoch: 3 [20320/23491 (87%)]\tLoss: 1.109395\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:55 | INFO | Rank 0 | Train Epoch: 3 [20352/23491 (87%)]\tLoss: 1.008559\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:55 | INFO | Rank 0 | Train Epoch: 3 [20384/23491 (87%)]\tLoss: 0.632324\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:56 | INFO | Rank 0 | Train Epoch: 3 [20416/23491 (87%)]\tLoss: 0.980048\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:56 | INFO | Rank 0 | Train Epoch: 3 [20448/23491 (87%)]\tLoss: 0.420528\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:56 | INFO | Rank 0 | Train Epoch: 3 [20480/23491 (87%)]\tLoss: 0.468991\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:56 | INFO | Rank 0 | Train Epoch: 3 [20512/23491 (87%)]\tLoss: 0.356693\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:57 | INFO | Rank 0 | Train Epoch: 3 [20544/23491 (87%)]\tLoss: 0.794254\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:57 | INFO | Rank 0 | Train Epoch: 3 [20576/23491 (88%)]\tLoss: 0.675360\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:57 | INFO | Rank 0 | Train Epoch: 3 [20608/23491 (88%)]\tLoss: 0.883534\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:58 | INFO | Rank 0 | Train Epoch: 3 [20640/23491 (88%)]\tLoss: 0.775670\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:58 | INFO | Rank 0 | Train Epoch: 3 [20672/23491 (88%)]\tLoss: 0.681610\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:58 | INFO | Rank 0 | Train Epoch: 3 [20704/23491 (88%)]\tLoss: 0.736062\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:58 | INFO | Rank 0 | Train Epoch: 3 [20736/23491 (88%)]\tLoss: 0.861436\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:59 | INFO | Rank 0 | Train Epoch: 3 [20768/23491 (88%)]\tLoss: 0.869119\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:59 | INFO | Rank 0 | Train Epoch: 3 [20800/23491 (89%)]\tLoss: 0.594845\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:59 | INFO | Rank 0 | Train Epoch: 3 [20832/23491 (89%)]\tLoss: 0.407744\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:38:59 | INFO | Rank 0 | Train Epoch: 3 [20864/23491 (89%)]\tLoss: 0.498769\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:00 | INFO | Rank 0 | Train Epoch: 3 [20896/23491 (89%)]\tLoss: 0.756045\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:00 | INFO | Rank 0 | Train Epoch: 3 [20928/23491 (89%)]\tLoss: 0.694838\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:00 | INFO | Rank 0 | Train Epoch: 3 [20960/23491 (89%)]\tLoss: 0.493663\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:00 | INFO | Rank 0 | Train Epoch: 3 [20992/23491 (89%)]\tLoss: 0.610919\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:01 | INFO | Rank 0 | Train Epoch: 3 [21024/23491 (90%)]\tLoss: 1.002629\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:01 | INFO | Rank 0 | Train Epoch: 3 [21056/23491 (90%)]\tLoss: 0.741347\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:01 | INFO | Rank 0 | Train Epoch: 3 [21088/23491 (90%)]\tLoss: 0.478217\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:02 | INFO | Rank 0 | Train Epoch: 3 [21120/23491 (90%)]\tLoss: 1.127143\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:02 | INFO | Rank 0 | Train Epoch: 3 [21152/23491 (90%)]\tLoss: 0.682689\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:02 | INFO | Rank 0 | Train Epoch: 3 [21184/23491 (90%)]\tLoss: 0.713760\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:02 | INFO | Rank 0 | Train Epoch: 3 [21216/23491 (90%)]\tLoss: 0.765216\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:03 | INFO | Rank 0 | Train Epoch: 3 [21248/23491 (90%)]\tLoss: 0.708795\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:03 | INFO | Rank 0 | Train Epoch: 3 [21280/23491 (91%)]\tLoss: 0.893767\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:03 | INFO | Rank 0 | Train Epoch: 3 [21312/23491 (91%)]\tLoss: 0.720953\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:03 | INFO | Rank 0 | Train Epoch: 3 [21344/23491 (91%)]\tLoss: 0.742450\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:04 | INFO | Rank 0 | Train Epoch: 3 [21376/23491 (91%)]\tLoss: 0.635493\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:04 | INFO | Rank 0 | Train Epoch: 3 [21408/23491 (91%)]\tLoss: 0.706198\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:04 | INFO | Rank 0 | Train Epoch: 3 [21440/23491 (91%)]\tLoss: 0.644829\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:04 | INFO | Rank 0 | Train Epoch: 3 [21472/23491 (91%)]\tLoss: 0.611612\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000059\tlogit_scale 4.550\n",
      "2022-11-08,05:39:05 | INFO | Rank 0 | Train Epoch: 3 [21504/23491 (92%)]\tLoss: 0.606048\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.550\n",
      "2022-11-08,05:39:05 | INFO | Rank 0 | Train Epoch: 3 [21536/23491 (92%)]\tLoss: 0.948128\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.550\n",
      "2022-11-08,05:39:05 | INFO | Rank 0 | Train Epoch: 3 [21568/23491 (92%)]\tLoss: 0.814930\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.550\n",
      "2022-11-08,05:39:06 | INFO | Rank 0 | Train Epoch: 3 [21600/23491 (92%)]\tLoss: 0.535400\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.550\n",
      "2022-11-08,05:39:06 | INFO | Rank 0 | Train Epoch: 3 [21632/23491 (92%)]\tLoss: 0.988053\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.550\n",
      "2022-11-08,05:39:06 | INFO | Rank 0 | Train Epoch: 3 [21664/23491 (92%)]\tLoss: 0.670360\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.550\n",
      "2022-11-08,05:39:06 | INFO | Rank 0 | Train Epoch: 3 [21696/23491 (92%)]\tLoss: 1.037518\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.550\n",
      "2022-11-08,05:39:07 | INFO | Rank 0 | Train Epoch: 3 [21728/23491 (93%)]\tLoss: 0.882815\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.550\n",
      "2022-11-08,05:39:07 | INFO | Rank 0 | Train Epoch: 3 [21760/23491 (93%)]\tLoss: 0.714573\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.550\n",
      "2022-11-08,05:39:07 | INFO | Rank 0 | Train Epoch: 3 [21792/23491 (93%)]\tLoss: 0.831285\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.550\n",
      "2022-11-08,05:39:07 | INFO | Rank 0 | Train Epoch: 3 [21824/23491 (93%)]\tLoss: 0.751601\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.550\n",
      "2022-11-08,05:39:08 | INFO | Rank 0 | Train Epoch: 3 [21856/23491 (93%)]\tLoss: 0.679446\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.550\n",
      "2022-11-08,05:39:08 | INFO | Rank 0 | Train Epoch: 3 [21888/23491 (93%)]\tLoss: 0.751066\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.550\n",
      "2022-11-08,05:39:08 | INFO | Rank 0 | Train Epoch: 3 [21920/23491 (93%)]\tLoss: 0.721838\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.550\n",
      "2022-11-08,05:39:08 | INFO | Rank 0 | Train Epoch: 3 [21952/23491 (93%)]\tLoss: 0.858568\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:09 | INFO | Rank 0 | Train Epoch: 3 [21984/23491 (94%)]\tLoss: 0.564474\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:09 | INFO | Rank 0 | Train Epoch: 3 [22016/23491 (94%)]\tLoss: 0.556269\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:09 | INFO | Rank 0 | Train Epoch: 3 [22048/23491 (94%)]\tLoss: 0.797531\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:10 | INFO | Rank 0 | Train Epoch: 3 [22080/23491 (94%)]\tLoss: 0.577192\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:10 | INFO | Rank 0 | Train Epoch: 3 [22112/23491 (94%)]\tLoss: 0.651327\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:10 | INFO | Rank 0 | Train Epoch: 3 [22144/23491 (94%)]\tLoss: 0.650405\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:10 | INFO | Rank 0 | Train Epoch: 3 [22176/23491 (94%)]\tLoss: 0.460292\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:11 | INFO | Rank 0 | Train Epoch: 3 [22208/23491 (95%)]\tLoss: 0.891116\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:11 | INFO | Rank 0 | Train Epoch: 3 [22240/23491 (95%)]\tLoss: 0.750850\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:11 | INFO | Rank 0 | Train Epoch: 3 [22272/23491 (95%)]\tLoss: 0.526230\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:11 | INFO | Rank 0 | Train Epoch: 3 [22304/23491 (95%)]\tLoss: 0.696401\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:12 | INFO | Rank 0 | Train Epoch: 3 [22336/23491 (95%)]\tLoss: 0.745502\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:12 | INFO | Rank 0 | Train Epoch: 3 [22368/23491 (95%)]\tLoss: 0.607932\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:12 | INFO | Rank 0 | Train Epoch: 3 [22400/23491 (95%)]\tLoss: 0.871512\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:12 | INFO | Rank 0 | Train Epoch: 3 [22432/23491 (96%)]\tLoss: 0.611379\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:13 | INFO | Rank 0 | Train Epoch: 3 [22464/23491 (96%)]\tLoss: 1.052355\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:13 | INFO | Rank 0 | Train Epoch: 3 [22496/23491 (96%)]\tLoss: 0.903580\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:13 | INFO | Rank 0 | Train Epoch: 3 [22528/23491 (96%)]\tLoss: 0.559777\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:14 | INFO | Rank 0 | Train Epoch: 3 [22560/23491 (96%)]\tLoss: 0.525276\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:14 | INFO | Rank 0 | Train Epoch: 3 [22592/23491 (96%)]\tLoss: 0.618745\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:14 | INFO | Rank 0 | Train Epoch: 3 [22624/23491 (96%)]\tLoss: 0.800406\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:14 | INFO | Rank 0 | Train Epoch: 3 [22656/23491 (96%)]\tLoss: 0.589170\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:15 | INFO | Rank 0 | Train Epoch: 3 [22688/23491 (97%)]\tLoss: 0.907671\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:15 | INFO | Rank 0 | Train Epoch: 3 [22720/23491 (97%)]\tLoss: 0.713214\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:15 | INFO | Rank 0 | Train Epoch: 3 [22752/23491 (97%)]\tLoss: 0.561615\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:15 | INFO | Rank 0 | Train Epoch: 3 [22784/23491 (97%)]\tLoss: 0.858101\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:16 | INFO | Rank 0 | Train Epoch: 3 [22816/23491 (97%)]\tLoss: 0.728949\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:16 | INFO | Rank 0 | Train Epoch: 3 [22848/23491 (97%)]\tLoss: 0.625155\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:16 | INFO | Rank 0 | Train Epoch: 3 [22880/23491 (97%)]\tLoss: 0.430344\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:16 | INFO | Rank 0 | Train Epoch: 3 [22912/23491 (98%)]\tLoss: 0.806790\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:17 | INFO | Rank 0 | Train Epoch: 3 [22944/23491 (98%)]\tLoss: 0.717214\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:17 | INFO | Rank 0 | Train Epoch: 3 [22976/23491 (98%)]\tLoss: 0.839890\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:17 | INFO | Rank 0 | Train Epoch: 3 [23008/23491 (98%)]\tLoss: 0.973929\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:17 | INFO | Rank 0 | Train Epoch: 3 [23040/23491 (98%)]\tLoss: 0.740831\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:18 | INFO | Rank 0 | Train Epoch: 3 [23072/23491 (98%)]\tLoss: 0.664973\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:18 | INFO | Rank 0 | Train Epoch: 3 [23104/23491 (98%)]\tLoss: 0.726867\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:18 | INFO | Rank 0 | Train Epoch: 3 [23136/23491 (99%)]\tLoss: 0.555226\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:19 | INFO | Rank 0 | Train Epoch: 3 [23168/23491 (99%)]\tLoss: 0.945579\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:19 | INFO | Rank 0 | Train Epoch: 3 [23200/23491 (99%)]\tLoss: 0.461564\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:19 | INFO | Rank 0 | Train Epoch: 3 [23232/23491 (99%)]\tLoss: 1.134156\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:19 | INFO | Rank 0 | Train Epoch: 3 [23264/23491 (99%)]\tLoss: 0.926094\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:20 | INFO | Rank 0 | Train Epoch: 3 [23296/23491 (99%)]\tLoss: 0.698455\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:20 | INFO | Rank 0 | Train Epoch: 3 [23328/23491 (99%)]\tLoss: 0.826114\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:20 | INFO | Rank 0 | Train Epoch: 3 [23360/23491 (99%)]\tLoss: 0.565041\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:20 | INFO | Rank 0 | Train Epoch: 3 [23392/23491 (100%)]\tLoss: 0.437293\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:21 | INFO | Rank 0 | Train Epoch: 3 [23424/23491 (100%)]\tLoss: 0.549454\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000058\tlogit_scale 4.549\n",
      "2022-11-08,05:39:21 | INFO | Rank 0 | Train Epoch: 3 [23456/23491 (100%)]\tLoss: 0.990941\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000057\tlogit_scale 4.549\n",
      "  0%|                                                   | 0/386 [00:00<?, ?it/s]2022-11-08,05:39:21 | INFO | Rank 0 | Begin to eval epoch: 4...\n",
      "100%|█████████████████████████████████████████| 386/386 [00:46<00:00,  8.36it/s]\n",
      "2022-11-08,05:40:07 | INFO | Rank 0 | Eval Epoch: 4 val_loss: 2.4403\tepoch: 4.0000\tnum_elements: 12328.0000\n",
      "2022-11-08,05:40:07 | INFO | Rank 0 | Start epoch 4\n",
      "2022-11-08,05:40:07 | INFO | Rank 0 | Train Epoch: 4 [0/23491 (0%)]\tLoss: 0.585919\tData (t) 0.035\tBatch (t) 0.249\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:08 | INFO | Rank 0 | Train Epoch: 4 [32/23491 (0%)]\tLoss: 0.575123\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:08 | INFO | Rank 0 | Train Epoch: 4 [64/23491 (0%)]\tLoss: 0.341435\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:08 | INFO | Rank 0 | Train Epoch: 4 [96/23491 (0%)]\tLoss: 0.455123\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:08 | INFO | Rank 0 | Train Epoch: 4 [128/23491 (1%)]\tLoss: 0.575083\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:09 | INFO | Rank 0 | Train Epoch: 4 [160/23491 (1%)]\tLoss: 0.300079\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:09 | INFO | Rank 0 | Train Epoch: 4 [192/23491 (1%)]\tLoss: 0.338789\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:09 | INFO | Rank 0 | Train Epoch: 4 [224/23491 (1%)]\tLoss: 0.406689\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:10 | INFO | Rank 0 | Train Epoch: 4 [256/23491 (1%)]\tLoss: 0.908819\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:10 | INFO | Rank 0 | Train Epoch: 4 [288/23491 (1%)]\tLoss: 0.590552\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:10 | INFO | Rank 0 | Train Epoch: 4 [320/23491 (1%)]\tLoss: 0.414346\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:10 | INFO | Rank 0 | Train Epoch: 4 [352/23491 (1%)]\tLoss: 0.401589\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:11 | INFO | Rank 0 | Train Epoch: 4 [384/23491 (2%)]\tLoss: 0.295040\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:11 | INFO | Rank 0 | Train Epoch: 4 [416/23491 (2%)]\tLoss: 0.300531\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:11 | INFO | Rank 0 | Train Epoch: 4 [448/23491 (2%)]\tLoss: 0.509164\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:11 | INFO | Rank 0 | Train Epoch: 4 [480/23491 (2%)]\tLoss: 0.451895\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:12 | INFO | Rank 0 | Train Epoch: 4 [512/23491 (2%)]\tLoss: 0.524133\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:12 | INFO | Rank 0 | Train Epoch: 4 [544/23491 (2%)]\tLoss: 0.457914\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:12 | INFO | Rank 0 | Train Epoch: 4 [576/23491 (2%)]\tLoss: 0.431129\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:12 | INFO | Rank 0 | Train Epoch: 4 [608/23491 (3%)]\tLoss: 0.301797\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:13 | INFO | Rank 0 | Train Epoch: 4 [640/23491 (3%)]\tLoss: 0.143693\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:13 | INFO | Rank 0 | Train Epoch: 4 [672/23491 (3%)]\tLoss: 0.266283\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:13 | INFO | Rank 0 | Train Epoch: 4 [704/23491 (3%)]\tLoss: 0.318736\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:14 | INFO | Rank 0 | Train Epoch: 4 [736/23491 (3%)]\tLoss: 0.318045\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:14 | INFO | Rank 0 | Train Epoch: 4 [768/23491 (3%)]\tLoss: 0.337567\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:14 | INFO | Rank 0 | Train Epoch: 4 [800/23491 (3%)]\tLoss: 0.226779\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:14 | INFO | Rank 0 | Train Epoch: 4 [832/23491 (4%)]\tLoss: 0.321057\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:15 | INFO | Rank 0 | Train Epoch: 4 [864/23491 (4%)]\tLoss: 0.352985\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:15 | INFO | Rank 0 | Train Epoch: 4 [896/23491 (4%)]\tLoss: 0.257995\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.550\n",
      "2022-11-08,05:40:15 | INFO | Rank 0 | Train Epoch: 4 [928/23491 (4%)]\tLoss: 0.490538\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.550\n",
      "2022-11-08,05:40:15 | INFO | Rank 0 | Train Epoch: 4 [960/23491 (4%)]\tLoss: 0.465096\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.550\n",
      "2022-11-08,05:40:16 | INFO | Rank 0 | Train Epoch: 4 [992/23491 (4%)]\tLoss: 0.194796\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.550\n",
      "2022-11-08,05:40:16 | INFO | Rank 0 | Train Epoch: 4 [1024/23491 (4%)]\tLoss: 0.340232\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.550\n",
      "2022-11-08,05:40:16 | INFO | Rank 0 | Train Epoch: 4 [1056/23491 (4%)]\tLoss: 0.243481\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.550\n",
      "2022-11-08,05:40:16 | INFO | Rank 0 | Train Epoch: 4 [1088/23491 (5%)]\tLoss: 0.638923\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.550\n",
      "2022-11-08,05:40:17 | INFO | Rank 0 | Train Epoch: 4 [1120/23491 (5%)]\tLoss: 0.475881\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.550\n",
      "2022-11-08,05:40:17 | INFO | Rank 0 | Train Epoch: 4 [1152/23491 (5%)]\tLoss: 0.465592\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.550\n",
      "2022-11-08,05:40:17 | INFO | Rank 0 | Train Epoch: 4 [1184/23491 (5%)]\tLoss: 0.652900\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.550\n",
      "2022-11-08,05:40:18 | INFO | Rank 0 | Train Epoch: 4 [1216/23491 (5%)]\tLoss: 0.597608\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.550\n",
      "2022-11-08,05:40:18 | INFO | Rank 0 | Train Epoch: 4 [1248/23491 (5%)]\tLoss: 0.382050\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.550\n",
      "2022-11-08,05:40:18 | INFO | Rank 0 | Train Epoch: 4 [1280/23491 (5%)]\tLoss: 0.585773\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000057\tlogit_scale 4.550\n",
      "2022-11-08,05:40:18 | INFO | Rank 0 | Train Epoch: 4 [1312/23491 (6%)]\tLoss: 0.417146\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.550\n",
      "2022-11-08,05:40:19 | INFO | Rank 0 | Train Epoch: 4 [1344/23491 (6%)]\tLoss: 0.499299\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:19 | INFO | Rank 0 | Train Epoch: 4 [1376/23491 (6%)]\tLoss: 0.666270\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:19 | INFO | Rank 0 | Train Epoch: 4 [1408/23491 (6%)]\tLoss: 0.427676\tData (t) 0.058\tBatch (t) 0.271\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:19 | INFO | Rank 0 | Train Epoch: 4 [1440/23491 (6%)]\tLoss: 0.479863\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:20 | INFO | Rank 0 | Train Epoch: 4 [1472/23491 (6%)]\tLoss: 0.567488\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:20 | INFO | Rank 0 | Train Epoch: 4 [1504/23491 (6%)]\tLoss: 0.382299\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:20 | INFO | Rank 0 | Train Epoch: 4 [1536/23491 (7%)]\tLoss: 0.260988\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:20 | INFO | Rank 0 | Train Epoch: 4 [1568/23491 (7%)]\tLoss: 0.463283\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:21 | INFO | Rank 0 | Train Epoch: 4 [1600/23491 (7%)]\tLoss: 0.611488\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:21 | INFO | Rank 0 | Train Epoch: 4 [1632/23491 (7%)]\tLoss: 0.278795\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:21 | INFO | Rank 0 | Train Epoch: 4 [1664/23491 (7%)]\tLoss: 0.623737\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:22 | INFO | Rank 0 | Train Epoch: 4 [1696/23491 (7%)]\tLoss: 0.509284\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:22 | INFO | Rank 0 | Train Epoch: 4 [1728/23491 (7%)]\tLoss: 0.595693\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:22 | INFO | Rank 0 | Train Epoch: 4 [1760/23491 (7%)]\tLoss: 0.349373\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:22 | INFO | Rank 0 | Train Epoch: 4 [1792/23491 (8%)]\tLoss: 0.533343\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:23 | INFO | Rank 0 | Train Epoch: 4 [1824/23491 (8%)]\tLoss: 0.334682\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:23 | INFO | Rank 0 | Train Epoch: 4 [1856/23491 (8%)]\tLoss: 0.336017\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000057\tlogit_scale 4.549\n",
      "2022-11-08,05:40:23 | INFO | Rank 0 | Train Epoch: 4 [1888/23491 (8%)]\tLoss: 0.531398\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:23 | INFO | Rank 0 | Train Epoch: 4 [1920/23491 (8%)]\tLoss: 0.478888\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:24 | INFO | Rank 0 | Train Epoch: 4 [1952/23491 (8%)]\tLoss: 0.367869\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:24 | INFO | Rank 0 | Train Epoch: 4 [1984/23491 (8%)]\tLoss: 0.193325\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:24 | INFO | Rank 0 | Train Epoch: 4 [2016/23491 (9%)]\tLoss: 0.301554\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:24 | INFO | Rank 0 | Train Epoch: 4 [2048/23491 (9%)]\tLoss: 0.542409\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:25 | INFO | Rank 0 | Train Epoch: 4 [2080/23491 (9%)]\tLoss: 0.413023\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:25 | INFO | Rank 0 | Train Epoch: 4 [2112/23491 (9%)]\tLoss: 0.696436\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:25 | INFO | Rank 0 | Train Epoch: 4 [2144/23491 (9%)]\tLoss: 0.347045\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:26 | INFO | Rank 0 | Train Epoch: 4 [2176/23491 (9%)]\tLoss: 0.560810\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:26 | INFO | Rank 0 | Train Epoch: 4 [2208/23491 (9%)]\tLoss: 0.349817\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:26 | INFO | Rank 0 | Train Epoch: 4 [2240/23491 (10%)]\tLoss: 0.429549\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:26 | INFO | Rank 0 | Train Epoch: 4 [2272/23491 (10%)]\tLoss: 0.699216\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:27 | INFO | Rank 0 | Train Epoch: 4 [2304/23491 (10%)]\tLoss: 0.866891\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:27 | INFO | Rank 0 | Train Epoch: 4 [2336/23491 (10%)]\tLoss: 0.424499\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:27 | INFO | Rank 0 | Train Epoch: 4 [2368/23491 (10%)]\tLoss: 0.618337\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:27 | INFO | Rank 0 | Train Epoch: 4 [2400/23491 (10%)]\tLoss: 0.555418\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:28 | INFO | Rank 0 | Train Epoch: 4 [2432/23491 (10%)]\tLoss: 0.698508\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:28 | INFO | Rank 0 | Train Epoch: 4 [2464/23491 (10%)]\tLoss: 0.682856\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:28 | INFO | Rank 0 | Train Epoch: 4 [2496/23491 (11%)]\tLoss: 0.454860\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:28 | INFO | Rank 0 | Train Epoch: 4 [2528/23491 (11%)]\tLoss: 0.422918\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:29 | INFO | Rank 0 | Train Epoch: 4 [2560/23491 (11%)]\tLoss: 0.450197\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:29 | INFO | Rank 0 | Train Epoch: 4 [2592/23491 (11%)]\tLoss: 0.339507\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:29 | INFO | Rank 0 | Train Epoch: 4 [2624/23491 (11%)]\tLoss: 0.583222\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:30 | INFO | Rank 0 | Train Epoch: 4 [2656/23491 (11%)]\tLoss: 0.410099\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:30 | INFO | Rank 0 | Train Epoch: 4 [2688/23491 (11%)]\tLoss: 0.650907\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:30 | INFO | Rank 0 | Train Epoch: 4 [2720/23491 (12%)]\tLoss: 0.767334\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:30 | INFO | Rank 0 | Train Epoch: 4 [2752/23491 (12%)]\tLoss: 0.391344\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:31 | INFO | Rank 0 | Train Epoch: 4 [2784/23491 (12%)]\tLoss: 0.339997\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:31 | INFO | Rank 0 | Train Epoch: 4 [2816/23491 (12%)]\tLoss: 0.597019\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:31 | INFO | Rank 0 | Train Epoch: 4 [2848/23491 (12%)]\tLoss: 0.497709\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:31 | INFO | Rank 0 | Train Epoch: 4 [2880/23491 (12%)]\tLoss: 0.296760\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:32 | INFO | Rank 0 | Train Epoch: 4 [2912/23491 (12%)]\tLoss: 0.500990\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:32 | INFO | Rank 0 | Train Epoch: 4 [2944/23491 (13%)]\tLoss: 0.481694\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:32 | INFO | Rank 0 | Train Epoch: 4 [2976/23491 (13%)]\tLoss: 0.481129\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:32 | INFO | Rank 0 | Train Epoch: 4 [3008/23491 (13%)]\tLoss: 0.547660\tData (t) 0.052\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:33 | INFO | Rank 0 | Train Epoch: 4 [3040/23491 (13%)]\tLoss: 0.418937\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:33 | INFO | Rank 0 | Train Epoch: 4 [3072/23491 (13%)]\tLoss: 0.341274\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:33 | INFO | Rank 0 | Train Epoch: 4 [3104/23491 (13%)]\tLoss: 0.340537\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:34 | INFO | Rank 0 | Train Epoch: 4 [3136/23491 (13%)]\tLoss: 0.299401\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:34 | INFO | Rank 0 | Train Epoch: 4 [3168/23491 (13%)]\tLoss: 0.362123\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:34 | INFO | Rank 0 | Train Epoch: 4 [3200/23491 (14%)]\tLoss: 0.355523\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:34 | INFO | Rank 0 | Train Epoch: 4 [3232/23491 (14%)]\tLoss: 0.473946\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:35 | INFO | Rank 0 | Train Epoch: 4 [3264/23491 (14%)]\tLoss: 0.283787\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:35 | INFO | Rank 0 | Train Epoch: 4 [3296/23491 (14%)]\tLoss: 0.450859\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:35 | INFO | Rank 0 | Train Epoch: 4 [3328/23491 (14%)]\tLoss: 0.609223\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:35 | INFO | Rank 0 | Train Epoch: 4 [3360/23491 (14%)]\tLoss: 0.491832\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:36 | INFO | Rank 0 | Train Epoch: 4 [3392/23491 (14%)]\tLoss: 0.677984\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:36 | INFO | Rank 0 | Train Epoch: 4 [3424/23491 (15%)]\tLoss: 0.347969\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:36 | INFO | Rank 0 | Train Epoch: 4 [3456/23491 (15%)]\tLoss: 0.530528\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:36 | INFO | Rank 0 | Train Epoch: 4 [3488/23491 (15%)]\tLoss: 0.774522\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:37 | INFO | Rank 0 | Train Epoch: 4 [3520/23491 (15%)]\tLoss: 0.415403\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:37 | INFO | Rank 0 | Train Epoch: 4 [3552/23491 (15%)]\tLoss: 0.184245\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:37 | INFO | Rank 0 | Train Epoch: 4 [3584/23491 (15%)]\tLoss: 0.421355\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:38 | INFO | Rank 0 | Train Epoch: 4 [3616/23491 (15%)]\tLoss: 0.314166\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:38 | INFO | Rank 0 | Train Epoch: 4 [3648/23491 (16%)]\tLoss: 0.511913\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:38 | INFO | Rank 0 | Train Epoch: 4 [3680/23491 (16%)]\tLoss: 0.573441\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:38 | INFO | Rank 0 | Train Epoch: 4 [3712/23491 (16%)]\tLoss: 0.448458\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:39 | INFO | Rank 0 | Train Epoch: 4 [3744/23491 (16%)]\tLoss: 0.668221\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000056\tlogit_scale 4.549\n",
      "2022-11-08,05:40:39 | INFO | Rank 0 | Train Epoch: 4 [3776/23491 (16%)]\tLoss: 0.903445\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:39 | INFO | Rank 0 | Train Epoch: 4 [3808/23491 (16%)]\tLoss: 0.418373\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:39 | INFO | Rank 0 | Train Epoch: 4 [3840/23491 (16%)]\tLoss: 0.333908\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:40 | INFO | Rank 0 | Train Epoch: 4 [3872/23491 (16%)]\tLoss: 0.456109\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:40 | INFO | Rank 0 | Train Epoch: 4 [3904/23491 (17%)]\tLoss: 0.550878\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:40 | INFO | Rank 0 | Train Epoch: 4 [3936/23491 (17%)]\tLoss: 0.597276\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:40 | INFO | Rank 0 | Train Epoch: 4 [3968/23491 (17%)]\tLoss: 0.331721\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:41 | INFO | Rank 0 | Train Epoch: 4 [4000/23491 (17%)]\tLoss: 0.225642\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:41 | INFO | Rank 0 | Train Epoch: 4 [4032/23491 (17%)]\tLoss: 0.629637\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:41 | INFO | Rank 0 | Train Epoch: 4 [4064/23491 (17%)]\tLoss: 0.662928\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:41 | INFO | Rank 0 | Train Epoch: 4 [4096/23491 (17%)]\tLoss: 0.300979\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:42 | INFO | Rank 0 | Train Epoch: 4 [4128/23491 (18%)]\tLoss: 0.432339\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:42 | INFO | Rank 0 | Train Epoch: 4 [4160/23491 (18%)]\tLoss: 0.282587\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:42 | INFO | Rank 0 | Train Epoch: 4 [4192/23491 (18%)]\tLoss: 0.573894\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:43 | INFO | Rank 0 | Train Epoch: 4 [4224/23491 (18%)]\tLoss: 0.462832\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:43 | INFO | Rank 0 | Train Epoch: 4 [4256/23491 (18%)]\tLoss: 0.467712\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:43 | INFO | Rank 0 | Train Epoch: 4 [4288/23491 (18%)]\tLoss: 0.491198\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:43 | INFO | Rank 0 | Train Epoch: 4 [4320/23491 (18%)]\tLoss: 0.265344\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:44 | INFO | Rank 0 | Train Epoch: 4 [4352/23491 (19%)]\tLoss: 0.562233\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:44 | INFO | Rank 0 | Train Epoch: 4 [4384/23491 (19%)]\tLoss: 0.565068\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:44 | INFO | Rank 0 | Train Epoch: 4 [4416/23491 (19%)]\tLoss: 0.883990\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:44 | INFO | Rank 0 | Train Epoch: 4 [4448/23491 (19%)]\tLoss: 0.294798\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:45 | INFO | Rank 0 | Train Epoch: 4 [4480/23491 (19%)]\tLoss: 0.303673\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:45 | INFO | Rank 0 | Train Epoch: 4 [4512/23491 (19%)]\tLoss: 0.547815\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:45 | INFO | Rank 0 | Train Epoch: 4 [4544/23491 (19%)]\tLoss: 0.603945\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:45 | INFO | Rank 0 | Train Epoch: 4 [4576/23491 (19%)]\tLoss: 0.631439\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:46 | INFO | Rank 0 | Train Epoch: 4 [4608/23491 (20%)]\tLoss: 0.326712\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:46 | INFO | Rank 0 | Train Epoch: 4 [4640/23491 (20%)]\tLoss: 0.273105\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:46 | INFO | Rank 0 | Train Epoch: 4 [4672/23491 (20%)]\tLoss: 0.476128\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:47 | INFO | Rank 0 | Train Epoch: 4 [4704/23491 (20%)]\tLoss: 0.480216\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:47 | INFO | Rank 0 | Train Epoch: 4 [4736/23491 (20%)]\tLoss: 0.608864\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:47 | INFO | Rank 0 | Train Epoch: 4 [4768/23491 (20%)]\tLoss: 0.316623\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:47 | INFO | Rank 0 | Train Epoch: 4 [4800/23491 (20%)]\tLoss: 0.439068\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:48 | INFO | Rank 0 | Train Epoch: 4 [4832/23491 (21%)]\tLoss: 0.101104\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:48 | INFO | Rank 0 | Train Epoch: 4 [4864/23491 (21%)]\tLoss: 0.355903\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:48 | INFO | Rank 0 | Train Epoch: 4 [4896/23491 (21%)]\tLoss: 0.443203\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:48 | INFO | Rank 0 | Train Epoch: 4 [4928/23491 (21%)]\tLoss: 0.556095\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:49 | INFO | Rank 0 | Train Epoch: 4 [4960/23491 (21%)]\tLoss: 0.326603\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:49 | INFO | Rank 0 | Train Epoch: 4 [4992/23491 (21%)]\tLoss: 0.436359\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:49 | INFO | Rank 0 | Train Epoch: 4 [5024/23491 (21%)]\tLoss: 0.437604\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.549\n",
      "2022-11-08,05:40:49 | INFO | Rank 0 | Train Epoch: 4 [5056/23491 (22%)]\tLoss: 0.536900\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:50 | INFO | Rank 0 | Train Epoch: 4 [5088/23491 (22%)]\tLoss: 0.641694\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:50 | INFO | Rank 0 | Train Epoch: 4 [5120/23491 (22%)]\tLoss: 0.410819\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:50 | INFO | Rank 0 | Train Epoch: 4 [5152/23491 (22%)]\tLoss: 0.739423\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:51 | INFO | Rank 0 | Train Epoch: 4 [5184/23491 (22%)]\tLoss: 0.340189\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:51 | INFO | Rank 0 | Train Epoch: 4 [5216/23491 (22%)]\tLoss: 0.218531\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:51 | INFO | Rank 0 | Train Epoch: 4 [5248/23491 (22%)]\tLoss: 0.374178\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:51 | INFO | Rank 0 | Train Epoch: 4 [5280/23491 (22%)]\tLoss: 0.562895\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:52 | INFO | Rank 0 | Train Epoch: 4 [5312/23491 (23%)]\tLoss: 0.307567\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:52 | INFO | Rank 0 | Train Epoch: 4 [5344/23491 (23%)]\tLoss: 0.211582\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:52 | INFO | Rank 0 | Train Epoch: 4 [5376/23491 (23%)]\tLoss: 0.371625\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:52 | INFO | Rank 0 | Train Epoch: 4 [5408/23491 (23%)]\tLoss: 0.254241\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:53 | INFO | Rank 0 | Train Epoch: 4 [5440/23491 (23%)]\tLoss: 0.666834\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:53 | INFO | Rank 0 | Train Epoch: 4 [5472/23491 (23%)]\tLoss: 0.357523\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:53 | INFO | Rank 0 | Train Epoch: 4 [5504/23491 (23%)]\tLoss: 0.479757\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:53 | INFO | Rank 0 | Train Epoch: 4 [5536/23491 (24%)]\tLoss: 0.701870\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:54 | INFO | Rank 0 | Train Epoch: 4 [5568/23491 (24%)]\tLoss: 0.458987\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:54 | INFO | Rank 0 | Train Epoch: 4 [5600/23491 (24%)]\tLoss: 0.732024\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:54 | INFO | Rank 0 | Train Epoch: 4 [5632/23491 (24%)]\tLoss: 0.894780\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000055\tlogit_scale 4.548\n",
      "2022-11-08,05:40:55 | INFO | Rank 0 | Train Epoch: 4 [5664/23491 (24%)]\tLoss: 0.283168\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:55 | INFO | Rank 0 | Train Epoch: 4 [5696/23491 (24%)]\tLoss: 0.286786\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:55 | INFO | Rank 0 | Train Epoch: 4 [5728/23491 (24%)]\tLoss: 0.485525\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:55 | INFO | Rank 0 | Train Epoch: 4 [5760/23491 (25%)]\tLoss: 0.555615\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:56 | INFO | Rank 0 | Train Epoch: 4 [5792/23491 (25%)]\tLoss: 0.455619\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:56 | INFO | Rank 0 | Train Epoch: 4 [5824/23491 (25%)]\tLoss: 0.550197\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:56 | INFO | Rank 0 | Train Epoch: 4 [5856/23491 (25%)]\tLoss: 0.310052\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:56 | INFO | Rank 0 | Train Epoch: 4 [5888/23491 (25%)]\tLoss: 0.455979\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:57 | INFO | Rank 0 | Train Epoch: 4 [5920/23491 (25%)]\tLoss: 0.587041\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:57 | INFO | Rank 0 | Train Epoch: 4 [5952/23491 (25%)]\tLoss: 0.477436\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:57 | INFO | Rank 0 | Train Epoch: 4 [5984/23491 (25%)]\tLoss: 0.567573\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:57 | INFO | Rank 0 | Train Epoch: 4 [6016/23491 (26%)]\tLoss: 0.363201\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:58 | INFO | Rank 0 | Train Epoch: 4 [6048/23491 (26%)]\tLoss: 0.477298\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:58 | INFO | Rank 0 | Train Epoch: 4 [6080/23491 (26%)]\tLoss: 0.334362\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:58 | INFO | Rank 0 | Train Epoch: 4 [6112/23491 (26%)]\tLoss: 0.572058\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:59 | INFO | Rank 0 | Train Epoch: 4 [6144/23491 (26%)]\tLoss: 0.272496\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:59 | INFO | Rank 0 | Train Epoch: 4 [6176/23491 (26%)]\tLoss: 0.484102\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:59 | INFO | Rank 0 | Train Epoch: 4 [6208/23491 (26%)]\tLoss: 0.555929\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:40:59 | INFO | Rank 0 | Train Epoch: 4 [6240/23491 (27%)]\tLoss: 0.351948\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:00 | INFO | Rank 0 | Train Epoch: 4 [6272/23491 (27%)]\tLoss: 0.469805\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:00 | INFO | Rank 0 | Train Epoch: 4 [6304/23491 (27%)]\tLoss: 0.390716\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:00 | INFO | Rank 0 | Train Epoch: 4 [6336/23491 (27%)]\tLoss: 0.432733\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:00 | INFO | Rank 0 | Train Epoch: 4 [6368/23491 (27%)]\tLoss: 0.490081\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:01 | INFO | Rank 0 | Train Epoch: 4 [6400/23491 (27%)]\tLoss: 0.263848\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:01 | INFO | Rank 0 | Train Epoch: 4 [6432/23491 (27%)]\tLoss: 0.464081\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:01 | INFO | Rank 0 | Train Epoch: 4 [6464/23491 (28%)]\tLoss: 0.470796\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:01 | INFO | Rank 0 | Train Epoch: 4 [6496/23491 (28%)]\tLoss: 0.526967\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:02 | INFO | Rank 0 | Train Epoch: 4 [6528/23491 (28%)]\tLoss: 0.600228\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:02 | INFO | Rank 0 | Train Epoch: 4 [6560/23491 (28%)]\tLoss: 0.563629\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:02 | INFO | Rank 0 | Train Epoch: 4 [6592/23491 (28%)]\tLoss: 0.524199\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:03 | INFO | Rank 0 | Train Epoch: 4 [6624/23491 (28%)]\tLoss: 0.501641\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:03 | INFO | Rank 0 | Train Epoch: 4 [6656/23491 (28%)]\tLoss: 0.283873\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:03 | INFO | Rank 0 | Train Epoch: 4 [6688/23491 (28%)]\tLoss: 0.398705\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:03 | INFO | Rank 0 | Train Epoch: 4 [6720/23491 (29%)]\tLoss: 0.370449\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:04 | INFO | Rank 0 | Train Epoch: 4 [6752/23491 (29%)]\tLoss: 0.558523\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:04 | INFO | Rank 0 | Train Epoch: 4 [6784/23491 (29%)]\tLoss: 0.335815\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:04 | INFO | Rank 0 | Train Epoch: 4 [6816/23491 (29%)]\tLoss: 0.298099\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:04 | INFO | Rank 0 | Train Epoch: 4 [6848/23491 (29%)]\tLoss: 0.324541\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:05 | INFO | Rank 0 | Train Epoch: 4 [6880/23491 (29%)]\tLoss: 0.438535\tData (t) 0.055\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:05 | INFO | Rank 0 | Train Epoch: 4 [6912/23491 (29%)]\tLoss: 0.821378\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:05 | INFO | Rank 0 | Train Epoch: 4 [6944/23491 (30%)]\tLoss: 0.231166\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:05 | INFO | Rank 0 | Train Epoch: 4 [6976/23491 (30%)]\tLoss: 0.555779\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:06 | INFO | Rank 0 | Train Epoch: 4 [7008/23491 (30%)]\tLoss: 0.416755\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:06 | INFO | Rank 0 | Train Epoch: 4 [7040/23491 (30%)]\tLoss: 0.691268\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:06 | INFO | Rank 0 | Train Epoch: 4 [7072/23491 (30%)]\tLoss: 0.563174\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:07 | INFO | Rank 0 | Train Epoch: 4 [7104/23491 (30%)]\tLoss: 0.582070\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:07 | INFO | Rank 0 | Train Epoch: 4 [7136/23491 (30%)]\tLoss: 0.452750\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:07 | INFO | Rank 0 | Train Epoch: 4 [7168/23491 (31%)]\tLoss: 0.317615\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:07 | INFO | Rank 0 | Train Epoch: 4 [7200/23491 (31%)]\tLoss: 0.270222\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:08 | INFO | Rank 0 | Train Epoch: 4 [7232/23491 (31%)]\tLoss: 0.364691\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:08 | INFO | Rank 0 | Train Epoch: 4 [7264/23491 (31%)]\tLoss: 0.552798\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:08 | INFO | Rank 0 | Train Epoch: 4 [7296/23491 (31%)]\tLoss: 0.879313\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:08 | INFO | Rank 0 | Train Epoch: 4 [7328/23491 (31%)]\tLoss: 0.689656\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:09 | INFO | Rank 0 | Train Epoch: 4 [7360/23491 (31%)]\tLoss: 0.623547\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:09 | INFO | Rank 0 | Train Epoch: 4 [7392/23491 (31%)]\tLoss: 0.378941\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:09 | INFO | Rank 0 | Train Epoch: 4 [7424/23491 (32%)]\tLoss: 0.473711\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:09 | INFO | Rank 0 | Train Epoch: 4 [7456/23491 (32%)]\tLoss: 0.705782\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:10 | INFO | Rank 0 | Train Epoch: 4 [7488/23491 (32%)]\tLoss: 0.420559\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000054\tlogit_scale 4.548\n",
      "2022-11-08,05:41:10 | INFO | Rank 0 | Train Epoch: 4 [7520/23491 (32%)]\tLoss: 0.406892\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:10 | INFO | Rank 0 | Train Epoch: 4 [7552/23491 (32%)]\tLoss: 0.260665\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:11 | INFO | Rank 0 | Train Epoch: 4 [7584/23491 (32%)]\tLoss: 0.325009\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:11 | INFO | Rank 0 | Train Epoch: 4 [7616/23491 (32%)]\tLoss: 0.236114\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:11 | INFO | Rank 0 | Train Epoch: 4 [7648/23491 (33%)]\tLoss: 0.451451\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:11 | INFO | Rank 0 | Train Epoch: 4 [7680/23491 (33%)]\tLoss: 0.720457\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:12 | INFO | Rank 0 | Train Epoch: 4 [7712/23491 (33%)]\tLoss: 0.351072\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:12 | INFO | Rank 0 | Train Epoch: 4 [7744/23491 (33%)]\tLoss: 0.737864\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:12 | INFO | Rank 0 | Train Epoch: 4 [7776/23491 (33%)]\tLoss: 0.384346\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:12 | INFO | Rank 0 | Train Epoch: 4 [7808/23491 (33%)]\tLoss: 0.245322\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:13 | INFO | Rank 0 | Train Epoch: 4 [7840/23491 (33%)]\tLoss: 0.563901\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:13 | INFO | Rank 0 | Train Epoch: 4 [7872/23491 (34%)]\tLoss: 0.513929\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:13 | INFO | Rank 0 | Train Epoch: 4 [7904/23491 (34%)]\tLoss: 0.493278\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:13 | INFO | Rank 0 | Train Epoch: 4 [7936/23491 (34%)]\tLoss: 0.390259\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:14 | INFO | Rank 0 | Train Epoch: 4 [7968/23491 (34%)]\tLoss: 0.225951\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:14 | INFO | Rank 0 | Train Epoch: 4 [8000/23491 (34%)]\tLoss: 0.756270\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:14 | INFO | Rank 0 | Train Epoch: 4 [8032/23491 (34%)]\tLoss: 0.504385\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:15 | INFO | Rank 0 | Train Epoch: 4 [8064/23491 (34%)]\tLoss: 0.325236\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:15 | INFO | Rank 0 | Train Epoch: 4 [8096/23491 (34%)]\tLoss: 0.602266\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:15 | INFO | Rank 0 | Train Epoch: 4 [8128/23491 (35%)]\tLoss: 0.541309\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:15 | INFO | Rank 0 | Train Epoch: 4 [8160/23491 (35%)]\tLoss: 0.602541\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.548\n",
      "2022-11-08,05:41:16 | INFO | Rank 0 | Train Epoch: 4 [8192/23491 (35%)]\tLoss: 0.580078\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:16 | INFO | Rank 0 | Train Epoch: 4 [8224/23491 (35%)]\tLoss: 0.592888\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:16 | INFO | Rank 0 | Train Epoch: 4 [8256/23491 (35%)]\tLoss: 0.791465\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:16 | INFO | Rank 0 | Train Epoch: 4 [8288/23491 (35%)]\tLoss: 0.506149\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:17 | INFO | Rank 0 | Train Epoch: 4 [8320/23491 (35%)]\tLoss: 0.424378\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:17 | INFO | Rank 0 | Train Epoch: 4 [8352/23491 (36%)]\tLoss: 0.305279\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:17 | INFO | Rank 0 | Train Epoch: 4 [8384/23491 (36%)]\tLoss: 0.591516\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:17 | INFO | Rank 0 | Train Epoch: 4 [8416/23491 (36%)]\tLoss: 0.752599\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:18 | INFO | Rank 0 | Train Epoch: 4 [8448/23491 (36%)]\tLoss: 0.442935\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:18 | INFO | Rank 0 | Train Epoch: 4 [8480/23491 (36%)]\tLoss: 0.352574\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:18 | INFO | Rank 0 | Train Epoch: 4 [8512/23491 (36%)]\tLoss: 0.418788\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:19 | INFO | Rank 0 | Train Epoch: 4 [8544/23491 (36%)]\tLoss: 0.298306\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:19 | INFO | Rank 0 | Train Epoch: 4 [8576/23491 (37%)]\tLoss: 0.425869\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:19 | INFO | Rank 0 | Train Epoch: 4 [8608/23491 (37%)]\tLoss: 0.289983\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:19 | INFO | Rank 0 | Train Epoch: 4 [8640/23491 (37%)]\tLoss: 0.506738\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:20 | INFO | Rank 0 | Train Epoch: 4 [8672/23491 (37%)]\tLoss: 0.385756\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:20 | INFO | Rank 0 | Train Epoch: 4 [8704/23491 (37%)]\tLoss: 0.626174\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:20 | INFO | Rank 0 | Train Epoch: 4 [8736/23491 (37%)]\tLoss: 0.536794\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:20 | INFO | Rank 0 | Train Epoch: 4 [8768/23491 (37%)]\tLoss: 0.591305\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:21 | INFO | Rank 0 | Train Epoch: 4 [8800/23491 (37%)]\tLoss: 0.330202\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:21 | INFO | Rank 0 | Train Epoch: 4 [8832/23491 (38%)]\tLoss: 0.596202\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:21 | INFO | Rank 0 | Train Epoch: 4 [8864/23491 (38%)]\tLoss: 0.589799\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:21 | INFO | Rank 0 | Train Epoch: 4 [8896/23491 (38%)]\tLoss: 0.378517\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:22 | INFO | Rank 0 | Train Epoch: 4 [8928/23491 (38%)]\tLoss: 0.312002\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:22 | INFO | Rank 0 | Train Epoch: 4 [8960/23491 (38%)]\tLoss: 0.360263\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:22 | INFO | Rank 0 | Train Epoch: 4 [8992/23491 (38%)]\tLoss: 0.551032\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:22 | INFO | Rank 0 | Train Epoch: 4 [9024/23491 (38%)]\tLoss: 0.662769\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:23 | INFO | Rank 0 | Train Epoch: 4 [9056/23491 (39%)]\tLoss: 0.288778\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:23 | INFO | Rank 0 | Train Epoch: 4 [9088/23491 (39%)]\tLoss: 0.746353\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:23 | INFO | Rank 0 | Train Epoch: 4 [9120/23491 (39%)]\tLoss: 0.748566\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:24 | INFO | Rank 0 | Train Epoch: 4 [9152/23491 (39%)]\tLoss: 0.528563\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:24 | INFO | Rank 0 | Train Epoch: 4 [9184/23491 (39%)]\tLoss: 0.776191\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:24 | INFO | Rank 0 | Train Epoch: 4 [9216/23491 (39%)]\tLoss: 0.616148\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:24 | INFO | Rank 0 | Train Epoch: 4 [9248/23491 (39%)]\tLoss: 0.404115\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:25 | INFO | Rank 0 | Train Epoch: 4 [9280/23491 (40%)]\tLoss: 0.223164\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:25 | INFO | Rank 0 | Train Epoch: 4 [9312/23491 (40%)]\tLoss: 0.448699\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:25 | INFO | Rank 0 | Train Epoch: 4 [9344/23491 (40%)]\tLoss: 0.562437\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000053\tlogit_scale 4.547\n",
      "2022-11-08,05:41:25 | INFO | Rank 0 | Train Epoch: 4 [9376/23491 (40%)]\tLoss: 0.508743\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:26 | INFO | Rank 0 | Train Epoch: 4 [9408/23491 (40%)]\tLoss: 0.593524\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:26 | INFO | Rank 0 | Train Epoch: 4 [9440/23491 (40%)]\tLoss: 0.328959\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:26 | INFO | Rank 0 | Train Epoch: 4 [9472/23491 (40%)]\tLoss: 0.583490\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:26 | INFO | Rank 0 | Train Epoch: 4 [9504/23491 (40%)]\tLoss: 0.762740\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:27 | INFO | Rank 0 | Train Epoch: 4 [9536/23491 (41%)]\tLoss: 0.682323\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:27 | INFO | Rank 0 | Train Epoch: 4 [9568/23491 (41%)]\tLoss: 0.528251\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:27 | INFO | Rank 0 | Train Epoch: 4 [9600/23491 (41%)]\tLoss: 0.257563\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:28 | INFO | Rank 0 | Train Epoch: 4 [9632/23491 (41%)]\tLoss: 0.273323\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:28 | INFO | Rank 0 | Train Epoch: 4 [9664/23491 (41%)]\tLoss: 0.416209\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:28 | INFO | Rank 0 | Train Epoch: 4 [9696/23491 (41%)]\tLoss: 0.370186\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:28 | INFO | Rank 0 | Train Epoch: 4 [9728/23491 (41%)]\tLoss: 0.307069\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:29 | INFO | Rank 0 | Train Epoch: 4 [9760/23491 (42%)]\tLoss: 0.612095\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:29 | INFO | Rank 0 | Train Epoch: 4 [9792/23491 (42%)]\tLoss: 0.345996\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:29 | INFO | Rank 0 | Train Epoch: 4 [9824/23491 (42%)]\tLoss: 0.416308\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:29 | INFO | Rank 0 | Train Epoch: 4 [9856/23491 (42%)]\tLoss: 0.818966\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:30 | INFO | Rank 0 | Train Epoch: 4 [9888/23491 (42%)]\tLoss: 0.330876\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:30 | INFO | Rank 0 | Train Epoch: 4 [9920/23491 (42%)]\tLoss: 0.393810\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:30 | INFO | Rank 0 | Train Epoch: 4 [9952/23491 (42%)]\tLoss: 0.287936\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:30 | INFO | Rank 0 | Train Epoch: 4 [9984/23491 (43%)]\tLoss: 0.400822\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:31 | INFO | Rank 0 | Train Epoch: 4 [10016/23491 (43%)]\tLoss: 0.508490\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:31 | INFO | Rank 0 | Train Epoch: 4 [10048/23491 (43%)]\tLoss: 0.692520\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:31 | INFO | Rank 0 | Train Epoch: 4 [10080/23491 (43%)]\tLoss: 0.238111\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:32 | INFO | Rank 0 | Train Epoch: 4 [10112/23491 (43%)]\tLoss: 0.440655\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:32 | INFO | Rank 0 | Train Epoch: 4 [10144/23491 (43%)]\tLoss: 0.586962\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:32 | INFO | Rank 0 | Train Epoch: 4 [10176/23491 (43%)]\tLoss: 0.544556\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:32 | INFO | Rank 0 | Train Epoch: 4 [10208/23491 (43%)]\tLoss: 0.468977\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:33 | INFO | Rank 0 | Train Epoch: 4 [10240/23491 (44%)]\tLoss: 0.780794\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:33 | INFO | Rank 0 | Train Epoch: 4 [10272/23491 (44%)]\tLoss: 0.500868\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:33 | INFO | Rank 0 | Train Epoch: 4 [10304/23491 (44%)]\tLoss: 0.430194\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:33 | INFO | Rank 0 | Train Epoch: 4 [10336/23491 (44%)]\tLoss: 0.324249\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:34 | INFO | Rank 0 | Train Epoch: 4 [10368/23491 (44%)]\tLoss: 0.482015\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:34 | INFO | Rank 0 | Train Epoch: 4 [10400/23491 (44%)]\tLoss: 0.403752\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:34 | INFO | Rank 0 | Train Epoch: 4 [10432/23491 (44%)]\tLoss: 0.395173\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:34 | INFO | Rank 0 | Train Epoch: 4 [10464/23491 (45%)]\tLoss: 0.613999\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:35 | INFO | Rank 0 | Train Epoch: 4 [10496/23491 (45%)]\tLoss: 1.099587\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:35 | INFO | Rank 0 | Train Epoch: 4 [10528/23491 (45%)]\tLoss: 0.424301\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:35 | INFO | Rank 0 | Train Epoch: 4 [10560/23491 (45%)]\tLoss: 0.475395\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:36 | INFO | Rank 0 | Train Epoch: 4 [10592/23491 (45%)]\tLoss: 0.380490\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:36 | INFO | Rank 0 | Train Epoch: 4 [10624/23491 (45%)]\tLoss: 0.564371\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:36 | INFO | Rank 0 | Train Epoch: 4 [10656/23491 (45%)]\tLoss: 0.532199\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:36 | INFO | Rank 0 | Train Epoch: 4 [10688/23491 (46%)]\tLoss: 0.429281\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:37 | INFO | Rank 0 | Train Epoch: 4 [10720/23491 (46%)]\tLoss: 0.482801\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:37 | INFO | Rank 0 | Train Epoch: 4 [10752/23491 (46%)]\tLoss: 0.442710\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:37 | INFO | Rank 0 | Train Epoch: 4 [10784/23491 (46%)]\tLoss: 0.449491\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:37 | INFO | Rank 0 | Train Epoch: 4 [10816/23491 (46%)]\tLoss: 0.307825\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:38 | INFO | Rank 0 | Train Epoch: 4 [10848/23491 (46%)]\tLoss: 0.219393\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:38 | INFO | Rank 0 | Train Epoch: 4 [10880/23491 (46%)]\tLoss: 0.545012\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:38 | INFO | Rank 0 | Train Epoch: 4 [10912/23491 (46%)]\tLoss: 0.519214\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:38 | INFO | Rank 0 | Train Epoch: 4 [10944/23491 (47%)]\tLoss: 0.226263\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:39 | INFO | Rank 0 | Train Epoch: 4 [10976/23491 (47%)]\tLoss: 0.495830\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:39 | INFO | Rank 0 | Train Epoch: 4 [11008/23491 (47%)]\tLoss: 0.392168\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:39 | INFO | Rank 0 | Train Epoch: 4 [11040/23491 (47%)]\tLoss: 0.440714\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:40 | INFO | Rank 0 | Train Epoch: 4 [11072/23491 (47%)]\tLoss: 0.629685\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:40 | INFO | Rank 0 | Train Epoch: 4 [11104/23491 (47%)]\tLoss: 0.400669\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:40 | INFO | Rank 0 | Train Epoch: 4 [11136/23491 (47%)]\tLoss: 0.438013\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:40 | INFO | Rank 0 | Train Epoch: 4 [11168/23491 (48%)]\tLoss: 0.317397\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000052\tlogit_scale 4.547\n",
      "2022-11-08,05:41:41 | INFO | Rank 0 | Train Epoch: 4 [11200/23491 (48%)]\tLoss: 0.385851\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:41 | INFO | Rank 0 | Train Epoch: 4 [11232/23491 (48%)]\tLoss: 0.465901\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:41 | INFO | Rank 0 | Train Epoch: 4 [11264/23491 (48%)]\tLoss: 0.307262\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:41 | INFO | Rank 0 | Train Epoch: 4 [11296/23491 (48%)]\tLoss: 0.181209\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:42 | INFO | Rank 0 | Train Epoch: 4 [11328/23491 (48%)]\tLoss: 0.258446\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:42 | INFO | Rank 0 | Train Epoch: 4 [11360/23491 (48%)]\tLoss: 0.403116\tData (t) 0.053\tBatch (t) 0.268\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:42 | INFO | Rank 0 | Train Epoch: 4 [11392/23491 (49%)]\tLoss: 0.911276\tData (t) 0.055\tBatch (t) 0.270\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:42 | INFO | Rank 0 | Train Epoch: 4 [11424/23491 (49%)]\tLoss: 0.282011\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:43 | INFO | Rank 0 | Train Epoch: 4 [11456/23491 (49%)]\tLoss: 0.607900\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:43 | INFO | Rank 0 | Train Epoch: 4 [11488/23491 (49%)]\tLoss: 0.535263\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:43 | INFO | Rank 0 | Train Epoch: 4 [11520/23491 (49%)]\tLoss: 0.593600\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:44 | INFO | Rank 0 | Train Epoch: 4 [11552/23491 (49%)]\tLoss: 0.298380\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:44 | INFO | Rank 0 | Train Epoch: 4 [11584/23491 (49%)]\tLoss: 0.340048\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:44 | INFO | Rank 0 | Train Epoch: 4 [11616/23491 (49%)]\tLoss: 0.682970\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:44 | INFO | Rank 0 | Train Epoch: 4 [11648/23491 (50%)]\tLoss: 0.548798\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:45 | INFO | Rank 0 | Train Epoch: 4 [11680/23491 (50%)]\tLoss: 0.457064\tData (t) 0.053\tBatch (t) 0.268\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:45 | INFO | Rank 0 | Train Epoch: 4 [11712/23491 (50%)]\tLoss: 0.228024\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:45 | INFO | Rank 0 | Train Epoch: 4 [11744/23491 (50%)]\tLoss: 0.478862\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:45 | INFO | Rank 0 | Train Epoch: 4 [11776/23491 (50%)]\tLoss: 0.259887\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:46 | INFO | Rank 0 | Train Epoch: 4 [11808/23491 (50%)]\tLoss: 0.313665\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:46 | INFO | Rank 0 | Train Epoch: 4 [11840/23491 (50%)]\tLoss: 0.540368\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:46 | INFO | Rank 0 | Train Epoch: 4 [11872/23491 (51%)]\tLoss: 0.637272\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:46 | INFO | Rank 0 | Train Epoch: 4 [11904/23491 (51%)]\tLoss: 0.463437\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:47 | INFO | Rank 0 | Train Epoch: 4 [11936/23491 (51%)]\tLoss: 1.039605\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:47 | INFO | Rank 0 | Train Epoch: 4 [11968/23491 (51%)]\tLoss: 0.380753\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:47 | INFO | Rank 0 | Train Epoch: 4 [12000/23491 (51%)]\tLoss: 0.589140\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:47 | INFO | Rank 0 | Train Epoch: 4 [12032/23491 (51%)]\tLoss: 0.286591\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.547\n",
      "2022-11-08,05:41:48 | INFO | Rank 0 | Train Epoch: 4 [12064/23491 (51%)]\tLoss: 0.467549\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:48 | INFO | Rank 0 | Train Epoch: 4 [12096/23491 (51%)]\tLoss: 0.443726\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:48 | INFO | Rank 0 | Train Epoch: 4 [12128/23491 (52%)]\tLoss: 0.649878\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:49 | INFO | Rank 0 | Train Epoch: 4 [12160/23491 (52%)]\tLoss: 0.633159\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:49 | INFO | Rank 0 | Train Epoch: 4 [12192/23491 (52%)]\tLoss: 0.422282\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:49 | INFO | Rank 0 | Train Epoch: 4 [12224/23491 (52%)]\tLoss: 0.390304\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:49 | INFO | Rank 0 | Train Epoch: 4 [12256/23491 (52%)]\tLoss: 0.385032\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:50 | INFO | Rank 0 | Train Epoch: 4 [12288/23491 (52%)]\tLoss: 0.765926\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:50 | INFO | Rank 0 | Train Epoch: 4 [12320/23491 (52%)]\tLoss: 0.242646\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:50 | INFO | Rank 0 | Train Epoch: 4 [12352/23491 (53%)]\tLoss: 0.303123\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:50 | INFO | Rank 0 | Train Epoch: 4 [12384/23491 (53%)]\tLoss: 0.399109\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:51 | INFO | Rank 0 | Train Epoch: 4 [12416/23491 (53%)]\tLoss: 0.336170\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:51 | INFO | Rank 0 | Train Epoch: 4 [12448/23491 (53%)]\tLoss: 0.446240\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:51 | INFO | Rank 0 | Train Epoch: 4 [12480/23491 (53%)]\tLoss: 0.390445\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:51 | INFO | Rank 0 | Train Epoch: 4 [12512/23491 (53%)]\tLoss: 0.279177\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:52 | INFO | Rank 0 | Train Epoch: 4 [12544/23491 (53%)]\tLoss: 0.418148\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:52 | INFO | Rank 0 | Train Epoch: 4 [12576/23491 (54%)]\tLoss: 0.273670\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:52 | INFO | Rank 0 | Train Epoch: 4 [12608/23491 (54%)]\tLoss: 0.761472\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:53 | INFO | Rank 0 | Train Epoch: 4 [12640/23491 (54%)]\tLoss: 0.454294\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:53 | INFO | Rank 0 | Train Epoch: 4 [12672/23491 (54%)]\tLoss: 0.366471\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:53 | INFO | Rank 0 | Train Epoch: 4 [12704/23491 (54%)]\tLoss: 0.483857\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:53 | INFO | Rank 0 | Train Epoch: 4 [12736/23491 (54%)]\tLoss: 0.503088\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:54 | INFO | Rank 0 | Train Epoch: 4 [12768/23491 (54%)]\tLoss: 0.542158\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:54 | INFO | Rank 0 | Train Epoch: 4 [12800/23491 (54%)]\tLoss: 0.388178\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:54 | INFO | Rank 0 | Train Epoch: 4 [12832/23491 (55%)]\tLoss: 0.628044\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:54 | INFO | Rank 0 | Train Epoch: 4 [12864/23491 (55%)]\tLoss: 0.254273\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:55 | INFO | Rank 0 | Train Epoch: 4 [12896/23491 (55%)]\tLoss: 0.639333\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:55 | INFO | Rank 0 | Train Epoch: 4 [12928/23491 (55%)]\tLoss: 0.847545\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:55 | INFO | Rank 0 | Train Epoch: 4 [12960/23491 (55%)]\tLoss: 0.573440\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000051\tlogit_scale 4.546\n",
      "2022-11-08,05:41:55 | INFO | Rank 0 | Train Epoch: 4 [12992/23491 (55%)]\tLoss: 0.700875\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:41:56 | INFO | Rank 0 | Train Epoch: 4 [13024/23491 (55%)]\tLoss: 0.648454\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:41:56 | INFO | Rank 0 | Train Epoch: 4 [13056/23491 (56%)]\tLoss: 0.397344\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:41:56 | INFO | Rank 0 | Train Epoch: 4 [13088/23491 (56%)]\tLoss: 0.383272\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:41:57 | INFO | Rank 0 | Train Epoch: 4 [13120/23491 (56%)]\tLoss: 0.335370\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:41:57 | INFO | Rank 0 | Train Epoch: 4 [13152/23491 (56%)]\tLoss: 0.331898\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:41:57 | INFO | Rank 0 | Train Epoch: 4 [13184/23491 (56%)]\tLoss: 0.461100\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:41:57 | INFO | Rank 0 | Train Epoch: 4 [13216/23491 (56%)]\tLoss: 0.601857\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:41:58 | INFO | Rank 0 | Train Epoch: 4 [13248/23491 (56%)]\tLoss: 0.515423\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:41:58 | INFO | Rank 0 | Train Epoch: 4 [13280/23491 (57%)]\tLoss: 0.403049\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:41:58 | INFO | Rank 0 | Train Epoch: 4 [13312/23491 (57%)]\tLoss: 0.491536\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:41:58 | INFO | Rank 0 | Train Epoch: 4 [13344/23491 (57%)]\tLoss: 0.227477\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:41:59 | INFO | Rank 0 | Train Epoch: 4 [13376/23491 (57%)]\tLoss: 0.626300\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:41:59 | INFO | Rank 0 | Train Epoch: 4 [13408/23491 (57%)]\tLoss: 0.569331\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:41:59 | INFO | Rank 0 | Train Epoch: 4 [13440/23491 (57%)]\tLoss: 0.463709\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:41:59 | INFO | Rank 0 | Train Epoch: 4 [13472/23491 (57%)]\tLoss: 0.695551\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:00 | INFO | Rank 0 | Train Epoch: 4 [13504/23491 (57%)]\tLoss: 0.464062\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:00 | INFO | Rank 0 | Train Epoch: 4 [13536/23491 (58%)]\tLoss: 0.696788\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:00 | INFO | Rank 0 | Train Epoch: 4 [13568/23491 (58%)]\tLoss: 0.480804\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:01 | INFO | Rank 0 | Train Epoch: 4 [13600/23491 (58%)]\tLoss: 0.525023\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:01 | INFO | Rank 0 | Train Epoch: 4 [13632/23491 (58%)]\tLoss: 0.559664\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:01 | INFO | Rank 0 | Train Epoch: 4 [13664/23491 (58%)]\tLoss: 0.383820\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:01 | INFO | Rank 0 | Train Epoch: 4 [13696/23491 (58%)]\tLoss: 0.412595\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:02 | INFO | Rank 0 | Train Epoch: 4 [13728/23491 (58%)]\tLoss: 0.489996\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:02 | INFO | Rank 0 | Train Epoch: 4 [13760/23491 (59%)]\tLoss: 0.219375\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:02 | INFO | Rank 0 | Train Epoch: 4 [13792/23491 (59%)]\tLoss: 0.369840\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:02 | INFO | Rank 0 | Train Epoch: 4 [13824/23491 (59%)]\tLoss: 0.586480\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:03 | INFO | Rank 0 | Train Epoch: 4 [13856/23491 (59%)]\tLoss: 0.331401\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:03 | INFO | Rank 0 | Train Epoch: 4 [13888/23491 (59%)]\tLoss: 0.731185\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:03 | INFO | Rank 0 | Train Epoch: 4 [13920/23491 (59%)]\tLoss: 0.711435\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:03 | INFO | Rank 0 | Train Epoch: 4 [13952/23491 (59%)]\tLoss: 0.465106\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:04 | INFO | Rank 0 | Train Epoch: 4 [13984/23491 (60%)]\tLoss: 0.282235\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:04 | INFO | Rank 0 | Train Epoch: 4 [14016/23491 (60%)]\tLoss: 0.388197\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:04 | INFO | Rank 0 | Train Epoch: 4 [14048/23491 (60%)]\tLoss: 0.470888\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:05 | INFO | Rank 0 | Train Epoch: 4 [14080/23491 (60%)]\tLoss: 0.595919\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:05 | INFO | Rank 0 | Train Epoch: 4 [14112/23491 (60%)]\tLoss: 0.268205\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:05 | INFO | Rank 0 | Train Epoch: 4 [14144/23491 (60%)]\tLoss: 1.102618\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:05 | INFO | Rank 0 | Train Epoch: 4 [14176/23491 (60%)]\tLoss: 0.446892\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:06 | INFO | Rank 0 | Train Epoch: 4 [14208/23491 (60%)]\tLoss: 0.434496\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:06 | INFO | Rank 0 | Train Epoch: 4 [14240/23491 (61%)]\tLoss: 0.280731\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:06 | INFO | Rank 0 | Train Epoch: 4 [14272/23491 (61%)]\tLoss: 0.381583\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:06 | INFO | Rank 0 | Train Epoch: 4 [14304/23491 (61%)]\tLoss: 0.568984\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:07 | INFO | Rank 0 | Train Epoch: 4 [14336/23491 (61%)]\tLoss: 0.418626\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:07 | INFO | Rank 0 | Train Epoch: 4 [14368/23491 (61%)]\tLoss: 0.366222\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:07 | INFO | Rank 0 | Train Epoch: 4 [14400/23491 (61%)]\tLoss: 0.473842\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:07 | INFO | Rank 0 | Train Epoch: 4 [14432/23491 (61%)]\tLoss: 0.455377\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:08 | INFO | Rank 0 | Train Epoch: 4 [14464/23491 (62%)]\tLoss: 0.730949\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:08 | INFO | Rank 0 | Train Epoch: 4 [14496/23491 (62%)]\tLoss: 0.629327\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:08 | INFO | Rank 0 | Train Epoch: 4 [14528/23491 (62%)]\tLoss: 0.478372\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:08 | INFO | Rank 0 | Train Epoch: 4 [14560/23491 (62%)]\tLoss: 0.364608\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:09 | INFO | Rank 0 | Train Epoch: 4 [14592/23491 (62%)]\tLoss: 0.158756\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:09 | INFO | Rank 0 | Train Epoch: 4 [14624/23491 (62%)]\tLoss: 0.385098\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:09 | INFO | Rank 0 | Train Epoch: 4 [14656/23491 (62%)]\tLoss: 0.496464\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:10 | INFO | Rank 0 | Train Epoch: 4 [14688/23491 (63%)]\tLoss: 0.455609\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:10 | INFO | Rank 0 | Train Epoch: 4 [14720/23491 (63%)]\tLoss: 0.379815\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:10 | INFO | Rank 0 | Train Epoch: 4 [14752/23491 (63%)]\tLoss: 0.768081\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000050\tlogit_scale 4.546\n",
      "2022-11-08,05:42:10 | INFO | Rank 0 | Train Epoch: 4 [14784/23491 (63%)]\tLoss: 0.496894\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.546\n",
      "2022-11-08,05:42:11 | INFO | Rank 0 | Train Epoch: 4 [14816/23491 (63%)]\tLoss: 0.411657\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.546\n",
      "2022-11-08,05:42:11 | INFO | Rank 0 | Train Epoch: 4 [14848/23491 (63%)]\tLoss: 0.561058\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.546\n",
      "2022-11-08,05:42:11 | INFO | Rank 0 | Train Epoch: 4 [14880/23491 (63%)]\tLoss: 0.592170\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.546\n",
      "2022-11-08,05:42:11 | INFO | Rank 0 | Train Epoch: 4 [14912/23491 (63%)]\tLoss: 0.491835\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.546\n",
      "2022-11-08,05:42:12 | INFO | Rank 0 | Train Epoch: 4 [14944/23491 (64%)]\tLoss: 0.525564\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.546\n",
      "2022-11-08,05:42:12 | INFO | Rank 0 | Train Epoch: 4 [14976/23491 (64%)]\tLoss: 0.511128\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.546\n",
      "2022-11-08,05:42:12 | INFO | Rank 0 | Train Epoch: 4 [15008/23491 (64%)]\tLoss: 1.054913\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.546\n",
      "2022-11-08,05:42:12 | INFO | Rank 0 | Train Epoch: 4 [15040/23491 (64%)]\tLoss: 0.450190\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.546\n",
      "2022-11-08,05:42:13 | INFO | Rank 0 | Train Epoch: 4 [15072/23491 (64%)]\tLoss: 0.558137\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.546\n",
      "2022-11-08,05:42:13 | INFO | Rank 0 | Train Epoch: 4 [15104/23491 (64%)]\tLoss: 0.706440\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.546\n",
      "2022-11-08,05:42:13 | INFO | Rank 0 | Train Epoch: 4 [15136/23491 (64%)]\tLoss: 0.282289\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.546\n",
      "2022-11-08,05:42:14 | INFO | Rank 0 | Train Epoch: 4 [15168/23491 (65%)]\tLoss: 0.521031\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.546\n",
      "2022-11-08,05:42:14 | INFO | Rank 0 | Train Epoch: 4 [15200/23491 (65%)]\tLoss: 0.573853\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:14 | INFO | Rank 0 | Train Epoch: 4 [15232/23491 (65%)]\tLoss: 0.176674\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:14 | INFO | Rank 0 | Train Epoch: 4 [15264/23491 (65%)]\tLoss: 0.539235\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:15 | INFO | Rank 0 | Train Epoch: 4 [15296/23491 (65%)]\tLoss: 0.611111\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:15 | INFO | Rank 0 | Train Epoch: 4 [15328/23491 (65%)]\tLoss: 0.308205\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:15 | INFO | Rank 0 | Train Epoch: 4 [15360/23491 (65%)]\tLoss: 0.648408\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:15 | INFO | Rank 0 | Train Epoch: 4 [15392/23491 (66%)]\tLoss: 0.858202\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:16 | INFO | Rank 0 | Train Epoch: 4 [15424/23491 (66%)]\tLoss: 0.291784\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:16 | INFO | Rank 0 | Train Epoch: 4 [15456/23491 (66%)]\tLoss: 0.453527\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:16 | INFO | Rank 0 | Train Epoch: 4 [15488/23491 (66%)]\tLoss: 0.334899\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:16 | INFO | Rank 0 | Train Epoch: 4 [15520/23491 (66%)]\tLoss: 0.517811\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:17 | INFO | Rank 0 | Train Epoch: 4 [15552/23491 (66%)]\tLoss: 0.606117\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:17 | INFO | Rank 0 | Train Epoch: 4 [15584/23491 (66%)]\tLoss: 0.526139\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:17 | INFO | Rank 0 | Train Epoch: 4 [15616/23491 (66%)]\tLoss: 0.284568\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:18 | INFO | Rank 0 | Train Epoch: 4 [15648/23491 (67%)]\tLoss: 0.538192\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:18 | INFO | Rank 0 | Train Epoch: 4 [15680/23491 (67%)]\tLoss: 0.386020\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:18 | INFO | Rank 0 | Train Epoch: 4 [15712/23491 (67%)]\tLoss: 0.520689\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:18 | INFO | Rank 0 | Train Epoch: 4 [15744/23491 (67%)]\tLoss: 0.755594\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:19 | INFO | Rank 0 | Train Epoch: 4 [15776/23491 (67%)]\tLoss: 0.387177\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:19 | INFO | Rank 0 | Train Epoch: 4 [15808/23491 (67%)]\tLoss: 0.210624\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:19 | INFO | Rank 0 | Train Epoch: 4 [15840/23491 (67%)]\tLoss: 0.751950\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:19 | INFO | Rank 0 | Train Epoch: 4 [15872/23491 (68%)]\tLoss: 0.621753\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:20 | INFO | Rank 0 | Train Epoch: 4 [15904/23491 (68%)]\tLoss: 0.464353\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:20 | INFO | Rank 0 | Train Epoch: 4 [15936/23491 (68%)]\tLoss: 0.396216\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:20 | INFO | Rank 0 | Train Epoch: 4 [15968/23491 (68%)]\tLoss: 0.527514\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:20 | INFO | Rank 0 | Train Epoch: 4 [16000/23491 (68%)]\tLoss: 0.384616\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:21 | INFO | Rank 0 | Train Epoch: 4 [16032/23491 (68%)]\tLoss: 0.403998\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:21 | INFO | Rank 0 | Train Epoch: 4 [16064/23491 (68%)]\tLoss: 0.477583\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:21 | INFO | Rank 0 | Train Epoch: 4 [16096/23491 (69%)]\tLoss: 0.591608\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:22 | INFO | Rank 0 | Train Epoch: 4 [16128/23491 (69%)]\tLoss: 0.434020\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:22 | INFO | Rank 0 | Train Epoch: 4 [16160/23491 (69%)]\tLoss: 0.471886\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:22 | INFO | Rank 0 | Train Epoch: 4 [16192/23491 (69%)]\tLoss: 0.333546\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:22 | INFO | Rank 0 | Train Epoch: 4 [16224/23491 (69%)]\tLoss: 0.408980\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:23 | INFO | Rank 0 | Train Epoch: 4 [16256/23491 (69%)]\tLoss: 0.696856\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:23 | INFO | Rank 0 | Train Epoch: 4 [16288/23491 (69%)]\tLoss: 0.619464\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:23 | INFO | Rank 0 | Train Epoch: 4 [16320/23491 (69%)]\tLoss: 0.614981\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:23 | INFO | Rank 0 | Train Epoch: 4 [16352/23491 (70%)]\tLoss: 0.244063\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:24 | INFO | Rank 0 | Train Epoch: 4 [16384/23491 (70%)]\tLoss: 0.686893\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:24 | INFO | Rank 0 | Train Epoch: 4 [16416/23491 (70%)]\tLoss: 0.369919\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:24 | INFO | Rank 0 | Train Epoch: 4 [16448/23491 (70%)]\tLoss: 0.221215\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:24 | INFO | Rank 0 | Train Epoch: 4 [16480/23491 (70%)]\tLoss: 0.547648\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:25 | INFO | Rank 0 | Train Epoch: 4 [16512/23491 (70%)]\tLoss: 0.583234\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:25 | INFO | Rank 0 | Train Epoch: 4 [16544/23491 (70%)]\tLoss: 0.606626\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000049\tlogit_scale 4.545\n",
      "2022-11-08,05:42:25 | INFO | Rank 0 | Train Epoch: 4 [16576/23491 (71%)]\tLoss: 0.272820\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:25 | INFO | Rank 0 | Train Epoch: 4 [16608/23491 (71%)]\tLoss: 0.340297\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:26 | INFO | Rank 0 | Train Epoch: 4 [16640/23491 (71%)]\tLoss: 0.332280\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:26 | INFO | Rank 0 | Train Epoch: 4 [16672/23491 (71%)]\tLoss: 0.480987\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:26 | INFO | Rank 0 | Train Epoch: 4 [16704/23491 (71%)]\tLoss: 0.618329\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:27 | INFO | Rank 0 | Train Epoch: 4 [16736/23491 (71%)]\tLoss: 0.650671\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:27 | INFO | Rank 0 | Train Epoch: 4 [16768/23491 (71%)]\tLoss: 0.296336\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:27 | INFO | Rank 0 | Train Epoch: 4 [16800/23491 (72%)]\tLoss: 0.464341\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:27 | INFO | Rank 0 | Train Epoch: 4 [16832/23491 (72%)]\tLoss: 0.554555\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:28 | INFO | Rank 0 | Train Epoch: 4 [16864/23491 (72%)]\tLoss: 0.278404\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:28 | INFO | Rank 0 | Train Epoch: 4 [16896/23491 (72%)]\tLoss: 0.213204\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:28 | INFO | Rank 0 | Train Epoch: 4 [16928/23491 (72%)]\tLoss: 0.248962\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:28 | INFO | Rank 0 | Train Epoch: 4 [16960/23491 (72%)]\tLoss: 0.278145\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:29 | INFO | Rank 0 | Train Epoch: 4 [16992/23491 (72%)]\tLoss: 0.335996\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:29 | INFO | Rank 0 | Train Epoch: 4 [17024/23491 (72%)]\tLoss: 0.275040\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:29 | INFO | Rank 0 | Train Epoch: 4 [17056/23491 (73%)]\tLoss: 0.288616\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:29 | INFO | Rank 0 | Train Epoch: 4 [17088/23491 (73%)]\tLoss: 0.659803\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:30 | INFO | Rank 0 | Train Epoch: 4 [17120/23491 (73%)]\tLoss: 0.273236\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:30 | INFO | Rank 0 | Train Epoch: 4 [17152/23491 (73%)]\tLoss: 0.270954\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:30 | INFO | Rank 0 | Train Epoch: 4 [17184/23491 (73%)]\tLoss: 0.371011\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:31 | INFO | Rank 0 | Train Epoch: 4 [17216/23491 (73%)]\tLoss: 0.742678\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:31 | INFO | Rank 0 | Train Epoch: 4 [17248/23491 (73%)]\tLoss: 0.439481\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:31 | INFO | Rank 0 | Train Epoch: 4 [17280/23491 (74%)]\tLoss: 0.713731\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:31 | INFO | Rank 0 | Train Epoch: 4 [17312/23491 (74%)]\tLoss: 0.514863\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:32 | INFO | Rank 0 | Train Epoch: 4 [17344/23491 (74%)]\tLoss: 0.619419\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:32 | INFO | Rank 0 | Train Epoch: 4 [17376/23491 (74%)]\tLoss: 0.440402\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:32 | INFO | Rank 0 | Train Epoch: 4 [17408/23491 (74%)]\tLoss: 0.303996\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:32 | INFO | Rank 0 | Train Epoch: 4 [17440/23491 (74%)]\tLoss: 1.053782\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:33 | INFO | Rank 0 | Train Epoch: 4 [17472/23491 (74%)]\tLoss: 0.499749\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:33 | INFO | Rank 0 | Train Epoch: 4 [17504/23491 (75%)]\tLoss: 0.743450\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:33 | INFO | Rank 0 | Train Epoch: 4 [17536/23491 (75%)]\tLoss: 0.556442\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:33 | INFO | Rank 0 | Train Epoch: 4 [17568/23491 (75%)]\tLoss: 0.332099\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:34 | INFO | Rank 0 | Train Epoch: 4 [17600/23491 (75%)]\tLoss: 0.493797\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:34 | INFO | Rank 0 | Train Epoch: 4 [17632/23491 (75%)]\tLoss: 0.358664\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:34 | INFO | Rank 0 | Train Epoch: 4 [17664/23491 (75%)]\tLoss: 0.199850\tData (t) 0.052\tBatch (t) 0.264\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:35 | INFO | Rank 0 | Train Epoch: 4 [17696/23491 (75%)]\tLoss: 0.681830\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:35 | INFO | Rank 0 | Train Epoch: 4 [17728/23491 (75%)]\tLoss: 0.554595\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:35 | INFO | Rank 0 | Train Epoch: 4 [17760/23491 (76%)]\tLoss: 0.305537\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:35 | INFO | Rank 0 | Train Epoch: 4 [17792/23491 (76%)]\tLoss: 0.304184\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:36 | INFO | Rank 0 | Train Epoch: 4 [17824/23491 (76%)]\tLoss: 0.495233\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:36 | INFO | Rank 0 | Train Epoch: 4 [17856/23491 (76%)]\tLoss: 0.374023\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:36 | INFO | Rank 0 | Train Epoch: 4 [17888/23491 (76%)]\tLoss: 0.391407\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:36 | INFO | Rank 0 | Train Epoch: 4 [17920/23491 (76%)]\tLoss: 0.403865\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:37 | INFO | Rank 0 | Train Epoch: 4 [17952/23491 (76%)]\tLoss: 0.315060\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:37 | INFO | Rank 0 | Train Epoch: 4 [17984/23491 (77%)]\tLoss: 0.287907\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:37 | INFO | Rank 0 | Train Epoch: 4 [18016/23491 (77%)]\tLoss: 0.340923\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:37 | INFO | Rank 0 | Train Epoch: 4 [18048/23491 (77%)]\tLoss: 0.399773\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:38 | INFO | Rank 0 | Train Epoch: 4 [18080/23491 (77%)]\tLoss: 0.261095\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:38 | INFO | Rank 0 | Train Epoch: 4 [18112/23491 (77%)]\tLoss: 0.268343\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:38 | INFO | Rank 0 | Train Epoch: 4 [18144/23491 (77%)]\tLoss: 0.317053\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:38 | INFO | Rank 0 | Train Epoch: 4 [18176/23491 (77%)]\tLoss: 0.448353\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:39 | INFO | Rank 0 | Train Epoch: 4 [18208/23491 (78%)]\tLoss: 0.857884\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:39 | INFO | Rank 0 | Train Epoch: 4 [18240/23491 (78%)]\tLoss: 0.330561\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:39 | INFO | Rank 0 | Train Epoch: 4 [18272/23491 (78%)]\tLoss: 0.450482\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:40 | INFO | Rank 0 | Train Epoch: 4 [18304/23491 (78%)]\tLoss: 0.376153\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:40 | INFO | Rank 0 | Train Epoch: 4 [18336/23491 (78%)]\tLoss: 0.526213\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000048\tlogit_scale 4.545\n",
      "2022-11-08,05:42:40 | INFO | Rank 0 | Train Epoch: 4 [18368/23491 (78%)]\tLoss: 0.543989\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:40 | INFO | Rank 0 | Train Epoch: 4 [18400/23491 (78%)]\tLoss: 0.693432\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:41 | INFO | Rank 0 | Train Epoch: 4 [18432/23491 (78%)]\tLoss: 0.190343\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:41 | INFO | Rank 0 | Train Epoch: 4 [18464/23491 (79%)]\tLoss: 0.307051\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:41 | INFO | Rank 0 | Train Epoch: 4 [18496/23491 (79%)]\tLoss: 0.301558\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:41 | INFO | Rank 0 | Train Epoch: 4 [18528/23491 (79%)]\tLoss: 0.330678\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:42 | INFO | Rank 0 | Train Epoch: 4 [18560/23491 (79%)]\tLoss: 0.165980\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:42 | INFO | Rank 0 | Train Epoch: 4 [18592/23491 (79%)]\tLoss: 0.350445\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:42 | INFO | Rank 0 | Train Epoch: 4 [18624/23491 (79%)]\tLoss: 0.401705\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:42 | INFO | Rank 0 | Train Epoch: 4 [18656/23491 (79%)]\tLoss: 0.465800\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:43 | INFO | Rank 0 | Train Epoch: 4 [18688/23491 (80%)]\tLoss: 0.570933\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:43 | INFO | Rank 0 | Train Epoch: 4 [18720/23491 (80%)]\tLoss: 0.837702\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:43 | INFO | Rank 0 | Train Epoch: 4 [18752/23491 (80%)]\tLoss: 0.222329\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:44 | INFO | Rank 0 | Train Epoch: 4 [18784/23491 (80%)]\tLoss: 0.474451\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:44 | INFO | Rank 0 | Train Epoch: 4 [18816/23491 (80%)]\tLoss: 0.508896\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:44 | INFO | Rank 0 | Train Epoch: 4 [18848/23491 (80%)]\tLoss: 0.499827\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:44 | INFO | Rank 0 | Train Epoch: 4 [18880/23491 (80%)]\tLoss: 0.233832\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:45 | INFO | Rank 0 | Train Epoch: 4 [18912/23491 (81%)]\tLoss: 0.186856\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:45 | INFO | Rank 0 | Train Epoch: 4 [18944/23491 (81%)]\tLoss: 0.345928\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:45 | INFO | Rank 0 | Train Epoch: 4 [18976/23491 (81%)]\tLoss: 0.203789\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:45 | INFO | Rank 0 | Train Epoch: 4 [19008/23491 (81%)]\tLoss: 0.607262\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:46 | INFO | Rank 0 | Train Epoch: 4 [19040/23491 (81%)]\tLoss: 0.315980\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:46 | INFO | Rank 0 | Train Epoch: 4 [19072/23491 (81%)]\tLoss: 0.473960\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:46 | INFO | Rank 0 | Train Epoch: 4 [19104/23491 (81%)]\tLoss: 0.474263\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:46 | INFO | Rank 0 | Train Epoch: 4 [19136/23491 (81%)]\tLoss: 0.513676\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:47 | INFO | Rank 0 | Train Epoch: 4 [19168/23491 (82%)]\tLoss: 0.574641\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:47 | INFO | Rank 0 | Train Epoch: 4 [19200/23491 (82%)]\tLoss: 0.506845\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.545\n",
      "2022-11-08,05:42:47 | INFO | Rank 0 | Train Epoch: 4 [19232/23491 (82%)]\tLoss: 0.415320\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:48 | INFO | Rank 0 | Train Epoch: 4 [19264/23491 (82%)]\tLoss: 0.488900\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:48 | INFO | Rank 0 | Train Epoch: 4 [19296/23491 (82%)]\tLoss: 0.584677\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:48 | INFO | Rank 0 | Train Epoch: 4 [19328/23491 (82%)]\tLoss: 0.787379\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:48 | INFO | Rank 0 | Train Epoch: 4 [19360/23491 (82%)]\tLoss: 0.521973\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:49 | INFO | Rank 0 | Train Epoch: 4 [19392/23491 (83%)]\tLoss: 0.758275\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:49 | INFO | Rank 0 | Train Epoch: 4 [19424/23491 (83%)]\tLoss: 0.401590\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:49 | INFO | Rank 0 | Train Epoch: 4 [19456/23491 (83%)]\tLoss: 0.286230\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:49 | INFO | Rank 0 | Train Epoch: 4 [19488/23491 (83%)]\tLoss: 0.307726\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:50 | INFO | Rank 0 | Train Epoch: 4 [19520/23491 (83%)]\tLoss: 0.564894\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:50 | INFO | Rank 0 | Train Epoch: 4 [19552/23491 (83%)]\tLoss: 0.411437\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:50 | INFO | Rank 0 | Train Epoch: 4 [19584/23491 (83%)]\tLoss: 0.388402\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:50 | INFO | Rank 0 | Train Epoch: 4 [19616/23491 (84%)]\tLoss: 0.324608\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:51 | INFO | Rank 0 | Train Epoch: 4 [19648/23491 (84%)]\tLoss: 0.547597\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:51 | INFO | Rank 0 | Train Epoch: 4 [19680/23491 (84%)]\tLoss: 0.292334\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:51 | INFO | Rank 0 | Train Epoch: 4 [19712/23491 (84%)]\tLoss: 0.404146\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:51 | INFO | Rank 0 | Train Epoch: 4 [19744/23491 (84%)]\tLoss: 0.696383\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:52 | INFO | Rank 0 | Train Epoch: 4 [19776/23491 (84%)]\tLoss: 0.679316\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:52 | INFO | Rank 0 | Train Epoch: 4 [19808/23491 (84%)]\tLoss: 0.669577\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:52 | INFO | Rank 0 | Train Epoch: 4 [19840/23491 (84%)]\tLoss: 0.838745\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:53 | INFO | Rank 0 | Train Epoch: 4 [19872/23491 (85%)]\tLoss: 0.636600\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:53 | INFO | Rank 0 | Train Epoch: 4 [19904/23491 (85%)]\tLoss: 0.548303\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:53 | INFO | Rank 0 | Train Epoch: 4 [19936/23491 (85%)]\tLoss: 0.366089\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:53 | INFO | Rank 0 | Train Epoch: 4 [19968/23491 (85%)]\tLoss: 0.396961\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:54 | INFO | Rank 0 | Train Epoch: 4 [20000/23491 (85%)]\tLoss: 0.251868\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:54 | INFO | Rank 0 | Train Epoch: 4 [20032/23491 (85%)]\tLoss: 0.697861\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:54 | INFO | Rank 0 | Train Epoch: 4 [20064/23491 (85%)]\tLoss: 0.497807\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:54 | INFO | Rank 0 | Train Epoch: 4 [20096/23491 (86%)]\tLoss: 0.632130\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000047\tlogit_scale 4.544\n",
      "2022-11-08,05:42:55 | INFO | Rank 0 | Train Epoch: 4 [20128/23491 (86%)]\tLoss: 0.664494\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:55 | INFO | Rank 0 | Train Epoch: 4 [20160/23491 (86%)]\tLoss: 0.923466\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:55 | INFO | Rank 0 | Train Epoch: 4 [20192/23491 (86%)]\tLoss: 0.420372\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:55 | INFO | Rank 0 | Train Epoch: 4 [20224/23491 (86%)]\tLoss: 0.331623\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:56 | INFO | Rank 0 | Train Epoch: 4 [20256/23491 (86%)]\tLoss: 0.528279\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:56 | INFO | Rank 0 | Train Epoch: 4 [20288/23491 (86%)]\tLoss: 0.263605\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:56 | INFO | Rank 0 | Train Epoch: 4 [20320/23491 (87%)]\tLoss: 0.519824\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:57 | INFO | Rank 0 | Train Epoch: 4 [20352/23491 (87%)]\tLoss: 0.357622\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:57 | INFO | Rank 0 | Train Epoch: 4 [20384/23491 (87%)]\tLoss: 0.611501\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:57 | INFO | Rank 0 | Train Epoch: 4 [20416/23491 (87%)]\tLoss: 0.897701\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:57 | INFO | Rank 0 | Train Epoch: 4 [20448/23491 (87%)]\tLoss: 0.448978\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:58 | INFO | Rank 0 | Train Epoch: 4 [20480/23491 (87%)]\tLoss: 0.438369\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:58 | INFO | Rank 0 | Train Epoch: 4 [20512/23491 (87%)]\tLoss: 0.439647\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:58 | INFO | Rank 0 | Train Epoch: 4 [20544/23491 (87%)]\tLoss: 0.486457\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:58 | INFO | Rank 0 | Train Epoch: 4 [20576/23491 (88%)]\tLoss: 0.541160\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:59 | INFO | Rank 0 | Train Epoch: 4 [20608/23491 (88%)]\tLoss: 0.423379\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:59 | INFO | Rank 0 | Train Epoch: 4 [20640/23491 (88%)]\tLoss: 0.392983\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:59 | INFO | Rank 0 | Train Epoch: 4 [20672/23491 (88%)]\tLoss: 0.449005\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:42:59 | INFO | Rank 0 | Train Epoch: 4 [20704/23491 (88%)]\tLoss: 0.432774\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:00 | INFO | Rank 0 | Train Epoch: 4 [20736/23491 (88%)]\tLoss: 0.341864\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:00 | INFO | Rank 0 | Train Epoch: 4 [20768/23491 (88%)]\tLoss: 0.733029\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:00 | INFO | Rank 0 | Train Epoch: 4 [20800/23491 (89%)]\tLoss: 0.470144\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:01 | INFO | Rank 0 | Train Epoch: 4 [20832/23491 (89%)]\tLoss: 0.360553\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:01 | INFO | Rank 0 | Train Epoch: 4 [20864/23491 (89%)]\tLoss: 0.359782\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:01 | INFO | Rank 0 | Train Epoch: 4 [20896/23491 (89%)]\tLoss: 0.367479\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:01 | INFO | Rank 0 | Train Epoch: 4 [20928/23491 (89%)]\tLoss: 0.511627\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:02 | INFO | Rank 0 | Train Epoch: 4 [20960/23491 (89%)]\tLoss: 0.482297\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:02 | INFO | Rank 0 | Train Epoch: 4 [20992/23491 (89%)]\tLoss: 0.604261\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:02 | INFO | Rank 0 | Train Epoch: 4 [21024/23491 (90%)]\tLoss: 0.447042\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:02 | INFO | Rank 0 | Train Epoch: 4 [21056/23491 (90%)]\tLoss: 0.360800\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:03 | INFO | Rank 0 | Train Epoch: 4 [21088/23491 (90%)]\tLoss: 0.643609\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:03 | INFO | Rank 0 | Train Epoch: 4 [21120/23491 (90%)]\tLoss: 0.444050\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:03 | INFO | Rank 0 | Train Epoch: 4 [21152/23491 (90%)]\tLoss: 0.647360\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:03 | INFO | Rank 0 | Train Epoch: 4 [21184/23491 (90%)]\tLoss: 0.303241\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:04 | INFO | Rank 0 | Train Epoch: 4 [21216/23491 (90%)]\tLoss: 0.672134\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:04 | INFO | Rank 0 | Train Epoch: 4 [21248/23491 (90%)]\tLoss: 0.283119\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:04 | INFO | Rank 0 | Train Epoch: 4 [21280/23491 (91%)]\tLoss: 0.584094\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:05 | INFO | Rank 0 | Train Epoch: 4 [21312/23491 (91%)]\tLoss: 0.359355\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:05 | INFO | Rank 0 | Train Epoch: 4 [21344/23491 (91%)]\tLoss: 0.612264\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:05 | INFO | Rank 0 | Train Epoch: 4 [21376/23491 (91%)]\tLoss: 0.603786\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:05 | INFO | Rank 0 | Train Epoch: 4 [21408/23491 (91%)]\tLoss: 0.289228\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:06 | INFO | Rank 0 | Train Epoch: 4 [21440/23491 (91%)]\tLoss: 0.598936\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:06 | INFO | Rank 0 | Train Epoch: 4 [21472/23491 (91%)]\tLoss: 0.571239\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:06 | INFO | Rank 0 | Train Epoch: 4 [21504/23491 (92%)]\tLoss: 0.505845\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:06 | INFO | Rank 0 | Train Epoch: 4 [21536/23491 (92%)]\tLoss: 0.510903\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:07 | INFO | Rank 0 | Train Epoch: 4 [21568/23491 (92%)]\tLoss: 0.317739\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:07 | INFO | Rank 0 | Train Epoch: 4 [21600/23491 (92%)]\tLoss: 0.586122\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:07 | INFO | Rank 0 | Train Epoch: 4 [21632/23491 (92%)]\tLoss: 0.556733\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:07 | INFO | Rank 0 | Train Epoch: 4 [21664/23491 (92%)]\tLoss: 0.568702\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:08 | INFO | Rank 0 | Train Epoch: 4 [21696/23491 (92%)]\tLoss: 0.474566\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:08 | INFO | Rank 0 | Train Epoch: 4 [21728/23491 (93%)]\tLoss: 0.579584\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:08 | INFO | Rank 0 | Train Epoch: 4 [21760/23491 (93%)]\tLoss: 0.548357\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:08 | INFO | Rank 0 | Train Epoch: 4 [21792/23491 (93%)]\tLoss: 0.574570\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:09 | INFO | Rank 0 | Train Epoch: 4 [21824/23491 (93%)]\tLoss: 0.491282\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:09 | INFO | Rank 0 | Train Epoch: 4 [21856/23491 (93%)]\tLoss: 0.461296\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000046\tlogit_scale 4.544\n",
      "2022-11-08,05:43:09 | INFO | Rank 0 | Train Epoch: 4 [21888/23491 (93%)]\tLoss: 0.451072\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:10 | INFO | Rank 0 | Train Epoch: 4 [21920/23491 (93%)]\tLoss: 0.351771\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:10 | INFO | Rank 0 | Train Epoch: 4 [21952/23491 (93%)]\tLoss: 0.464485\tData (t) 0.052\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:10 | INFO | Rank 0 | Train Epoch: 4 [21984/23491 (94%)]\tLoss: 0.749600\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:10 | INFO | Rank 0 | Train Epoch: 4 [22016/23491 (94%)]\tLoss: 0.345605\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:11 | INFO | Rank 0 | Train Epoch: 4 [22048/23491 (94%)]\tLoss: 0.258852\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:11 | INFO | Rank 0 | Train Epoch: 4 [22080/23491 (94%)]\tLoss: 0.415255\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:11 | INFO | Rank 0 | Train Epoch: 4 [22112/23491 (94%)]\tLoss: 0.351049\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:11 | INFO | Rank 0 | Train Epoch: 4 [22144/23491 (94%)]\tLoss: 0.541877\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:12 | INFO | Rank 0 | Train Epoch: 4 [22176/23491 (94%)]\tLoss: 0.327160\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:12 | INFO | Rank 0 | Train Epoch: 4 [22208/23491 (95%)]\tLoss: 0.433462\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:12 | INFO | Rank 0 | Train Epoch: 4 [22240/23491 (95%)]\tLoss: 0.559790\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:12 | INFO | Rank 0 | Train Epoch: 4 [22272/23491 (95%)]\tLoss: 0.487606\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:13 | INFO | Rank 0 | Train Epoch: 4 [22304/23491 (95%)]\tLoss: 0.348196\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:13 | INFO | Rank 0 | Train Epoch: 4 [22336/23491 (95%)]\tLoss: 0.383547\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:13 | INFO | Rank 0 | Train Epoch: 4 [22368/23491 (95%)]\tLoss: 0.357424\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:14 | INFO | Rank 0 | Train Epoch: 4 [22400/23491 (95%)]\tLoss: 0.590487\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:14 | INFO | Rank 0 | Train Epoch: 4 [22432/23491 (96%)]\tLoss: 0.353448\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:14 | INFO | Rank 0 | Train Epoch: 4 [22464/23491 (96%)]\tLoss: 0.380415\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:14 | INFO | Rank 0 | Train Epoch: 4 [22496/23491 (96%)]\tLoss: 0.254065\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:15 | INFO | Rank 0 | Train Epoch: 4 [22528/23491 (96%)]\tLoss: 0.357677\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:15 | INFO | Rank 0 | Train Epoch: 4 [22560/23491 (96%)]\tLoss: 0.389175\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:15 | INFO | Rank 0 | Train Epoch: 4 [22592/23491 (96%)]\tLoss: 0.447586\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:15 | INFO | Rank 0 | Train Epoch: 4 [22624/23491 (96%)]\tLoss: 0.395038\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:16 | INFO | Rank 0 | Train Epoch: 4 [22656/23491 (96%)]\tLoss: 0.265947\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:16 | INFO | Rank 0 | Train Epoch: 4 [22688/23491 (97%)]\tLoss: 0.529473\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:16 | INFO | Rank 0 | Train Epoch: 4 [22720/23491 (97%)]\tLoss: 0.319035\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:16 | INFO | Rank 0 | Train Epoch: 4 [22752/23491 (97%)]\tLoss: 0.627545\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:17 | INFO | Rank 0 | Train Epoch: 4 [22784/23491 (97%)]\tLoss: 0.655558\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:17 | INFO | Rank 0 | Train Epoch: 4 [22816/23491 (97%)]\tLoss: 0.343991\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:17 | INFO | Rank 0 | Train Epoch: 4 [22848/23491 (97%)]\tLoss: 0.336123\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:18 | INFO | Rank 0 | Train Epoch: 4 [22880/23491 (97%)]\tLoss: 0.527021\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:18 | INFO | Rank 0 | Train Epoch: 4 [22912/23491 (98%)]\tLoss: 0.236562\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:18 | INFO | Rank 0 | Train Epoch: 4 [22944/23491 (98%)]\tLoss: 0.281643\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:18 | INFO | Rank 0 | Train Epoch: 4 [22976/23491 (98%)]\tLoss: 0.292353\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:19 | INFO | Rank 0 | Train Epoch: 4 [23008/23491 (98%)]\tLoss: 0.316649\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:19 | INFO | Rank 0 | Train Epoch: 4 [23040/23491 (98%)]\tLoss: 0.544954\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:19 | INFO | Rank 0 | Train Epoch: 4 [23072/23491 (98%)]\tLoss: 0.407305\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:19 | INFO | Rank 0 | Train Epoch: 4 [23104/23491 (98%)]\tLoss: 0.304124\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:20 | INFO | Rank 0 | Train Epoch: 4 [23136/23491 (99%)]\tLoss: 0.225259\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:20 | INFO | Rank 0 | Train Epoch: 4 [23168/23491 (99%)]\tLoss: 0.381379\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:20 | INFO | Rank 0 | Train Epoch: 4 [23200/23491 (99%)]\tLoss: 0.444550\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:20 | INFO | Rank 0 | Train Epoch: 4 [23232/23491 (99%)]\tLoss: 0.299160\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:21 | INFO | Rank 0 | Train Epoch: 4 [23264/23491 (99%)]\tLoss: 0.565174\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:21 | INFO | Rank 0 | Train Epoch: 4 [23296/23491 (99%)]\tLoss: 0.284542\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:21 | INFO | Rank 0 | Train Epoch: 4 [23328/23491 (99%)]\tLoss: 0.451023\tData (t) 0.052\tBatch (t) 0.264\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:22 | INFO | Rank 0 | Train Epoch: 4 [23360/23491 (99%)]\tLoss: 0.823965\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:22 | INFO | Rank 0 | Train Epoch: 4 [23392/23491 (100%)]\tLoss: 0.262795\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:22 | INFO | Rank 0 | Train Epoch: 4 [23424/23491 (100%)]\tLoss: 0.279384\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:43:22 | INFO | Rank 0 | Train Epoch: 4 [23456/23491 (100%)]\tLoss: 0.435751\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000045\tlogit_scale 4.544\n",
      "  0%|                                                   | 0/386 [00:00<?, ?it/s]2022-11-08,05:43:22 | INFO | Rank 0 | Begin to eval epoch: 5...\n",
      "100%|█████████████████████████████████████████| 386/386 [00:46<00:00,  8.36it/s]\n",
      "2022-11-08,05:44:09 | INFO | Rank 0 | Eval Epoch: 5 val_loss: 2.6684\tepoch: 5.0000\tnum_elements: 12328.0000\n",
      "2022-11-08,05:44:13 | INFO | Rank 0 | Start epoch 5\n",
      "2022-11-08,05:44:13 | INFO | Rank 0 | Train Epoch: 5 [0/23491 (0%)]\tLoss: 0.274926\tData (t) 0.036\tBatch (t) 0.253\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:44:13 | INFO | Rank 0 | Train Epoch: 5 [32/23491 (0%)]\tLoss: 0.328233\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:44:13 | INFO | Rank 0 | Train Epoch: 5 [64/23491 (0%)]\tLoss: 0.385316\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:44:14 | INFO | Rank 0 | Train Epoch: 5 [96/23491 (0%)]\tLoss: 0.202871\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:44:14 | INFO | Rank 0 | Train Epoch: 5 [128/23491 (1%)]\tLoss: 0.307943\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000045\tlogit_scale 4.544\n",
      "2022-11-08,05:44:14 | INFO | Rank 0 | Train Epoch: 5 [160/23491 (1%)]\tLoss: 0.226056\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:14 | INFO | Rank 0 | Train Epoch: 5 [192/23491 (1%)]\tLoss: 0.231342\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:15 | INFO | Rank 0 | Train Epoch: 5 [224/23491 (1%)]\tLoss: 0.466536\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:15 | INFO | Rank 0 | Train Epoch: 5 [256/23491 (1%)]\tLoss: 0.197363\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:15 | INFO | Rank 0 | Train Epoch: 5 [288/23491 (1%)]\tLoss: 0.285536\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:15 | INFO | Rank 0 | Train Epoch: 5 [320/23491 (1%)]\tLoss: 0.233699\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:16 | INFO | Rank 0 | Train Epoch: 5 [352/23491 (1%)]\tLoss: 0.223475\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:16 | INFO | Rank 0 | Train Epoch: 5 [384/23491 (2%)]\tLoss: 0.488879\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:16 | INFO | Rank 0 | Train Epoch: 5 [416/23491 (2%)]\tLoss: 0.475396\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:17 | INFO | Rank 0 | Train Epoch: 5 [448/23491 (2%)]\tLoss: 0.167437\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:17 | INFO | Rank 0 | Train Epoch: 5 [480/23491 (2%)]\tLoss: 0.200666\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:17 | INFO | Rank 0 | Train Epoch: 5 [512/23491 (2%)]\tLoss: 0.309165\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:17 | INFO | Rank 0 | Train Epoch: 5 [544/23491 (2%)]\tLoss: 0.229553\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:18 | INFO | Rank 0 | Train Epoch: 5 [576/23491 (2%)]\tLoss: 0.248924\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:18 | INFO | Rank 0 | Train Epoch: 5 [608/23491 (3%)]\tLoss: 0.158673\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:18 | INFO | Rank 0 | Train Epoch: 5 [640/23491 (3%)]\tLoss: 0.499788\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:18 | INFO | Rank 0 | Train Epoch: 5 [672/23491 (3%)]\tLoss: 0.345158\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:19 | INFO | Rank 0 | Train Epoch: 5 [704/23491 (3%)]\tLoss: 0.291780\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:19 | INFO | Rank 0 | Train Epoch: 5 [736/23491 (3%)]\tLoss: 0.303550\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:19 | INFO | Rank 0 | Train Epoch: 5 [768/23491 (3%)]\tLoss: 0.299685\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:19 | INFO | Rank 0 | Train Epoch: 5 [800/23491 (3%)]\tLoss: 0.358954\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:20 | INFO | Rank 0 | Train Epoch: 5 [832/23491 (4%)]\tLoss: 0.225226\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:20 | INFO | Rank 0 | Train Epoch: 5 [864/23491 (4%)]\tLoss: 0.290507\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:20 | INFO | Rank 0 | Train Epoch: 5 [896/23491 (4%)]\tLoss: 0.229062\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:21 | INFO | Rank 0 | Train Epoch: 5 [928/23491 (4%)]\tLoss: 0.268576\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:21 | INFO | Rank 0 | Train Epoch: 5 [960/23491 (4%)]\tLoss: 0.409215\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:21 | INFO | Rank 0 | Train Epoch: 5 [992/23491 (4%)]\tLoss: 0.242236\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:21 | INFO | Rank 0 | Train Epoch: 5 [1024/23491 (4%)]\tLoss: 0.387412\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:22 | INFO | Rank 0 | Train Epoch: 5 [1056/23491 (4%)]\tLoss: 0.290790\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:22 | INFO | Rank 0 | Train Epoch: 5 [1088/23491 (5%)]\tLoss: 0.256939\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:22 | INFO | Rank 0 | Train Epoch: 5 [1120/23491 (5%)]\tLoss: 0.424902\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:22 | INFO | Rank 0 | Train Epoch: 5 [1152/23491 (5%)]\tLoss: 0.217738\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:23 | INFO | Rank 0 | Train Epoch: 5 [1184/23491 (5%)]\tLoss: 0.352867\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:23 | INFO | Rank 0 | Train Epoch: 5 [1216/23491 (5%)]\tLoss: 0.209246\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:23 | INFO | Rank 0 | Train Epoch: 5 [1248/23491 (5%)]\tLoss: 0.340192\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:23 | INFO | Rank 0 | Train Epoch: 5 [1280/23491 (5%)]\tLoss: 0.264684\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:24 | INFO | Rank 0 | Train Epoch: 5 [1312/23491 (6%)]\tLoss: 0.201201\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:24 | INFO | Rank 0 | Train Epoch: 5 [1344/23491 (6%)]\tLoss: 0.108706\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:24 | INFO | Rank 0 | Train Epoch: 5 [1376/23491 (6%)]\tLoss: 0.125237\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:25 | INFO | Rank 0 | Train Epoch: 5 [1408/23491 (6%)]\tLoss: 0.288242\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:25 | INFO | Rank 0 | Train Epoch: 5 [1440/23491 (6%)]\tLoss: 0.448553\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:25 | INFO | Rank 0 | Train Epoch: 5 [1472/23491 (6%)]\tLoss: 0.080371\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:25 | INFO | Rank 0 | Train Epoch: 5 [1504/23491 (6%)]\tLoss: 0.322810\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:26 | INFO | Rank 0 | Train Epoch: 5 [1536/23491 (7%)]\tLoss: 0.304779\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:26 | INFO | Rank 0 | Train Epoch: 5 [1568/23491 (7%)]\tLoss: 0.276024\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:26 | INFO | Rank 0 | Train Epoch: 5 [1600/23491 (7%)]\tLoss: 0.090437\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:26 | INFO | Rank 0 | Train Epoch: 5 [1632/23491 (7%)]\tLoss: 0.106229\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:27 | INFO | Rank 0 | Train Epoch: 5 [1664/23491 (7%)]\tLoss: 0.199687\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:27 | INFO | Rank 0 | Train Epoch: 5 [1696/23491 (7%)]\tLoss: 0.370852\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:27 | INFO | Rank 0 | Train Epoch: 5 [1728/23491 (7%)]\tLoss: 0.285207\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:27 | INFO | Rank 0 | Train Epoch: 5 [1760/23491 (7%)]\tLoss: 0.341449\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:28 | INFO | Rank 0 | Train Epoch: 5 [1792/23491 (8%)]\tLoss: 0.193797\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:28 | INFO | Rank 0 | Train Epoch: 5 [1824/23491 (8%)]\tLoss: 0.246247\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:28 | INFO | Rank 0 | Train Epoch: 5 [1856/23491 (8%)]\tLoss: 0.195527\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:29 | INFO | Rank 0 | Train Epoch: 5 [1888/23491 (8%)]\tLoss: 0.316355\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000044\tlogit_scale 4.544\n",
      "2022-11-08,05:44:29 | INFO | Rank 0 | Train Epoch: 5 [1920/23491 (8%)]\tLoss: 0.201635\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:29 | INFO | Rank 0 | Train Epoch: 5 [1952/23491 (8%)]\tLoss: 0.161776\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:29 | INFO | Rank 0 | Train Epoch: 5 [1984/23491 (8%)]\tLoss: 0.150896\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:30 | INFO | Rank 0 | Train Epoch: 5 [2016/23491 (9%)]\tLoss: 0.146914\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:30 | INFO | Rank 0 | Train Epoch: 5 [2048/23491 (9%)]\tLoss: 0.104914\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:30 | INFO | Rank 0 | Train Epoch: 5 [2080/23491 (9%)]\tLoss: 0.140511\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:30 | INFO | Rank 0 | Train Epoch: 5 [2112/23491 (9%)]\tLoss: 0.245457\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:31 | INFO | Rank 0 | Train Epoch: 5 [2144/23491 (9%)]\tLoss: 0.298630\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:31 | INFO | Rank 0 | Train Epoch: 5 [2176/23491 (9%)]\tLoss: 0.182481\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:31 | INFO | Rank 0 | Train Epoch: 5 [2208/23491 (9%)]\tLoss: 0.243943\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:31 | INFO | Rank 0 | Train Epoch: 5 [2240/23491 (10%)]\tLoss: 0.249485\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:32 | INFO | Rank 0 | Train Epoch: 5 [2272/23491 (10%)]\tLoss: 0.314088\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:32 | INFO | Rank 0 | Train Epoch: 5 [2304/23491 (10%)]\tLoss: 0.210939\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:32 | INFO | Rank 0 | Train Epoch: 5 [2336/23491 (10%)]\tLoss: 0.344007\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:33 | INFO | Rank 0 | Train Epoch: 5 [2368/23491 (10%)]\tLoss: 0.287663\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:33 | INFO | Rank 0 | Train Epoch: 5 [2400/23491 (10%)]\tLoss: 0.353979\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:33 | INFO | Rank 0 | Train Epoch: 5 [2432/23491 (10%)]\tLoss: 0.190461\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:33 | INFO | Rank 0 | Train Epoch: 5 [2464/23491 (10%)]\tLoss: 0.176000\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:34 | INFO | Rank 0 | Train Epoch: 5 [2496/23491 (11%)]\tLoss: 0.336889\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:34 | INFO | Rank 0 | Train Epoch: 5 [2528/23491 (11%)]\tLoss: 0.323736\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:34 | INFO | Rank 0 | Train Epoch: 5 [2560/23491 (11%)]\tLoss: 0.169778\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:34 | INFO | Rank 0 | Train Epoch: 5 [2592/23491 (11%)]\tLoss: 0.226753\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:35 | INFO | Rank 0 | Train Epoch: 5 [2624/23491 (11%)]\tLoss: 0.147783\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:35 | INFO | Rank 0 | Train Epoch: 5 [2656/23491 (11%)]\tLoss: 0.320753\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:35 | INFO | Rank 0 | Train Epoch: 5 [2688/23491 (11%)]\tLoss: 0.198977\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:35 | INFO | Rank 0 | Train Epoch: 5 [2720/23491 (12%)]\tLoss: 0.296953\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:36 | INFO | Rank 0 | Train Epoch: 5 [2752/23491 (12%)]\tLoss: 0.134863\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:36 | INFO | Rank 0 | Train Epoch: 5 [2784/23491 (12%)]\tLoss: 0.216485\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:36 | INFO | Rank 0 | Train Epoch: 5 [2816/23491 (12%)]\tLoss: 0.563969\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:37 | INFO | Rank 0 | Train Epoch: 5 [2848/23491 (12%)]\tLoss: 0.470539\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:37 | INFO | Rank 0 | Train Epoch: 5 [2880/23491 (12%)]\tLoss: 0.276531\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:37 | INFO | Rank 0 | Train Epoch: 5 [2912/23491 (12%)]\tLoss: 0.512395\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:37 | INFO | Rank 0 | Train Epoch: 5 [2944/23491 (13%)]\tLoss: 0.173384\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:38 | INFO | Rank 0 | Train Epoch: 5 [2976/23491 (13%)]\tLoss: 0.271358\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:38 | INFO | Rank 0 | Train Epoch: 5 [3008/23491 (13%)]\tLoss: 0.366293\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:38 | INFO | Rank 0 | Train Epoch: 5 [3040/23491 (13%)]\tLoss: 0.313132\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:38 | INFO | Rank 0 | Train Epoch: 5 [3072/23491 (13%)]\tLoss: 0.189818\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:39 | INFO | Rank 0 | Train Epoch: 5 [3104/23491 (13%)]\tLoss: 0.402772\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:39 | INFO | Rank 0 | Train Epoch: 5 [3136/23491 (13%)]\tLoss: 0.241578\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:39 | INFO | Rank 0 | Train Epoch: 5 [3168/23491 (13%)]\tLoss: 0.222574\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:39 | INFO | Rank 0 | Train Epoch: 5 [3200/23491 (14%)]\tLoss: 0.083133\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:40 | INFO | Rank 0 | Train Epoch: 5 [3232/23491 (14%)]\tLoss: 0.304323\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:40 | INFO | Rank 0 | Train Epoch: 5 [3264/23491 (14%)]\tLoss: 0.457133\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:40 | INFO | Rank 0 | Train Epoch: 5 [3296/23491 (14%)]\tLoss: 0.322466\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:41 | INFO | Rank 0 | Train Epoch: 5 [3328/23491 (14%)]\tLoss: 0.149037\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:41 | INFO | Rank 0 | Train Epoch: 5 [3360/23491 (14%)]\tLoss: 0.404185\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:41 | INFO | Rank 0 | Train Epoch: 5 [3392/23491 (14%)]\tLoss: 0.157951\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:41 | INFO | Rank 0 | Train Epoch: 5 [3424/23491 (15%)]\tLoss: 0.212915\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:42 | INFO | Rank 0 | Train Epoch: 5 [3456/23491 (15%)]\tLoss: 0.272579\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:42 | INFO | Rank 0 | Train Epoch: 5 [3488/23491 (15%)]\tLoss: 0.210768\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:42 | INFO | Rank 0 | Train Epoch: 5 [3520/23491 (15%)]\tLoss: 0.380285\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:42 | INFO | Rank 0 | Train Epoch: 5 [3552/23491 (15%)]\tLoss: 0.260297\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:43 | INFO | Rank 0 | Train Epoch: 5 [3584/23491 (15%)]\tLoss: 0.414909\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:43 | INFO | Rank 0 | Train Epoch: 5 [3616/23491 (15%)]\tLoss: 0.497388\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000043\tlogit_scale 4.544\n",
      "2022-11-08,05:44:43 | INFO | Rank 0 | Train Epoch: 5 [3648/23491 (16%)]\tLoss: 0.363718\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.544\n",
      "2022-11-08,05:44:43 | INFO | Rank 0 | Train Epoch: 5 [3680/23491 (16%)]\tLoss: 0.374770\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.544\n",
      "2022-11-08,05:44:44 | INFO | Rank 0 | Train Epoch: 5 [3712/23491 (16%)]\tLoss: 0.301846\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.544\n",
      "2022-11-08,05:44:44 | INFO | Rank 0 | Train Epoch: 5 [3744/23491 (16%)]\tLoss: 0.100825\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.544\n",
      "2022-11-08,05:44:44 | INFO | Rank 0 | Train Epoch: 5 [3776/23491 (16%)]\tLoss: 0.293379\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.544\n",
      "2022-11-08,05:44:45 | INFO | Rank 0 | Train Epoch: 5 [3808/23491 (16%)]\tLoss: 0.350888\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.544\n",
      "2022-11-08,05:44:45 | INFO | Rank 0 | Train Epoch: 5 [3840/23491 (16%)]\tLoss: 0.463300\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.544\n",
      "2022-11-08,05:44:45 | INFO | Rank 0 | Train Epoch: 5 [3872/23491 (16%)]\tLoss: 0.398555\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.544\n",
      "2022-11-08,05:44:45 | INFO | Rank 0 | Train Epoch: 5 [3904/23491 (17%)]\tLoss: 0.108808\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.544\n",
      "2022-11-08,05:44:46 | INFO | Rank 0 | Train Epoch: 5 [3936/23491 (17%)]\tLoss: 0.246349\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.544\n",
      "2022-11-08,05:44:46 | INFO | Rank 0 | Train Epoch: 5 [3968/23491 (17%)]\tLoss: 0.337496\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.544\n",
      "2022-11-08,05:44:46 | INFO | Rank 0 | Train Epoch: 5 [4000/23491 (17%)]\tLoss: 0.232309\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.544\n",
      "2022-11-08,05:44:46 | INFO | Rank 0 | Train Epoch: 5 [4032/23491 (17%)]\tLoss: 0.411570\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.544\n",
      "2022-11-08,05:44:47 | INFO | Rank 0 | Train Epoch: 5 [4064/23491 (17%)]\tLoss: 0.415328\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.544\n",
      "2022-11-08,05:44:47 | INFO | Rank 0 | Train Epoch: 5 [4096/23491 (17%)]\tLoss: 0.444516\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.544\n",
      "2022-11-08,05:44:47 | INFO | Rank 0 | Train Epoch: 5 [4128/23491 (18%)]\tLoss: 0.310026\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:47 | INFO | Rank 0 | Train Epoch: 5 [4160/23491 (18%)]\tLoss: 0.106006\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:48 | INFO | Rank 0 | Train Epoch: 5 [4192/23491 (18%)]\tLoss: 0.309017\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:48 | INFO | Rank 0 | Train Epoch: 5 [4224/23491 (18%)]\tLoss: 0.159948\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:48 | INFO | Rank 0 | Train Epoch: 5 [4256/23491 (18%)]\tLoss: 0.199157\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:49 | INFO | Rank 0 | Train Epoch: 5 [4288/23491 (18%)]\tLoss: 0.452125\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:49 | INFO | Rank 0 | Train Epoch: 5 [4320/23491 (18%)]\tLoss: 0.476310\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:49 | INFO | Rank 0 | Train Epoch: 5 [4352/23491 (19%)]\tLoss: 0.310458\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:49 | INFO | Rank 0 | Train Epoch: 5 [4384/23491 (19%)]\tLoss: 0.708176\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:50 | INFO | Rank 0 | Train Epoch: 5 [4416/23491 (19%)]\tLoss: 0.181194\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:50 | INFO | Rank 0 | Train Epoch: 5 [4448/23491 (19%)]\tLoss: 0.391738\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:50 | INFO | Rank 0 | Train Epoch: 5 [4480/23491 (19%)]\tLoss: 0.364580\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:50 | INFO | Rank 0 | Train Epoch: 5 [4512/23491 (19%)]\tLoss: 0.269637\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:51 | INFO | Rank 0 | Train Epoch: 5 [4544/23491 (19%)]\tLoss: 0.434353\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:51 | INFO | Rank 0 | Train Epoch: 5 [4576/23491 (19%)]\tLoss: 0.302440\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:51 | INFO | Rank 0 | Train Epoch: 5 [4608/23491 (20%)]\tLoss: 0.226671\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:51 | INFO | Rank 0 | Train Epoch: 5 [4640/23491 (20%)]\tLoss: 0.284388\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:52 | INFO | Rank 0 | Train Epoch: 5 [4672/23491 (20%)]\tLoss: 0.191080\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:52 | INFO | Rank 0 | Train Epoch: 5 [4704/23491 (20%)]\tLoss: 0.393525\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:52 | INFO | Rank 0 | Train Epoch: 5 [4736/23491 (20%)]\tLoss: 0.244929\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:53 | INFO | Rank 0 | Train Epoch: 5 [4768/23491 (20%)]\tLoss: 0.699738\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:53 | INFO | Rank 0 | Train Epoch: 5 [4800/23491 (20%)]\tLoss: 0.383699\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:53 | INFO | Rank 0 | Train Epoch: 5 [4832/23491 (21%)]\tLoss: 0.265645\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:53 | INFO | Rank 0 | Train Epoch: 5 [4864/23491 (21%)]\tLoss: 0.299370\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:54 | INFO | Rank 0 | Train Epoch: 5 [4896/23491 (21%)]\tLoss: 0.350010\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:54 | INFO | Rank 0 | Train Epoch: 5 [4928/23491 (21%)]\tLoss: 0.217972\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:54 | INFO | Rank 0 | Train Epoch: 5 [4960/23491 (21%)]\tLoss: 0.346938\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:54 | INFO | Rank 0 | Train Epoch: 5 [4992/23491 (21%)]\tLoss: 0.332617\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:55 | INFO | Rank 0 | Train Epoch: 5 [5024/23491 (21%)]\tLoss: 0.229724\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:55 | INFO | Rank 0 | Train Epoch: 5 [5056/23491 (22%)]\tLoss: 0.516284\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:55 | INFO | Rank 0 | Train Epoch: 5 [5088/23491 (22%)]\tLoss: 0.364686\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:55 | INFO | Rank 0 | Train Epoch: 5 [5120/23491 (22%)]\tLoss: 0.336604\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:56 | INFO | Rank 0 | Train Epoch: 5 [5152/23491 (22%)]\tLoss: 0.482874\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:56 | INFO | Rank 0 | Train Epoch: 5 [5184/23491 (22%)]\tLoss: 0.448580\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:56 | INFO | Rank 0 | Train Epoch: 5 [5216/23491 (22%)]\tLoss: 0.397577\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:56 | INFO | Rank 0 | Train Epoch: 5 [5248/23491 (22%)]\tLoss: 0.438675\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:57 | INFO | Rank 0 | Train Epoch: 5 [5280/23491 (22%)]\tLoss: 0.164833\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:57 | INFO | Rank 0 | Train Epoch: 5 [5312/23491 (23%)]\tLoss: 0.401814\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:57 | INFO | Rank 0 | Train Epoch: 5 [5344/23491 (23%)]\tLoss: 0.394004\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:58 | INFO | Rank 0 | Train Epoch: 5 [5376/23491 (23%)]\tLoss: 0.215402\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000042\tlogit_scale 4.543\n",
      "2022-11-08,05:44:58 | INFO | Rank 0 | Train Epoch: 5 [5408/23491 (23%)]\tLoss: 0.253691\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:44:58 | INFO | Rank 0 | Train Epoch: 5 [5440/23491 (23%)]\tLoss: 0.317613\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:44:58 | INFO | Rank 0 | Train Epoch: 5 [5472/23491 (23%)]\tLoss: 0.302432\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:44:59 | INFO | Rank 0 | Train Epoch: 5 [5504/23491 (23%)]\tLoss: 0.340815\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:44:59 | INFO | Rank 0 | Train Epoch: 5 [5536/23491 (24%)]\tLoss: 0.119339\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:44:59 | INFO | Rank 0 | Train Epoch: 5 [5568/23491 (24%)]\tLoss: 0.364968\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:44:59 | INFO | Rank 0 | Train Epoch: 5 [5600/23491 (24%)]\tLoss: 0.282578\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:00 | INFO | Rank 0 | Train Epoch: 5 [5632/23491 (24%)]\tLoss: 0.247863\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:00 | INFO | Rank 0 | Train Epoch: 5 [5664/23491 (24%)]\tLoss: 0.252897\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:00 | INFO | Rank 0 | Train Epoch: 5 [5696/23491 (24%)]\tLoss: 0.264025\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:00 | INFO | Rank 0 | Train Epoch: 5 [5728/23491 (24%)]\tLoss: 0.263548\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:01 | INFO | Rank 0 | Train Epoch: 5 [5760/23491 (25%)]\tLoss: 0.172672\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:01 | INFO | Rank 0 | Train Epoch: 5 [5792/23491 (25%)]\tLoss: 0.189825\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:01 | INFO | Rank 0 | Train Epoch: 5 [5824/23491 (25%)]\tLoss: 0.234427\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:02 | INFO | Rank 0 | Train Epoch: 5 [5856/23491 (25%)]\tLoss: 0.222406\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:02 | INFO | Rank 0 | Train Epoch: 5 [5888/23491 (25%)]\tLoss: 0.379421\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:02 | INFO | Rank 0 | Train Epoch: 5 [5920/23491 (25%)]\tLoss: 0.143550\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:02 | INFO | Rank 0 | Train Epoch: 5 [5952/23491 (25%)]\tLoss: 0.124139\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:03 | INFO | Rank 0 | Train Epoch: 5 [5984/23491 (25%)]\tLoss: 0.462650\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:03 | INFO | Rank 0 | Train Epoch: 5 [6016/23491 (26%)]\tLoss: 0.410390\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:03 | INFO | Rank 0 | Train Epoch: 5 [6048/23491 (26%)]\tLoss: 0.208898\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:03 | INFO | Rank 0 | Train Epoch: 5 [6080/23491 (26%)]\tLoss: 0.299375\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:04 | INFO | Rank 0 | Train Epoch: 5 [6112/23491 (26%)]\tLoss: 0.294976\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:04 | INFO | Rank 0 | Train Epoch: 5 [6144/23491 (26%)]\tLoss: 0.537712\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:04 | INFO | Rank 0 | Train Epoch: 5 [6176/23491 (26%)]\tLoss: 0.384916\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:04 | INFO | Rank 0 | Train Epoch: 5 [6208/23491 (26%)]\tLoss: 0.245127\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:05 | INFO | Rank 0 | Train Epoch: 5 [6240/23491 (27%)]\tLoss: 0.213638\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:05 | INFO | Rank 0 | Train Epoch: 5 [6272/23491 (27%)]\tLoss: 0.296073\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:05 | INFO | Rank 0 | Train Epoch: 5 [6304/23491 (27%)]\tLoss: 0.316579\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:06 | INFO | Rank 0 | Train Epoch: 5 [6336/23491 (27%)]\tLoss: 0.169555\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:06 | INFO | Rank 0 | Train Epoch: 5 [6368/23491 (27%)]\tLoss: 0.323026\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:06 | INFO | Rank 0 | Train Epoch: 5 [6400/23491 (27%)]\tLoss: 0.241561\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:06 | INFO | Rank 0 | Train Epoch: 5 [6432/23491 (27%)]\tLoss: 0.398718\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:07 | INFO | Rank 0 | Train Epoch: 5 [6464/23491 (28%)]\tLoss: 0.310916\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:07 | INFO | Rank 0 | Train Epoch: 5 [6496/23491 (28%)]\tLoss: 0.136899\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:07 | INFO | Rank 0 | Train Epoch: 5 [6528/23491 (28%)]\tLoss: 0.367350\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:07 | INFO | Rank 0 | Train Epoch: 5 [6560/23491 (28%)]\tLoss: 0.328185\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:08 | INFO | Rank 0 | Train Epoch: 5 [6592/23491 (28%)]\tLoss: 0.191718\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:08 | INFO | Rank 0 | Train Epoch: 5 [6624/23491 (28%)]\tLoss: 0.230864\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:08 | INFO | Rank 0 | Train Epoch: 5 [6656/23491 (28%)]\tLoss: 0.319686\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:08 | INFO | Rank 0 | Train Epoch: 5 [6688/23491 (28%)]\tLoss: 0.438973\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:09 | INFO | Rank 0 | Train Epoch: 5 [6720/23491 (29%)]\tLoss: 0.356712\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:09 | INFO | Rank 0 | Train Epoch: 5 [6752/23491 (29%)]\tLoss: 0.202520\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:09 | INFO | Rank 0 | Train Epoch: 5 [6784/23491 (29%)]\tLoss: 0.386195\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:10 | INFO | Rank 0 | Train Epoch: 5 [6816/23491 (29%)]\tLoss: 0.346418\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:10 | INFO | Rank 0 | Train Epoch: 5 [6848/23491 (29%)]\tLoss: 0.279452\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:10 | INFO | Rank 0 | Train Epoch: 5 [6880/23491 (29%)]\tLoss: 0.426479\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:10 | INFO | Rank 0 | Train Epoch: 5 [6912/23491 (29%)]\tLoss: 0.566253\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:11 | INFO | Rank 0 | Train Epoch: 5 [6944/23491 (30%)]\tLoss: 0.251328\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:11 | INFO | Rank 0 | Train Epoch: 5 [6976/23491 (30%)]\tLoss: 0.351626\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:11 | INFO | Rank 0 | Train Epoch: 5 [7008/23491 (30%)]\tLoss: 0.146062\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:11 | INFO | Rank 0 | Train Epoch: 5 [7040/23491 (30%)]\tLoss: 0.364639\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:12 | INFO | Rank 0 | Train Epoch: 5 [7072/23491 (30%)]\tLoss: 0.294861\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:12 | INFO | Rank 0 | Train Epoch: 5 [7104/23491 (30%)]\tLoss: 0.319015\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000041\tlogit_scale 4.543\n",
      "2022-11-08,05:45:12 | INFO | Rank 0 | Train Epoch: 5 [7136/23491 (30%)]\tLoss: 0.323982\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:12 | INFO | Rank 0 | Train Epoch: 5 [7168/23491 (31%)]\tLoss: 0.561664\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:13 | INFO | Rank 0 | Train Epoch: 5 [7200/23491 (31%)]\tLoss: 0.095482\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:13 | INFO | Rank 0 | Train Epoch: 5 [7232/23491 (31%)]\tLoss: 0.402906\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:13 | INFO | Rank 0 | Train Epoch: 5 [7264/23491 (31%)]\tLoss: 0.200084\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:14 | INFO | Rank 0 | Train Epoch: 5 [7296/23491 (31%)]\tLoss: 0.203212\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:14 | INFO | Rank 0 | Train Epoch: 5 [7328/23491 (31%)]\tLoss: 0.205731\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:14 | INFO | Rank 0 | Train Epoch: 5 [7360/23491 (31%)]\tLoss: 0.167236\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:14 | INFO | Rank 0 | Train Epoch: 5 [7392/23491 (31%)]\tLoss: 0.114175\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:15 | INFO | Rank 0 | Train Epoch: 5 [7424/23491 (32%)]\tLoss: 0.373309\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:15 | INFO | Rank 0 | Train Epoch: 5 [7456/23491 (32%)]\tLoss: 0.491936\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:15 | INFO | Rank 0 | Train Epoch: 5 [7488/23491 (32%)]\tLoss: 0.263025\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:15 | INFO | Rank 0 | Train Epoch: 5 [7520/23491 (32%)]\tLoss: 0.336903\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:16 | INFO | Rank 0 | Train Epoch: 5 [7552/23491 (32%)]\tLoss: 0.463837\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:16 | INFO | Rank 0 | Train Epoch: 5 [7584/23491 (32%)]\tLoss: 0.284572\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:16 | INFO | Rank 0 | Train Epoch: 5 [7616/23491 (32%)]\tLoss: 0.449794\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:16 | INFO | Rank 0 | Train Epoch: 5 [7648/23491 (33%)]\tLoss: 0.123911\tData (t) 0.055\tBatch (t) 0.270\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:17 | INFO | Rank 0 | Train Epoch: 5 [7680/23491 (33%)]\tLoss: 0.536677\tData (t) 0.055\tBatch (t) 0.269\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:17 | INFO | Rank 0 | Train Epoch: 5 [7712/23491 (33%)]\tLoss: 0.365505\tData (t) 0.055\tBatch (t) 0.269\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:17 | INFO | Rank 0 | Train Epoch: 5 [7744/23491 (33%)]\tLoss: 0.506473\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:18 | INFO | Rank 0 | Train Epoch: 5 [7776/23491 (33%)]\tLoss: 0.191642\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:18 | INFO | Rank 0 | Train Epoch: 5 [7808/23491 (33%)]\tLoss: 0.270650\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:18 | INFO | Rank 0 | Train Epoch: 5 [7840/23491 (33%)]\tLoss: 0.266593\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:18 | INFO | Rank 0 | Train Epoch: 5 [7872/23491 (34%)]\tLoss: 0.249582\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:19 | INFO | Rank 0 | Train Epoch: 5 [7904/23491 (34%)]\tLoss: 0.632438\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:19 | INFO | Rank 0 | Train Epoch: 5 [7936/23491 (34%)]\tLoss: 0.222643\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:19 | INFO | Rank 0 | Train Epoch: 5 [7968/23491 (34%)]\tLoss: 0.415381\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:19 | INFO | Rank 0 | Train Epoch: 5 [8000/23491 (34%)]\tLoss: 0.421802\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:20 | INFO | Rank 0 | Train Epoch: 5 [8032/23491 (34%)]\tLoss: 0.288928\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:20 | INFO | Rank 0 | Train Epoch: 5 [8064/23491 (34%)]\tLoss: 0.451912\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:20 | INFO | Rank 0 | Train Epoch: 5 [8096/23491 (34%)]\tLoss: 0.501750\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:20 | INFO | Rank 0 | Train Epoch: 5 [8128/23491 (35%)]\tLoss: 0.230188\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:21 | INFO | Rank 0 | Train Epoch: 5 [8160/23491 (35%)]\tLoss: 0.258706\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:21 | INFO | Rank 0 | Train Epoch: 5 [8192/23491 (35%)]\tLoss: 0.323816\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:21 | INFO | Rank 0 | Train Epoch: 5 [8224/23491 (35%)]\tLoss: 0.168383\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:22 | INFO | Rank 0 | Train Epoch: 5 [8256/23491 (35%)]\tLoss: 0.547944\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:22 | INFO | Rank 0 | Train Epoch: 5 [8288/23491 (35%)]\tLoss: 0.245694\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:22 | INFO | Rank 0 | Train Epoch: 5 [8320/23491 (35%)]\tLoss: 0.258253\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:22 | INFO | Rank 0 | Train Epoch: 5 [8352/23491 (36%)]\tLoss: 0.203326\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:23 | INFO | Rank 0 | Train Epoch: 5 [8384/23491 (36%)]\tLoss: 0.208012\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:23 | INFO | Rank 0 | Train Epoch: 5 [8416/23491 (36%)]\tLoss: 0.327389\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:23 | INFO | Rank 0 | Train Epoch: 5 [8448/23491 (36%)]\tLoss: 0.365686\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:23 | INFO | Rank 0 | Train Epoch: 5 [8480/23491 (36%)]\tLoss: 0.215485\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:24 | INFO | Rank 0 | Train Epoch: 5 [8512/23491 (36%)]\tLoss: 0.177595\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:24 | INFO | Rank 0 | Train Epoch: 5 [8544/23491 (36%)]\tLoss: 0.179963\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:24 | INFO | Rank 0 | Train Epoch: 5 [8576/23491 (37%)]\tLoss: 0.412443\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:24 | INFO | Rank 0 | Train Epoch: 5 [8608/23491 (37%)]\tLoss: 0.517939\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:25 | INFO | Rank 0 | Train Epoch: 5 [8640/23491 (37%)]\tLoss: 0.228476\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:25 | INFO | Rank 0 | Train Epoch: 5 [8672/23491 (37%)]\tLoss: 0.243349\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:25 | INFO | Rank 0 | Train Epoch: 5 [8704/23491 (37%)]\tLoss: 0.408074\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:26 | INFO | Rank 0 | Train Epoch: 5 [8736/23491 (37%)]\tLoss: 0.222768\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:26 | INFO | Rank 0 | Train Epoch: 5 [8768/23491 (37%)]\tLoss: 0.351450\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:26 | INFO | Rank 0 | Train Epoch: 5 [8800/23491 (37%)]\tLoss: 0.259868\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:26 | INFO | Rank 0 | Train Epoch: 5 [8832/23491 (38%)]\tLoss: 0.164964\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:27 | INFO | Rank 0 | Train Epoch: 5 [8864/23491 (38%)]\tLoss: 0.074171\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000040\tlogit_scale 4.543\n",
      "2022-11-08,05:45:27 | INFO | Rank 0 | Train Epoch: 5 [8896/23491 (38%)]\tLoss: 0.337461\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:27 | INFO | Rank 0 | Train Epoch: 5 [8928/23491 (38%)]\tLoss: 0.259332\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:27 | INFO | Rank 0 | Train Epoch: 5 [8960/23491 (38%)]\tLoss: 0.411985\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:28 | INFO | Rank 0 | Train Epoch: 5 [8992/23491 (38%)]\tLoss: 0.112417\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:28 | INFO | Rank 0 | Train Epoch: 5 [9024/23491 (38%)]\tLoss: 0.178396\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:28 | INFO | Rank 0 | Train Epoch: 5 [9056/23491 (39%)]\tLoss: 0.284118\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:28 | INFO | Rank 0 | Train Epoch: 5 [9088/23491 (39%)]\tLoss: 0.299570\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:29 | INFO | Rank 0 | Train Epoch: 5 [9120/23491 (39%)]\tLoss: 0.221148\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:29 | INFO | Rank 0 | Train Epoch: 5 [9152/23491 (39%)]\tLoss: 0.118207\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:29 | INFO | Rank 0 | Train Epoch: 5 [9184/23491 (39%)]\tLoss: 0.224309\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:30 | INFO | Rank 0 | Train Epoch: 5 [9216/23491 (39%)]\tLoss: 0.269747\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:30 | INFO | Rank 0 | Train Epoch: 5 [9248/23491 (39%)]\tLoss: 0.216973\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:30 | INFO | Rank 0 | Train Epoch: 5 [9280/23491 (40%)]\tLoss: 0.276449\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:30 | INFO | Rank 0 | Train Epoch: 5 [9312/23491 (40%)]\tLoss: 0.285601\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:31 | INFO | Rank 0 | Train Epoch: 5 [9344/23491 (40%)]\tLoss: 0.095233\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:31 | INFO | Rank 0 | Train Epoch: 5 [9376/23491 (40%)]\tLoss: 0.295338\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:31 | INFO | Rank 0 | Train Epoch: 5 [9408/23491 (40%)]\tLoss: 0.529583\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:31 | INFO | Rank 0 | Train Epoch: 5 [9440/23491 (40%)]\tLoss: 0.269047\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:32 | INFO | Rank 0 | Train Epoch: 5 [9472/23491 (40%)]\tLoss: 0.421781\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:32 | INFO | Rank 0 | Train Epoch: 5 [9504/23491 (40%)]\tLoss: 0.369286\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:32 | INFO | Rank 0 | Train Epoch: 5 [9536/23491 (41%)]\tLoss: 0.315937\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:32 | INFO | Rank 0 | Train Epoch: 5 [9568/23491 (41%)]\tLoss: 0.395540\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:33 | INFO | Rank 0 | Train Epoch: 5 [9600/23491 (41%)]\tLoss: 0.340520\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:33 | INFO | Rank 0 | Train Epoch: 5 [9632/23491 (41%)]\tLoss: 0.240796\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:33 | INFO | Rank 0 | Train Epoch: 5 [9664/23491 (41%)]\tLoss: 0.257578\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:34 | INFO | Rank 0 | Train Epoch: 5 [9696/23491 (41%)]\tLoss: 0.294756\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:34 | INFO | Rank 0 | Train Epoch: 5 [9728/23491 (41%)]\tLoss: 0.339087\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:34 | INFO | Rank 0 | Train Epoch: 5 [9760/23491 (42%)]\tLoss: 0.140694\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:34 | INFO | Rank 0 | Train Epoch: 5 [9792/23491 (42%)]\tLoss: 0.580106\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:35 | INFO | Rank 0 | Train Epoch: 5 [9824/23491 (42%)]\tLoss: 0.194655\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:35 | INFO | Rank 0 | Train Epoch: 5 [9856/23491 (42%)]\tLoss: 0.195693\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:35 | INFO | Rank 0 | Train Epoch: 5 [9888/23491 (42%)]\tLoss: 0.268192\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:35 | INFO | Rank 0 | Train Epoch: 5 [9920/23491 (42%)]\tLoss: 0.184231\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:36 | INFO | Rank 0 | Train Epoch: 5 [9952/23491 (42%)]\tLoss: 0.617620\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:36 | INFO | Rank 0 | Train Epoch: 5 [9984/23491 (43%)]\tLoss: 0.270296\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:36 | INFO | Rank 0 | Train Epoch: 5 [10016/23491 (43%)]\tLoss: 0.211562\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:36 | INFO | Rank 0 | Train Epoch: 5 [10048/23491 (43%)]\tLoss: 0.226831\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:37 | INFO | Rank 0 | Train Epoch: 5 [10080/23491 (43%)]\tLoss: 0.250886\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:37 | INFO | Rank 0 | Train Epoch: 5 [10112/23491 (43%)]\tLoss: 0.234305\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:37 | INFO | Rank 0 | Train Epoch: 5 [10144/23491 (43%)]\tLoss: 0.328981\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:38 | INFO | Rank 0 | Train Epoch: 5 [10176/23491 (43%)]\tLoss: 0.385849\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:38 | INFO | Rank 0 | Train Epoch: 5 [10208/23491 (43%)]\tLoss: 0.439920\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:38 | INFO | Rank 0 | Train Epoch: 5 [10240/23491 (44%)]\tLoss: 0.201185\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:38 | INFO | Rank 0 | Train Epoch: 5 [10272/23491 (44%)]\tLoss: 0.216172\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:39 | INFO | Rank 0 | Train Epoch: 5 [10304/23491 (44%)]\tLoss: 0.200540\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:39 | INFO | Rank 0 | Train Epoch: 5 [10336/23491 (44%)]\tLoss: 0.301821\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:39 | INFO | Rank 0 | Train Epoch: 5 [10368/23491 (44%)]\tLoss: 0.178537\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:39 | INFO | Rank 0 | Train Epoch: 5 [10400/23491 (44%)]\tLoss: 0.240328\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:40 | INFO | Rank 0 | Train Epoch: 5 [10432/23491 (44%)]\tLoss: 0.124539\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:40 | INFO | Rank 0 | Train Epoch: 5 [10464/23491 (45%)]\tLoss: 0.341980\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:40 | INFO | Rank 0 | Train Epoch: 5 [10496/23491 (45%)]\tLoss: 0.311529\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:40 | INFO | Rank 0 | Train Epoch: 5 [10528/23491 (45%)]\tLoss: 0.269013\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:41 | INFO | Rank 0 | Train Epoch: 5 [10560/23491 (45%)]\tLoss: 0.095750\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:41 | INFO | Rank 0 | Train Epoch: 5 [10592/23491 (45%)]\tLoss: 0.375989\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000039\tlogit_scale 4.543\n",
      "2022-11-08,05:45:41 | INFO | Rank 0 | Train Epoch: 5 [10624/23491 (45%)]\tLoss: 0.270263\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.543\n",
      "2022-11-08,05:45:42 | INFO | Rank 0 | Train Epoch: 5 [10656/23491 (45%)]\tLoss: 0.174233\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.543\n",
      "2022-11-08,05:45:42 | INFO | Rank 0 | Train Epoch: 5 [10688/23491 (46%)]\tLoss: 0.455795\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.543\n",
      "2022-11-08,05:45:42 | INFO | Rank 0 | Train Epoch: 5 [10720/23491 (46%)]\tLoss: 0.307204\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.543\n",
      "2022-11-08,05:45:42 | INFO | Rank 0 | Train Epoch: 5 [10752/23491 (46%)]\tLoss: 0.317161\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:43 | INFO | Rank 0 | Train Epoch: 5 [10784/23491 (46%)]\tLoss: 0.435750\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:43 | INFO | Rank 0 | Train Epoch: 5 [10816/23491 (46%)]\tLoss: 0.229484\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:43 | INFO | Rank 0 | Train Epoch: 5 [10848/23491 (46%)]\tLoss: 0.293453\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:43 | INFO | Rank 0 | Train Epoch: 5 [10880/23491 (46%)]\tLoss: 0.132066\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:44 | INFO | Rank 0 | Train Epoch: 5 [10912/23491 (46%)]\tLoss: 0.471349\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:44 | INFO | Rank 0 | Train Epoch: 5 [10944/23491 (47%)]\tLoss: 0.118066\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:44 | INFO | Rank 0 | Train Epoch: 5 [10976/23491 (47%)]\tLoss: 0.275208\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:44 | INFO | Rank 0 | Train Epoch: 5 [11008/23491 (47%)]\tLoss: 0.261521\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:45 | INFO | Rank 0 | Train Epoch: 5 [11040/23491 (47%)]\tLoss: 0.402351\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:45 | INFO | Rank 0 | Train Epoch: 5 [11072/23491 (47%)]\tLoss: 0.361702\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:45 | INFO | Rank 0 | Train Epoch: 5 [11104/23491 (47%)]\tLoss: 0.484698\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:46 | INFO | Rank 0 | Train Epoch: 5 [11136/23491 (47%)]\tLoss: 0.070241\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:46 | INFO | Rank 0 | Train Epoch: 5 [11168/23491 (48%)]\tLoss: 0.221295\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:46 | INFO | Rank 0 | Train Epoch: 5 [11200/23491 (48%)]\tLoss: 0.132292\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:46 | INFO | Rank 0 | Train Epoch: 5 [11232/23491 (48%)]\tLoss: 0.143629\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:47 | INFO | Rank 0 | Train Epoch: 5 [11264/23491 (48%)]\tLoss: 0.223236\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:47 | INFO | Rank 0 | Train Epoch: 5 [11296/23491 (48%)]\tLoss: 0.153272\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:47 | INFO | Rank 0 | Train Epoch: 5 [11328/23491 (48%)]\tLoss: 0.296161\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:47 | INFO | Rank 0 | Train Epoch: 5 [11360/23491 (48%)]\tLoss: 0.238650\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:48 | INFO | Rank 0 | Train Epoch: 5 [11392/23491 (49%)]\tLoss: 0.307116\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:48 | INFO | Rank 0 | Train Epoch: 5 [11424/23491 (49%)]\tLoss: 0.270993\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:48 | INFO | Rank 0 | Train Epoch: 5 [11456/23491 (49%)]\tLoss: 0.378285\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:48 | INFO | Rank 0 | Train Epoch: 5 [11488/23491 (49%)]\tLoss: 0.495847\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:49 | INFO | Rank 0 | Train Epoch: 5 [11520/23491 (49%)]\tLoss: 0.259611\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:49 | INFO | Rank 0 | Train Epoch: 5 [11552/23491 (49%)]\tLoss: 0.356498\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:49 | INFO | Rank 0 | Train Epoch: 5 [11584/23491 (49%)]\tLoss: 0.158091\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:50 | INFO | Rank 0 | Train Epoch: 5 [11616/23491 (49%)]\tLoss: 0.374751\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:50 | INFO | Rank 0 | Train Epoch: 5 [11648/23491 (50%)]\tLoss: 0.156058\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:50 | INFO | Rank 0 | Train Epoch: 5 [11680/23491 (50%)]\tLoss: 0.352982\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:50 | INFO | Rank 0 | Train Epoch: 5 [11712/23491 (50%)]\tLoss: 0.154952\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:51 | INFO | Rank 0 | Train Epoch: 5 [11744/23491 (50%)]\tLoss: 0.245180\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:51 | INFO | Rank 0 | Train Epoch: 5 [11776/23491 (50%)]\tLoss: 0.444333\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:51 | INFO | Rank 0 | Train Epoch: 5 [11808/23491 (50%)]\tLoss: 0.177707\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:51 | INFO | Rank 0 | Train Epoch: 5 [11840/23491 (50%)]\tLoss: 0.137674\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:52 | INFO | Rank 0 | Train Epoch: 5 [11872/23491 (51%)]\tLoss: 0.238864\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:52 | INFO | Rank 0 | Train Epoch: 5 [11904/23491 (51%)]\tLoss: 0.252340\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:52 | INFO | Rank 0 | Train Epoch: 5 [11936/23491 (51%)]\tLoss: 0.601115\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:52 | INFO | Rank 0 | Train Epoch: 5 [11968/23491 (51%)]\tLoss: 0.277137\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:53 | INFO | Rank 0 | Train Epoch: 5 [12000/23491 (51%)]\tLoss: 0.446692\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:53 | INFO | Rank 0 | Train Epoch: 5 [12032/23491 (51%)]\tLoss: 0.502689\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:53 | INFO | Rank 0 | Train Epoch: 5 [12064/23491 (51%)]\tLoss: 0.304903\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:53 | INFO | Rank 0 | Train Epoch: 5 [12096/23491 (51%)]\tLoss: 0.215052\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:54 | INFO | Rank 0 | Train Epoch: 5 [12128/23491 (52%)]\tLoss: 0.152844\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:54 | INFO | Rank 0 | Train Epoch: 5 [12160/23491 (52%)]\tLoss: 0.169633\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:54 | INFO | Rank 0 | Train Epoch: 5 [12192/23491 (52%)]\tLoss: 0.349222\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:55 | INFO | Rank 0 | Train Epoch: 5 [12224/23491 (52%)]\tLoss: 0.487645\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:55 | INFO | Rank 0 | Train Epoch: 5 [12256/23491 (52%)]\tLoss: 0.300341\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:55 | INFO | Rank 0 | Train Epoch: 5 [12288/23491 (52%)]\tLoss: 0.197196\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:55 | INFO | Rank 0 | Train Epoch: 5 [12320/23491 (52%)]\tLoss: 0.339418\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:56 | INFO | Rank 0 | Train Epoch: 5 [12352/23491 (53%)]\tLoss: 0.405028\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000038\tlogit_scale 4.542\n",
      "2022-11-08,05:45:56 | INFO | Rank 0 | Train Epoch: 5 [12384/23491 (53%)]\tLoss: 0.304353\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:45:56 | INFO | Rank 0 | Train Epoch: 5 [12416/23491 (53%)]\tLoss: 0.054271\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:45:56 | INFO | Rank 0 | Train Epoch: 5 [12448/23491 (53%)]\tLoss: 0.427413\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:45:57 | INFO | Rank 0 | Train Epoch: 5 [12480/23491 (53%)]\tLoss: 0.344008\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:45:57 | INFO | Rank 0 | Train Epoch: 5 [12512/23491 (53%)]\tLoss: 0.284308\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:45:57 | INFO | Rank 0 | Train Epoch: 5 [12544/23491 (53%)]\tLoss: 0.196537\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:45:57 | INFO | Rank 0 | Train Epoch: 5 [12576/23491 (54%)]\tLoss: 0.353773\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:45:58 | INFO | Rank 0 | Train Epoch: 5 [12608/23491 (54%)]\tLoss: 0.313339\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:45:58 | INFO | Rank 0 | Train Epoch: 5 [12640/23491 (54%)]\tLoss: 0.291037\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:45:58 | INFO | Rank 0 | Train Epoch: 5 [12672/23491 (54%)]\tLoss: 0.211909\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:45:59 | INFO | Rank 0 | Train Epoch: 5 [12704/23491 (54%)]\tLoss: 0.292713\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:45:59 | INFO | Rank 0 | Train Epoch: 5 [12736/23491 (54%)]\tLoss: 0.156911\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:45:59 | INFO | Rank 0 | Train Epoch: 5 [12768/23491 (54%)]\tLoss: 0.158382\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:45:59 | INFO | Rank 0 | Train Epoch: 5 [12800/23491 (54%)]\tLoss: 0.245388\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:00 | INFO | Rank 0 | Train Epoch: 5 [12832/23491 (55%)]\tLoss: 0.458783\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:00 | INFO | Rank 0 | Train Epoch: 5 [12864/23491 (55%)]\tLoss: 0.275349\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:00 | INFO | Rank 0 | Train Epoch: 5 [12896/23491 (55%)]\tLoss: 0.220944\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:00 | INFO | Rank 0 | Train Epoch: 5 [12928/23491 (55%)]\tLoss: 0.216756\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:01 | INFO | Rank 0 | Train Epoch: 5 [12960/23491 (55%)]\tLoss: 0.215111\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:01 | INFO | Rank 0 | Train Epoch: 5 [12992/23491 (55%)]\tLoss: 0.266486\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:01 | INFO | Rank 0 | Train Epoch: 5 [13024/23491 (55%)]\tLoss: 0.267723\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:01 | INFO | Rank 0 | Train Epoch: 5 [13056/23491 (56%)]\tLoss: 0.317256\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:02 | INFO | Rank 0 | Train Epoch: 5 [13088/23491 (56%)]\tLoss: 0.352811\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:02 | INFO | Rank 0 | Train Epoch: 5 [13120/23491 (56%)]\tLoss: 0.149616\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:02 | INFO | Rank 0 | Train Epoch: 5 [13152/23491 (56%)]\tLoss: 0.401324\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:03 | INFO | Rank 0 | Train Epoch: 5 [13184/23491 (56%)]\tLoss: 0.274040\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:03 | INFO | Rank 0 | Train Epoch: 5 [13216/23491 (56%)]\tLoss: 0.103186\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:03 | INFO | Rank 0 | Train Epoch: 5 [13248/23491 (56%)]\tLoss: 0.235054\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:03 | INFO | Rank 0 | Train Epoch: 5 [13280/23491 (57%)]\tLoss: 0.167226\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:04 | INFO | Rank 0 | Train Epoch: 5 [13312/23491 (57%)]\tLoss: 0.307679\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:04 | INFO | Rank 0 | Train Epoch: 5 [13344/23491 (57%)]\tLoss: 0.201051\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:04 | INFO | Rank 0 | Train Epoch: 5 [13376/23491 (57%)]\tLoss: 0.203652\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:04 | INFO | Rank 0 | Train Epoch: 5 [13408/23491 (57%)]\tLoss: 0.214307\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:05 | INFO | Rank 0 | Train Epoch: 5 [13440/23491 (57%)]\tLoss: 0.300354\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:05 | INFO | Rank 0 | Train Epoch: 5 [13472/23491 (57%)]\tLoss: 0.099753\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:05 | INFO | Rank 0 | Train Epoch: 5 [13504/23491 (57%)]\tLoss: 0.193537\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:05 | INFO | Rank 0 | Train Epoch: 5 [13536/23491 (58%)]\tLoss: 0.422570\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:06 | INFO | Rank 0 | Train Epoch: 5 [13568/23491 (58%)]\tLoss: 0.192995\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:06 | INFO | Rank 0 | Train Epoch: 5 [13600/23491 (58%)]\tLoss: 0.148974\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:06 | INFO | Rank 0 | Train Epoch: 5 [13632/23491 (58%)]\tLoss: 0.555387\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:07 | INFO | Rank 0 | Train Epoch: 5 [13664/23491 (58%)]\tLoss: 0.197592\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:07 | INFO | Rank 0 | Train Epoch: 5 [13696/23491 (58%)]\tLoss: 0.323824\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:07 | INFO | Rank 0 | Train Epoch: 5 [13728/23491 (58%)]\tLoss: 0.435049\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:07 | INFO | Rank 0 | Train Epoch: 5 [13760/23491 (59%)]\tLoss: 0.315502\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:08 | INFO | Rank 0 | Train Epoch: 5 [13792/23491 (59%)]\tLoss: 0.282264\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:08 | INFO | Rank 0 | Train Epoch: 5 [13824/23491 (59%)]\tLoss: 0.106027\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:08 | INFO | Rank 0 | Train Epoch: 5 [13856/23491 (59%)]\tLoss: 0.275445\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:08 | INFO | Rank 0 | Train Epoch: 5 [13888/23491 (59%)]\tLoss: 0.205928\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:09 | INFO | Rank 0 | Train Epoch: 5 [13920/23491 (59%)]\tLoss: 0.242506\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:09 | INFO | Rank 0 | Train Epoch: 5 [13952/23491 (59%)]\tLoss: 0.439034\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:09 | INFO | Rank 0 | Train Epoch: 5 [13984/23491 (60%)]\tLoss: 0.170264\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:09 | INFO | Rank 0 | Train Epoch: 5 [14016/23491 (60%)]\tLoss: 0.076185\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:10 | INFO | Rank 0 | Train Epoch: 5 [14048/23491 (60%)]\tLoss: 0.310531\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:10 | INFO | Rank 0 | Train Epoch: 5 [14080/23491 (60%)]\tLoss: 0.426389\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000037\tlogit_scale 4.542\n",
      "2022-11-08,05:46:10 | INFO | Rank 0 | Train Epoch: 5 [14112/23491 (60%)]\tLoss: 0.601855\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:11 | INFO | Rank 0 | Train Epoch: 5 [14144/23491 (60%)]\tLoss: 0.406161\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:11 | INFO | Rank 0 | Train Epoch: 5 [14176/23491 (60%)]\tLoss: 0.165092\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:11 | INFO | Rank 0 | Train Epoch: 5 [14208/23491 (60%)]\tLoss: 0.230618\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:11 | INFO | Rank 0 | Train Epoch: 5 [14240/23491 (61%)]\tLoss: 0.397176\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:12 | INFO | Rank 0 | Train Epoch: 5 [14272/23491 (61%)]\tLoss: 0.279835\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:12 | INFO | Rank 0 | Train Epoch: 5 [14304/23491 (61%)]\tLoss: 0.130327\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:12 | INFO | Rank 0 | Train Epoch: 5 [14336/23491 (61%)]\tLoss: 0.498948\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:12 | INFO | Rank 0 | Train Epoch: 5 [14368/23491 (61%)]\tLoss: 0.110984\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:13 | INFO | Rank 0 | Train Epoch: 5 [14400/23491 (61%)]\tLoss: 0.186365\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:13 | INFO | Rank 0 | Train Epoch: 5 [14432/23491 (61%)]\tLoss: 0.262493\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:13 | INFO | Rank 0 | Train Epoch: 5 [14464/23491 (62%)]\tLoss: 0.318296\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:13 | INFO | Rank 0 | Train Epoch: 5 [14496/23491 (62%)]\tLoss: 0.284032\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:14 | INFO | Rank 0 | Train Epoch: 5 [14528/23491 (62%)]\tLoss: 0.339913\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:14 | INFO | Rank 0 | Train Epoch: 5 [14560/23491 (62%)]\tLoss: 0.471287\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:14 | INFO | Rank 0 | Train Epoch: 5 [14592/23491 (62%)]\tLoss: 0.223189\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:15 | INFO | Rank 0 | Train Epoch: 5 [14624/23491 (62%)]\tLoss: 0.357653\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:15 | INFO | Rank 0 | Train Epoch: 5 [14656/23491 (62%)]\tLoss: 0.135100\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:15 | INFO | Rank 0 | Train Epoch: 5 [14688/23491 (63%)]\tLoss: 0.257960\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:15 | INFO | Rank 0 | Train Epoch: 5 [14720/23491 (63%)]\tLoss: 0.263178\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:16 | INFO | Rank 0 | Train Epoch: 5 [14752/23491 (63%)]\tLoss: 0.228597\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:16 | INFO | Rank 0 | Train Epoch: 5 [14784/23491 (63%)]\tLoss: 0.332613\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:16 | INFO | Rank 0 | Train Epoch: 5 [14816/23491 (63%)]\tLoss: 0.403266\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:16 | INFO | Rank 0 | Train Epoch: 5 [14848/23491 (63%)]\tLoss: 0.381827\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:17 | INFO | Rank 0 | Train Epoch: 5 [14880/23491 (63%)]\tLoss: 0.168100\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:17 | INFO | Rank 0 | Train Epoch: 5 [14912/23491 (63%)]\tLoss: 0.349589\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:17 | INFO | Rank 0 | Train Epoch: 5 [14944/23491 (64%)]\tLoss: 0.193038\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:17 | INFO | Rank 0 | Train Epoch: 5 [14976/23491 (64%)]\tLoss: 0.206746\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:18 | INFO | Rank 0 | Train Epoch: 5 [15008/23491 (64%)]\tLoss: 0.284869\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:18 | INFO | Rank 0 | Train Epoch: 5 [15040/23491 (64%)]\tLoss: 0.187292\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:18 | INFO | Rank 0 | Train Epoch: 5 [15072/23491 (64%)]\tLoss: 0.224890\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:19 | INFO | Rank 0 | Train Epoch: 5 [15104/23491 (64%)]\tLoss: 0.287355\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:19 | INFO | Rank 0 | Train Epoch: 5 [15136/23491 (64%)]\tLoss: 0.336088\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:19 | INFO | Rank 0 | Train Epoch: 5 [15168/23491 (65%)]\tLoss: 0.309154\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:19 | INFO | Rank 0 | Train Epoch: 5 [15200/23491 (65%)]\tLoss: 0.150347\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:20 | INFO | Rank 0 | Train Epoch: 5 [15232/23491 (65%)]\tLoss: 0.388024\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:20 | INFO | Rank 0 | Train Epoch: 5 [15264/23491 (65%)]\tLoss: 0.290091\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:20 | INFO | Rank 0 | Train Epoch: 5 [15296/23491 (65%)]\tLoss: 0.311760\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:20 | INFO | Rank 0 | Train Epoch: 5 [15328/23491 (65%)]\tLoss: 0.095685\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:21 | INFO | Rank 0 | Train Epoch: 5 [15360/23491 (65%)]\tLoss: 0.434752\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:21 | INFO | Rank 0 | Train Epoch: 5 [15392/23491 (66%)]\tLoss: 0.406386\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:21 | INFO | Rank 0 | Train Epoch: 5 [15424/23491 (66%)]\tLoss: 0.273875\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:21 | INFO | Rank 0 | Train Epoch: 5 [15456/23491 (66%)]\tLoss: 0.264082\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:22 | INFO | Rank 0 | Train Epoch: 5 [15488/23491 (66%)]\tLoss: 0.294234\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:22 | INFO | Rank 0 | Train Epoch: 5 [15520/23491 (66%)]\tLoss: 0.239712\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:22 | INFO | Rank 0 | Train Epoch: 5 [15552/23491 (66%)]\tLoss: 0.196929\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:23 | INFO | Rank 0 | Train Epoch: 5 [15584/23491 (66%)]\tLoss: 0.433142\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:23 | INFO | Rank 0 | Train Epoch: 5 [15616/23491 (66%)]\tLoss: 0.265968\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:23 | INFO | Rank 0 | Train Epoch: 5 [15648/23491 (67%)]\tLoss: 0.354868\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:23 | INFO | Rank 0 | Train Epoch: 5 [15680/23491 (67%)]\tLoss: 0.292277\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:24 | INFO | Rank 0 | Train Epoch: 5 [15712/23491 (67%)]\tLoss: 0.181696\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:24 | INFO | Rank 0 | Train Epoch: 5 [15744/23491 (67%)]\tLoss: 0.110729\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:24 | INFO | Rank 0 | Train Epoch: 5 [15776/23491 (67%)]\tLoss: 0.290800\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:24 | INFO | Rank 0 | Train Epoch: 5 [15808/23491 (67%)]\tLoss: 0.274196\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:25 | INFO | Rank 0 | Train Epoch: 5 [15840/23491 (67%)]\tLoss: 0.312533\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000036\tlogit_scale 4.542\n",
      "2022-11-08,05:46:25 | INFO | Rank 0 | Train Epoch: 5 [15872/23491 (68%)]\tLoss: 0.397577\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:25 | INFO | Rank 0 | Train Epoch: 5 [15904/23491 (68%)]\tLoss: 0.387791\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:25 | INFO | Rank 0 | Train Epoch: 5 [15936/23491 (68%)]\tLoss: 0.197938\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:26 | INFO | Rank 0 | Train Epoch: 5 [15968/23491 (68%)]\tLoss: 0.147367\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:26 | INFO | Rank 0 | Train Epoch: 5 [16000/23491 (68%)]\tLoss: 0.182355\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:26 | INFO | Rank 0 | Train Epoch: 5 [16032/23491 (68%)]\tLoss: 0.232131\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:27 | INFO | Rank 0 | Train Epoch: 5 [16064/23491 (68%)]\tLoss: 0.215259\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:27 | INFO | Rank 0 | Train Epoch: 5 [16096/23491 (69%)]\tLoss: 0.245824\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:27 | INFO | Rank 0 | Train Epoch: 5 [16128/23491 (69%)]\tLoss: 0.086915\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:27 | INFO | Rank 0 | Train Epoch: 5 [16160/23491 (69%)]\tLoss: 0.370025\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:28 | INFO | Rank 0 | Train Epoch: 5 [16192/23491 (69%)]\tLoss: 0.369930\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:28 | INFO | Rank 0 | Train Epoch: 5 [16224/23491 (69%)]\tLoss: 0.346925\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:28 | INFO | Rank 0 | Train Epoch: 5 [16256/23491 (69%)]\tLoss: 0.079910\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:28 | INFO | Rank 0 | Train Epoch: 5 [16288/23491 (69%)]\tLoss: 0.167012\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:29 | INFO | Rank 0 | Train Epoch: 5 [16320/23491 (69%)]\tLoss: 0.243199\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:29 | INFO | Rank 0 | Train Epoch: 5 [16352/23491 (70%)]\tLoss: 0.149566\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:29 | INFO | Rank 0 | Train Epoch: 5 [16384/23491 (70%)]\tLoss: 0.068878\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:29 | INFO | Rank 0 | Train Epoch: 5 [16416/23491 (70%)]\tLoss: 0.205756\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:30 | INFO | Rank 0 | Train Epoch: 5 [16448/23491 (70%)]\tLoss: 0.416268\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:30 | INFO | Rank 0 | Train Epoch: 5 [16480/23491 (70%)]\tLoss: 0.080443\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:30 | INFO | Rank 0 | Train Epoch: 5 [16512/23491 (70%)]\tLoss: 0.452874\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:31 | INFO | Rank 0 | Train Epoch: 5 [16544/23491 (70%)]\tLoss: 0.176054\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:31 | INFO | Rank 0 | Train Epoch: 5 [16576/23491 (71%)]\tLoss: 0.190963\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:31 | INFO | Rank 0 | Train Epoch: 5 [16608/23491 (71%)]\tLoss: 0.346272\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:31 | INFO | Rank 0 | Train Epoch: 5 [16640/23491 (71%)]\tLoss: 0.301535\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:32 | INFO | Rank 0 | Train Epoch: 5 [16672/23491 (71%)]\tLoss: 0.191063\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:32 | INFO | Rank 0 | Train Epoch: 5 [16704/23491 (71%)]\tLoss: 0.289656\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:32 | INFO | Rank 0 | Train Epoch: 5 [16736/23491 (71%)]\tLoss: 0.314715\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:32 | INFO | Rank 0 | Train Epoch: 5 [16768/23491 (71%)]\tLoss: 0.299967\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:33 | INFO | Rank 0 | Train Epoch: 5 [16800/23491 (72%)]\tLoss: 0.347277\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:33 | INFO | Rank 0 | Train Epoch: 5 [16832/23491 (72%)]\tLoss: 0.316429\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:33 | INFO | Rank 0 | Train Epoch: 5 [16864/23491 (72%)]\tLoss: 0.485219\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:33 | INFO | Rank 0 | Train Epoch: 5 [16896/23491 (72%)]\tLoss: 0.283968\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:34 | INFO | Rank 0 | Train Epoch: 5 [16928/23491 (72%)]\tLoss: 0.477423\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:34 | INFO | Rank 0 | Train Epoch: 5 [16960/23491 (72%)]\tLoss: 0.141147\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:34 | INFO | Rank 0 | Train Epoch: 5 [16992/23491 (72%)]\tLoss: 0.312442\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:35 | INFO | Rank 0 | Train Epoch: 5 [17024/23491 (72%)]\tLoss: 0.219328\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:35 | INFO | Rank 0 | Train Epoch: 5 [17056/23491 (73%)]\tLoss: 0.308138\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:35 | INFO | Rank 0 | Train Epoch: 5 [17088/23491 (73%)]\tLoss: 0.351215\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:35 | INFO | Rank 0 | Train Epoch: 5 [17120/23491 (73%)]\tLoss: 0.166246\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:36 | INFO | Rank 0 | Train Epoch: 5 [17152/23491 (73%)]\tLoss: 0.264170\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:36 | INFO | Rank 0 | Train Epoch: 5 [17184/23491 (73%)]\tLoss: 0.251090\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:36 | INFO | Rank 0 | Train Epoch: 5 [17216/23491 (73%)]\tLoss: 0.097600\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:36 | INFO | Rank 0 | Train Epoch: 5 [17248/23491 (73%)]\tLoss: 0.135802\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:37 | INFO | Rank 0 | Train Epoch: 5 [17280/23491 (74%)]\tLoss: 0.332411\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:37 | INFO | Rank 0 | Train Epoch: 5 [17312/23491 (74%)]\tLoss: 0.221849\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:37 | INFO | Rank 0 | Train Epoch: 5 [17344/23491 (74%)]\tLoss: 0.273923\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:37 | INFO | Rank 0 | Train Epoch: 5 [17376/23491 (74%)]\tLoss: 0.476034\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:38 | INFO | Rank 0 | Train Epoch: 5 [17408/23491 (74%)]\tLoss: 0.219227\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:38 | INFO | Rank 0 | Train Epoch: 5 [17440/23491 (74%)]\tLoss: 0.183852\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:38 | INFO | Rank 0 | Train Epoch: 5 [17472/23491 (74%)]\tLoss: 0.377657\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:38 | INFO | Rank 0 | Train Epoch: 5 [17504/23491 (75%)]\tLoss: 0.232810\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:39 | INFO | Rank 0 | Train Epoch: 5 [17536/23491 (75%)]\tLoss: 0.131340\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:39 | INFO | Rank 0 | Train Epoch: 5 [17568/23491 (75%)]\tLoss: 0.395483\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:39 | INFO | Rank 0 | Train Epoch: 5 [17600/23491 (75%)]\tLoss: 0.542161\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000035\tlogit_scale 4.542\n",
      "2022-11-08,05:46:40 | INFO | Rank 0 | Train Epoch: 5 [17632/23491 (75%)]\tLoss: 0.187561\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:40 | INFO | Rank 0 | Train Epoch: 5 [17664/23491 (75%)]\tLoss: 0.198499\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:40 | INFO | Rank 0 | Train Epoch: 5 [17696/23491 (75%)]\tLoss: 0.278143\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:40 | INFO | Rank 0 | Train Epoch: 5 [17728/23491 (75%)]\tLoss: 0.294453\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:41 | INFO | Rank 0 | Train Epoch: 5 [17760/23491 (76%)]\tLoss: 0.139418\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:41 | INFO | Rank 0 | Train Epoch: 5 [17792/23491 (76%)]\tLoss: 0.159540\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:41 | INFO | Rank 0 | Train Epoch: 5 [17824/23491 (76%)]\tLoss: 0.266700\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:41 | INFO | Rank 0 | Train Epoch: 5 [17856/23491 (76%)]\tLoss: 0.356396\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:42 | INFO | Rank 0 | Train Epoch: 5 [17888/23491 (76%)]\tLoss: 0.247846\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:42 | INFO | Rank 0 | Train Epoch: 5 [17920/23491 (76%)]\tLoss: 0.160245\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:42 | INFO | Rank 0 | Train Epoch: 5 [17952/23491 (76%)]\tLoss: 0.179617\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:42 | INFO | Rank 0 | Train Epoch: 5 [17984/23491 (77%)]\tLoss: 0.671770\tData (t) 0.053\tBatch (t) 0.222\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:43 | INFO | Rank 0 | Train Epoch: 5 [18016/23491 (77%)]\tLoss: 0.204501\tData (t) 0.035\tBatch (t) 0.248\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:43 | INFO | Rank 0 | Train Epoch: 5 [18048/23491 (77%)]\tLoss: 0.226039\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:43 | INFO | Rank 0 | Train Epoch: 5 [18080/23491 (77%)]\tLoss: 0.396854\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:43 | INFO | Rank 0 | Train Epoch: 5 [18112/23491 (77%)]\tLoss: 0.328485\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:44 | INFO | Rank 0 | Train Epoch: 5 [18144/23491 (77%)]\tLoss: 0.583031\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:44 | INFO | Rank 0 | Train Epoch: 5 [18176/23491 (77%)]\tLoss: 0.104947\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:44 | INFO | Rank 0 | Train Epoch: 5 [18208/23491 (78%)]\tLoss: 0.146934\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:45 | INFO | Rank 0 | Train Epoch: 5 [18240/23491 (78%)]\tLoss: 0.413968\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:45 | INFO | Rank 0 | Train Epoch: 5 [18272/23491 (78%)]\tLoss: 0.075224\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:45 | INFO | Rank 0 | Train Epoch: 5 [18304/23491 (78%)]\tLoss: 0.341626\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:45 | INFO | Rank 0 | Train Epoch: 5 [18336/23491 (78%)]\tLoss: 0.090710\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:46 | INFO | Rank 0 | Train Epoch: 5 [18368/23491 (78%)]\tLoss: 0.202758\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:46 | INFO | Rank 0 | Train Epoch: 5 [18400/23491 (78%)]\tLoss: 0.285629\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:46 | INFO | Rank 0 | Train Epoch: 5 [18432/23491 (78%)]\tLoss: 0.330000\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:46 | INFO | Rank 0 | Train Epoch: 5 [18464/23491 (79%)]\tLoss: 0.449431\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:47 | INFO | Rank 0 | Train Epoch: 5 [18496/23491 (79%)]\tLoss: 0.230710\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:47 | INFO | Rank 0 | Train Epoch: 5 [18528/23491 (79%)]\tLoss: 0.362732\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:47 | INFO | Rank 0 | Train Epoch: 5 [18560/23491 (79%)]\tLoss: 0.250173\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:47 | INFO | Rank 0 | Train Epoch: 5 [18592/23491 (79%)]\tLoss: 0.340619\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:48 | INFO | Rank 0 | Train Epoch: 5 [18624/23491 (79%)]\tLoss: 0.309826\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:48 | INFO | Rank 0 | Train Epoch: 5 [18656/23491 (79%)]\tLoss: 0.177801\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:48 | INFO | Rank 0 | Train Epoch: 5 [18688/23491 (80%)]\tLoss: 0.325316\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:49 | INFO | Rank 0 | Train Epoch: 5 [18720/23491 (80%)]\tLoss: 0.193341\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:49 | INFO | Rank 0 | Train Epoch: 5 [18752/23491 (80%)]\tLoss: 0.267382\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:49 | INFO | Rank 0 | Train Epoch: 5 [18784/23491 (80%)]\tLoss: 0.176672\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:49 | INFO | Rank 0 | Train Epoch: 5 [18816/23491 (80%)]\tLoss: 0.271065\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:50 | INFO | Rank 0 | Train Epoch: 5 [18848/23491 (80%)]\tLoss: 0.529097\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.542\n",
      "2022-11-08,05:46:50 | INFO | Rank 0 | Train Epoch: 5 [18880/23491 (80%)]\tLoss: 0.396068\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.541\n",
      "2022-11-08,05:46:50 | INFO | Rank 0 | Train Epoch: 5 [18912/23491 (81%)]\tLoss: 0.217266\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.541\n",
      "2022-11-08,05:46:50 | INFO | Rank 0 | Train Epoch: 5 [18944/23491 (81%)]\tLoss: 0.309690\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.541\n",
      "2022-11-08,05:46:51 | INFO | Rank 0 | Train Epoch: 5 [18976/23491 (81%)]\tLoss: 0.261020\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.541\n",
      "2022-11-08,05:46:51 | INFO | Rank 0 | Train Epoch: 5 [19008/23491 (81%)]\tLoss: 0.157395\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000034\tlogit_scale 4.541\n",
      "2022-11-08,05:46:51 | INFO | Rank 0 | Train Epoch: 5 [19040/23491 (81%)]\tLoss: 0.440456\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.541\n",
      "2022-11-08,05:46:51 | INFO | Rank 0 | Train Epoch: 5 [19072/23491 (81%)]\tLoss: 0.198400\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000034\tlogit_scale 4.541\n",
      "2022-11-08,05:46:52 | INFO | Rank 0 | Train Epoch: 5 [19104/23491 (81%)]\tLoss: 0.197935\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.541\n",
      "2022-11-08,05:46:52 | INFO | Rank 0 | Train Epoch: 5 [19136/23491 (81%)]\tLoss: 0.285002\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000034\tlogit_scale 4.541\n",
      "2022-11-08,05:46:52 | INFO | Rank 0 | Train Epoch: 5 [19168/23491 (82%)]\tLoss: 0.153820\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000034\tlogit_scale 4.541\n",
      "2022-11-08,05:46:53 | INFO | Rank 0 | Train Epoch: 5 [19200/23491 (82%)]\tLoss: 0.039019\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.541\n",
      "2022-11-08,05:46:53 | INFO | Rank 0 | Train Epoch: 5 [19232/23491 (82%)]\tLoss: 0.279913\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000034\tlogit_scale 4.541\n",
      "2022-11-08,05:46:53 | INFO | Rank 0 | Train Epoch: 5 [19264/23491 (82%)]\tLoss: 0.127442\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.541\n",
      "2022-11-08,05:46:53 | INFO | Rank 0 | Train Epoch: 5 [19296/23491 (82%)]\tLoss: 0.543584\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.541\n",
      "2022-11-08,05:46:54 | INFO | Rank 0 | Train Epoch: 5 [19328/23491 (82%)]\tLoss: 0.313997\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.541\n",
      "2022-11-08,05:46:54 | INFO | Rank 0 | Train Epoch: 5 [19360/23491 (82%)]\tLoss: 0.074099\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000034\tlogit_scale 4.541\n",
      "2022-11-08,05:46:54 | INFO | Rank 0 | Train Epoch: 5 [19392/23491 (83%)]\tLoss: 0.098083\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:54 | INFO | Rank 0 | Train Epoch: 5 [19424/23491 (83%)]\tLoss: 0.216556\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:55 | INFO | Rank 0 | Train Epoch: 5 [19456/23491 (83%)]\tLoss: 0.088993\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:55 | INFO | Rank 0 | Train Epoch: 5 [19488/23491 (83%)]\tLoss: 0.289016\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:55 | INFO | Rank 0 | Train Epoch: 5 [19520/23491 (83%)]\tLoss: 0.289326\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:55 | INFO | Rank 0 | Train Epoch: 5 [19552/23491 (83%)]\tLoss: 0.456679\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:56 | INFO | Rank 0 | Train Epoch: 5 [19584/23491 (83%)]\tLoss: 0.297359\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:56 | INFO | Rank 0 | Train Epoch: 5 [19616/23491 (84%)]\tLoss: 0.244089\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:56 | INFO | Rank 0 | Train Epoch: 5 [19648/23491 (84%)]\tLoss: 0.197182\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:57 | INFO | Rank 0 | Train Epoch: 5 [19680/23491 (84%)]\tLoss: 0.545700\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:57 | INFO | Rank 0 | Train Epoch: 5 [19712/23491 (84%)]\tLoss: 0.245234\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:57 | INFO | Rank 0 | Train Epoch: 5 [19744/23491 (84%)]\tLoss: 0.275253\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:57 | INFO | Rank 0 | Train Epoch: 5 [19776/23491 (84%)]\tLoss: 0.221483\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:58 | INFO | Rank 0 | Train Epoch: 5 [19808/23491 (84%)]\tLoss: 0.353237\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:58 | INFO | Rank 0 | Train Epoch: 5 [19840/23491 (84%)]\tLoss: 0.122112\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:58 | INFO | Rank 0 | Train Epoch: 5 [19872/23491 (85%)]\tLoss: 0.167036\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:58 | INFO | Rank 0 | Train Epoch: 5 [19904/23491 (85%)]\tLoss: 0.389020\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:59 | INFO | Rank 0 | Train Epoch: 5 [19936/23491 (85%)]\tLoss: 0.114263\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:59 | INFO | Rank 0 | Train Epoch: 5 [19968/23491 (85%)]\tLoss: 0.130459\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:59 | INFO | Rank 0 | Train Epoch: 5 [20000/23491 (85%)]\tLoss: 0.380078\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:46:59 | INFO | Rank 0 | Train Epoch: 5 [20032/23491 (85%)]\tLoss: 0.270853\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:00 | INFO | Rank 0 | Train Epoch: 5 [20064/23491 (85%)]\tLoss: 0.234450\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:00 | INFO | Rank 0 | Train Epoch: 5 [20096/23491 (86%)]\tLoss: 0.361665\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:00 | INFO | Rank 0 | Train Epoch: 5 [20128/23491 (86%)]\tLoss: 0.278518\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:01 | INFO | Rank 0 | Train Epoch: 5 [20160/23491 (86%)]\tLoss: 0.328890\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:01 | INFO | Rank 0 | Train Epoch: 5 [20192/23491 (86%)]\tLoss: 0.358011\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:01 | INFO | Rank 0 | Train Epoch: 5 [20224/23491 (86%)]\tLoss: 0.254508\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:01 | INFO | Rank 0 | Train Epoch: 5 [20256/23491 (86%)]\tLoss: 0.141613\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:02 | INFO | Rank 0 | Train Epoch: 5 [20288/23491 (86%)]\tLoss: 0.085412\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:02 | INFO | Rank 0 | Train Epoch: 5 [20320/23491 (87%)]\tLoss: 0.431320\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:02 | INFO | Rank 0 | Train Epoch: 5 [20352/23491 (87%)]\tLoss: 0.591911\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:02 | INFO | Rank 0 | Train Epoch: 5 [20384/23491 (87%)]\tLoss: 0.188797\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:03 | INFO | Rank 0 | Train Epoch: 5 [20416/23491 (87%)]\tLoss: 0.272949\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:03 | INFO | Rank 0 | Train Epoch: 5 [20448/23491 (87%)]\tLoss: 0.481769\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:03 | INFO | Rank 0 | Train Epoch: 5 [20480/23491 (87%)]\tLoss: 0.057625\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:03 | INFO | Rank 0 | Train Epoch: 5 [20512/23491 (87%)]\tLoss: 0.499577\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:04 | INFO | Rank 0 | Train Epoch: 5 [20544/23491 (87%)]\tLoss: 0.086110\tData (t) 0.055\tBatch (t) 0.269\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:04 | INFO | Rank 0 | Train Epoch: 5 [20576/23491 (88%)]\tLoss: 0.237162\tData (t) 0.055\tBatch (t) 0.270\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:04 | INFO | Rank 0 | Train Epoch: 5 [20608/23491 (88%)]\tLoss: 0.701651\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:05 | INFO | Rank 0 | Train Epoch: 5 [20640/23491 (88%)]\tLoss: 0.288311\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:05 | INFO | Rank 0 | Train Epoch: 5 [20672/23491 (88%)]\tLoss: 0.252519\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:05 | INFO | Rank 0 | Train Epoch: 5 [20704/23491 (88%)]\tLoss: 0.509696\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:05 | INFO | Rank 0 | Train Epoch: 5 [20736/23491 (88%)]\tLoss: 0.161734\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:06 | INFO | Rank 0 | Train Epoch: 5 [20768/23491 (88%)]\tLoss: 0.216969\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:06 | INFO | Rank 0 | Train Epoch: 5 [20800/23491 (89%)]\tLoss: 0.455583\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:06 | INFO | Rank 0 | Train Epoch: 5 [20832/23491 (89%)]\tLoss: 0.163391\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:06 | INFO | Rank 0 | Train Epoch: 5 [20864/23491 (89%)]\tLoss: 0.166031\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:07 | INFO | Rank 0 | Train Epoch: 5 [20896/23491 (89%)]\tLoss: 0.267613\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:07 | INFO | Rank 0 | Train Epoch: 5 [20928/23491 (89%)]\tLoss: 0.170707\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:07 | INFO | Rank 0 | Train Epoch: 5 [20960/23491 (89%)]\tLoss: 0.284757\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:07 | INFO | Rank 0 | Train Epoch: 5 [20992/23491 (89%)]\tLoss: 0.236031\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:08 | INFO | Rank 0 | Train Epoch: 5 [21024/23491 (90%)]\tLoss: 0.109405\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:08 | INFO | Rank 0 | Train Epoch: 5 [21056/23491 (90%)]\tLoss: 0.355698\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:08 | INFO | Rank 0 | Train Epoch: 5 [21088/23491 (90%)]\tLoss: 0.151185\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:09 | INFO | Rank 0 | Train Epoch: 5 [21120/23491 (90%)]\tLoss: 0.292928\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000033\tlogit_scale 4.541\n",
      "2022-11-08,05:47:09 | INFO | Rank 0 | Train Epoch: 5 [21152/23491 (90%)]\tLoss: 0.304153\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:09 | INFO | Rank 0 | Train Epoch: 5 [21184/23491 (90%)]\tLoss: 0.129743\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:09 | INFO | Rank 0 | Train Epoch: 5 [21216/23491 (90%)]\tLoss: 0.537705\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:10 | INFO | Rank 0 | Train Epoch: 5 [21248/23491 (90%)]\tLoss: 0.462691\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:10 | INFO | Rank 0 | Train Epoch: 5 [21280/23491 (91%)]\tLoss: 0.320266\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:10 | INFO | Rank 0 | Train Epoch: 5 [21312/23491 (91%)]\tLoss: 0.119387\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:10 | INFO | Rank 0 | Train Epoch: 5 [21344/23491 (91%)]\tLoss: 0.390236\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:11 | INFO | Rank 0 | Train Epoch: 5 [21376/23491 (91%)]\tLoss: 0.448391\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:11 | INFO | Rank 0 | Train Epoch: 5 [21408/23491 (91%)]\tLoss: 0.340401\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:11 | INFO | Rank 0 | Train Epoch: 5 [21440/23491 (91%)]\tLoss: 0.231147\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:11 | INFO | Rank 0 | Train Epoch: 5 [21472/23491 (91%)]\tLoss: 0.285107\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:12 | INFO | Rank 0 | Train Epoch: 5 [21504/23491 (92%)]\tLoss: 0.308250\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:12 | INFO | Rank 0 | Train Epoch: 5 [21536/23491 (92%)]\tLoss: 0.235396\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:12 | INFO | Rank 0 | Train Epoch: 5 [21568/23491 (92%)]\tLoss: 0.152616\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:13 | INFO | Rank 0 | Train Epoch: 5 [21600/23491 (92%)]\tLoss: 0.121819\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:13 | INFO | Rank 0 | Train Epoch: 5 [21632/23491 (92%)]\tLoss: 0.318065\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:13 | INFO | Rank 0 | Train Epoch: 5 [21664/23491 (92%)]\tLoss: 0.167883\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:13 | INFO | Rank 0 | Train Epoch: 5 [21696/23491 (92%)]\tLoss: 0.209593\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:14 | INFO | Rank 0 | Train Epoch: 5 [21728/23491 (93%)]\tLoss: 0.248486\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:14 | INFO | Rank 0 | Train Epoch: 5 [21760/23491 (93%)]\tLoss: 0.346090\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:14 | INFO | Rank 0 | Train Epoch: 5 [21792/23491 (93%)]\tLoss: 0.394496\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:14 | INFO | Rank 0 | Train Epoch: 5 [21824/23491 (93%)]\tLoss: 0.231058\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:15 | INFO | Rank 0 | Train Epoch: 5 [21856/23491 (93%)]\tLoss: 0.228364\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:15 | INFO | Rank 0 | Train Epoch: 5 [21888/23491 (93%)]\tLoss: 0.225963\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:15 | INFO | Rank 0 | Train Epoch: 5 [21920/23491 (93%)]\tLoss: 0.280863\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:15 | INFO | Rank 0 | Train Epoch: 5 [21952/23491 (93%)]\tLoss: 0.157305\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:16 | INFO | Rank 0 | Train Epoch: 5 [21984/23491 (94%)]\tLoss: 0.153462\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:16 | INFO | Rank 0 | Train Epoch: 5 [22016/23491 (94%)]\tLoss: 0.306000\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:16 | INFO | Rank 0 | Train Epoch: 5 [22048/23491 (94%)]\tLoss: 0.170992\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:17 | INFO | Rank 0 | Train Epoch: 5 [22080/23491 (94%)]\tLoss: 0.254702\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:17 | INFO | Rank 0 | Train Epoch: 5 [22112/23491 (94%)]\tLoss: 0.185358\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:17 | INFO | Rank 0 | Train Epoch: 5 [22144/23491 (94%)]\tLoss: 0.203242\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:17 | INFO | Rank 0 | Train Epoch: 5 [22176/23491 (94%)]\tLoss: 0.171312\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:18 | INFO | Rank 0 | Train Epoch: 5 [22208/23491 (95%)]\tLoss: 0.202796\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:18 | INFO | Rank 0 | Train Epoch: 5 [22240/23491 (95%)]\tLoss: 0.055145\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:18 | INFO | Rank 0 | Train Epoch: 5 [22272/23491 (95%)]\tLoss: 0.259769\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:18 | INFO | Rank 0 | Train Epoch: 5 [22304/23491 (95%)]\tLoss: 0.320331\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:19 | INFO | Rank 0 | Train Epoch: 5 [22336/23491 (95%)]\tLoss: 0.178004\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:19 | INFO | Rank 0 | Train Epoch: 5 [22368/23491 (95%)]\tLoss: 0.310803\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:19 | INFO | Rank 0 | Train Epoch: 5 [22400/23491 (95%)]\tLoss: 0.208826\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:19 | INFO | Rank 0 | Train Epoch: 5 [22432/23491 (96%)]\tLoss: 0.604699\tData (t) 0.055\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:20 | INFO | Rank 0 | Train Epoch: 5 [22464/23491 (96%)]\tLoss: 0.243180\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:20 | INFO | Rank 0 | Train Epoch: 5 [22496/23491 (96%)]\tLoss: 0.240068\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:20 | INFO | Rank 0 | Train Epoch: 5 [22528/23491 (96%)]\tLoss: 0.189973\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:21 | INFO | Rank 0 | Train Epoch: 5 [22560/23491 (96%)]\tLoss: 0.494427\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:21 | INFO | Rank 0 | Train Epoch: 5 [22592/23491 (96%)]\tLoss: 0.623205\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:21 | INFO | Rank 0 | Train Epoch: 5 [22624/23491 (96%)]\tLoss: 0.116617\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:21 | INFO | Rank 0 | Train Epoch: 5 [22656/23491 (96%)]\tLoss: 0.258184\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:22 | INFO | Rank 0 | Train Epoch: 5 [22688/23491 (97%)]\tLoss: 0.256962\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:22 | INFO | Rank 0 | Train Epoch: 5 [22720/23491 (97%)]\tLoss: 0.276359\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:22 | INFO | Rank 0 | Train Epoch: 5 [22752/23491 (97%)]\tLoss: 0.113466\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:22 | INFO | Rank 0 | Train Epoch: 5 [22784/23491 (97%)]\tLoss: 0.069024\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:23 | INFO | Rank 0 | Train Epoch: 5 [22816/23491 (97%)]\tLoss: 0.222977\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:23 | INFO | Rank 0 | Train Epoch: 5 [22848/23491 (97%)]\tLoss: 0.184781\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:23 | INFO | Rank 0 | Train Epoch: 5 [22880/23491 (97%)]\tLoss: 0.305218\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:23 | INFO | Rank 0 | Train Epoch: 5 [22912/23491 (98%)]\tLoss: 0.427117\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000032\tlogit_scale 4.541\n",
      "2022-11-08,05:47:24 | INFO | Rank 0 | Train Epoch: 5 [22944/23491 (98%)]\tLoss: 0.365305\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:47:24 | INFO | Rank 0 | Train Epoch: 5 [22976/23491 (98%)]\tLoss: 0.230173\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:47:24 | INFO | Rank 0 | Train Epoch: 5 [23008/23491 (98%)]\tLoss: 0.390484\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:47:24 | INFO | Rank 0 | Train Epoch: 5 [23040/23491 (98%)]\tLoss: 0.220410\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:47:25 | INFO | Rank 0 | Train Epoch: 5 [23072/23491 (98%)]\tLoss: 0.301666\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:47:25 | INFO | Rank 0 | Train Epoch: 5 [23104/23491 (98%)]\tLoss: 0.219945\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:47:25 | INFO | Rank 0 | Train Epoch: 5 [23136/23491 (99%)]\tLoss: 0.180057\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:47:26 | INFO | Rank 0 | Train Epoch: 5 [23168/23491 (99%)]\tLoss: 0.241054\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:47:26 | INFO | Rank 0 | Train Epoch: 5 [23200/23491 (99%)]\tLoss: 0.239489\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:47:26 | INFO | Rank 0 | Train Epoch: 5 [23232/23491 (99%)]\tLoss: 0.237895\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:47:26 | INFO | Rank 0 | Train Epoch: 5 [23264/23491 (99%)]\tLoss: 0.078742\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:47:27 | INFO | Rank 0 | Train Epoch: 5 [23296/23491 (99%)]\tLoss: 0.329502\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:47:27 | INFO | Rank 0 | Train Epoch: 5 [23328/23491 (99%)]\tLoss: 0.239750\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:47:27 | INFO | Rank 0 | Train Epoch: 5 [23360/23491 (99%)]\tLoss: 0.336556\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:47:27 | INFO | Rank 0 | Train Epoch: 5 [23392/23491 (100%)]\tLoss: 0.214097\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:47:28 | INFO | Rank 0 | Train Epoch: 5 [23424/23491 (100%)]\tLoss: 0.325973\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:47:28 | INFO | Rank 0 | Train Epoch: 5 [23456/23491 (100%)]\tLoss: 0.461104\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "  0%|                                                   | 0/386 [00:00<?, ?it/s]2022-11-08,05:47:28 | INFO | Rank 0 | Begin to eval epoch: 6...\n",
      "100%|█████████████████████████████████████████| 386/386 [00:46<00:00,  8.36it/s]\n",
      "2022-11-08,05:48:14 | INFO | Rank 0 | Eval Epoch: 6 val_loss: 2.7128\tepoch: 6.0000\tnum_elements: 12328.0000\n",
      "2022-11-08,05:48:14 | INFO | Rank 0 | Start epoch 6\n",
      "2022-11-08,05:48:14 | INFO | Rank 0 | Train Epoch: 6 [0/23491 (0%)]\tLoss: 0.105423\tData (t) 0.035\tBatch (t) 0.248\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:15 | INFO | Rank 0 | Train Epoch: 6 [32/23491 (0%)]\tLoss: 0.122376\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:15 | INFO | Rank 0 | Train Epoch: 6 [64/23491 (0%)]\tLoss: 0.274508\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:15 | INFO | Rank 0 | Train Epoch: 6 [96/23491 (0%)]\tLoss: 0.166297\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:16 | INFO | Rank 0 | Train Epoch: 6 [128/23491 (1%)]\tLoss: 0.132134\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:16 | INFO | Rank 0 | Train Epoch: 6 [160/23491 (1%)]\tLoss: 0.094582\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:16 | INFO | Rank 0 | Train Epoch: 6 [192/23491 (1%)]\tLoss: 0.145905\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:16 | INFO | Rank 0 | Train Epoch: 6 [224/23491 (1%)]\tLoss: 0.106133\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:17 | INFO | Rank 0 | Train Epoch: 6 [256/23491 (1%)]\tLoss: 0.227320\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:17 | INFO | Rank 0 | Train Epoch: 6 [288/23491 (1%)]\tLoss: 0.295241\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:17 | INFO | Rank 0 | Train Epoch: 6 [320/23491 (1%)]\tLoss: 0.111695\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:17 | INFO | Rank 0 | Train Epoch: 6 [352/23491 (1%)]\tLoss: 0.055277\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:18 | INFO | Rank 0 | Train Epoch: 6 [384/23491 (2%)]\tLoss: 0.283408\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:18 | INFO | Rank 0 | Train Epoch: 6 [416/23491 (2%)]\tLoss: 0.220024\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:18 | INFO | Rank 0 | Train Epoch: 6 [448/23491 (2%)]\tLoss: 0.200024\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:18 | INFO | Rank 0 | Train Epoch: 6 [480/23491 (2%)]\tLoss: 0.103652\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:19 | INFO | Rank 0 | Train Epoch: 6 [512/23491 (2%)]\tLoss: 0.198608\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:19 | INFO | Rank 0 | Train Epoch: 6 [544/23491 (2%)]\tLoss: 0.134196\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:19 | INFO | Rank 0 | Train Epoch: 6 [576/23491 (2%)]\tLoss: 0.249297\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:20 | INFO | Rank 0 | Train Epoch: 6 [608/23491 (3%)]\tLoss: 0.169448\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:20 | INFO | Rank 0 | Train Epoch: 6 [640/23491 (3%)]\tLoss: 0.107938\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:20 | INFO | Rank 0 | Train Epoch: 6 [672/23491 (3%)]\tLoss: 0.242412\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:20 | INFO | Rank 0 | Train Epoch: 6 [704/23491 (3%)]\tLoss: 0.121503\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:21 | INFO | Rank 0 | Train Epoch: 6 [736/23491 (3%)]\tLoss: 0.202715\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:21 | INFO | Rank 0 | Train Epoch: 6 [768/23491 (3%)]\tLoss: 0.134474\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:21 | INFO | Rank 0 | Train Epoch: 6 [800/23491 (3%)]\tLoss: 0.128314\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:21 | INFO | Rank 0 | Train Epoch: 6 [832/23491 (4%)]\tLoss: 0.274411\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:22 | INFO | Rank 0 | Train Epoch: 6 [864/23491 (4%)]\tLoss: 0.094729\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:22 | INFO | Rank 0 | Train Epoch: 6 [896/23491 (4%)]\tLoss: 0.064222\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:22 | INFO | Rank 0 | Train Epoch: 6 [928/23491 (4%)]\tLoss: 0.075710\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:22 | INFO | Rank 0 | Train Epoch: 6 [960/23491 (4%)]\tLoss: 0.110008\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:23 | INFO | Rank 0 | Train Epoch: 6 [992/23491 (4%)]\tLoss: 0.212106\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:23 | INFO | Rank 0 | Train Epoch: 6 [1024/23491 (4%)]\tLoss: 0.210576\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:23 | INFO | Rank 0 | Train Epoch: 6 [1056/23491 (4%)]\tLoss: 0.066902\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:24 | INFO | Rank 0 | Train Epoch: 6 [1088/23491 (5%)]\tLoss: 0.172556\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:24 | INFO | Rank 0 | Train Epoch: 6 [1120/23491 (5%)]\tLoss: 0.181470\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:24 | INFO | Rank 0 | Train Epoch: 6 [1152/23491 (5%)]\tLoss: 0.210181\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:24 | INFO | Rank 0 | Train Epoch: 6 [1184/23491 (5%)]\tLoss: 0.404424\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:25 | INFO | Rank 0 | Train Epoch: 6 [1216/23491 (5%)]\tLoss: 0.252137\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000031\tlogit_scale 4.541\n",
      "2022-11-08,05:48:25 | INFO | Rank 0 | Train Epoch: 6 [1248/23491 (5%)]\tLoss: 0.149646\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:25 | INFO | Rank 0 | Train Epoch: 6 [1280/23491 (5%)]\tLoss: 0.221990\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:25 | INFO | Rank 0 | Train Epoch: 6 [1312/23491 (6%)]\tLoss: 0.138962\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:26 | INFO | Rank 0 | Train Epoch: 6 [1344/23491 (6%)]\tLoss: 0.197879\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:26 | INFO | Rank 0 | Train Epoch: 6 [1376/23491 (6%)]\tLoss: 0.134498\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:26 | INFO | Rank 0 | Train Epoch: 6 [1408/23491 (6%)]\tLoss: 0.198815\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:26 | INFO | Rank 0 | Train Epoch: 6 [1440/23491 (6%)]\tLoss: 0.093347\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:27 | INFO | Rank 0 | Train Epoch: 6 [1472/23491 (6%)]\tLoss: 0.154434\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:27 | INFO | Rank 0 | Train Epoch: 6 [1504/23491 (6%)]\tLoss: 0.290002\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:27 | INFO | Rank 0 | Train Epoch: 6 [1536/23491 (7%)]\tLoss: 0.468084\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:27 | INFO | Rank 0 | Train Epoch: 6 [1568/23491 (7%)]\tLoss: 0.194957\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:28 | INFO | Rank 0 | Train Epoch: 6 [1600/23491 (7%)]\tLoss: 0.103837\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:28 | INFO | Rank 0 | Train Epoch: 6 [1632/23491 (7%)]\tLoss: 0.297881\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:28 | INFO | Rank 0 | Train Epoch: 6 [1664/23491 (7%)]\tLoss: 0.170661\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:29 | INFO | Rank 0 | Train Epoch: 6 [1696/23491 (7%)]\tLoss: 0.173685\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:29 | INFO | Rank 0 | Train Epoch: 6 [1728/23491 (7%)]\tLoss: 0.311801\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:29 | INFO | Rank 0 | Train Epoch: 6 [1760/23491 (7%)]\tLoss: 0.216753\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:29 | INFO | Rank 0 | Train Epoch: 6 [1792/23491 (8%)]\tLoss: 0.098619\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:30 | INFO | Rank 0 | Train Epoch: 6 [1824/23491 (8%)]\tLoss: 0.140244\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:30 | INFO | Rank 0 | Train Epoch: 6 [1856/23491 (8%)]\tLoss: 0.227020\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:30 | INFO | Rank 0 | Train Epoch: 6 [1888/23491 (8%)]\tLoss: 0.210790\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:30 | INFO | Rank 0 | Train Epoch: 6 [1920/23491 (8%)]\tLoss: 0.087425\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:31 | INFO | Rank 0 | Train Epoch: 6 [1952/23491 (8%)]\tLoss: 0.069178\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:31 | INFO | Rank 0 | Train Epoch: 6 [1984/23491 (8%)]\tLoss: 0.160865\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:31 | INFO | Rank 0 | Train Epoch: 6 [2016/23491 (9%)]\tLoss: 0.062172\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:31 | INFO | Rank 0 | Train Epoch: 6 [2048/23491 (9%)]\tLoss: 0.263490\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:32 | INFO | Rank 0 | Train Epoch: 6 [2080/23491 (9%)]\tLoss: 0.119798\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:32 | INFO | Rank 0 | Train Epoch: 6 [2112/23491 (9%)]\tLoss: 0.247667\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:32 | INFO | Rank 0 | Train Epoch: 6 [2144/23491 (9%)]\tLoss: 0.380600\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:33 | INFO | Rank 0 | Train Epoch: 6 [2176/23491 (9%)]\tLoss: 0.034786\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:33 | INFO | Rank 0 | Train Epoch: 6 [2208/23491 (9%)]\tLoss: 0.055896\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:33 | INFO | Rank 0 | Train Epoch: 6 [2240/23491 (10%)]\tLoss: 0.256376\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:33 | INFO | Rank 0 | Train Epoch: 6 [2272/23491 (10%)]\tLoss: 0.099839\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:34 | INFO | Rank 0 | Train Epoch: 6 [2304/23491 (10%)]\tLoss: 0.184454\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:34 | INFO | Rank 0 | Train Epoch: 6 [2336/23491 (10%)]\tLoss: 0.241986\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:34 | INFO | Rank 0 | Train Epoch: 6 [2368/23491 (10%)]\tLoss: 0.175465\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:34 | INFO | Rank 0 | Train Epoch: 6 [2400/23491 (10%)]\tLoss: 0.159575\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:35 | INFO | Rank 0 | Train Epoch: 6 [2432/23491 (10%)]\tLoss: 0.217994\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:35 | INFO | Rank 0 | Train Epoch: 6 [2464/23491 (10%)]\tLoss: 0.155935\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:35 | INFO | Rank 0 | Train Epoch: 6 [2496/23491 (11%)]\tLoss: 0.131453\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:35 | INFO | Rank 0 | Train Epoch: 6 [2528/23491 (11%)]\tLoss: 0.076941\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:36 | INFO | Rank 0 | Train Epoch: 6 [2560/23491 (11%)]\tLoss: 0.097771\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:36 | INFO | Rank 0 | Train Epoch: 6 [2592/23491 (11%)]\tLoss: 0.132234\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:36 | INFO | Rank 0 | Train Epoch: 6 [2624/23491 (11%)]\tLoss: 0.052293\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:37 | INFO | Rank 0 | Train Epoch: 6 [2656/23491 (11%)]\tLoss: 0.095732\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:37 | INFO | Rank 0 | Train Epoch: 6 [2688/23491 (11%)]\tLoss: 0.174718\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:37 | INFO | Rank 0 | Train Epoch: 6 [2720/23491 (12%)]\tLoss: 0.242921\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:37 | INFO | Rank 0 | Train Epoch: 6 [2752/23491 (12%)]\tLoss: 0.230879\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:38 | INFO | Rank 0 | Train Epoch: 6 [2784/23491 (12%)]\tLoss: 0.248159\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:38 | INFO | Rank 0 | Train Epoch: 6 [2816/23491 (12%)]\tLoss: 0.126170\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:38 | INFO | Rank 0 | Train Epoch: 6 [2848/23491 (12%)]\tLoss: 0.174331\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:38 | INFO | Rank 0 | Train Epoch: 6 [2880/23491 (12%)]\tLoss: 0.064327\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:39 | INFO | Rank 0 | Train Epoch: 6 [2912/23491 (12%)]\tLoss: 0.226977\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:39 | INFO | Rank 0 | Train Epoch: 6 [2944/23491 (13%)]\tLoss: 0.521221\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:39 | INFO | Rank 0 | Train Epoch: 6 [2976/23491 (13%)]\tLoss: 0.594103\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:39 | INFO | Rank 0 | Train Epoch: 6 [3008/23491 (13%)]\tLoss: 0.128861\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000030\tlogit_scale 4.541\n",
      "2022-11-08,05:48:40 | INFO | Rank 0 | Train Epoch: 6 [3040/23491 (13%)]\tLoss: 0.141515\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:40 | INFO | Rank 0 | Train Epoch: 6 [3072/23491 (13%)]\tLoss: 0.165382\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:40 | INFO | Rank 0 | Train Epoch: 6 [3104/23491 (13%)]\tLoss: 0.245086\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:41 | INFO | Rank 0 | Train Epoch: 6 [3136/23491 (13%)]\tLoss: 0.044610\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:41 | INFO | Rank 0 | Train Epoch: 6 [3168/23491 (13%)]\tLoss: 0.166507\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:41 | INFO | Rank 0 | Train Epoch: 6 [3200/23491 (14%)]\tLoss: 0.078556\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:41 | INFO | Rank 0 | Train Epoch: 6 [3232/23491 (14%)]\tLoss: 0.085728\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:42 | INFO | Rank 0 | Train Epoch: 6 [3264/23491 (14%)]\tLoss: 0.125606\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:42 | INFO | Rank 0 | Train Epoch: 6 [3296/23491 (14%)]\tLoss: 0.130450\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:42 | INFO | Rank 0 | Train Epoch: 6 [3328/23491 (14%)]\tLoss: 0.250408\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:42 | INFO | Rank 0 | Train Epoch: 6 [3360/23491 (14%)]\tLoss: 0.146700\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:43 | INFO | Rank 0 | Train Epoch: 6 [3392/23491 (14%)]\tLoss: 0.099418\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:43 | INFO | Rank 0 | Train Epoch: 6 [3424/23491 (15%)]\tLoss: 0.464648\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:43 | INFO | Rank 0 | Train Epoch: 6 [3456/23491 (15%)]\tLoss: 0.265221\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:43 | INFO | Rank 0 | Train Epoch: 6 [3488/23491 (15%)]\tLoss: 0.094873\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:44 | INFO | Rank 0 | Train Epoch: 6 [3520/23491 (15%)]\tLoss: 0.097425\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:44 | INFO | Rank 0 | Train Epoch: 6 [3552/23491 (15%)]\tLoss: 0.089036\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:44 | INFO | Rank 0 | Train Epoch: 6 [3584/23491 (15%)]\tLoss: 0.116761\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:45 | INFO | Rank 0 | Train Epoch: 6 [3616/23491 (15%)]\tLoss: 0.211147\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:45 | INFO | Rank 0 | Train Epoch: 6 [3648/23491 (16%)]\tLoss: 0.183543\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:45 | INFO | Rank 0 | Train Epoch: 6 [3680/23491 (16%)]\tLoss: 0.366967\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:45 | INFO | Rank 0 | Train Epoch: 6 [3712/23491 (16%)]\tLoss: 0.088339\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:46 | INFO | Rank 0 | Train Epoch: 6 [3744/23491 (16%)]\tLoss: 0.160912\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:46 | INFO | Rank 0 | Train Epoch: 6 [3776/23491 (16%)]\tLoss: 0.220544\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:46 | INFO | Rank 0 | Train Epoch: 6 [3808/23491 (16%)]\tLoss: 0.142907\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:46 | INFO | Rank 0 | Train Epoch: 6 [3840/23491 (16%)]\tLoss: 0.367250\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:47 | INFO | Rank 0 | Train Epoch: 6 [3872/23491 (16%)]\tLoss: 0.092583\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:47 | INFO | Rank 0 | Train Epoch: 6 [3904/23491 (17%)]\tLoss: 0.193117\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:47 | INFO | Rank 0 | Train Epoch: 6 [3936/23491 (17%)]\tLoss: 0.186837\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:47 | INFO | Rank 0 | Train Epoch: 6 [3968/23491 (17%)]\tLoss: 0.135197\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:48 | INFO | Rank 0 | Train Epoch: 6 [4000/23491 (17%)]\tLoss: 0.161444\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:48 | INFO | Rank 0 | Train Epoch: 6 [4032/23491 (17%)]\tLoss: 0.059267\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:48 | INFO | Rank 0 | Train Epoch: 6 [4064/23491 (17%)]\tLoss: 0.290680\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:49 | INFO | Rank 0 | Train Epoch: 6 [4096/23491 (17%)]\tLoss: 0.418660\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:49 | INFO | Rank 0 | Train Epoch: 6 [4128/23491 (18%)]\tLoss: 0.239581\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:49 | INFO | Rank 0 | Train Epoch: 6 [4160/23491 (18%)]\tLoss: 0.244322\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:49 | INFO | Rank 0 | Train Epoch: 6 [4192/23491 (18%)]\tLoss: 0.348717\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:50 | INFO | Rank 0 | Train Epoch: 6 [4224/23491 (18%)]\tLoss: 0.042447\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:50 | INFO | Rank 0 | Train Epoch: 6 [4256/23491 (18%)]\tLoss: 0.222622\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:50 | INFO | Rank 0 | Train Epoch: 6 [4288/23491 (18%)]\tLoss: 0.198909\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:50 | INFO | Rank 0 | Train Epoch: 6 [4320/23491 (18%)]\tLoss: 0.066312\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:51 | INFO | Rank 0 | Train Epoch: 6 [4352/23491 (19%)]\tLoss: 0.197664\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:51 | INFO | Rank 0 | Train Epoch: 6 [4384/23491 (19%)]\tLoss: 0.072143\tData (t) 0.055\tBatch (t) 0.270\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:51 | INFO | Rank 0 | Train Epoch: 6 [4416/23491 (19%)]\tLoss: 0.193128\tData (t) 0.055\tBatch (t) 0.270\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:51 | INFO | Rank 0 | Train Epoch: 6 [4448/23491 (19%)]\tLoss: 0.182465\tData (t) 0.055\tBatch (t) 0.269\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:52 | INFO | Rank 0 | Train Epoch: 6 [4480/23491 (19%)]\tLoss: 0.093627\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:52 | INFO | Rank 0 | Train Epoch: 6 [4512/23491 (19%)]\tLoss: 0.168733\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:52 | INFO | Rank 0 | Train Epoch: 6 [4544/23491 (19%)]\tLoss: 0.104671\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:53 | INFO | Rank 0 | Train Epoch: 6 [4576/23491 (19%)]\tLoss: 0.302121\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:53 | INFO | Rank 0 | Train Epoch: 6 [4608/23491 (20%)]\tLoss: 0.137467\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:53 | INFO | Rank 0 | Train Epoch: 6 [4640/23491 (20%)]\tLoss: 0.261600\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:53 | INFO | Rank 0 | Train Epoch: 6 [4672/23491 (20%)]\tLoss: 0.100064\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:54 | INFO | Rank 0 | Train Epoch: 6 [4704/23491 (20%)]\tLoss: 0.138130\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:54 | INFO | Rank 0 | Train Epoch: 6 [4736/23491 (20%)]\tLoss: 0.257387\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:54 | INFO | Rank 0 | Train Epoch: 6 [4768/23491 (20%)]\tLoss: 0.133155\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:54 | INFO | Rank 0 | Train Epoch: 6 [4800/23491 (20%)]\tLoss: 0.240915\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000029\tlogit_scale 4.541\n",
      "2022-11-08,05:48:55 | INFO | Rank 0 | Train Epoch: 6 [4832/23491 (21%)]\tLoss: 0.101097\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:55 | INFO | Rank 0 | Train Epoch: 6 [4864/23491 (21%)]\tLoss: 0.084957\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:55 | INFO | Rank 0 | Train Epoch: 6 [4896/23491 (21%)]\tLoss: 0.174819\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:55 | INFO | Rank 0 | Train Epoch: 6 [4928/23491 (21%)]\tLoss: 0.236298\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:56 | INFO | Rank 0 | Train Epoch: 6 [4960/23491 (21%)]\tLoss: 0.278567\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:56 | INFO | Rank 0 | Train Epoch: 6 [4992/23491 (21%)]\tLoss: 0.127745\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:56 | INFO | Rank 0 | Train Epoch: 6 [5024/23491 (21%)]\tLoss: 0.024468\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:57 | INFO | Rank 0 | Train Epoch: 6 [5056/23491 (22%)]\tLoss: 0.305110\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:57 | INFO | Rank 0 | Train Epoch: 6 [5088/23491 (22%)]\tLoss: 0.074598\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:57 | INFO | Rank 0 | Train Epoch: 6 [5120/23491 (22%)]\tLoss: 0.075684\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:57 | INFO | Rank 0 | Train Epoch: 6 [5152/23491 (22%)]\tLoss: 0.167021\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:58 | INFO | Rank 0 | Train Epoch: 6 [5184/23491 (22%)]\tLoss: 0.179366\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:58 | INFO | Rank 0 | Train Epoch: 6 [5216/23491 (22%)]\tLoss: 0.118086\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:58 | INFO | Rank 0 | Train Epoch: 6 [5248/23491 (22%)]\tLoss: 0.157094\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:58 | INFO | Rank 0 | Train Epoch: 6 [5280/23491 (22%)]\tLoss: 0.268647\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:59 | INFO | Rank 0 | Train Epoch: 6 [5312/23491 (23%)]\tLoss: 0.308596\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:59 | INFO | Rank 0 | Train Epoch: 6 [5344/23491 (23%)]\tLoss: 0.052345\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:59 | INFO | Rank 0 | Train Epoch: 6 [5376/23491 (23%)]\tLoss: 0.148536\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:48:59 | INFO | Rank 0 | Train Epoch: 6 [5408/23491 (23%)]\tLoss: 0.295984\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:00 | INFO | Rank 0 | Train Epoch: 6 [5440/23491 (23%)]\tLoss: 0.247094\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:00 | INFO | Rank 0 | Train Epoch: 6 [5472/23491 (23%)]\tLoss: 0.145249\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:00 | INFO | Rank 0 | Train Epoch: 6 [5504/23491 (23%)]\tLoss: 0.138777\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:01 | INFO | Rank 0 | Train Epoch: 6 [5536/23491 (24%)]\tLoss: 0.207510\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:01 | INFO | Rank 0 | Train Epoch: 6 [5568/23491 (24%)]\tLoss: 0.210841\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:01 | INFO | Rank 0 | Train Epoch: 6 [5600/23491 (24%)]\tLoss: 0.133274\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:01 | INFO | Rank 0 | Train Epoch: 6 [5632/23491 (24%)]\tLoss: 0.284251\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:02 | INFO | Rank 0 | Train Epoch: 6 [5664/23491 (24%)]\tLoss: 0.206185\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:02 | INFO | Rank 0 | Train Epoch: 6 [5696/23491 (24%)]\tLoss: 0.168620\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:02 | INFO | Rank 0 | Train Epoch: 6 [5728/23491 (24%)]\tLoss: 0.054358\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:02 | INFO | Rank 0 | Train Epoch: 6 [5760/23491 (25%)]\tLoss: 0.134693\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:03 | INFO | Rank 0 | Train Epoch: 6 [5792/23491 (25%)]\tLoss: 0.025416\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:03 | INFO | Rank 0 | Train Epoch: 6 [5824/23491 (25%)]\tLoss: 0.165340\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:03 | INFO | Rank 0 | Train Epoch: 6 [5856/23491 (25%)]\tLoss: 0.273426\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:03 | INFO | Rank 0 | Train Epoch: 6 [5888/23491 (25%)]\tLoss: 0.186847\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:04 | INFO | Rank 0 | Train Epoch: 6 [5920/23491 (25%)]\tLoss: 0.152025\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:04 | INFO | Rank 0 | Train Epoch: 6 [5952/23491 (25%)]\tLoss: 0.080221\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:04 | INFO | Rank 0 | Train Epoch: 6 [5984/23491 (25%)]\tLoss: 0.205424\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:05 | INFO | Rank 0 | Train Epoch: 6 [6016/23491 (26%)]\tLoss: 0.255355\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:05 | INFO | Rank 0 | Train Epoch: 6 [6048/23491 (26%)]\tLoss: 0.273568\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:05 | INFO | Rank 0 | Train Epoch: 6 [6080/23491 (26%)]\tLoss: 0.067371\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:05 | INFO | Rank 0 | Train Epoch: 6 [6112/23491 (26%)]\tLoss: 0.201706\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:06 | INFO | Rank 0 | Train Epoch: 6 [6144/23491 (26%)]\tLoss: 0.195014\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:06 | INFO | Rank 0 | Train Epoch: 6 [6176/23491 (26%)]\tLoss: 0.149403\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:06 | INFO | Rank 0 | Train Epoch: 6 [6208/23491 (26%)]\tLoss: 0.129653\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:06 | INFO | Rank 0 | Train Epoch: 6 [6240/23491 (27%)]\tLoss: 0.030523\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:07 | INFO | Rank 0 | Train Epoch: 6 [6272/23491 (27%)]\tLoss: 0.030278\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:07 | INFO | Rank 0 | Train Epoch: 6 [6304/23491 (27%)]\tLoss: 0.208751\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:07 | INFO | Rank 0 | Train Epoch: 6 [6336/23491 (27%)]\tLoss: 0.284511\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:07 | INFO | Rank 0 | Train Epoch: 6 [6368/23491 (27%)]\tLoss: 0.152601\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:08 | INFO | Rank 0 | Train Epoch: 6 [6400/23491 (27%)]\tLoss: 0.227452\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:08 | INFO | Rank 0 | Train Epoch: 6 [6432/23491 (27%)]\tLoss: 0.391442\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:08 | INFO | Rank 0 | Train Epoch: 6 [6464/23491 (28%)]\tLoss: 0.250355\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:09 | INFO | Rank 0 | Train Epoch: 6 [6496/23491 (28%)]\tLoss: 0.115733\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:09 | INFO | Rank 0 | Train Epoch: 6 [6528/23491 (28%)]\tLoss: 0.104785\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:09 | INFO | Rank 0 | Train Epoch: 6 [6560/23491 (28%)]\tLoss: 0.284988\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:09 | INFO | Rank 0 | Train Epoch: 6 [6592/23491 (28%)]\tLoss: 0.063878\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:10 | INFO | Rank 0 | Train Epoch: 6 [6624/23491 (28%)]\tLoss: 0.058178\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000028\tlogit_scale 4.541\n",
      "2022-11-08,05:49:10 | INFO | Rank 0 | Train Epoch: 6 [6656/23491 (28%)]\tLoss: 0.119305\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:10 | INFO | Rank 0 | Train Epoch: 6 [6688/23491 (28%)]\tLoss: 0.234566\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:10 | INFO | Rank 0 | Train Epoch: 6 [6720/23491 (29%)]\tLoss: 0.073348\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:11 | INFO | Rank 0 | Train Epoch: 6 [6752/23491 (29%)]\tLoss: 0.057549\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:11 | INFO | Rank 0 | Train Epoch: 6 [6784/23491 (29%)]\tLoss: 0.207820\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:11 | INFO | Rank 0 | Train Epoch: 6 [6816/23491 (29%)]\tLoss: 0.187670\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:11 | INFO | Rank 0 | Train Epoch: 6 [6848/23491 (29%)]\tLoss: 0.101618\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:12 | INFO | Rank 0 | Train Epoch: 6 [6880/23491 (29%)]\tLoss: 0.115245\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:12 | INFO | Rank 0 | Train Epoch: 6 [6912/23491 (29%)]\tLoss: 0.473584\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:12 | INFO | Rank 0 | Train Epoch: 6 [6944/23491 (30%)]\tLoss: 0.174189\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:13 | INFO | Rank 0 | Train Epoch: 6 [6976/23491 (30%)]\tLoss: 0.125322\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:13 | INFO | Rank 0 | Train Epoch: 6 [7008/23491 (30%)]\tLoss: 0.167444\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:13 | INFO | Rank 0 | Train Epoch: 6 [7040/23491 (30%)]\tLoss: 0.167130\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:13 | INFO | Rank 0 | Train Epoch: 6 [7072/23491 (30%)]\tLoss: 0.334136\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:14 | INFO | Rank 0 | Train Epoch: 6 [7104/23491 (30%)]\tLoss: 0.251311\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:14 | INFO | Rank 0 | Train Epoch: 6 [7136/23491 (30%)]\tLoss: 0.364884\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:14 | INFO | Rank 0 | Train Epoch: 6 [7168/23491 (31%)]\tLoss: 0.087281\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:14 | INFO | Rank 0 | Train Epoch: 6 [7200/23491 (31%)]\tLoss: 0.079336\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:15 | INFO | Rank 0 | Train Epoch: 6 [7232/23491 (31%)]\tLoss: 0.151821\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:15 | INFO | Rank 0 | Train Epoch: 6 [7264/23491 (31%)]\tLoss: 0.282726\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:15 | INFO | Rank 0 | Train Epoch: 6 [7296/23491 (31%)]\tLoss: 0.056553\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:15 | INFO | Rank 0 | Train Epoch: 6 [7328/23491 (31%)]\tLoss: 0.306319\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:16 | INFO | Rank 0 | Train Epoch: 6 [7360/23491 (31%)]\tLoss: 0.232834\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:16 | INFO | Rank 0 | Train Epoch: 6 [7392/23491 (31%)]\tLoss: 0.094411\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:16 | INFO | Rank 0 | Train Epoch: 6 [7424/23491 (32%)]\tLoss: 0.121095\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:16 | INFO | Rank 0 | Train Epoch: 6 [7456/23491 (32%)]\tLoss: 0.139238\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:17 | INFO | Rank 0 | Train Epoch: 6 [7488/23491 (32%)]\tLoss: 0.088858\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:17 | INFO | Rank 0 | Train Epoch: 6 [7520/23491 (32%)]\tLoss: 0.192393\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:17 | INFO | Rank 0 | Train Epoch: 6 [7552/23491 (32%)]\tLoss: 0.051293\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:18 | INFO | Rank 0 | Train Epoch: 6 [7584/23491 (32%)]\tLoss: 0.139998\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:18 | INFO | Rank 0 | Train Epoch: 6 [7616/23491 (32%)]\tLoss: 0.355559\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:18 | INFO | Rank 0 | Train Epoch: 6 [7648/23491 (33%)]\tLoss: 0.201150\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:18 | INFO | Rank 0 | Train Epoch: 6 [7680/23491 (33%)]\tLoss: 0.178580\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:19 | INFO | Rank 0 | Train Epoch: 6 [7712/23491 (33%)]\tLoss: 0.183504\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:19 | INFO | Rank 0 | Train Epoch: 6 [7744/23491 (33%)]\tLoss: 0.100124\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:19 | INFO | Rank 0 | Train Epoch: 6 [7776/23491 (33%)]\tLoss: 0.130522\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:19 | INFO | Rank 0 | Train Epoch: 6 [7808/23491 (33%)]\tLoss: 0.239264\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:20 | INFO | Rank 0 | Train Epoch: 6 [7840/23491 (33%)]\tLoss: 0.258817\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:20 | INFO | Rank 0 | Train Epoch: 6 [7872/23491 (34%)]\tLoss: 0.174962\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:20 | INFO | Rank 0 | Train Epoch: 6 [7904/23491 (34%)]\tLoss: 0.213636\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:20 | INFO | Rank 0 | Train Epoch: 6 [7936/23491 (34%)]\tLoss: 0.269466\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:21 | INFO | Rank 0 | Train Epoch: 6 [7968/23491 (34%)]\tLoss: 0.183517\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:21 | INFO | Rank 0 | Train Epoch: 6 [8000/23491 (34%)]\tLoss: 0.097244\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:21 | INFO | Rank 0 | Train Epoch: 6 [8032/23491 (34%)]\tLoss: 0.128385\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:22 | INFO | Rank 0 | Train Epoch: 6 [8064/23491 (34%)]\tLoss: 0.100372\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:22 | INFO | Rank 0 | Train Epoch: 6 [8096/23491 (34%)]\tLoss: 0.107877\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:22 | INFO | Rank 0 | Train Epoch: 6 [8128/23491 (35%)]\tLoss: 0.242404\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:22 | INFO | Rank 0 | Train Epoch: 6 [8160/23491 (35%)]\tLoss: 0.194599\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:23 | INFO | Rank 0 | Train Epoch: 6 [8192/23491 (35%)]\tLoss: 0.058138\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:23 | INFO | Rank 0 | Train Epoch: 6 [8224/23491 (35%)]\tLoss: 0.256858\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:23 | INFO | Rank 0 | Train Epoch: 6 [8256/23491 (35%)]\tLoss: 0.081961\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:23 | INFO | Rank 0 | Train Epoch: 6 [8288/23491 (35%)]\tLoss: 0.108954\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:24 | INFO | Rank 0 | Train Epoch: 6 [8320/23491 (35%)]\tLoss: 0.069784\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:24 | INFO | Rank 0 | Train Epoch: 6 [8352/23491 (36%)]\tLoss: 0.108867\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:24 | INFO | Rank 0 | Train Epoch: 6 [8384/23491 (36%)]\tLoss: 0.072138\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:24 | INFO | Rank 0 | Train Epoch: 6 [8416/23491 (36%)]\tLoss: 0.314658\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:25 | INFO | Rank 0 | Train Epoch: 6 [8448/23491 (36%)]\tLoss: 0.101599\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:25 | INFO | Rank 0 | Train Epoch: 6 [8480/23491 (36%)]\tLoss: 0.328580\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000027\tlogit_scale 4.541\n",
      "2022-11-08,05:49:25 | INFO | Rank 0 | Train Epoch: 6 [8512/23491 (36%)]\tLoss: 0.310210\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:26 | INFO | Rank 0 | Train Epoch: 6 [8544/23491 (36%)]\tLoss: 0.273501\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:26 | INFO | Rank 0 | Train Epoch: 6 [8576/23491 (37%)]\tLoss: 0.053114\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:26 | INFO | Rank 0 | Train Epoch: 6 [8608/23491 (37%)]\tLoss: 0.041018\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:26 | INFO | Rank 0 | Train Epoch: 6 [8640/23491 (37%)]\tLoss: 0.100181\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:27 | INFO | Rank 0 | Train Epoch: 6 [8672/23491 (37%)]\tLoss: 0.108907\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:27 | INFO | Rank 0 | Train Epoch: 6 [8704/23491 (37%)]\tLoss: 0.144547\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:27 | INFO | Rank 0 | Train Epoch: 6 [8736/23491 (37%)]\tLoss: 0.163064\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:27 | INFO | Rank 0 | Train Epoch: 6 [8768/23491 (37%)]\tLoss: 0.073000\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:28 | INFO | Rank 0 | Train Epoch: 6 [8800/23491 (37%)]\tLoss: 0.133327\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:28 | INFO | Rank 0 | Train Epoch: 6 [8832/23491 (38%)]\tLoss: 0.077561\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:28 | INFO | Rank 0 | Train Epoch: 6 [8864/23491 (38%)]\tLoss: 0.086829\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:28 | INFO | Rank 0 | Train Epoch: 6 [8896/23491 (38%)]\tLoss: 0.307837\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:29 | INFO | Rank 0 | Train Epoch: 6 [8928/23491 (38%)]\tLoss: 0.206588\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:29 | INFO | Rank 0 | Train Epoch: 6 [8960/23491 (38%)]\tLoss: 0.128670\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:29 | INFO | Rank 0 | Train Epoch: 6 [8992/23491 (38%)]\tLoss: 0.198464\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:30 | INFO | Rank 0 | Train Epoch: 6 [9024/23491 (38%)]\tLoss: 0.086092\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:30 | INFO | Rank 0 | Train Epoch: 6 [9056/23491 (39%)]\tLoss: 0.187510\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:30 | INFO | Rank 0 | Train Epoch: 6 [9088/23491 (39%)]\tLoss: 0.175550\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:30 | INFO | Rank 0 | Train Epoch: 6 [9120/23491 (39%)]\tLoss: 0.122110\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:31 | INFO | Rank 0 | Train Epoch: 6 [9152/23491 (39%)]\tLoss: 0.106414\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:31 | INFO | Rank 0 | Train Epoch: 6 [9184/23491 (39%)]\tLoss: 0.115190\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:31 | INFO | Rank 0 | Train Epoch: 6 [9216/23491 (39%)]\tLoss: 0.019621\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:31 | INFO | Rank 0 | Train Epoch: 6 [9248/23491 (39%)]\tLoss: 0.139690\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:32 | INFO | Rank 0 | Train Epoch: 6 [9280/23491 (40%)]\tLoss: 0.130301\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:32 | INFO | Rank 0 | Train Epoch: 6 [9312/23491 (40%)]\tLoss: 0.164626\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:32 | INFO | Rank 0 | Train Epoch: 6 [9344/23491 (40%)]\tLoss: 0.246364\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:32 | INFO | Rank 0 | Train Epoch: 6 [9376/23491 (40%)]\tLoss: 0.145445\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:33 | INFO | Rank 0 | Train Epoch: 6 [9408/23491 (40%)]\tLoss: 0.239017\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:33 | INFO | Rank 0 | Train Epoch: 6 [9440/23491 (40%)]\tLoss: 0.095074\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:33 | INFO | Rank 0 | Train Epoch: 6 [9472/23491 (40%)]\tLoss: 0.043158\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:34 | INFO | Rank 0 | Train Epoch: 6 [9504/23491 (40%)]\tLoss: 0.157133\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:34 | INFO | Rank 0 | Train Epoch: 6 [9536/23491 (41%)]\tLoss: 0.042015\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:34 | INFO | Rank 0 | Train Epoch: 6 [9568/23491 (41%)]\tLoss: 0.124959\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:34 | INFO | Rank 0 | Train Epoch: 6 [9600/23491 (41%)]\tLoss: 0.117937\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:35 | INFO | Rank 0 | Train Epoch: 6 [9632/23491 (41%)]\tLoss: 0.195706\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:35 | INFO | Rank 0 | Train Epoch: 6 [9664/23491 (41%)]\tLoss: 0.260003\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:35 | INFO | Rank 0 | Train Epoch: 6 [9696/23491 (41%)]\tLoss: 0.094538\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:35 | INFO | Rank 0 | Train Epoch: 6 [9728/23491 (41%)]\tLoss: 0.132163\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:36 | INFO | Rank 0 | Train Epoch: 6 [9760/23491 (42%)]\tLoss: 0.155744\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:36 | INFO | Rank 0 | Train Epoch: 6 [9792/23491 (42%)]\tLoss: 0.317039\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:36 | INFO | Rank 0 | Train Epoch: 6 [9824/23491 (42%)]\tLoss: 0.129692\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:36 | INFO | Rank 0 | Train Epoch: 6 [9856/23491 (42%)]\tLoss: 0.201564\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:37 | INFO | Rank 0 | Train Epoch: 6 [9888/23491 (42%)]\tLoss: 0.106128\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:37 | INFO | Rank 0 | Train Epoch: 6 [9920/23491 (42%)]\tLoss: 0.096762\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:37 | INFO | Rank 0 | Train Epoch: 6 [9952/23491 (42%)]\tLoss: 0.165186\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:38 | INFO | Rank 0 | Train Epoch: 6 [9984/23491 (43%)]\tLoss: 0.109385\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:38 | INFO | Rank 0 | Train Epoch: 6 [10016/23491 (43%)]\tLoss: 0.241139\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:38 | INFO | Rank 0 | Train Epoch: 6 [10048/23491 (43%)]\tLoss: 0.284797\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:38 | INFO | Rank 0 | Train Epoch: 6 [10080/23491 (43%)]\tLoss: 0.347835\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:39 | INFO | Rank 0 | Train Epoch: 6 [10112/23491 (43%)]\tLoss: 0.175418\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:39 | INFO | Rank 0 | Train Epoch: 6 [10144/23491 (43%)]\tLoss: 0.053720\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:39 | INFO | Rank 0 | Train Epoch: 6 [10176/23491 (43%)]\tLoss: 0.291354\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:39 | INFO | Rank 0 | Train Epoch: 6 [10208/23491 (43%)]\tLoss: 0.231215\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:40 | INFO | Rank 0 | Train Epoch: 6 [10240/23491 (44%)]\tLoss: 0.075290\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:40 | INFO | Rank 0 | Train Epoch: 6 [10272/23491 (44%)]\tLoss: 0.244983\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:40 | INFO | Rank 0 | Train Epoch: 6 [10304/23491 (44%)]\tLoss: 0.218963\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:40 | INFO | Rank 0 | Train Epoch: 6 [10336/23491 (44%)]\tLoss: 0.104599\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000026\tlogit_scale 4.541\n",
      "2022-11-08,05:49:41 | INFO | Rank 0 | Train Epoch: 6 [10368/23491 (44%)]\tLoss: 0.258144\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:41 | INFO | Rank 0 | Train Epoch: 6 [10400/23491 (44%)]\tLoss: 0.227465\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:41 | INFO | Rank 0 | Train Epoch: 6 [10432/23491 (44%)]\tLoss: 0.051054\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:42 | INFO | Rank 0 | Train Epoch: 6 [10464/23491 (45%)]\tLoss: 0.242105\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:42 | INFO | Rank 0 | Train Epoch: 6 [10496/23491 (45%)]\tLoss: 0.305515\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:42 | INFO | Rank 0 | Train Epoch: 6 [10528/23491 (45%)]\tLoss: 0.067480\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:42 | INFO | Rank 0 | Train Epoch: 6 [10560/23491 (45%)]\tLoss: 0.230928\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:43 | INFO | Rank 0 | Train Epoch: 6 [10592/23491 (45%)]\tLoss: 0.321344\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:43 | INFO | Rank 0 | Train Epoch: 6 [10624/23491 (45%)]\tLoss: 0.128604\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:43 | INFO | Rank 0 | Train Epoch: 6 [10656/23491 (45%)]\tLoss: 0.427442\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:43 | INFO | Rank 0 | Train Epoch: 6 [10688/23491 (46%)]\tLoss: 0.214808\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:44 | INFO | Rank 0 | Train Epoch: 6 [10720/23491 (46%)]\tLoss: 0.177189\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:44 | INFO | Rank 0 | Train Epoch: 6 [10752/23491 (46%)]\tLoss: 0.250006\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:44 | INFO | Rank 0 | Train Epoch: 6 [10784/23491 (46%)]\tLoss: 0.021083\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:44 | INFO | Rank 0 | Train Epoch: 6 [10816/23491 (46%)]\tLoss: 0.146911\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:45 | INFO | Rank 0 | Train Epoch: 6 [10848/23491 (46%)]\tLoss: 0.196269\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:45 | INFO | Rank 0 | Train Epoch: 6 [10880/23491 (46%)]\tLoss: 0.290821\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:45 | INFO | Rank 0 | Train Epoch: 6 [10912/23491 (46%)]\tLoss: 0.192639\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:46 | INFO | Rank 0 | Train Epoch: 6 [10944/23491 (47%)]\tLoss: 0.104503\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:46 | INFO | Rank 0 | Train Epoch: 6 [10976/23491 (47%)]\tLoss: 0.099284\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:46 | INFO | Rank 0 | Train Epoch: 6 [11008/23491 (47%)]\tLoss: 0.316349\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:46 | INFO | Rank 0 | Train Epoch: 6 [11040/23491 (47%)]\tLoss: 0.153776\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:47 | INFO | Rank 0 | Train Epoch: 6 [11072/23491 (47%)]\tLoss: 0.063446\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:47 | INFO | Rank 0 | Train Epoch: 6 [11104/23491 (47%)]\tLoss: 0.316069\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:47 | INFO | Rank 0 | Train Epoch: 6 [11136/23491 (47%)]\tLoss: 0.239528\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:47 | INFO | Rank 0 | Train Epoch: 6 [11168/23491 (48%)]\tLoss: 0.057700\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:48 | INFO | Rank 0 | Train Epoch: 6 [11200/23491 (48%)]\tLoss: 0.236282\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:48 | INFO | Rank 0 | Train Epoch: 6 [11232/23491 (48%)]\tLoss: 0.246607\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:48 | INFO | Rank 0 | Train Epoch: 6 [11264/23491 (48%)]\tLoss: 0.145307\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:48 | INFO | Rank 0 | Train Epoch: 6 [11296/23491 (48%)]\tLoss: 0.061267\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:49 | INFO | Rank 0 | Train Epoch: 6 [11328/23491 (48%)]\tLoss: 0.163500\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:49 | INFO | Rank 0 | Train Epoch: 6 [11360/23491 (48%)]\tLoss: 0.120460\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:49 | INFO | Rank 0 | Train Epoch: 6 [11392/23491 (49%)]\tLoss: 0.159773\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:49 | INFO | Rank 0 | Train Epoch: 6 [11424/23491 (49%)]\tLoss: 0.189890\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:50 | INFO | Rank 0 | Train Epoch: 6 [11456/23491 (49%)]\tLoss: 0.159499\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:50 | INFO | Rank 0 | Train Epoch: 6 [11488/23491 (49%)]\tLoss: 0.198840\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:50 | INFO | Rank 0 | Train Epoch: 6 [11520/23491 (49%)]\tLoss: 0.179552\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:51 | INFO | Rank 0 | Train Epoch: 6 [11552/23491 (49%)]\tLoss: 0.273864\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:51 | INFO | Rank 0 | Train Epoch: 6 [11584/23491 (49%)]\tLoss: 0.398153\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:51 | INFO | Rank 0 | Train Epoch: 6 [11616/23491 (49%)]\tLoss: 0.186319\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:51 | INFO | Rank 0 | Train Epoch: 6 [11648/23491 (50%)]\tLoss: 0.071315\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:52 | INFO | Rank 0 | Train Epoch: 6 [11680/23491 (50%)]\tLoss: 0.111114\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:52 | INFO | Rank 0 | Train Epoch: 6 [11712/23491 (50%)]\tLoss: 0.151718\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:52 | INFO | Rank 0 | Train Epoch: 6 [11744/23491 (50%)]\tLoss: 0.204246\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:52 | INFO | Rank 0 | Train Epoch: 6 [11776/23491 (50%)]\tLoss: 0.175317\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:53 | INFO | Rank 0 | Train Epoch: 6 [11808/23491 (50%)]\tLoss: 0.154032\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:53 | INFO | Rank 0 | Train Epoch: 6 [11840/23491 (50%)]\tLoss: 0.142563\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:53 | INFO | Rank 0 | Train Epoch: 6 [11872/23491 (51%)]\tLoss: 0.263275\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:53 | INFO | Rank 0 | Train Epoch: 6 [11904/23491 (51%)]\tLoss: 0.150979\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:54 | INFO | Rank 0 | Train Epoch: 6 [11936/23491 (51%)]\tLoss: 0.233238\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:54 | INFO | Rank 0 | Train Epoch: 6 [11968/23491 (51%)]\tLoss: 0.257316\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:54 | INFO | Rank 0 | Train Epoch: 6 [12000/23491 (51%)]\tLoss: 0.278319\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:55 | INFO | Rank 0 | Train Epoch: 6 [12032/23491 (51%)]\tLoss: 0.251753\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:55 | INFO | Rank 0 | Train Epoch: 6 [12064/23491 (51%)]\tLoss: 0.267999\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:55 | INFO | Rank 0 | Train Epoch: 6 [12096/23491 (51%)]\tLoss: 0.335407\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:55 | INFO | Rank 0 | Train Epoch: 6 [12128/23491 (52%)]\tLoss: 0.112169\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:56 | INFO | Rank 0 | Train Epoch: 6 [12160/23491 (52%)]\tLoss: 0.078275\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:56 | INFO | Rank 0 | Train Epoch: 6 [12192/23491 (52%)]\tLoss: 0.085045\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:56 | INFO | Rank 0 | Train Epoch: 6 [12224/23491 (52%)]\tLoss: 0.157910\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000025\tlogit_scale 4.541\n",
      "2022-11-08,05:49:56 | INFO | Rank 0 | Train Epoch: 6 [12256/23491 (52%)]\tLoss: 0.186864\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:49:57 | INFO | Rank 0 | Train Epoch: 6 [12288/23491 (52%)]\tLoss: 0.331876\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:49:57 | INFO | Rank 0 | Train Epoch: 6 [12320/23491 (52%)]\tLoss: 0.084666\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:49:57 | INFO | Rank 0 | Train Epoch: 6 [12352/23491 (53%)]\tLoss: 0.090582\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:49:57 | INFO | Rank 0 | Train Epoch: 6 [12384/23491 (53%)]\tLoss: 0.261949\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:49:58 | INFO | Rank 0 | Train Epoch: 6 [12416/23491 (53%)]\tLoss: 0.206921\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:49:58 | INFO | Rank 0 | Train Epoch: 6 [12448/23491 (53%)]\tLoss: 0.136759\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:49:58 | INFO | Rank 0 | Train Epoch: 6 [12480/23491 (53%)]\tLoss: 0.258132\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:49:59 | INFO | Rank 0 | Train Epoch: 6 [12512/23491 (53%)]\tLoss: 0.130141\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:49:59 | INFO | Rank 0 | Train Epoch: 6 [12544/23491 (53%)]\tLoss: 0.300435\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:49:59 | INFO | Rank 0 | Train Epoch: 6 [12576/23491 (54%)]\tLoss: 0.128856\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:49:59 | INFO | Rank 0 | Train Epoch: 6 [12608/23491 (54%)]\tLoss: 0.159634\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:00 | INFO | Rank 0 | Train Epoch: 6 [12640/23491 (54%)]\tLoss: 0.249248\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:00 | INFO | Rank 0 | Train Epoch: 6 [12672/23491 (54%)]\tLoss: 0.179615\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:00 | INFO | Rank 0 | Train Epoch: 6 [12704/23491 (54%)]\tLoss: 0.111020\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:00 | INFO | Rank 0 | Train Epoch: 6 [12736/23491 (54%)]\tLoss: 0.154453\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:01 | INFO | Rank 0 | Train Epoch: 6 [12768/23491 (54%)]\tLoss: 0.163312\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:01 | INFO | Rank 0 | Train Epoch: 6 [12800/23491 (54%)]\tLoss: 0.170805\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:01 | INFO | Rank 0 | Train Epoch: 6 [12832/23491 (55%)]\tLoss: 0.258391\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:01 | INFO | Rank 0 | Train Epoch: 6 [12864/23491 (55%)]\tLoss: 0.071174\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:02 | INFO | Rank 0 | Train Epoch: 6 [12896/23491 (55%)]\tLoss: 0.236899\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:02 | INFO | Rank 0 | Train Epoch: 6 [12928/23491 (55%)]\tLoss: 0.206576\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:02 | INFO | Rank 0 | Train Epoch: 6 [12960/23491 (55%)]\tLoss: 0.145348\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:03 | INFO | Rank 0 | Train Epoch: 6 [12992/23491 (55%)]\tLoss: 0.040582\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:03 | INFO | Rank 0 | Train Epoch: 6 [13024/23491 (55%)]\tLoss: 0.049877\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:03 | INFO | Rank 0 | Train Epoch: 6 [13056/23491 (56%)]\tLoss: 0.212937\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:03 | INFO | Rank 0 | Train Epoch: 6 [13088/23491 (56%)]\tLoss: 0.202048\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:04 | INFO | Rank 0 | Train Epoch: 6 [13120/23491 (56%)]\tLoss: 0.094010\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:04 | INFO | Rank 0 | Train Epoch: 6 [13152/23491 (56%)]\tLoss: 0.083345\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:04 | INFO | Rank 0 | Train Epoch: 6 [13184/23491 (56%)]\tLoss: 0.302926\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:04 | INFO | Rank 0 | Train Epoch: 6 [13216/23491 (56%)]\tLoss: 0.047980\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:05 | INFO | Rank 0 | Train Epoch: 6 [13248/23491 (56%)]\tLoss: 0.086957\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:05 | INFO | Rank 0 | Train Epoch: 6 [13280/23491 (57%)]\tLoss: 0.051010\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:05 | INFO | Rank 0 | Train Epoch: 6 [13312/23491 (57%)]\tLoss: 0.172514\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:05 | INFO | Rank 0 | Train Epoch: 6 [13344/23491 (57%)]\tLoss: 0.092298\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:06 | INFO | Rank 0 | Train Epoch: 6 [13376/23491 (57%)]\tLoss: 0.073368\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:06 | INFO | Rank 0 | Train Epoch: 6 [13408/23491 (57%)]\tLoss: 0.095990\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:06 | INFO | Rank 0 | Train Epoch: 6 [13440/23491 (57%)]\tLoss: 0.231909\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:07 | INFO | Rank 0 | Train Epoch: 6 [13472/23491 (57%)]\tLoss: 0.182243\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:07 | INFO | Rank 0 | Train Epoch: 6 [13504/23491 (57%)]\tLoss: 0.166634\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:07 | INFO | Rank 0 | Train Epoch: 6 [13536/23491 (58%)]\tLoss: 0.070173\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:07 | INFO | Rank 0 | Train Epoch: 6 [13568/23491 (58%)]\tLoss: 0.090684\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:08 | INFO | Rank 0 | Train Epoch: 6 [13600/23491 (58%)]\tLoss: 0.102242\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:08 | INFO | Rank 0 | Train Epoch: 6 [13632/23491 (58%)]\tLoss: 0.112772\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:08 | INFO | Rank 0 | Train Epoch: 6 [13664/23491 (58%)]\tLoss: 0.239749\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:08 | INFO | Rank 0 | Train Epoch: 6 [13696/23491 (58%)]\tLoss: 0.462976\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:09 | INFO | Rank 0 | Train Epoch: 6 [13728/23491 (58%)]\tLoss: 0.103641\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:09 | INFO | Rank 0 | Train Epoch: 6 [13760/23491 (59%)]\tLoss: 0.213070\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:09 | INFO | Rank 0 | Train Epoch: 6 [13792/23491 (59%)]\tLoss: 0.269080\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:09 | INFO | Rank 0 | Train Epoch: 6 [13824/23491 (59%)]\tLoss: 0.266594\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:10 | INFO | Rank 0 | Train Epoch: 6 [13856/23491 (59%)]\tLoss: 0.098794\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:10 | INFO | Rank 0 | Train Epoch: 6 [13888/23491 (59%)]\tLoss: 0.068666\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:10 | INFO | Rank 0 | Train Epoch: 6 [13920/23491 (59%)]\tLoss: 0.111259\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:11 | INFO | Rank 0 | Train Epoch: 6 [13952/23491 (59%)]\tLoss: 0.089066\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:11 | INFO | Rank 0 | Train Epoch: 6 [13984/23491 (60%)]\tLoss: 0.105355\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:11 | INFO | Rank 0 | Train Epoch: 6 [14016/23491 (60%)]\tLoss: 0.070098\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:11 | INFO | Rank 0 | Train Epoch: 6 [14048/23491 (60%)]\tLoss: 0.137651\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:12 | INFO | Rank 0 | Train Epoch: 6 [14080/23491 (60%)]\tLoss: 0.147522\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:12 | INFO | Rank 0 | Train Epoch: 6 [14112/23491 (60%)]\tLoss: 0.163493\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000024\tlogit_scale 4.541\n",
      "2022-11-08,05:50:12 | INFO | Rank 0 | Train Epoch: 6 [14144/23491 (60%)]\tLoss: 0.046843\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:12 | INFO | Rank 0 | Train Epoch: 6 [14176/23491 (60%)]\tLoss: 0.050097\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:13 | INFO | Rank 0 | Train Epoch: 6 [14208/23491 (60%)]\tLoss: 0.085220\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:13 | INFO | Rank 0 | Train Epoch: 6 [14240/23491 (61%)]\tLoss: 0.109059\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:13 | INFO | Rank 0 | Train Epoch: 6 [14272/23491 (61%)]\tLoss: 0.111514\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:13 | INFO | Rank 0 | Train Epoch: 6 [14304/23491 (61%)]\tLoss: 0.083870\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:14 | INFO | Rank 0 | Train Epoch: 6 [14336/23491 (61%)]\tLoss: 0.148132\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:14 | INFO | Rank 0 | Train Epoch: 6 [14368/23491 (61%)]\tLoss: 0.314768\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:14 | INFO | Rank 0 | Train Epoch: 6 [14400/23491 (61%)]\tLoss: 0.380882\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:15 | INFO | Rank 0 | Train Epoch: 6 [14432/23491 (61%)]\tLoss: 0.193195\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:15 | INFO | Rank 0 | Train Epoch: 6 [14464/23491 (62%)]\tLoss: 0.198862\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:15 | INFO | Rank 0 | Train Epoch: 6 [14496/23491 (62%)]\tLoss: 0.157295\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:15 | INFO | Rank 0 | Train Epoch: 6 [14528/23491 (62%)]\tLoss: 0.239151\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:16 | INFO | Rank 0 | Train Epoch: 6 [14560/23491 (62%)]\tLoss: 0.114825\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:16 | INFO | Rank 0 | Train Epoch: 6 [14592/23491 (62%)]\tLoss: 0.092502\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:16 | INFO | Rank 0 | Train Epoch: 6 [14624/23491 (62%)]\tLoss: 0.719010\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:16 | INFO | Rank 0 | Train Epoch: 6 [14656/23491 (62%)]\tLoss: 0.087886\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:17 | INFO | Rank 0 | Train Epoch: 6 [14688/23491 (63%)]\tLoss: 0.056797\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:17 | INFO | Rank 0 | Train Epoch: 6 [14720/23491 (63%)]\tLoss: 0.158038\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:17 | INFO | Rank 0 | Train Epoch: 6 [14752/23491 (63%)]\tLoss: 0.038784\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:17 | INFO | Rank 0 | Train Epoch: 6 [14784/23491 (63%)]\tLoss: 0.199107\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:18 | INFO | Rank 0 | Train Epoch: 6 [14816/23491 (63%)]\tLoss: 0.182244\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:18 | INFO | Rank 0 | Train Epoch: 6 [14848/23491 (63%)]\tLoss: 0.146304\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:18 | INFO | Rank 0 | Train Epoch: 6 [14880/23491 (63%)]\tLoss: 0.093265\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:19 | INFO | Rank 0 | Train Epoch: 6 [14912/23491 (63%)]\tLoss: 0.132267\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:19 | INFO | Rank 0 | Train Epoch: 6 [14944/23491 (64%)]\tLoss: 0.152976\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:19 | INFO | Rank 0 | Train Epoch: 6 [14976/23491 (64%)]\tLoss: 0.120423\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:19 | INFO | Rank 0 | Train Epoch: 6 [15008/23491 (64%)]\tLoss: 0.264795\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:20 | INFO | Rank 0 | Train Epoch: 6 [15040/23491 (64%)]\tLoss: 0.280140\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:20 | INFO | Rank 0 | Train Epoch: 6 [15072/23491 (64%)]\tLoss: 0.126953\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:20 | INFO | Rank 0 | Train Epoch: 6 [15104/23491 (64%)]\tLoss: 0.109108\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:20 | INFO | Rank 0 | Train Epoch: 6 [15136/23491 (64%)]\tLoss: 0.190417\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:21 | INFO | Rank 0 | Train Epoch: 6 [15168/23491 (65%)]\tLoss: 0.154211\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:21 | INFO | Rank 0 | Train Epoch: 6 [15200/23491 (65%)]\tLoss: 0.276364\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:21 | INFO | Rank 0 | Train Epoch: 6 [15232/23491 (65%)]\tLoss: 0.124176\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:21 | INFO | Rank 0 | Train Epoch: 6 [15264/23491 (65%)]\tLoss: 0.131752\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:22 | INFO | Rank 0 | Train Epoch: 6 [15296/23491 (65%)]\tLoss: 0.138651\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:22 | INFO | Rank 0 | Train Epoch: 6 [15328/23491 (65%)]\tLoss: 0.139197\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:22 | INFO | Rank 0 | Train Epoch: 6 [15360/23491 (65%)]\tLoss: 0.053602\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:22 | INFO | Rank 0 | Train Epoch: 6 [15392/23491 (66%)]\tLoss: 0.087343\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:23 | INFO | Rank 0 | Train Epoch: 6 [15424/23491 (66%)]\tLoss: 0.063460\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:23 | INFO | Rank 0 | Train Epoch: 6 [15456/23491 (66%)]\tLoss: 0.117846\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:23 | INFO | Rank 0 | Train Epoch: 6 [15488/23491 (66%)]\tLoss: 0.342159\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:24 | INFO | Rank 0 | Train Epoch: 6 [15520/23491 (66%)]\tLoss: 0.167740\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:24 | INFO | Rank 0 | Train Epoch: 6 [15552/23491 (66%)]\tLoss: 0.187277\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:24 | INFO | Rank 0 | Train Epoch: 6 [15584/23491 (66%)]\tLoss: 0.123273\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:24 | INFO | Rank 0 | Train Epoch: 6 [15616/23491 (66%)]\tLoss: 0.167337\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:25 | INFO | Rank 0 | Train Epoch: 6 [15648/23491 (67%)]\tLoss: 0.170042\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:25 | INFO | Rank 0 | Train Epoch: 6 [15680/23491 (67%)]\tLoss: 0.296437\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:25 | INFO | Rank 0 | Train Epoch: 6 [15712/23491 (67%)]\tLoss: 0.319408\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:25 | INFO | Rank 0 | Train Epoch: 6 [15744/23491 (67%)]\tLoss: 0.270697\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:26 | INFO | Rank 0 | Train Epoch: 6 [15776/23491 (67%)]\tLoss: 0.062958\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:26 | INFO | Rank 0 | Train Epoch: 6 [15808/23491 (67%)]\tLoss: 0.116395\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:26 | INFO | Rank 0 | Train Epoch: 6 [15840/23491 (67%)]\tLoss: 0.425665\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:26 | INFO | Rank 0 | Train Epoch: 6 [15872/23491 (68%)]\tLoss: 0.066197\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:27 | INFO | Rank 0 | Train Epoch: 6 [15904/23491 (68%)]\tLoss: 0.103429\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:27 | INFO | Rank 0 | Train Epoch: 6 [15936/23491 (68%)]\tLoss: 0.164097\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:27 | INFO | Rank 0 | Train Epoch: 6 [15968/23491 (68%)]\tLoss: 0.150393\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:28 | INFO | Rank 0 | Train Epoch: 6 [16000/23491 (68%)]\tLoss: 0.209973\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:28 | INFO | Rank 0 | Train Epoch: 6 [16032/23491 (68%)]\tLoss: 0.260153\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000023\tlogit_scale 4.541\n",
      "2022-11-08,05:50:28 | INFO | Rank 0 | Train Epoch: 6 [16064/23491 (68%)]\tLoss: 0.182059\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:28 | INFO | Rank 0 | Train Epoch: 6 [16096/23491 (69%)]\tLoss: 0.164092\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:29 | INFO | Rank 0 | Train Epoch: 6 [16128/23491 (69%)]\tLoss: 0.095023\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:29 | INFO | Rank 0 | Train Epoch: 6 [16160/23491 (69%)]\tLoss: 0.034635\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:29 | INFO | Rank 0 | Train Epoch: 6 [16192/23491 (69%)]\tLoss: 0.208238\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:29 | INFO | Rank 0 | Train Epoch: 6 [16224/23491 (69%)]\tLoss: 0.317033\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:30 | INFO | Rank 0 | Train Epoch: 6 [16256/23491 (69%)]\tLoss: 0.012219\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:30 | INFO | Rank 0 | Train Epoch: 6 [16288/23491 (69%)]\tLoss: 0.211774\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:30 | INFO | Rank 0 | Train Epoch: 6 [16320/23491 (69%)]\tLoss: 0.085628\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:30 | INFO | Rank 0 | Train Epoch: 6 [16352/23491 (70%)]\tLoss: 0.080256\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:31 | INFO | Rank 0 | Train Epoch: 6 [16384/23491 (70%)]\tLoss: 0.115068\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:31 | INFO | Rank 0 | Train Epoch: 6 [16416/23491 (70%)]\tLoss: 0.058471\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:31 | INFO | Rank 0 | Train Epoch: 6 [16448/23491 (70%)]\tLoss: 0.188030\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:32 | INFO | Rank 0 | Train Epoch: 6 [16480/23491 (70%)]\tLoss: 0.071212\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:32 | INFO | Rank 0 | Train Epoch: 6 [16512/23491 (70%)]\tLoss: 0.253343\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:32 | INFO | Rank 0 | Train Epoch: 6 [16544/23491 (70%)]\tLoss: 0.230567\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:32 | INFO | Rank 0 | Train Epoch: 6 [16576/23491 (71%)]\tLoss: 0.104217\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:33 | INFO | Rank 0 | Train Epoch: 6 [16608/23491 (71%)]\tLoss: 0.205449\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:33 | INFO | Rank 0 | Train Epoch: 6 [16640/23491 (71%)]\tLoss: 0.083080\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:33 | INFO | Rank 0 | Train Epoch: 6 [16672/23491 (71%)]\tLoss: 0.122085\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:33 | INFO | Rank 0 | Train Epoch: 6 [16704/23491 (71%)]\tLoss: 0.095470\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:34 | INFO | Rank 0 | Train Epoch: 6 [16736/23491 (71%)]\tLoss: 0.064419\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:34 | INFO | Rank 0 | Train Epoch: 6 [16768/23491 (71%)]\tLoss: 0.194346\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:34 | INFO | Rank 0 | Train Epoch: 6 [16800/23491 (72%)]\tLoss: 0.105406\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:34 | INFO | Rank 0 | Train Epoch: 6 [16832/23491 (72%)]\tLoss: 0.221000\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:35 | INFO | Rank 0 | Train Epoch: 6 [16864/23491 (72%)]\tLoss: 0.209070\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:35 | INFO | Rank 0 | Train Epoch: 6 [16896/23491 (72%)]\tLoss: 0.040020\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:35 | INFO | Rank 0 | Train Epoch: 6 [16928/23491 (72%)]\tLoss: 0.172145\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:36 | INFO | Rank 0 | Train Epoch: 6 [16960/23491 (72%)]\tLoss: 0.033651\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:36 | INFO | Rank 0 | Train Epoch: 6 [16992/23491 (72%)]\tLoss: 0.396214\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:36 | INFO | Rank 0 | Train Epoch: 6 [17024/23491 (72%)]\tLoss: 0.095531\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:36 | INFO | Rank 0 | Train Epoch: 6 [17056/23491 (73%)]\tLoss: 0.125670\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:37 | INFO | Rank 0 | Train Epoch: 6 [17088/23491 (73%)]\tLoss: 0.264754\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:37 | INFO | Rank 0 | Train Epoch: 6 [17120/23491 (73%)]\tLoss: 0.245440\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:37 | INFO | Rank 0 | Train Epoch: 6 [17152/23491 (73%)]\tLoss: 0.275764\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:37 | INFO | Rank 0 | Train Epoch: 6 [17184/23491 (73%)]\tLoss: 0.170864\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:38 | INFO | Rank 0 | Train Epoch: 6 [17216/23491 (73%)]\tLoss: 0.158773\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:38 | INFO | Rank 0 | Train Epoch: 6 [17248/23491 (73%)]\tLoss: 0.111303\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:38 | INFO | Rank 0 | Train Epoch: 6 [17280/23491 (74%)]\tLoss: 0.385280\tData (t) 0.055\tBatch (t) 0.269\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:38 | INFO | Rank 0 | Train Epoch: 6 [17312/23491 (74%)]\tLoss: 0.170668\tData (t) 0.055\tBatch (t) 0.271\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:39 | INFO | Rank 0 | Train Epoch: 6 [17344/23491 (74%)]\tLoss: 0.084361\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:39 | INFO | Rank 0 | Train Epoch: 6 [17376/23491 (74%)]\tLoss: 0.133098\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:39 | INFO | Rank 0 | Train Epoch: 6 [17408/23491 (74%)]\tLoss: 0.065385\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:40 | INFO | Rank 0 | Train Epoch: 6 [17440/23491 (74%)]\tLoss: 0.326038\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:40 | INFO | Rank 0 | Train Epoch: 6 [17472/23491 (74%)]\tLoss: 0.111700\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:40 | INFO | Rank 0 | Train Epoch: 6 [17504/23491 (75%)]\tLoss: 0.266790\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:40 | INFO | Rank 0 | Train Epoch: 6 [17536/23491 (75%)]\tLoss: 0.108880\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:41 | INFO | Rank 0 | Train Epoch: 6 [17568/23491 (75%)]\tLoss: 0.089845\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:41 | INFO | Rank 0 | Train Epoch: 6 [17600/23491 (75%)]\tLoss: 0.095363\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:41 | INFO | Rank 0 | Train Epoch: 6 [17632/23491 (75%)]\tLoss: 0.082961\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:41 | INFO | Rank 0 | Train Epoch: 6 [17664/23491 (75%)]\tLoss: 0.075689\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:42 | INFO | Rank 0 | Train Epoch: 6 [17696/23491 (75%)]\tLoss: 0.215439\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:42 | INFO | Rank 0 | Train Epoch: 6 [17728/23491 (75%)]\tLoss: 0.305598\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:42 | INFO | Rank 0 | Train Epoch: 6 [17760/23491 (76%)]\tLoss: 0.198711\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:42 | INFO | Rank 0 | Train Epoch: 6 [17792/23491 (76%)]\tLoss: 0.158838\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:43 | INFO | Rank 0 | Train Epoch: 6 [17824/23491 (76%)]\tLoss: 0.316421\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:43 | INFO | Rank 0 | Train Epoch: 6 [17856/23491 (76%)]\tLoss: 0.230901\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:43 | INFO | Rank 0 | Train Epoch: 6 [17888/23491 (76%)]\tLoss: 0.118198\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:44 | INFO | Rank 0 | Train Epoch: 6 [17920/23491 (76%)]\tLoss: 0.242419\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:44 | INFO | Rank 0 | Train Epoch: 6 [17952/23491 (76%)]\tLoss: 0.073934\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:44 | INFO | Rank 0 | Train Epoch: 6 [17984/23491 (77%)]\tLoss: 0.038857\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000022\tlogit_scale 4.541\n",
      "2022-11-08,05:50:44 | INFO | Rank 0 | Train Epoch: 6 [18016/23491 (77%)]\tLoss: 0.084696\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:45 | INFO | Rank 0 | Train Epoch: 6 [18048/23491 (77%)]\tLoss: 0.168835\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:45 | INFO | Rank 0 | Train Epoch: 6 [18080/23491 (77%)]\tLoss: 0.192472\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:45 | INFO | Rank 0 | Train Epoch: 6 [18112/23491 (77%)]\tLoss: 0.245195\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:45 | INFO | Rank 0 | Train Epoch: 6 [18144/23491 (77%)]\tLoss: 0.096851\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:46 | INFO | Rank 0 | Train Epoch: 6 [18176/23491 (77%)]\tLoss: 0.276908\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:46 | INFO | Rank 0 | Train Epoch: 6 [18208/23491 (78%)]\tLoss: 0.113932\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:46 | INFO | Rank 0 | Train Epoch: 6 [18240/23491 (78%)]\tLoss: 0.142787\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:46 | INFO | Rank 0 | Train Epoch: 6 [18272/23491 (78%)]\tLoss: 0.101383\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:47 | INFO | Rank 0 | Train Epoch: 6 [18304/23491 (78%)]\tLoss: 0.332679\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:47 | INFO | Rank 0 | Train Epoch: 6 [18336/23491 (78%)]\tLoss: 0.181320\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:47 | INFO | Rank 0 | Train Epoch: 6 [18368/23491 (78%)]\tLoss: 0.125198\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:48 | INFO | Rank 0 | Train Epoch: 6 [18400/23491 (78%)]\tLoss: 0.143271\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:48 | INFO | Rank 0 | Train Epoch: 6 [18432/23491 (78%)]\tLoss: 0.171671\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:48 | INFO | Rank 0 | Train Epoch: 6 [18464/23491 (79%)]\tLoss: 0.136577\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:48 | INFO | Rank 0 | Train Epoch: 6 [18496/23491 (79%)]\tLoss: 0.179705\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:49 | INFO | Rank 0 | Train Epoch: 6 [18528/23491 (79%)]\tLoss: 0.125469\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:49 | INFO | Rank 0 | Train Epoch: 6 [18560/23491 (79%)]\tLoss: 0.159121\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:49 | INFO | Rank 0 | Train Epoch: 6 [18592/23491 (79%)]\tLoss: 0.134665\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:49 | INFO | Rank 0 | Train Epoch: 6 [18624/23491 (79%)]\tLoss: 0.293170\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:50 | INFO | Rank 0 | Train Epoch: 6 [18656/23491 (79%)]\tLoss: 0.088466\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:50 | INFO | Rank 0 | Train Epoch: 6 [18688/23491 (80%)]\tLoss: 0.290252\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:50 | INFO | Rank 0 | Train Epoch: 6 [18720/23491 (80%)]\tLoss: 0.310063\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:50 | INFO | Rank 0 | Train Epoch: 6 [18752/23491 (80%)]\tLoss: 0.069133\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:51 | INFO | Rank 0 | Train Epoch: 6 [18784/23491 (80%)]\tLoss: 0.052515\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:51 | INFO | Rank 0 | Train Epoch: 6 [18816/23491 (80%)]\tLoss: 0.065322\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:51 | INFO | Rank 0 | Train Epoch: 6 [18848/23491 (80%)]\tLoss: 0.130934\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.541\n",
      "2022-11-08,05:50:52 | INFO | Rank 0 | Train Epoch: 6 [18880/23491 (80%)]\tLoss: 0.245314\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:52 | INFO | Rank 0 | Train Epoch: 6 [18912/23491 (81%)]\tLoss: 0.158229\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:52 | INFO | Rank 0 | Train Epoch: 6 [18944/23491 (81%)]\tLoss: 0.516039\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:52 | INFO | Rank 0 | Train Epoch: 6 [18976/23491 (81%)]\tLoss: 0.106687\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:53 | INFO | Rank 0 | Train Epoch: 6 [19008/23491 (81%)]\tLoss: 0.040007\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:53 | INFO | Rank 0 | Train Epoch: 6 [19040/23491 (81%)]\tLoss: 0.079952\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:53 | INFO | Rank 0 | Train Epoch: 6 [19072/23491 (81%)]\tLoss: 0.171037\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:53 | INFO | Rank 0 | Train Epoch: 6 [19104/23491 (81%)]\tLoss: 0.108885\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:54 | INFO | Rank 0 | Train Epoch: 6 [19136/23491 (81%)]\tLoss: 0.066012\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:54 | INFO | Rank 0 | Train Epoch: 6 [19168/23491 (82%)]\tLoss: 0.117060\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:54 | INFO | Rank 0 | Train Epoch: 6 [19200/23491 (82%)]\tLoss: 0.276338\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:54 | INFO | Rank 0 | Train Epoch: 6 [19232/23491 (82%)]\tLoss: 0.193796\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:55 | INFO | Rank 0 | Train Epoch: 6 [19264/23491 (82%)]\tLoss: 0.160108\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:55 | INFO | Rank 0 | Train Epoch: 6 [19296/23491 (82%)]\tLoss: 0.253554\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:55 | INFO | Rank 0 | Train Epoch: 6 [19328/23491 (82%)]\tLoss: 0.447978\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:56 | INFO | Rank 0 | Train Epoch: 6 [19360/23491 (82%)]\tLoss: 0.125827\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:56 | INFO | Rank 0 | Train Epoch: 6 [19392/23491 (83%)]\tLoss: 0.142526\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:56 | INFO | Rank 0 | Train Epoch: 6 [19424/23491 (83%)]\tLoss: 0.156669\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:56 | INFO | Rank 0 | Train Epoch: 6 [19456/23491 (83%)]\tLoss: 0.159202\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:57 | INFO | Rank 0 | Train Epoch: 6 [19488/23491 (83%)]\tLoss: 0.032878\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:57 | INFO | Rank 0 | Train Epoch: 6 [19520/23491 (83%)]\tLoss: 0.311494\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:57 | INFO | Rank 0 | Train Epoch: 6 [19552/23491 (83%)]\tLoss: 0.251902\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:57 | INFO | Rank 0 | Train Epoch: 6 [19584/23491 (83%)]\tLoss: 0.035561\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:58 | INFO | Rank 0 | Train Epoch: 6 [19616/23491 (84%)]\tLoss: 0.182048\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:58 | INFO | Rank 0 | Train Epoch: 6 [19648/23491 (84%)]\tLoss: 0.112518\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:58 | INFO | Rank 0 | Train Epoch: 6 [19680/23491 (84%)]\tLoss: 0.195950\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:58 | INFO | Rank 0 | Train Epoch: 6 [19712/23491 (84%)]\tLoss: 0.402756\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:59 | INFO | Rank 0 | Train Epoch: 6 [19744/23491 (84%)]\tLoss: 0.182609\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:59 | INFO | Rank 0 | Train Epoch: 6 [19776/23491 (84%)]\tLoss: 0.185974\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:59 | INFO | Rank 0 | Train Epoch: 6 [19808/23491 (84%)]\tLoss: 0.167315\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:50:59 | INFO | Rank 0 | Train Epoch: 6 [19840/23491 (84%)]\tLoss: 0.402909\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:51:00 | INFO | Rank 0 | Train Epoch: 6 [19872/23491 (85%)]\tLoss: 0.084416\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:51:00 | INFO | Rank 0 | Train Epoch: 6 [19904/23491 (85%)]\tLoss: 0.311593\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:51:00 | INFO | Rank 0 | Train Epoch: 6 [19936/23491 (85%)]\tLoss: 0.240188\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:51:01 | INFO | Rank 0 | Train Epoch: 6 [19968/23491 (85%)]\tLoss: 0.137643\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000021\tlogit_scale 4.540\n",
      "2022-11-08,05:51:01 | INFO | Rank 0 | Train Epoch: 6 [20000/23491 (85%)]\tLoss: 0.365626\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:01 | INFO | Rank 0 | Train Epoch: 6 [20032/23491 (85%)]\tLoss: 0.510049\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:01 | INFO | Rank 0 | Train Epoch: 6 [20064/23491 (85%)]\tLoss: 0.083065\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:02 | INFO | Rank 0 | Train Epoch: 6 [20096/23491 (86%)]\tLoss: 0.164596\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:02 | INFO | Rank 0 | Train Epoch: 6 [20128/23491 (86%)]\tLoss: 0.187896\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:02 | INFO | Rank 0 | Train Epoch: 6 [20160/23491 (86%)]\tLoss: 0.069707\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:02 | INFO | Rank 0 | Train Epoch: 6 [20192/23491 (86%)]\tLoss: 0.163601\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:03 | INFO | Rank 0 | Train Epoch: 6 [20224/23491 (86%)]\tLoss: 0.184667\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:03 | INFO | Rank 0 | Train Epoch: 6 [20256/23491 (86%)]\tLoss: 0.114592\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:03 | INFO | Rank 0 | Train Epoch: 6 [20288/23491 (86%)]\tLoss: 0.075643\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:03 | INFO | Rank 0 | Train Epoch: 6 [20320/23491 (87%)]\tLoss: 0.214092\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:04 | INFO | Rank 0 | Train Epoch: 6 [20352/23491 (87%)]\tLoss: 0.261301\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:04 | INFO | Rank 0 | Train Epoch: 6 [20384/23491 (87%)]\tLoss: 0.067450\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:04 | INFO | Rank 0 | Train Epoch: 6 [20416/23491 (87%)]\tLoss: 0.262633\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:05 | INFO | Rank 0 | Train Epoch: 6 [20448/23491 (87%)]\tLoss: 0.064071\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:05 | INFO | Rank 0 | Train Epoch: 6 [20480/23491 (87%)]\tLoss: 0.390906\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:05 | INFO | Rank 0 | Train Epoch: 6 [20512/23491 (87%)]\tLoss: 0.107343\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:05 | INFO | Rank 0 | Train Epoch: 6 [20544/23491 (87%)]\tLoss: 0.129829\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:06 | INFO | Rank 0 | Train Epoch: 6 [20576/23491 (88%)]\tLoss: 0.099555\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:06 | INFO | Rank 0 | Train Epoch: 6 [20608/23491 (88%)]\tLoss: 0.054430\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:06 | INFO | Rank 0 | Train Epoch: 6 [20640/23491 (88%)]\tLoss: 0.017472\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:06 | INFO | Rank 0 | Train Epoch: 6 [20672/23491 (88%)]\tLoss: 0.177869\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:07 | INFO | Rank 0 | Train Epoch: 6 [20704/23491 (88%)]\tLoss: 0.160676\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:07 | INFO | Rank 0 | Train Epoch: 6 [20736/23491 (88%)]\tLoss: 0.138874\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:07 | INFO | Rank 0 | Train Epoch: 6 [20768/23491 (88%)]\tLoss: 0.332093\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:07 | INFO | Rank 0 | Train Epoch: 6 [20800/23491 (89%)]\tLoss: 0.155437\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:08 | INFO | Rank 0 | Train Epoch: 6 [20832/23491 (89%)]\tLoss: 0.033549\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:08 | INFO | Rank 0 | Train Epoch: 6 [20864/23491 (89%)]\tLoss: 0.032022\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:08 | INFO | Rank 0 | Train Epoch: 6 [20896/23491 (89%)]\tLoss: 0.135354\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:09 | INFO | Rank 0 | Train Epoch: 6 [20928/23491 (89%)]\tLoss: 0.058030\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:09 | INFO | Rank 0 | Train Epoch: 6 [20960/23491 (89%)]\tLoss: 0.283046\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:09 | INFO | Rank 0 | Train Epoch: 6 [20992/23491 (89%)]\tLoss: 0.087568\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:09 | INFO | Rank 0 | Train Epoch: 6 [21024/23491 (90%)]\tLoss: 0.281288\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:10 | INFO | Rank 0 | Train Epoch: 6 [21056/23491 (90%)]\tLoss: 0.051383\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:10 | INFO | Rank 0 | Train Epoch: 6 [21088/23491 (90%)]\tLoss: 0.063612\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:10 | INFO | Rank 0 | Train Epoch: 6 [21120/23491 (90%)]\tLoss: 0.198223\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:10 | INFO | Rank 0 | Train Epoch: 6 [21152/23491 (90%)]\tLoss: 0.085227\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:11 | INFO | Rank 0 | Train Epoch: 6 [21184/23491 (90%)]\tLoss: 0.105798\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:11 | INFO | Rank 0 | Train Epoch: 6 [21216/23491 (90%)]\tLoss: 0.182124\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:11 | INFO | Rank 0 | Train Epoch: 6 [21248/23491 (90%)]\tLoss: 0.107922\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:11 | INFO | Rank 0 | Train Epoch: 6 [21280/23491 (91%)]\tLoss: 0.246252\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:12 | INFO | Rank 0 | Train Epoch: 6 [21312/23491 (91%)]\tLoss: 0.151482\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:12 | INFO | Rank 0 | Train Epoch: 6 [21344/23491 (91%)]\tLoss: 0.325135\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:12 | INFO | Rank 0 | Train Epoch: 6 [21376/23491 (91%)]\tLoss: 0.120121\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:13 | INFO | Rank 0 | Train Epoch: 6 [21408/23491 (91%)]\tLoss: 0.124269\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:13 | INFO | Rank 0 | Train Epoch: 6 [21440/23491 (91%)]\tLoss: 0.156831\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:13 | INFO | Rank 0 | Train Epoch: 6 [21472/23491 (91%)]\tLoss: 0.098864\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:13 | INFO | Rank 0 | Train Epoch: 6 [21504/23491 (92%)]\tLoss: 0.278455\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:14 | INFO | Rank 0 | Train Epoch: 6 [21536/23491 (92%)]\tLoss: 0.040513\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:14 | INFO | Rank 0 | Train Epoch: 6 [21568/23491 (92%)]\tLoss: 0.231861\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:14 | INFO | Rank 0 | Train Epoch: 6 [21600/23491 (92%)]\tLoss: 0.381823\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:14 | INFO | Rank 0 | Train Epoch: 6 [21632/23491 (92%)]\tLoss: 0.145220\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:15 | INFO | Rank 0 | Train Epoch: 6 [21664/23491 (92%)]\tLoss: 0.183904\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:15 | INFO | Rank 0 | Train Epoch: 6 [21696/23491 (92%)]\tLoss: 0.183089\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:15 | INFO | Rank 0 | Train Epoch: 6 [21728/23491 (93%)]\tLoss: 0.153479\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:15 | INFO | Rank 0 | Train Epoch: 6 [21760/23491 (93%)]\tLoss: 0.315324\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:16 | INFO | Rank 0 | Train Epoch: 6 [21792/23491 (93%)]\tLoss: 0.112193\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:16 | INFO | Rank 0 | Train Epoch: 6 [21824/23491 (93%)]\tLoss: 0.259001\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:16 | INFO | Rank 0 | Train Epoch: 6 [21856/23491 (93%)]\tLoss: 0.175079\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:17 | INFO | Rank 0 | Train Epoch: 6 [21888/23491 (93%)]\tLoss: 0.133365\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:17 | INFO | Rank 0 | Train Epoch: 6 [21920/23491 (93%)]\tLoss: 0.233146\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:17 | INFO | Rank 0 | Train Epoch: 6 [21952/23491 (93%)]\tLoss: 0.193930\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:17 | INFO | Rank 0 | Train Epoch: 6 [21984/23491 (94%)]\tLoss: 0.167992\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000020\tlogit_scale 4.540\n",
      "2022-11-08,05:51:18 | INFO | Rank 0 | Train Epoch: 6 [22016/23491 (94%)]\tLoss: 0.261352\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:18 | INFO | Rank 0 | Train Epoch: 6 [22048/23491 (94%)]\tLoss: 0.152944\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:18 | INFO | Rank 0 | Train Epoch: 6 [22080/23491 (94%)]\tLoss: 0.215764\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:18 | INFO | Rank 0 | Train Epoch: 6 [22112/23491 (94%)]\tLoss: 0.181541\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:19 | INFO | Rank 0 | Train Epoch: 6 [22144/23491 (94%)]\tLoss: 0.223665\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:19 | INFO | Rank 0 | Train Epoch: 6 [22176/23491 (94%)]\tLoss: 0.052115\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:19 | INFO | Rank 0 | Train Epoch: 6 [22208/23491 (95%)]\tLoss: 0.088966\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:19 | INFO | Rank 0 | Train Epoch: 6 [22240/23491 (95%)]\tLoss: 0.214194\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:20 | INFO | Rank 0 | Train Epoch: 6 [22272/23491 (95%)]\tLoss: 0.078070\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:20 | INFO | Rank 0 | Train Epoch: 6 [22304/23491 (95%)]\tLoss: 0.082461\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:20 | INFO | Rank 0 | Train Epoch: 6 [22336/23491 (95%)]\tLoss: 0.228653\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:20 | INFO | Rank 0 | Train Epoch: 6 [22368/23491 (95%)]\tLoss: 0.170758\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:21 | INFO | Rank 0 | Train Epoch: 6 [22400/23491 (95%)]\tLoss: 0.299357\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:21 | INFO | Rank 0 | Train Epoch: 6 [22432/23491 (96%)]\tLoss: 0.285715\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:21 | INFO | Rank 0 | Train Epoch: 6 [22464/23491 (96%)]\tLoss: 0.152770\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:22 | INFO | Rank 0 | Train Epoch: 6 [22496/23491 (96%)]\tLoss: 0.163013\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:22 | INFO | Rank 0 | Train Epoch: 6 [22528/23491 (96%)]\tLoss: 0.109151\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:22 | INFO | Rank 0 | Train Epoch: 6 [22560/23491 (96%)]\tLoss: 0.069078\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:22 | INFO | Rank 0 | Train Epoch: 6 [22592/23491 (96%)]\tLoss: 0.220088\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:23 | INFO | Rank 0 | Train Epoch: 6 [22624/23491 (96%)]\tLoss: 0.143065\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:23 | INFO | Rank 0 | Train Epoch: 6 [22656/23491 (96%)]\tLoss: 0.048892\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:23 | INFO | Rank 0 | Train Epoch: 6 [22688/23491 (97%)]\tLoss: 0.269903\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:23 | INFO | Rank 0 | Train Epoch: 6 [22720/23491 (97%)]\tLoss: 0.169266\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:24 | INFO | Rank 0 | Train Epoch: 6 [22752/23491 (97%)]\tLoss: 0.155169\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:24 | INFO | Rank 0 | Train Epoch: 6 [22784/23491 (97%)]\tLoss: 0.093376\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:24 | INFO | Rank 0 | Train Epoch: 6 [22816/23491 (97%)]\tLoss: 0.102716\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:24 | INFO | Rank 0 | Train Epoch: 6 [22848/23491 (97%)]\tLoss: 0.077847\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:25 | INFO | Rank 0 | Train Epoch: 6 [22880/23491 (97%)]\tLoss: 0.172585\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:25 | INFO | Rank 0 | Train Epoch: 6 [22912/23491 (98%)]\tLoss: 0.025331\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:25 | INFO | Rank 0 | Train Epoch: 6 [22944/23491 (98%)]\tLoss: 0.252005\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:26 | INFO | Rank 0 | Train Epoch: 6 [22976/23491 (98%)]\tLoss: 0.058211\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:26 | INFO | Rank 0 | Train Epoch: 6 [23008/23491 (98%)]\tLoss: 0.276741\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:26 | INFO | Rank 0 | Train Epoch: 6 [23040/23491 (98%)]\tLoss: 0.096289\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:26 | INFO | Rank 0 | Train Epoch: 6 [23072/23491 (98%)]\tLoss: 0.064473\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:27 | INFO | Rank 0 | Train Epoch: 6 [23104/23491 (98%)]\tLoss: 0.213821\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:27 | INFO | Rank 0 | Train Epoch: 6 [23136/23491 (99%)]\tLoss: 0.173253\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:27 | INFO | Rank 0 | Train Epoch: 6 [23168/23491 (99%)]\tLoss: 0.129221\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:27 | INFO | Rank 0 | Train Epoch: 6 [23200/23491 (99%)]\tLoss: 0.230332\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:28 | INFO | Rank 0 | Train Epoch: 6 [23232/23491 (99%)]\tLoss: 0.395362\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:28 | INFO | Rank 0 | Train Epoch: 6 [23264/23491 (99%)]\tLoss: 0.030551\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:28 | INFO | Rank 0 | Train Epoch: 6 [23296/23491 (99%)]\tLoss: 0.098715\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:28 | INFO | Rank 0 | Train Epoch: 6 [23328/23491 (99%)]\tLoss: 0.150527\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:29 | INFO | Rank 0 | Train Epoch: 6 [23360/23491 (99%)]\tLoss: 0.159988\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:29 | INFO | Rank 0 | Train Epoch: 6 [23392/23491 (100%)]\tLoss: 0.174087\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:29 | INFO | Rank 0 | Train Epoch: 6 [23424/23491 (100%)]\tLoss: 0.168448\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:51:30 | INFO | Rank 0 | Train Epoch: 6 [23456/23491 (100%)]\tLoss: 0.064475\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "  0%|                                                   | 0/386 [00:00<?, ?it/s]2022-11-08,05:51:30 | INFO | Rank 0 | Begin to eval epoch: 7...\n",
      "100%|█████████████████████████████████████████| 386/386 [00:46<00:00,  8.36it/s]\n",
      "2022-11-08,05:52:16 | INFO | Rank 0 | Eval Epoch: 7 val_loss: 2.9057\tepoch: 7.0000\tnum_elements: 12328.0000\n",
      "2022-11-08,05:52:16 | INFO | Rank 0 | Start epoch 7\n",
      "2022-11-08,05:52:16 | INFO | Rank 0 | Train Epoch: 7 [0/23491 (0%)]\tLoss: 0.152394\tData (t) 0.035\tBatch (t) 0.249\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:16 | INFO | Rank 0 | Train Epoch: 7 [32/23491 (0%)]\tLoss: 0.083258\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:17 | INFO | Rank 0 | Train Epoch: 7 [64/23491 (0%)]\tLoss: 0.071375\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:17 | INFO | Rank 0 | Train Epoch: 7 [96/23491 (0%)]\tLoss: 0.306172\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:17 | INFO | Rank 0 | Train Epoch: 7 [128/23491 (1%)]\tLoss: 0.064984\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:17 | INFO | Rank 0 | Train Epoch: 7 [160/23491 (1%)]\tLoss: 0.118969\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:18 | INFO | Rank 0 | Train Epoch: 7 [192/23491 (1%)]\tLoss: 0.220557\tData (t) 0.052\tBatch (t) 0.265\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:18 | INFO | Rank 0 | Train Epoch: 7 [224/23491 (1%)]\tLoss: 0.196982\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:18 | INFO | Rank 0 | Train Epoch: 7 [256/23491 (1%)]\tLoss: 0.079684\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:18 | INFO | Rank 0 | Train Epoch: 7 [288/23491 (1%)]\tLoss: 0.127386\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:19 | INFO | Rank 0 | Train Epoch: 7 [320/23491 (1%)]\tLoss: 0.145349\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:19 | INFO | Rank 0 | Train Epoch: 7 [352/23491 (1%)]\tLoss: 0.145202\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:19 | INFO | Rank 0 | Train Epoch: 7 [384/23491 (2%)]\tLoss: 0.081210\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:19 | INFO | Rank 0 | Train Epoch: 7 [416/23491 (2%)]\tLoss: 0.111053\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:20 | INFO | Rank 0 | Train Epoch: 7 [448/23491 (2%)]\tLoss: 0.154612\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:20 | INFO | Rank 0 | Train Epoch: 7 [480/23491 (2%)]\tLoss: 0.062718\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:20 | INFO | Rank 0 | Train Epoch: 7 [512/23491 (2%)]\tLoss: 0.091233\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:21 | INFO | Rank 0 | Train Epoch: 7 [544/23491 (2%)]\tLoss: 0.124025\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000019\tlogit_scale 4.540\n",
      "2022-11-08,05:52:21 | INFO | Rank 0 | Train Epoch: 7 [576/23491 (2%)]\tLoss: 0.103276\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:21 | INFO | Rank 0 | Train Epoch: 7 [608/23491 (3%)]\tLoss: 0.099415\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:21 | INFO | Rank 0 | Train Epoch: 7 [640/23491 (3%)]\tLoss: 0.058730\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:22 | INFO | Rank 0 | Train Epoch: 7 [672/23491 (3%)]\tLoss: 0.081210\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:22 | INFO | Rank 0 | Train Epoch: 7 [704/23491 (3%)]\tLoss: 0.166902\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:22 | INFO | Rank 0 | Train Epoch: 7 [736/23491 (3%)]\tLoss: 0.075589\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:22 | INFO | Rank 0 | Train Epoch: 7 [768/23491 (3%)]\tLoss: 0.080851\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:23 | INFO | Rank 0 | Train Epoch: 7 [800/23491 (3%)]\tLoss: 0.112662\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:23 | INFO | Rank 0 | Train Epoch: 7 [832/23491 (4%)]\tLoss: 0.235137\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:23 | INFO | Rank 0 | Train Epoch: 7 [864/23491 (4%)]\tLoss: 0.024383\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:23 | INFO | Rank 0 | Train Epoch: 7 [896/23491 (4%)]\tLoss: 0.095430\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:24 | INFO | Rank 0 | Train Epoch: 7 [928/23491 (4%)]\tLoss: 0.086713\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:24 | INFO | Rank 0 | Train Epoch: 7 [960/23491 (4%)]\tLoss: 0.151548\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:24 | INFO | Rank 0 | Train Epoch: 7 [992/23491 (4%)]\tLoss: 0.143287\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:25 | INFO | Rank 0 | Train Epoch: 7 [1024/23491 (4%)]\tLoss: 0.062660\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:25 | INFO | Rank 0 | Train Epoch: 7 [1056/23491 (4%)]\tLoss: 0.060789\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:25 | INFO | Rank 0 | Train Epoch: 7 [1088/23491 (5%)]\tLoss: 0.038746\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:25 | INFO | Rank 0 | Train Epoch: 7 [1120/23491 (5%)]\tLoss: 0.205121\tData (t) 0.054\tBatch (t) 0.269\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:26 | INFO | Rank 0 | Train Epoch: 7 [1152/23491 (5%)]\tLoss: 0.388161\tData (t) 0.055\tBatch (t) 0.270\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:26 | INFO | Rank 0 | Train Epoch: 7 [1184/23491 (5%)]\tLoss: 0.179865\tData (t) 0.055\tBatch (t) 0.269\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:26 | INFO | Rank 0 | Train Epoch: 7 [1216/23491 (5%)]\tLoss: 0.069799\tData (t) 0.055\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:26 | INFO | Rank 0 | Train Epoch: 7 [1248/23491 (5%)]\tLoss: 0.159317\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:27 | INFO | Rank 0 | Train Epoch: 7 [1280/23491 (5%)]\tLoss: 0.175686\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:27 | INFO | Rank 0 | Train Epoch: 7 [1312/23491 (6%)]\tLoss: 0.113452\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:27 | INFO | Rank 0 | Train Epoch: 7 [1344/23491 (6%)]\tLoss: 0.086071\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:27 | INFO | Rank 0 | Train Epoch: 7 [1376/23491 (6%)]\tLoss: 0.172083\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:28 | INFO | Rank 0 | Train Epoch: 7 [1408/23491 (6%)]\tLoss: 0.195322\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:28 | INFO | Rank 0 | Train Epoch: 7 [1440/23491 (6%)]\tLoss: 0.092993\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:28 | INFO | Rank 0 | Train Epoch: 7 [1472/23491 (6%)]\tLoss: 0.070374\tData (t) 0.056\tBatch (t) 0.268\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:29 | INFO | Rank 0 | Train Epoch: 7 [1504/23491 (6%)]\tLoss: 0.032898\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:29 | INFO | Rank 0 | Train Epoch: 7 [1536/23491 (7%)]\tLoss: 0.154544\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:29 | INFO | Rank 0 | Train Epoch: 7 [1568/23491 (7%)]\tLoss: 0.116207\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:29 | INFO | Rank 0 | Train Epoch: 7 [1600/23491 (7%)]\tLoss: 0.155581\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:30 | INFO | Rank 0 | Train Epoch: 7 [1632/23491 (7%)]\tLoss: 0.190931\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:30 | INFO | Rank 0 | Train Epoch: 7 [1664/23491 (7%)]\tLoss: 0.075531\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:30 | INFO | Rank 0 | Train Epoch: 7 [1696/23491 (7%)]\tLoss: 0.012421\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:30 | INFO | Rank 0 | Train Epoch: 7 [1728/23491 (7%)]\tLoss: 0.104729\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:31 | INFO | Rank 0 | Train Epoch: 7 [1760/23491 (7%)]\tLoss: 0.070763\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:31 | INFO | Rank 0 | Train Epoch: 7 [1792/23491 (8%)]\tLoss: 0.036682\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:31 | INFO | Rank 0 | Train Epoch: 7 [1824/23491 (8%)]\tLoss: 0.127087\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:31 | INFO | Rank 0 | Train Epoch: 7 [1856/23491 (8%)]\tLoss: 0.125849\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:32 | INFO | Rank 0 | Train Epoch: 7 [1888/23491 (8%)]\tLoss: 0.117580\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:32 | INFO | Rank 0 | Train Epoch: 7 [1920/23491 (8%)]\tLoss: 0.062350\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:32 | INFO | Rank 0 | Train Epoch: 7 [1952/23491 (8%)]\tLoss: 0.172217\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:33 | INFO | Rank 0 | Train Epoch: 7 [1984/23491 (8%)]\tLoss: 0.179913\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:33 | INFO | Rank 0 | Train Epoch: 7 [2016/23491 (9%)]\tLoss: 0.163138\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:33 | INFO | Rank 0 | Train Epoch: 7 [2048/23491 (9%)]\tLoss: 0.126216\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:33 | INFO | Rank 0 | Train Epoch: 7 [2080/23491 (9%)]\tLoss: 0.026166\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:34 | INFO | Rank 0 | Train Epoch: 7 [2112/23491 (9%)]\tLoss: 0.048201\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:34 | INFO | Rank 0 | Train Epoch: 7 [2144/23491 (9%)]\tLoss: 0.005136\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:34 | INFO | Rank 0 | Train Epoch: 7 [2176/23491 (9%)]\tLoss: 0.169562\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:34 | INFO | Rank 0 | Train Epoch: 7 [2208/23491 (9%)]\tLoss: 0.157347\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:35 | INFO | Rank 0 | Train Epoch: 7 [2240/23491 (10%)]\tLoss: 0.237255\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:35 | INFO | Rank 0 | Train Epoch: 7 [2272/23491 (10%)]\tLoss: 0.057481\tData (t) 0.054\tBatch (t) 0.269\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:35 | INFO | Rank 0 | Train Epoch: 7 [2304/23491 (10%)]\tLoss: 0.131473\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:35 | INFO | Rank 0 | Train Epoch: 7 [2336/23491 (10%)]\tLoss: 0.069143\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:36 | INFO | Rank 0 | Train Epoch: 7 [2368/23491 (10%)]\tLoss: 0.019391\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:36 | INFO | Rank 0 | Train Epoch: 7 [2400/23491 (10%)]\tLoss: 0.088282\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:36 | INFO | Rank 0 | Train Epoch: 7 [2432/23491 (10%)]\tLoss: 0.034322\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:37 | INFO | Rank 0 | Train Epoch: 7 [2464/23491 (10%)]\tLoss: 0.071927\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:37 | INFO | Rank 0 | Train Epoch: 7 [2496/23491 (11%)]\tLoss: 0.088261\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:37 | INFO | Rank 0 | Train Epoch: 7 [2528/23491 (11%)]\tLoss: 0.080652\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:37 | INFO | Rank 0 | Train Epoch: 7 [2560/23491 (11%)]\tLoss: 0.055890\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:38 | INFO | Rank 0 | Train Epoch: 7 [2592/23491 (11%)]\tLoss: 0.030829\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:38 | INFO | Rank 0 | Train Epoch: 7 [2624/23491 (11%)]\tLoss: 0.202452\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000018\tlogit_scale 4.540\n",
      "2022-11-08,05:52:38 | INFO | Rank 0 | Train Epoch: 7 [2656/23491 (11%)]\tLoss: 0.116194\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:38 | INFO | Rank 0 | Train Epoch: 7 [2688/23491 (11%)]\tLoss: 0.200460\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:39 | INFO | Rank 0 | Train Epoch: 7 [2720/23491 (12%)]\tLoss: 0.021586\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:39 | INFO | Rank 0 | Train Epoch: 7 [2752/23491 (12%)]\tLoss: 0.122630\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:39 | INFO | Rank 0 | Train Epoch: 7 [2784/23491 (12%)]\tLoss: 0.106764\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:39 | INFO | Rank 0 | Train Epoch: 7 [2816/23491 (12%)]\tLoss: 0.068009\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:40 | INFO | Rank 0 | Train Epoch: 7 [2848/23491 (12%)]\tLoss: 0.328008\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:40 | INFO | Rank 0 | Train Epoch: 7 [2880/23491 (12%)]\tLoss: 0.102244\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:40 | INFO | Rank 0 | Train Epoch: 7 [2912/23491 (12%)]\tLoss: 0.155101\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:41 | INFO | Rank 0 | Train Epoch: 7 [2944/23491 (13%)]\tLoss: 0.049784\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:41 | INFO | Rank 0 | Train Epoch: 7 [2976/23491 (13%)]\tLoss: 0.172839\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:41 | INFO | Rank 0 | Train Epoch: 7 [3008/23491 (13%)]\tLoss: 0.087204\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:41 | INFO | Rank 0 | Train Epoch: 7 [3040/23491 (13%)]\tLoss: 0.085798\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:42 | INFO | Rank 0 | Train Epoch: 7 [3072/23491 (13%)]\tLoss: 0.056106\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:42 | INFO | Rank 0 | Train Epoch: 7 [3104/23491 (13%)]\tLoss: 0.097756\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:42 | INFO | Rank 0 | Train Epoch: 7 [3136/23491 (13%)]\tLoss: 0.050928\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:42 | INFO | Rank 0 | Train Epoch: 7 [3168/23491 (13%)]\tLoss: 0.164192\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:43 | INFO | Rank 0 | Train Epoch: 7 [3200/23491 (14%)]\tLoss: 0.150843\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:43 | INFO | Rank 0 | Train Epoch: 7 [3232/23491 (14%)]\tLoss: 0.102040\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:43 | INFO | Rank 0 | Train Epoch: 7 [3264/23491 (14%)]\tLoss: 0.119661\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:43 | INFO | Rank 0 | Train Epoch: 7 [3296/23491 (14%)]\tLoss: 0.060750\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.540\n",
      "2022-11-08,05:52:44 | INFO | Rank 0 | Train Epoch: 7 [3328/23491 (14%)]\tLoss: 0.140526\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:44 | INFO | Rank 0 | Train Epoch: 7 [3360/23491 (14%)]\tLoss: 0.071792\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:44 | INFO | Rank 0 | Train Epoch: 7 [3392/23491 (14%)]\tLoss: 0.052400\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:45 | INFO | Rank 0 | Train Epoch: 7 [3424/23491 (15%)]\tLoss: 0.071618\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:45 | INFO | Rank 0 | Train Epoch: 7 [3456/23491 (15%)]\tLoss: 0.243436\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:45 | INFO | Rank 0 | Train Epoch: 7 [3488/23491 (15%)]\tLoss: 0.077800\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:45 | INFO | Rank 0 | Train Epoch: 7 [3520/23491 (15%)]\tLoss: 0.190656\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:46 | INFO | Rank 0 | Train Epoch: 7 [3552/23491 (15%)]\tLoss: 0.207490\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:46 | INFO | Rank 0 | Train Epoch: 7 [3584/23491 (15%)]\tLoss: 0.143787\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:46 | INFO | Rank 0 | Train Epoch: 7 [3616/23491 (15%)]\tLoss: 0.053012\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:46 | INFO | Rank 0 | Train Epoch: 7 [3648/23491 (16%)]\tLoss: 0.235848\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:47 | INFO | Rank 0 | Train Epoch: 7 [3680/23491 (16%)]\tLoss: 0.046507\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:47 | INFO | Rank 0 | Train Epoch: 7 [3712/23491 (16%)]\tLoss: 0.079118\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:47 | INFO | Rank 0 | Train Epoch: 7 [3744/23491 (16%)]\tLoss: 0.046100\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:47 | INFO | Rank 0 | Train Epoch: 7 [3776/23491 (16%)]\tLoss: 0.060045\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:48 | INFO | Rank 0 | Train Epoch: 7 [3808/23491 (16%)]\tLoss: 0.049406\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:48 | INFO | Rank 0 | Train Epoch: 7 [3840/23491 (16%)]\tLoss: 0.126423\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:48 | INFO | Rank 0 | Train Epoch: 7 [3872/23491 (16%)]\tLoss: 0.026616\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:49 | INFO | Rank 0 | Train Epoch: 7 [3904/23491 (17%)]\tLoss: 0.014700\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:49 | INFO | Rank 0 | Train Epoch: 7 [3936/23491 (17%)]\tLoss: 0.046292\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:49 | INFO | Rank 0 | Train Epoch: 7 [3968/23491 (17%)]\tLoss: 0.128929\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:49 | INFO | Rank 0 | Train Epoch: 7 [4000/23491 (17%)]\tLoss: 0.094961\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:50 | INFO | Rank 0 | Train Epoch: 7 [4032/23491 (17%)]\tLoss: 0.069079\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:50 | INFO | Rank 0 | Train Epoch: 7 [4064/23491 (17%)]\tLoss: 0.148230\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:50 | INFO | Rank 0 | Train Epoch: 7 [4096/23491 (17%)]\tLoss: 0.124628\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:50 | INFO | Rank 0 | Train Epoch: 7 [4128/23491 (18%)]\tLoss: 0.033744\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:51 | INFO | Rank 0 | Train Epoch: 7 [4160/23491 (18%)]\tLoss: 0.021150\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:51 | INFO | Rank 0 | Train Epoch: 7 [4192/23491 (18%)]\tLoss: 0.030201\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:51 | INFO | Rank 0 | Train Epoch: 7 [4224/23491 (18%)]\tLoss: 0.033892\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:51 | INFO | Rank 0 | Train Epoch: 7 [4256/23491 (18%)]\tLoss: 0.046276\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:52 | INFO | Rank 0 | Train Epoch: 7 [4288/23491 (18%)]\tLoss: 0.224802\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:52 | INFO | Rank 0 | Train Epoch: 7 [4320/23491 (18%)]\tLoss: 0.105218\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:52 | INFO | Rank 0 | Train Epoch: 7 [4352/23491 (19%)]\tLoss: 0.076387\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:53 | INFO | Rank 0 | Train Epoch: 7 [4384/23491 (19%)]\tLoss: 0.036053\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:53 | INFO | Rank 0 | Train Epoch: 7 [4416/23491 (19%)]\tLoss: 0.054781\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:53 | INFO | Rank 0 | Train Epoch: 7 [4448/23491 (19%)]\tLoss: 0.154600\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:53 | INFO | Rank 0 | Train Epoch: 7 [4480/23491 (19%)]\tLoss: 0.057573\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:54 | INFO | Rank 0 | Train Epoch: 7 [4512/23491 (19%)]\tLoss: 0.098041\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:54 | INFO | Rank 0 | Train Epoch: 7 [4544/23491 (19%)]\tLoss: 0.174119\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:54 | INFO | Rank 0 | Train Epoch: 7 [4576/23491 (19%)]\tLoss: 0.037823\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:54 | INFO | Rank 0 | Train Epoch: 7 [4608/23491 (20%)]\tLoss: 0.192523\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:55 | INFO | Rank 0 | Train Epoch: 7 [4640/23491 (20%)]\tLoss: 0.175655\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:55 | INFO | Rank 0 | Train Epoch: 7 [4672/23491 (20%)]\tLoss: 0.082347\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:55 | INFO | Rank 0 | Train Epoch: 7 [4704/23491 (20%)]\tLoss: 0.109911\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:55 | INFO | Rank 0 | Train Epoch: 7 [4736/23491 (20%)]\tLoss: 0.018953\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:56 | INFO | Rank 0 | Train Epoch: 7 [4768/23491 (20%)]\tLoss: 0.173777\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000017\tlogit_scale 4.541\n",
      "2022-11-08,05:52:56 | INFO | Rank 0 | Train Epoch: 7 [4800/23491 (20%)]\tLoss: 0.090005\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:52:56 | INFO | Rank 0 | Train Epoch: 7 [4832/23491 (21%)]\tLoss: 0.048534\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:52:57 | INFO | Rank 0 | Train Epoch: 7 [4864/23491 (21%)]\tLoss: 0.053755\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:52:57 | INFO | Rank 0 | Train Epoch: 7 [4896/23491 (21%)]\tLoss: 0.100617\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:52:57 | INFO | Rank 0 | Train Epoch: 7 [4928/23491 (21%)]\tLoss: 0.001996\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:52:57 | INFO | Rank 0 | Train Epoch: 7 [4960/23491 (21%)]\tLoss: 0.096358\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:52:58 | INFO | Rank 0 | Train Epoch: 7 [4992/23491 (21%)]\tLoss: 0.307111\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:52:58 | INFO | Rank 0 | Train Epoch: 7 [5024/23491 (21%)]\tLoss: 0.057611\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:52:58 | INFO | Rank 0 | Train Epoch: 7 [5056/23491 (22%)]\tLoss: 0.047080\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:52:58 | INFO | Rank 0 | Train Epoch: 7 [5088/23491 (22%)]\tLoss: 0.127684\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:52:59 | INFO | Rank 0 | Train Epoch: 7 [5120/23491 (22%)]\tLoss: 0.086845\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:52:59 | INFO | Rank 0 | Train Epoch: 7 [5152/23491 (22%)]\tLoss: 0.160762\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:52:59 | INFO | Rank 0 | Train Epoch: 7 [5184/23491 (22%)]\tLoss: 0.079405\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:52:59 | INFO | Rank 0 | Train Epoch: 7 [5216/23491 (22%)]\tLoss: 0.057198\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:00 | INFO | Rank 0 | Train Epoch: 7 [5248/23491 (22%)]\tLoss: 0.059048\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:00 | INFO | Rank 0 | Train Epoch: 7 [5280/23491 (22%)]\tLoss: 0.042749\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:00 | INFO | Rank 0 | Train Epoch: 7 [5312/23491 (23%)]\tLoss: 0.069538\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:01 | INFO | Rank 0 | Train Epoch: 7 [5344/23491 (23%)]\tLoss: 0.183306\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:01 | INFO | Rank 0 | Train Epoch: 7 [5376/23491 (23%)]\tLoss: 0.383930\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:01 | INFO | Rank 0 | Train Epoch: 7 [5408/23491 (23%)]\tLoss: 0.054713\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:01 | INFO | Rank 0 | Train Epoch: 7 [5440/23491 (23%)]\tLoss: 0.240155\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:02 | INFO | Rank 0 | Train Epoch: 7 [5472/23491 (23%)]\tLoss: 0.066360\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:02 | INFO | Rank 0 | Train Epoch: 7 [5504/23491 (23%)]\tLoss: 0.103358\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:02 | INFO | Rank 0 | Train Epoch: 7 [5536/23491 (24%)]\tLoss: 0.116758\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:02 | INFO | Rank 0 | Train Epoch: 7 [5568/23491 (24%)]\tLoss: 0.062728\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:03 | INFO | Rank 0 | Train Epoch: 7 [5600/23491 (24%)]\tLoss: 0.167658\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:03 | INFO | Rank 0 | Train Epoch: 7 [5632/23491 (24%)]\tLoss: 0.009544\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:03 | INFO | Rank 0 | Train Epoch: 7 [5664/23491 (24%)]\tLoss: 0.065093\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:03 | INFO | Rank 0 | Train Epoch: 7 [5696/23491 (24%)]\tLoss: 0.089732\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:04 | INFO | Rank 0 | Train Epoch: 7 [5728/23491 (24%)]\tLoss: 0.190545\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:04 | INFO | Rank 0 | Train Epoch: 7 [5760/23491 (25%)]\tLoss: 0.172272\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:04 | INFO | Rank 0 | Train Epoch: 7 [5792/23491 (25%)]\tLoss: 0.160607\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:05 | INFO | Rank 0 | Train Epoch: 7 [5824/23491 (25%)]\tLoss: 0.054002\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:05 | INFO | Rank 0 | Train Epoch: 7 [5856/23491 (25%)]\tLoss: 0.025112\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:05 | INFO | Rank 0 | Train Epoch: 7 [5888/23491 (25%)]\tLoss: 0.087662\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:05 | INFO | Rank 0 | Train Epoch: 7 [5920/23491 (25%)]\tLoss: 0.060835\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:06 | INFO | Rank 0 | Train Epoch: 7 [5952/23491 (25%)]\tLoss: 0.177446\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:06 | INFO | Rank 0 | Train Epoch: 7 [5984/23491 (25%)]\tLoss: 0.105716\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:06 | INFO | Rank 0 | Train Epoch: 7 [6016/23491 (26%)]\tLoss: 0.132276\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:06 | INFO | Rank 0 | Train Epoch: 7 [6048/23491 (26%)]\tLoss: 0.099950\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:07 | INFO | Rank 0 | Train Epoch: 7 [6080/23491 (26%)]\tLoss: 0.195923\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:07 | INFO | Rank 0 | Train Epoch: 7 [6112/23491 (26%)]\tLoss: 0.070952\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:07 | INFO | Rank 0 | Train Epoch: 7 [6144/23491 (26%)]\tLoss: 0.049549\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:07 | INFO | Rank 0 | Train Epoch: 7 [6176/23491 (26%)]\tLoss: 0.038976\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:08 | INFO | Rank 0 | Train Epoch: 7 [6208/23491 (26%)]\tLoss: 0.088822\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:08 | INFO | Rank 0 | Train Epoch: 7 [6240/23491 (27%)]\tLoss: 0.073850\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:08 | INFO | Rank 0 | Train Epoch: 7 [6272/23491 (27%)]\tLoss: 0.057038\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:09 | INFO | Rank 0 | Train Epoch: 7 [6304/23491 (27%)]\tLoss: 0.086318\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:09 | INFO | Rank 0 | Train Epoch: 7 [6336/23491 (27%)]\tLoss: 0.066539\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:09 | INFO | Rank 0 | Train Epoch: 7 [6368/23491 (27%)]\tLoss: 0.170902\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:09 | INFO | Rank 0 | Train Epoch: 7 [6400/23491 (27%)]\tLoss: 0.009843\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:10 | INFO | Rank 0 | Train Epoch: 7 [6432/23491 (27%)]\tLoss: 0.144558\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:10 | INFO | Rank 0 | Train Epoch: 7 [6464/23491 (28%)]\tLoss: 0.170971\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:10 | INFO | Rank 0 | Train Epoch: 7 [6496/23491 (28%)]\tLoss: 0.105454\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:10 | INFO | Rank 0 | Train Epoch: 7 [6528/23491 (28%)]\tLoss: 0.025587\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:11 | INFO | Rank 0 | Train Epoch: 7 [6560/23491 (28%)]\tLoss: 0.166790\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:11 | INFO | Rank 0 | Train Epoch: 7 [6592/23491 (28%)]\tLoss: 0.069600\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:11 | INFO | Rank 0 | Train Epoch: 7 [6624/23491 (28%)]\tLoss: 0.014813\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:11 | INFO | Rank 0 | Train Epoch: 7 [6656/23491 (28%)]\tLoss: 0.069626\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:12 | INFO | Rank 0 | Train Epoch: 7 [6688/23491 (28%)]\tLoss: 0.181634\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:12 | INFO | Rank 0 | Train Epoch: 7 [6720/23491 (29%)]\tLoss: 0.198727\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:12 | INFO | Rank 0 | Train Epoch: 7 [6752/23491 (29%)]\tLoss: 0.058189\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:13 | INFO | Rank 0 | Train Epoch: 7 [6784/23491 (29%)]\tLoss: 0.029055\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:13 | INFO | Rank 0 | Train Epoch: 7 [6816/23491 (29%)]\tLoss: 0.021751\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:13 | INFO | Rank 0 | Train Epoch: 7 [6848/23491 (29%)]\tLoss: 0.127973\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:13 | INFO | Rank 0 | Train Epoch: 7 [6880/23491 (29%)]\tLoss: 0.162343\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:14 | INFO | Rank 0 | Train Epoch: 7 [6912/23491 (29%)]\tLoss: 0.110019\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:14 | INFO | Rank 0 | Train Epoch: 7 [6944/23491 (30%)]\tLoss: 0.197673\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000016\tlogit_scale 4.541\n",
      "2022-11-08,05:53:14 | INFO | Rank 0 | Train Epoch: 7 [6976/23491 (30%)]\tLoss: 0.029344\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:14 | INFO | Rank 0 | Train Epoch: 7 [7008/23491 (30%)]\tLoss: 0.316104\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:15 | INFO | Rank 0 | Train Epoch: 7 [7040/23491 (30%)]\tLoss: 0.187784\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:15 | INFO | Rank 0 | Train Epoch: 7 [7072/23491 (30%)]\tLoss: 0.052523\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:15 | INFO | Rank 0 | Train Epoch: 7 [7104/23491 (30%)]\tLoss: 0.144667\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:15 | INFO | Rank 0 | Train Epoch: 7 [7136/23491 (30%)]\tLoss: 0.083817\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:16 | INFO | Rank 0 | Train Epoch: 7 [7168/23491 (31%)]\tLoss: 0.298375\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:16 | INFO | Rank 0 | Train Epoch: 7 [7200/23491 (31%)]\tLoss: 0.269755\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:16 | INFO | Rank 0 | Train Epoch: 7 [7232/23491 (31%)]\tLoss: 0.103679\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:17 | INFO | Rank 0 | Train Epoch: 7 [7264/23491 (31%)]\tLoss: 0.022872\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:17 | INFO | Rank 0 | Train Epoch: 7 [7296/23491 (31%)]\tLoss: 0.155071\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:17 | INFO | Rank 0 | Train Epoch: 7 [7328/23491 (31%)]\tLoss: 0.282358\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:17 | INFO | Rank 0 | Train Epoch: 7 [7360/23491 (31%)]\tLoss: 0.115406\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:18 | INFO | Rank 0 | Train Epoch: 7 [7392/23491 (31%)]\tLoss: 0.175212\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:18 | INFO | Rank 0 | Train Epoch: 7 [7424/23491 (32%)]\tLoss: 0.057724\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:18 | INFO | Rank 0 | Train Epoch: 7 [7456/23491 (32%)]\tLoss: 0.105118\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:18 | INFO | Rank 0 | Train Epoch: 7 [7488/23491 (32%)]\tLoss: 0.215867\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:19 | INFO | Rank 0 | Train Epoch: 7 [7520/23491 (32%)]\tLoss: 0.123916\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:19 | INFO | Rank 0 | Train Epoch: 7 [7552/23491 (32%)]\tLoss: 0.131824\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:19 | INFO | Rank 0 | Train Epoch: 7 [7584/23491 (32%)]\tLoss: 0.082723\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:19 | INFO | Rank 0 | Train Epoch: 7 [7616/23491 (32%)]\tLoss: 0.314332\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:20 | INFO | Rank 0 | Train Epoch: 7 [7648/23491 (33%)]\tLoss: 0.115796\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:20 | INFO | Rank 0 | Train Epoch: 7 [7680/23491 (33%)]\tLoss: 0.277140\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:20 | INFO | Rank 0 | Train Epoch: 7 [7712/23491 (33%)]\tLoss: 0.042956\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:21 | INFO | Rank 0 | Train Epoch: 7 [7744/23491 (33%)]\tLoss: 0.117443\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:21 | INFO | Rank 0 | Train Epoch: 7 [7776/23491 (33%)]\tLoss: 0.114377\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:21 | INFO | Rank 0 | Train Epoch: 7 [7808/23491 (33%)]\tLoss: 0.083010\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:21 | INFO | Rank 0 | Train Epoch: 7 [7840/23491 (33%)]\tLoss: 0.321825\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:22 | INFO | Rank 0 | Train Epoch: 7 [7872/23491 (34%)]\tLoss: 0.039201\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:22 | INFO | Rank 0 | Train Epoch: 7 [7904/23491 (34%)]\tLoss: 0.084617\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:22 | INFO | Rank 0 | Train Epoch: 7 [7936/23491 (34%)]\tLoss: 0.029730\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:22 | INFO | Rank 0 | Train Epoch: 7 [7968/23491 (34%)]\tLoss: 0.093806\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:23 | INFO | Rank 0 | Train Epoch: 7 [8000/23491 (34%)]\tLoss: 0.065896\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:23 | INFO | Rank 0 | Train Epoch: 7 [8032/23491 (34%)]\tLoss: 0.099124\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:23 | INFO | Rank 0 | Train Epoch: 7 [8064/23491 (34%)]\tLoss: 0.087987\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:23 | INFO | Rank 0 | Train Epoch: 7 [8096/23491 (34%)]\tLoss: 0.148185\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:24 | INFO | Rank 0 | Train Epoch: 7 [8128/23491 (35%)]\tLoss: 0.349496\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:24 | INFO | Rank 0 | Train Epoch: 7 [8160/23491 (35%)]\tLoss: 0.028644\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:24 | INFO | Rank 0 | Train Epoch: 7 [8192/23491 (35%)]\tLoss: 0.026058\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:24 | INFO | Rank 0 | Train Epoch: 7 [8224/23491 (35%)]\tLoss: 0.177367\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:25 | INFO | Rank 0 | Train Epoch: 7 [8256/23491 (35%)]\tLoss: 0.036318\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:25 | INFO | Rank 0 | Train Epoch: 7 [8288/23491 (35%)]\tLoss: 0.061634\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:25 | INFO | Rank 0 | Train Epoch: 7 [8320/23491 (35%)]\tLoss: 0.036179\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:26 | INFO | Rank 0 | Train Epoch: 7 [8352/23491 (36%)]\tLoss: 0.297767\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:26 | INFO | Rank 0 | Train Epoch: 7 [8384/23491 (36%)]\tLoss: 0.098732\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:26 | INFO | Rank 0 | Train Epoch: 7 [8416/23491 (36%)]\tLoss: 0.088133\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:26 | INFO | Rank 0 | Train Epoch: 7 [8448/23491 (36%)]\tLoss: 0.031861\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:27 | INFO | Rank 0 | Train Epoch: 7 [8480/23491 (36%)]\tLoss: 0.176693\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:27 | INFO | Rank 0 | Train Epoch: 7 [8512/23491 (36%)]\tLoss: 0.127306\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:27 | INFO | Rank 0 | Train Epoch: 7 [8544/23491 (36%)]\tLoss: 0.087624\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:27 | INFO | Rank 0 | Train Epoch: 7 [8576/23491 (37%)]\tLoss: 0.109384\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:28 | INFO | Rank 0 | Train Epoch: 7 [8608/23491 (37%)]\tLoss: 0.068348\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:28 | INFO | Rank 0 | Train Epoch: 7 [8640/23491 (37%)]\tLoss: 0.122672\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:28 | INFO | Rank 0 | Train Epoch: 7 [8672/23491 (37%)]\tLoss: 0.040090\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:28 | INFO | Rank 0 | Train Epoch: 7 [8704/23491 (37%)]\tLoss: 0.013004\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:29 | INFO | Rank 0 | Train Epoch: 7 [8736/23491 (37%)]\tLoss: 0.081396\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:29 | INFO | Rank 0 | Train Epoch: 7 [8768/23491 (37%)]\tLoss: 0.272377\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:29 | INFO | Rank 0 | Train Epoch: 7 [8800/23491 (37%)]\tLoss: 0.085699\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:30 | INFO | Rank 0 | Train Epoch: 7 [8832/23491 (38%)]\tLoss: 0.165849\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:30 | INFO | Rank 0 | Train Epoch: 7 [8864/23491 (38%)]\tLoss: 0.082461\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:30 | INFO | Rank 0 | Train Epoch: 7 [8896/23491 (38%)]\tLoss: 0.065520\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:30 | INFO | Rank 0 | Train Epoch: 7 [8928/23491 (38%)]\tLoss: 0.209331\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:31 | INFO | Rank 0 | Train Epoch: 7 [8960/23491 (38%)]\tLoss: 0.108024\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:31 | INFO | Rank 0 | Train Epoch: 7 [8992/23491 (38%)]\tLoss: 0.009887\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:31 | INFO | Rank 0 | Train Epoch: 7 [9024/23491 (38%)]\tLoss: 0.086417\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:31 | INFO | Rank 0 | Train Epoch: 7 [9056/23491 (39%)]\tLoss: 0.125652\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:32 | INFO | Rank 0 | Train Epoch: 7 [9088/23491 (39%)]\tLoss: 0.146248\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:32 | INFO | Rank 0 | Train Epoch: 7 [9120/23491 (39%)]\tLoss: 0.073640\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:32 | INFO | Rank 0 | Train Epoch: 7 [9152/23491 (39%)]\tLoss: 0.222055\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:32 | INFO | Rank 0 | Train Epoch: 7 [9184/23491 (39%)]\tLoss: 0.035642\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000015\tlogit_scale 4.541\n",
      "2022-11-08,05:53:33 | INFO | Rank 0 | Train Epoch: 7 [9216/23491 (39%)]\tLoss: 0.145605\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:33 | INFO | Rank 0 | Train Epoch: 7 [9248/23491 (39%)]\tLoss: 0.065316\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:33 | INFO | Rank 0 | Train Epoch: 7 [9280/23491 (40%)]\tLoss: 0.064733\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:34 | INFO | Rank 0 | Train Epoch: 7 [9312/23491 (40%)]\tLoss: 0.084308\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:34 | INFO | Rank 0 | Train Epoch: 7 [9344/23491 (40%)]\tLoss: 0.039723\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:34 | INFO | Rank 0 | Train Epoch: 7 [9376/23491 (40%)]\tLoss: 0.200536\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:34 | INFO | Rank 0 | Train Epoch: 7 [9408/23491 (40%)]\tLoss: 0.173928\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:35 | INFO | Rank 0 | Train Epoch: 7 [9440/23491 (40%)]\tLoss: 0.035782\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:35 | INFO | Rank 0 | Train Epoch: 7 [9472/23491 (40%)]\tLoss: 0.154313\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:35 | INFO | Rank 0 | Train Epoch: 7 [9504/23491 (40%)]\tLoss: 0.043439\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:35 | INFO | Rank 0 | Train Epoch: 7 [9536/23491 (41%)]\tLoss: 0.055358\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:36 | INFO | Rank 0 | Train Epoch: 7 [9568/23491 (41%)]\tLoss: 0.133639\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:36 | INFO | Rank 0 | Train Epoch: 7 [9600/23491 (41%)]\tLoss: 0.080260\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:36 | INFO | Rank 0 | Train Epoch: 7 [9632/23491 (41%)]\tLoss: 0.120970\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:36 | INFO | Rank 0 | Train Epoch: 7 [9664/23491 (41%)]\tLoss: 0.066999\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:37 | INFO | Rank 0 | Train Epoch: 7 [9696/23491 (41%)]\tLoss: 0.144724\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:37 | INFO | Rank 0 | Train Epoch: 7 [9728/23491 (41%)]\tLoss: 0.031955\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:37 | INFO | Rank 0 | Train Epoch: 7 [9760/23491 (42%)]\tLoss: 0.260301\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:38 | INFO | Rank 0 | Train Epoch: 7 [9792/23491 (42%)]\tLoss: 0.177078\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:38 | INFO | Rank 0 | Train Epoch: 7 [9824/23491 (42%)]\tLoss: 0.048354\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:38 | INFO | Rank 0 | Train Epoch: 7 [9856/23491 (42%)]\tLoss: 0.089726\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:38 | INFO | Rank 0 | Train Epoch: 7 [9888/23491 (42%)]\tLoss: 0.114958\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:39 | INFO | Rank 0 | Train Epoch: 7 [9920/23491 (42%)]\tLoss: 0.011644\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:39 | INFO | Rank 0 | Train Epoch: 7 [9952/23491 (42%)]\tLoss: 0.102238\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:39 | INFO | Rank 0 | Train Epoch: 7 [9984/23491 (43%)]\tLoss: 0.244813\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:39 | INFO | Rank 0 | Train Epoch: 7 [10016/23491 (43%)]\tLoss: 0.020507\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:40 | INFO | Rank 0 | Train Epoch: 7 [10048/23491 (43%)]\tLoss: 0.206111\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:40 | INFO | Rank 0 | Train Epoch: 7 [10080/23491 (43%)]\tLoss: 0.056706\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:40 | INFO | Rank 0 | Train Epoch: 7 [10112/23491 (43%)]\tLoss: 0.094345\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:40 | INFO | Rank 0 | Train Epoch: 7 [10144/23491 (43%)]\tLoss: 0.034876\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:41 | INFO | Rank 0 | Train Epoch: 7 [10176/23491 (43%)]\tLoss: 0.010870\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:41 | INFO | Rank 0 | Train Epoch: 7 [10208/23491 (43%)]\tLoss: 0.136038\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:41 | INFO | Rank 0 | Train Epoch: 7 [10240/23491 (44%)]\tLoss: 0.178119\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:42 | INFO | Rank 0 | Train Epoch: 7 [10272/23491 (44%)]\tLoss: 0.012941\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:42 | INFO | Rank 0 | Train Epoch: 7 [10304/23491 (44%)]\tLoss: 0.075449\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:42 | INFO | Rank 0 | Train Epoch: 7 [10336/23491 (44%)]\tLoss: 0.218537\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:42 | INFO | Rank 0 | Train Epoch: 7 [10368/23491 (44%)]\tLoss: 0.100983\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:43 | INFO | Rank 0 | Train Epoch: 7 [10400/23491 (44%)]\tLoss: 0.150489\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:43 | INFO | Rank 0 | Train Epoch: 7 [10432/23491 (44%)]\tLoss: 0.217089\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:43 | INFO | Rank 0 | Train Epoch: 7 [10464/23491 (45%)]\tLoss: 0.192003\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:43 | INFO | Rank 0 | Train Epoch: 7 [10496/23491 (45%)]\tLoss: 0.037238\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:44 | INFO | Rank 0 | Train Epoch: 7 [10528/23491 (45%)]\tLoss: 0.147715\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:44 | INFO | Rank 0 | Train Epoch: 7 [10560/23491 (45%)]\tLoss: 0.009774\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:44 | INFO | Rank 0 | Train Epoch: 7 [10592/23491 (45%)]\tLoss: 0.125448\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:44 | INFO | Rank 0 | Train Epoch: 7 [10624/23491 (45%)]\tLoss: 0.182416\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:45 | INFO | Rank 0 | Train Epoch: 7 [10656/23491 (45%)]\tLoss: 0.060590\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:45 | INFO | Rank 0 | Train Epoch: 7 [10688/23491 (46%)]\tLoss: 0.159204\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:45 | INFO | Rank 0 | Train Epoch: 7 [10720/23491 (46%)]\tLoss: 0.155328\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:46 | INFO | Rank 0 | Train Epoch: 7 [10752/23491 (46%)]\tLoss: 0.086677\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:46 | INFO | Rank 0 | Train Epoch: 7 [10784/23491 (46%)]\tLoss: 0.114322\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:46 | INFO | Rank 0 | Train Epoch: 7 [10816/23491 (46%)]\tLoss: 0.047815\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:46 | INFO | Rank 0 | Train Epoch: 7 [10848/23491 (46%)]\tLoss: 0.200934\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:47 | INFO | Rank 0 | Train Epoch: 7 [10880/23491 (46%)]\tLoss: 0.144167\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:47 | INFO | Rank 0 | Train Epoch: 7 [10912/23491 (46%)]\tLoss: 0.082777\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:47 | INFO | Rank 0 | Train Epoch: 7 [10944/23491 (47%)]\tLoss: 0.412694\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:47 | INFO | Rank 0 | Train Epoch: 7 [10976/23491 (47%)]\tLoss: 0.054851\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:48 | INFO | Rank 0 | Train Epoch: 7 [11008/23491 (47%)]\tLoss: 0.030072\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:48 | INFO | Rank 0 | Train Epoch: 7 [11040/23491 (47%)]\tLoss: 0.110758\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:48 | INFO | Rank 0 | Train Epoch: 7 [11072/23491 (47%)]\tLoss: 0.064793\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:48 | INFO | Rank 0 | Train Epoch: 7 [11104/23491 (47%)]\tLoss: 0.069944\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:49 | INFO | Rank 0 | Train Epoch: 7 [11136/23491 (47%)]\tLoss: 0.078254\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:49 | INFO | Rank 0 | Train Epoch: 7 [11168/23491 (48%)]\tLoss: 0.042729\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:49 | INFO | Rank 0 | Train Epoch: 7 [11200/23491 (48%)]\tLoss: 0.126741\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:50 | INFO | Rank 0 | Train Epoch: 7 [11232/23491 (48%)]\tLoss: 0.019117\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:50 | INFO | Rank 0 | Train Epoch: 7 [11264/23491 (48%)]\tLoss: 0.106153\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:50 | INFO | Rank 0 | Train Epoch: 7 [11296/23491 (48%)]\tLoss: 0.094578\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:50 | INFO | Rank 0 | Train Epoch: 7 [11328/23491 (48%)]\tLoss: 0.092384\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:51 | INFO | Rank 0 | Train Epoch: 7 [11360/23491 (48%)]\tLoss: 0.058082\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:51 | INFO | Rank 0 | Train Epoch: 7 [11392/23491 (49%)]\tLoss: 0.061967\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:51 | INFO | Rank 0 | Train Epoch: 7 [11424/23491 (49%)]\tLoss: 0.007692\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:51 | INFO | Rank 0 | Train Epoch: 7 [11456/23491 (49%)]\tLoss: 0.067654\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000014\tlogit_scale 4.541\n",
      "2022-11-08,05:53:52 | INFO | Rank 0 | Train Epoch: 7 [11488/23491 (49%)]\tLoss: 0.110341\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:52 | INFO | Rank 0 | Train Epoch: 7 [11520/23491 (49%)]\tLoss: 0.059213\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:52 | INFO | Rank 0 | Train Epoch: 7 [11552/23491 (49%)]\tLoss: 0.040908\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:52 | INFO | Rank 0 | Train Epoch: 7 [11584/23491 (49%)]\tLoss: 0.065517\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:53 | INFO | Rank 0 | Train Epoch: 7 [11616/23491 (49%)]\tLoss: 0.021222\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:53 | INFO | Rank 0 | Train Epoch: 7 [11648/23491 (50%)]\tLoss: 0.068258\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:53 | INFO | Rank 0 | Train Epoch: 7 [11680/23491 (50%)]\tLoss: 0.164477\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:54 | INFO | Rank 0 | Train Epoch: 7 [11712/23491 (50%)]\tLoss: 0.042844\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:54 | INFO | Rank 0 | Train Epoch: 7 [11744/23491 (50%)]\tLoss: 0.032907\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:54 | INFO | Rank 0 | Train Epoch: 7 [11776/23491 (50%)]\tLoss: 0.072324\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:54 | INFO | Rank 0 | Train Epoch: 7 [11808/23491 (50%)]\tLoss: 0.258108\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:55 | INFO | Rank 0 | Train Epoch: 7 [11840/23491 (50%)]\tLoss: 0.112964\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:55 | INFO | Rank 0 | Train Epoch: 7 [11872/23491 (51%)]\tLoss: 0.203700\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:55 | INFO | Rank 0 | Train Epoch: 7 [11904/23491 (51%)]\tLoss: 0.079854\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:55 | INFO | Rank 0 | Train Epoch: 7 [11936/23491 (51%)]\tLoss: 0.137858\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:56 | INFO | Rank 0 | Train Epoch: 7 [11968/23491 (51%)]\tLoss: 0.016044\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:56 | INFO | Rank 0 | Train Epoch: 7 [12000/23491 (51%)]\tLoss: 0.059252\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:56 | INFO | Rank 0 | Train Epoch: 7 [12032/23491 (51%)]\tLoss: 0.165234\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:56 | INFO | Rank 0 | Train Epoch: 7 [12064/23491 (51%)]\tLoss: 0.084278\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:57 | INFO | Rank 0 | Train Epoch: 7 [12096/23491 (51%)]\tLoss: 0.034881\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:57 | INFO | Rank 0 | Train Epoch: 7 [12128/23491 (52%)]\tLoss: 0.268997\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:57 | INFO | Rank 0 | Train Epoch: 7 [12160/23491 (52%)]\tLoss: 0.170092\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:58 | INFO | Rank 0 | Train Epoch: 7 [12192/23491 (52%)]\tLoss: 0.017504\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:58 | INFO | Rank 0 | Train Epoch: 7 [12224/23491 (52%)]\tLoss: 0.054080\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:58 | INFO | Rank 0 | Train Epoch: 7 [12256/23491 (52%)]\tLoss: 0.100070\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:58 | INFO | Rank 0 | Train Epoch: 7 [12288/23491 (52%)]\tLoss: 0.041522\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:59 | INFO | Rank 0 | Train Epoch: 7 [12320/23491 (52%)]\tLoss: 0.022369\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:59 | INFO | Rank 0 | Train Epoch: 7 [12352/23491 (53%)]\tLoss: 0.061259\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:59 | INFO | Rank 0 | Train Epoch: 7 [12384/23491 (53%)]\tLoss: 0.059982\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:53:59 | INFO | Rank 0 | Train Epoch: 7 [12416/23491 (53%)]\tLoss: 0.026966\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:00 | INFO | Rank 0 | Train Epoch: 7 [12448/23491 (53%)]\tLoss: 0.084425\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:00 | INFO | Rank 0 | Train Epoch: 7 [12480/23491 (53%)]\tLoss: 0.144303\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:00 | INFO | Rank 0 | Train Epoch: 7 [12512/23491 (53%)]\tLoss: 0.030165\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:00 | INFO | Rank 0 | Train Epoch: 7 [12544/23491 (53%)]\tLoss: 0.139421\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:01 | INFO | Rank 0 | Train Epoch: 7 [12576/23491 (54%)]\tLoss: 0.159502\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:01 | INFO | Rank 0 | Train Epoch: 7 [12608/23491 (54%)]\tLoss: 0.129449\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:01 | INFO | Rank 0 | Train Epoch: 7 [12640/23491 (54%)]\tLoss: 0.015173\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:02 | INFO | Rank 0 | Train Epoch: 7 [12672/23491 (54%)]\tLoss: 0.131241\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:02 | INFO | Rank 0 | Train Epoch: 7 [12704/23491 (54%)]\tLoss: 0.070353\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:02 | INFO | Rank 0 | Train Epoch: 7 [12736/23491 (54%)]\tLoss: 0.114341\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:02 | INFO | Rank 0 | Train Epoch: 7 [12768/23491 (54%)]\tLoss: 0.009266\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:03 | INFO | Rank 0 | Train Epoch: 7 [12800/23491 (54%)]\tLoss: 0.075206\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:03 | INFO | Rank 0 | Train Epoch: 7 [12832/23491 (55%)]\tLoss: 0.051474\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:03 | INFO | Rank 0 | Train Epoch: 7 [12864/23491 (55%)]\tLoss: 0.082169\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:03 | INFO | Rank 0 | Train Epoch: 7 [12896/23491 (55%)]\tLoss: 0.124141\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:04 | INFO | Rank 0 | Train Epoch: 7 [12928/23491 (55%)]\tLoss: 0.053104\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:04 | INFO | Rank 0 | Train Epoch: 7 [12960/23491 (55%)]\tLoss: 0.070403\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:04 | INFO | Rank 0 | Train Epoch: 7 [12992/23491 (55%)]\tLoss: 0.082749\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:04 | INFO | Rank 0 | Train Epoch: 7 [13024/23491 (55%)]\tLoss: 0.203334\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:05 | INFO | Rank 0 | Train Epoch: 7 [13056/23491 (56%)]\tLoss: 0.194751\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:05 | INFO | Rank 0 | Train Epoch: 7 [13088/23491 (56%)]\tLoss: 0.087913\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:05 | INFO | Rank 0 | Train Epoch: 7 [13120/23491 (56%)]\tLoss: 0.159340\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:06 | INFO | Rank 0 | Train Epoch: 7 [13152/23491 (56%)]\tLoss: 0.030560\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:06 | INFO | Rank 0 | Train Epoch: 7 [13184/23491 (56%)]\tLoss: 0.052159\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:06 | INFO | Rank 0 | Train Epoch: 7 [13216/23491 (56%)]\tLoss: 0.093748\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:06 | INFO | Rank 0 | Train Epoch: 7 [13248/23491 (56%)]\tLoss: 0.060197\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:07 | INFO | Rank 0 | Train Epoch: 7 [13280/23491 (57%)]\tLoss: 0.093582\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:07 | INFO | Rank 0 | Train Epoch: 7 [13312/23491 (57%)]\tLoss: 0.162901\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:07 | INFO | Rank 0 | Train Epoch: 7 [13344/23491 (57%)]\tLoss: 0.068093\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:07 | INFO | Rank 0 | Train Epoch: 7 [13376/23491 (57%)]\tLoss: 0.103108\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:08 | INFO | Rank 0 | Train Epoch: 7 [13408/23491 (57%)]\tLoss: 0.092405\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:08 | INFO | Rank 0 | Train Epoch: 7 [13440/23491 (57%)]\tLoss: 0.032067\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:08 | INFO | Rank 0 | Train Epoch: 7 [13472/23491 (57%)]\tLoss: 0.233420\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:08 | INFO | Rank 0 | Train Epoch: 7 [13504/23491 (57%)]\tLoss: 0.105110\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:09 | INFO | Rank 0 | Train Epoch: 7 [13536/23491 (58%)]\tLoss: 0.162793\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:09 | INFO | Rank 0 | Train Epoch: 7 [13568/23491 (58%)]\tLoss: 0.019803\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:09 | INFO | Rank 0 | Train Epoch: 7 [13600/23491 (58%)]\tLoss: 0.134192\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:09 | INFO | Rank 0 | Train Epoch: 7 [13632/23491 (58%)]\tLoss: 0.081251\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:10 | INFO | Rank 0 | Train Epoch: 7 [13664/23491 (58%)]\tLoss: 0.035201\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:10 | INFO | Rank 0 | Train Epoch: 7 [13696/23491 (58%)]\tLoss: 0.015911\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:10 | INFO | Rank 0 | Train Epoch: 7 [13728/23491 (58%)]\tLoss: 0.089119\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:11 | INFO | Rank 0 | Train Epoch: 7 [13760/23491 (59%)]\tLoss: 0.160642\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:11 | INFO | Rank 0 | Train Epoch: 7 [13792/23491 (59%)]\tLoss: 0.086159\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:11 | INFO | Rank 0 | Train Epoch: 7 [13824/23491 (59%)]\tLoss: 0.017602\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000013\tlogit_scale 4.541\n",
      "2022-11-08,05:54:11 | INFO | Rank 0 | Train Epoch: 7 [13856/23491 (59%)]\tLoss: 0.075690\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:12 | INFO | Rank 0 | Train Epoch: 7 [13888/23491 (59%)]\tLoss: 0.089560\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:12 | INFO | Rank 0 | Train Epoch: 7 [13920/23491 (59%)]\tLoss: 0.034323\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:12 | INFO | Rank 0 | Train Epoch: 7 [13952/23491 (59%)]\tLoss: 0.042814\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:12 | INFO | Rank 0 | Train Epoch: 7 [13984/23491 (60%)]\tLoss: 0.093112\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:13 | INFO | Rank 0 | Train Epoch: 7 [14016/23491 (60%)]\tLoss: 0.082530\tData (t) 0.055\tBatch (t) 0.269\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:13 | INFO | Rank 0 | Train Epoch: 7 [14048/23491 (60%)]\tLoss: 0.057759\tData (t) 0.055\tBatch (t) 0.270\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:13 | INFO | Rank 0 | Train Epoch: 7 [14080/23491 (60%)]\tLoss: 0.071958\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:14 | INFO | Rank 0 | Train Epoch: 7 [14112/23491 (60%)]\tLoss: 0.103351\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:14 | INFO | Rank 0 | Train Epoch: 7 [14144/23491 (60%)]\tLoss: 0.117966\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:14 | INFO | Rank 0 | Train Epoch: 7 [14176/23491 (60%)]\tLoss: 0.107690\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:14 | INFO | Rank 0 | Train Epoch: 7 [14208/23491 (60%)]\tLoss: 0.192778\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:15 | INFO | Rank 0 | Train Epoch: 7 [14240/23491 (61%)]\tLoss: 0.182705\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:15 | INFO | Rank 0 | Train Epoch: 7 [14272/23491 (61%)]\tLoss: 0.098796\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:15 | INFO | Rank 0 | Train Epoch: 7 [14304/23491 (61%)]\tLoss: 0.086540\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:15 | INFO | Rank 0 | Train Epoch: 7 [14336/23491 (61%)]\tLoss: 0.114182\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:16 | INFO | Rank 0 | Train Epoch: 7 [14368/23491 (61%)]\tLoss: 0.318034\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:16 | INFO | Rank 0 | Train Epoch: 7 [14400/23491 (61%)]\tLoss: 0.097918\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:16 | INFO | Rank 0 | Train Epoch: 7 [14432/23491 (61%)]\tLoss: 0.021957\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:16 | INFO | Rank 0 | Train Epoch: 7 [14464/23491 (62%)]\tLoss: 0.123419\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:17 | INFO | Rank 0 | Train Epoch: 7 [14496/23491 (62%)]\tLoss: 0.050160\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:17 | INFO | Rank 0 | Train Epoch: 7 [14528/23491 (62%)]\tLoss: 0.097866\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:17 | INFO | Rank 0 | Train Epoch: 7 [14560/23491 (62%)]\tLoss: 0.085904\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:17 | INFO | Rank 0 | Train Epoch: 7 [14592/23491 (62%)]\tLoss: 0.062866\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:18 | INFO | Rank 0 | Train Epoch: 7 [14624/23491 (62%)]\tLoss: 0.046367\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:18 | INFO | Rank 0 | Train Epoch: 7 [14656/23491 (62%)]\tLoss: 0.130505\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:18 | INFO | Rank 0 | Train Epoch: 7 [14688/23491 (63%)]\tLoss: 0.070192\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:19 | INFO | Rank 0 | Train Epoch: 7 [14720/23491 (63%)]\tLoss: 0.280082\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:19 | INFO | Rank 0 | Train Epoch: 7 [14752/23491 (63%)]\tLoss: 0.062432\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:19 | INFO | Rank 0 | Train Epoch: 7 [14784/23491 (63%)]\tLoss: 0.125602\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:19 | INFO | Rank 0 | Train Epoch: 7 [14816/23491 (63%)]\tLoss: 0.106759\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:20 | INFO | Rank 0 | Train Epoch: 7 [14848/23491 (63%)]\tLoss: 0.160228\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:20 | INFO | Rank 0 | Train Epoch: 7 [14880/23491 (63%)]\tLoss: 0.034514\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:20 | INFO | Rank 0 | Train Epoch: 7 [14912/23491 (63%)]\tLoss: 0.135449\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:20 | INFO | Rank 0 | Train Epoch: 7 [14944/23491 (64%)]\tLoss: 0.133071\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:21 | INFO | Rank 0 | Train Epoch: 7 [14976/23491 (64%)]\tLoss: 0.089847\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:21 | INFO | Rank 0 | Train Epoch: 7 [15008/23491 (64%)]\tLoss: 0.011888\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:21 | INFO | Rank 0 | Train Epoch: 7 [15040/23491 (64%)]\tLoss: 0.141158\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:21 | INFO | Rank 0 | Train Epoch: 7 [15072/23491 (64%)]\tLoss: 0.018883\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:22 | INFO | Rank 0 | Train Epoch: 7 [15104/23491 (64%)]\tLoss: 0.112997\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:22 | INFO | Rank 0 | Train Epoch: 7 [15136/23491 (64%)]\tLoss: 0.117080\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:22 | INFO | Rank 0 | Train Epoch: 7 [15168/23491 (65%)]\tLoss: 0.244168\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:23 | INFO | Rank 0 | Train Epoch: 7 [15200/23491 (65%)]\tLoss: 0.030158\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:23 | INFO | Rank 0 | Train Epoch: 7 [15232/23491 (65%)]\tLoss: 0.156793\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:23 | INFO | Rank 0 | Train Epoch: 7 [15264/23491 (65%)]\tLoss: 0.060811\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:23 | INFO | Rank 0 | Train Epoch: 7 [15296/23491 (65%)]\tLoss: 0.003633\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:24 | INFO | Rank 0 | Train Epoch: 7 [15328/23491 (65%)]\tLoss: 0.072430\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:24 | INFO | Rank 0 | Train Epoch: 7 [15360/23491 (65%)]\tLoss: 0.135955\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:24 | INFO | Rank 0 | Train Epoch: 7 [15392/23491 (66%)]\tLoss: 0.186164\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:24 | INFO | Rank 0 | Train Epoch: 7 [15424/23491 (66%)]\tLoss: 0.170730\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:25 | INFO | Rank 0 | Train Epoch: 7 [15456/23491 (66%)]\tLoss: 0.028755\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:25 | INFO | Rank 0 | Train Epoch: 7 [15488/23491 (66%)]\tLoss: 0.132860\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:25 | INFO | Rank 0 | Train Epoch: 7 [15520/23491 (66%)]\tLoss: 0.037245\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:25 | INFO | Rank 0 | Train Epoch: 7 [15552/23491 (66%)]\tLoss: 0.046236\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:26 | INFO | Rank 0 | Train Epoch: 7 [15584/23491 (66%)]\tLoss: 0.131829\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:26 | INFO | Rank 0 | Train Epoch: 7 [15616/23491 (66%)]\tLoss: 0.173839\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:26 | INFO | Rank 0 | Train Epoch: 7 [15648/23491 (67%)]\tLoss: 0.093924\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:27 | INFO | Rank 0 | Train Epoch: 7 [15680/23491 (67%)]\tLoss: 0.090235\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:27 | INFO | Rank 0 | Train Epoch: 7 [15712/23491 (67%)]\tLoss: 0.029319\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:27 | INFO | Rank 0 | Train Epoch: 7 [15744/23491 (67%)]\tLoss: 0.104607\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:27 | INFO | Rank 0 | Train Epoch: 7 [15776/23491 (67%)]\tLoss: 0.085105\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:28 | INFO | Rank 0 | Train Epoch: 7 [15808/23491 (67%)]\tLoss: 0.037339\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:28 | INFO | Rank 0 | Train Epoch: 7 [15840/23491 (67%)]\tLoss: 0.080681\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:28 | INFO | Rank 0 | Train Epoch: 7 [15872/23491 (68%)]\tLoss: 0.050363\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:28 | INFO | Rank 0 | Train Epoch: 7 [15904/23491 (68%)]\tLoss: 0.131955\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:29 | INFO | Rank 0 | Train Epoch: 7 [15936/23491 (68%)]\tLoss: 0.229087\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:29 | INFO | Rank 0 | Train Epoch: 7 [15968/23491 (68%)]\tLoss: 0.253841\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:29 | INFO | Rank 0 | Train Epoch: 7 [16000/23491 (68%)]\tLoss: 0.062820\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:29 | INFO | Rank 0 | Train Epoch: 7 [16032/23491 (68%)]\tLoss: 0.020112\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:30 | INFO | Rank 0 | Train Epoch: 7 [16064/23491 (68%)]\tLoss: 0.016749\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:30 | INFO | Rank 0 | Train Epoch: 7 [16096/23491 (69%)]\tLoss: 0.080569\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:30 | INFO | Rank 0 | Train Epoch: 7 [16128/23491 (69%)]\tLoss: 0.025277\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:31 | INFO | Rank 0 | Train Epoch: 7 [16160/23491 (69%)]\tLoss: 0.021989\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:31 | INFO | Rank 0 | Train Epoch: 7 [16192/23491 (69%)]\tLoss: 0.126529\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:31 | INFO | Rank 0 | Train Epoch: 7 [16224/23491 (69%)]\tLoss: 0.057028\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:31 | INFO | Rank 0 | Train Epoch: 7 [16256/23491 (69%)]\tLoss: 0.123799\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000012\tlogit_scale 4.541\n",
      "2022-11-08,05:54:32 | INFO | Rank 0 | Train Epoch: 7 [16288/23491 (69%)]\tLoss: 0.177442\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:32 | INFO | Rank 0 | Train Epoch: 7 [16320/23491 (69%)]\tLoss: 0.181695\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:32 | INFO | Rank 0 | Train Epoch: 7 [16352/23491 (70%)]\tLoss: 0.189725\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:32 | INFO | Rank 0 | Train Epoch: 7 [16384/23491 (70%)]\tLoss: 0.083889\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:33 | INFO | Rank 0 | Train Epoch: 7 [16416/23491 (70%)]\tLoss: 0.112388\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:33 | INFO | Rank 0 | Train Epoch: 7 [16448/23491 (70%)]\tLoss: 0.174818\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:33 | INFO | Rank 0 | Train Epoch: 7 [16480/23491 (70%)]\tLoss: 0.110544\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:33 | INFO | Rank 0 | Train Epoch: 7 [16512/23491 (70%)]\tLoss: 0.105587\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:34 | INFO | Rank 0 | Train Epoch: 7 [16544/23491 (70%)]\tLoss: 0.058988\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:34 | INFO | Rank 0 | Train Epoch: 7 [16576/23491 (71%)]\tLoss: 0.032224\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:34 | INFO | Rank 0 | Train Epoch: 7 [16608/23491 (71%)]\tLoss: 0.273742\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:35 | INFO | Rank 0 | Train Epoch: 7 [16640/23491 (71%)]\tLoss: 0.131887\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:35 | INFO | Rank 0 | Train Epoch: 7 [16672/23491 (71%)]\tLoss: 0.079208\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:35 | INFO | Rank 0 | Train Epoch: 7 [16704/23491 (71%)]\tLoss: 0.230547\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:35 | INFO | Rank 0 | Train Epoch: 7 [16736/23491 (71%)]\tLoss: 0.017104\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:36 | INFO | Rank 0 | Train Epoch: 7 [16768/23491 (71%)]\tLoss: 0.106676\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:36 | INFO | Rank 0 | Train Epoch: 7 [16800/23491 (72%)]\tLoss: 0.176154\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:36 | INFO | Rank 0 | Train Epoch: 7 [16832/23491 (72%)]\tLoss: 0.038182\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:36 | INFO | Rank 0 | Train Epoch: 7 [16864/23491 (72%)]\tLoss: 0.040431\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:37 | INFO | Rank 0 | Train Epoch: 7 [16896/23491 (72%)]\tLoss: 0.073519\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:37 | INFO | Rank 0 | Train Epoch: 7 [16928/23491 (72%)]\tLoss: 0.072985\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:37 | INFO | Rank 0 | Train Epoch: 7 [16960/23491 (72%)]\tLoss: 0.152002\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:37 | INFO | Rank 0 | Train Epoch: 7 [16992/23491 (72%)]\tLoss: 0.058543\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:38 | INFO | Rank 0 | Train Epoch: 7 [17024/23491 (72%)]\tLoss: 0.184600\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:38 | INFO | Rank 0 | Train Epoch: 7 [17056/23491 (73%)]\tLoss: 0.095983\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:38 | INFO | Rank 0 | Train Epoch: 7 [17088/23491 (73%)]\tLoss: 0.117979\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:39 | INFO | Rank 0 | Train Epoch: 7 [17120/23491 (73%)]\tLoss: 0.015601\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:39 | INFO | Rank 0 | Train Epoch: 7 [17152/23491 (73%)]\tLoss: 0.016240\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:39 | INFO | Rank 0 | Train Epoch: 7 [17184/23491 (73%)]\tLoss: 0.009531\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:39 | INFO | Rank 0 | Train Epoch: 7 [17216/23491 (73%)]\tLoss: 0.091932\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:40 | INFO | Rank 0 | Train Epoch: 7 [17248/23491 (73%)]\tLoss: 0.181462\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:40 | INFO | Rank 0 | Train Epoch: 7 [17280/23491 (74%)]\tLoss: 0.005137\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:40 | INFO | Rank 0 | Train Epoch: 7 [17312/23491 (74%)]\tLoss: 0.126848\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:40 | INFO | Rank 0 | Train Epoch: 7 [17344/23491 (74%)]\tLoss: 0.097810\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:41 | INFO | Rank 0 | Train Epoch: 7 [17376/23491 (74%)]\tLoss: 0.100634\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:41 | INFO | Rank 0 | Train Epoch: 7 [17408/23491 (74%)]\tLoss: 0.118977\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:41 | INFO | Rank 0 | Train Epoch: 7 [17440/23491 (74%)]\tLoss: 0.119343\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:41 | INFO | Rank 0 | Train Epoch: 7 [17472/23491 (74%)]\tLoss: 0.076414\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:42 | INFO | Rank 0 | Train Epoch: 7 [17504/23491 (75%)]\tLoss: 0.045516\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:42 | INFO | Rank 0 | Train Epoch: 7 [17536/23491 (75%)]\tLoss: 0.142265\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:42 | INFO | Rank 0 | Train Epoch: 7 [17568/23491 (75%)]\tLoss: 0.137990\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:43 | INFO | Rank 0 | Train Epoch: 7 [17600/23491 (75%)]\tLoss: 0.112252\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:43 | INFO | Rank 0 | Train Epoch: 7 [17632/23491 (75%)]\tLoss: 0.022377\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:43 | INFO | Rank 0 | Train Epoch: 7 [17664/23491 (75%)]\tLoss: 0.190416\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:43 | INFO | Rank 0 | Train Epoch: 7 [17696/23491 (75%)]\tLoss: 0.101939\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:44 | INFO | Rank 0 | Train Epoch: 7 [17728/23491 (75%)]\tLoss: 0.154219\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:44 | INFO | Rank 0 | Train Epoch: 7 [17760/23491 (76%)]\tLoss: 0.073897\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:44 | INFO | Rank 0 | Train Epoch: 7 [17792/23491 (76%)]\tLoss: 0.153029\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:44 | INFO | Rank 0 | Train Epoch: 7 [17824/23491 (76%)]\tLoss: 0.122401\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:45 | INFO | Rank 0 | Train Epoch: 7 [17856/23491 (76%)]\tLoss: 0.119597\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:45 | INFO | Rank 0 | Train Epoch: 7 [17888/23491 (76%)]\tLoss: 0.054693\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:45 | INFO | Rank 0 | Train Epoch: 7 [17920/23491 (76%)]\tLoss: 0.122746\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:45 | INFO | Rank 0 | Train Epoch: 7 [17952/23491 (76%)]\tLoss: 0.272695\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:46 | INFO | Rank 0 | Train Epoch: 7 [17984/23491 (77%)]\tLoss: 0.010430\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:46 | INFO | Rank 0 | Train Epoch: 7 [18016/23491 (77%)]\tLoss: 0.135995\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:46 | INFO | Rank 0 | Train Epoch: 7 [18048/23491 (77%)]\tLoss: 0.121149\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:46 | INFO | Rank 0 | Train Epoch: 7 [18080/23491 (77%)]\tLoss: 0.092031\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:47 | INFO | Rank 0 | Train Epoch: 7 [18112/23491 (77%)]\tLoss: 0.123769\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:47 | INFO | Rank 0 | Train Epoch: 7 [18144/23491 (77%)]\tLoss: 0.058592\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:47 | INFO | Rank 0 | Train Epoch: 7 [18176/23491 (77%)]\tLoss: 0.068943\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:48 | INFO | Rank 0 | Train Epoch: 7 [18208/23491 (78%)]\tLoss: 0.202090\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:48 | INFO | Rank 0 | Train Epoch: 7 [18240/23491 (78%)]\tLoss: 0.086633\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:48 | INFO | Rank 0 | Train Epoch: 7 [18272/23491 (78%)]\tLoss: 0.023939\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:48 | INFO | Rank 0 | Train Epoch: 7 [18304/23491 (78%)]\tLoss: 0.067165\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:49 | INFO | Rank 0 | Train Epoch: 7 [18336/23491 (78%)]\tLoss: 0.194422\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:49 | INFO | Rank 0 | Train Epoch: 7 [18368/23491 (78%)]\tLoss: 0.058499\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:49 | INFO | Rank 0 | Train Epoch: 7 [18400/23491 (78%)]\tLoss: 0.156069\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:49 | INFO | Rank 0 | Train Epoch: 7 [18432/23491 (78%)]\tLoss: 0.186932\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:50 | INFO | Rank 0 | Train Epoch: 7 [18464/23491 (79%)]\tLoss: 0.047972\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:50 | INFO | Rank 0 | Train Epoch: 7 [18496/23491 (79%)]\tLoss: 0.041810\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:50 | INFO | Rank 0 | Train Epoch: 7 [18528/23491 (79%)]\tLoss: 0.140233\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:50 | INFO | Rank 0 | Train Epoch: 7 [18560/23491 (79%)]\tLoss: 0.169811\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:51 | INFO | Rank 0 | Train Epoch: 7 [18592/23491 (79%)]\tLoss: 0.114703\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:51 | INFO | Rank 0 | Train Epoch: 7 [18624/23491 (79%)]\tLoss: 0.043589\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:51 | INFO | Rank 0 | Train Epoch: 7 [18656/23491 (79%)]\tLoss: 0.030558\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:52 | INFO | Rank 0 | Train Epoch: 7 [18688/23491 (80%)]\tLoss: 0.055791\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:52 | INFO | Rank 0 | Train Epoch: 7 [18720/23491 (80%)]\tLoss: 0.103719\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:52 | INFO | Rank 0 | Train Epoch: 7 [18752/23491 (80%)]\tLoss: 0.098340\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:52 | INFO | Rank 0 | Train Epoch: 7 [18784/23491 (80%)]\tLoss: 0.140746\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000011\tlogit_scale 4.541\n",
      "2022-11-08,05:54:53 | INFO | Rank 0 | Train Epoch: 7 [18816/23491 (80%)]\tLoss: 0.085367\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:53 | INFO | Rank 0 | Train Epoch: 7 [18848/23491 (80%)]\tLoss: 0.089158\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:53 | INFO | Rank 0 | Train Epoch: 7 [18880/23491 (80%)]\tLoss: 0.084849\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:53 | INFO | Rank 0 | Train Epoch: 7 [18912/23491 (81%)]\tLoss: 0.125413\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:54 | INFO | Rank 0 | Train Epoch: 7 [18944/23491 (81%)]\tLoss: 0.114178\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:54 | INFO | Rank 0 | Train Epoch: 7 [18976/23491 (81%)]\tLoss: 0.082999\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:54 | INFO | Rank 0 | Train Epoch: 7 [19008/23491 (81%)]\tLoss: 0.120689\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:54 | INFO | Rank 0 | Train Epoch: 7 [19040/23491 (81%)]\tLoss: 0.025034\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:55 | INFO | Rank 0 | Train Epoch: 7 [19072/23491 (81%)]\tLoss: 0.116350\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:55 | INFO | Rank 0 | Train Epoch: 7 [19104/23491 (81%)]\tLoss: 0.027692\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:55 | INFO | Rank 0 | Train Epoch: 7 [19136/23491 (81%)]\tLoss: 0.033709\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:56 | INFO | Rank 0 | Train Epoch: 7 [19168/23491 (82%)]\tLoss: 0.074686\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:56 | INFO | Rank 0 | Train Epoch: 7 [19200/23491 (82%)]\tLoss: 0.083947\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:56 | INFO | Rank 0 | Train Epoch: 7 [19232/23491 (82%)]\tLoss: 0.072897\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:56 | INFO | Rank 0 | Train Epoch: 7 [19264/23491 (82%)]\tLoss: 0.057376\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:57 | INFO | Rank 0 | Train Epoch: 7 [19296/23491 (82%)]\tLoss: 0.091212\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:57 | INFO | Rank 0 | Train Epoch: 7 [19328/23491 (82%)]\tLoss: 0.091391\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:57 | INFO | Rank 0 | Train Epoch: 7 [19360/23491 (82%)]\tLoss: 0.145455\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:57 | INFO | Rank 0 | Train Epoch: 7 [19392/23491 (83%)]\tLoss: 0.051550\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:58 | INFO | Rank 0 | Train Epoch: 7 [19424/23491 (83%)]\tLoss: 0.113553\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:58 | INFO | Rank 0 | Train Epoch: 7 [19456/23491 (83%)]\tLoss: 0.021971\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:58 | INFO | Rank 0 | Train Epoch: 7 [19488/23491 (83%)]\tLoss: 0.021491\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:58 | INFO | Rank 0 | Train Epoch: 7 [19520/23491 (83%)]\tLoss: 0.115450\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:59 | INFO | Rank 0 | Train Epoch: 7 [19552/23491 (83%)]\tLoss: 0.073893\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:59 | INFO | Rank 0 | Train Epoch: 7 [19584/23491 (83%)]\tLoss: 0.047519\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:54:59 | INFO | Rank 0 | Train Epoch: 7 [19616/23491 (84%)]\tLoss: 0.106689\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:00 | INFO | Rank 0 | Train Epoch: 7 [19648/23491 (84%)]\tLoss: 0.011495\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:00 | INFO | Rank 0 | Train Epoch: 7 [19680/23491 (84%)]\tLoss: 0.091460\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:00 | INFO | Rank 0 | Train Epoch: 7 [19712/23491 (84%)]\tLoss: 0.176002\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:00 | INFO | Rank 0 | Train Epoch: 7 [19744/23491 (84%)]\tLoss: 0.119311\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:01 | INFO | Rank 0 | Train Epoch: 7 [19776/23491 (84%)]\tLoss: 0.117294\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:01 | INFO | Rank 0 | Train Epoch: 7 [19808/23491 (84%)]\tLoss: 0.026646\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:01 | INFO | Rank 0 | Train Epoch: 7 [19840/23491 (84%)]\tLoss: 0.108409\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:01 | INFO | Rank 0 | Train Epoch: 7 [19872/23491 (85%)]\tLoss: 0.137349\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:02 | INFO | Rank 0 | Train Epoch: 7 [19904/23491 (85%)]\tLoss: 0.039357\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:02 | INFO | Rank 0 | Train Epoch: 7 [19936/23491 (85%)]\tLoss: 0.135581\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:02 | INFO | Rank 0 | Train Epoch: 7 [19968/23491 (85%)]\tLoss: 0.049703\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:02 | INFO | Rank 0 | Train Epoch: 7 [20000/23491 (85%)]\tLoss: 0.038261\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:03 | INFO | Rank 0 | Train Epoch: 7 [20032/23491 (85%)]\tLoss: 0.076348\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:03 | INFO | Rank 0 | Train Epoch: 7 [20064/23491 (85%)]\tLoss: 0.012837\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:03 | INFO | Rank 0 | Train Epoch: 7 [20096/23491 (86%)]\tLoss: 0.167780\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:04 | INFO | Rank 0 | Train Epoch: 7 [20128/23491 (86%)]\tLoss: 0.068162\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:04 | INFO | Rank 0 | Train Epoch: 7 [20160/23491 (86%)]\tLoss: 0.090344\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:04 | INFO | Rank 0 | Train Epoch: 7 [20192/23491 (86%)]\tLoss: 0.088794\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:04 | INFO | Rank 0 | Train Epoch: 7 [20224/23491 (86%)]\tLoss: 0.198423\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:05 | INFO | Rank 0 | Train Epoch: 7 [20256/23491 (86%)]\tLoss: 0.193897\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:05 | INFO | Rank 0 | Train Epoch: 7 [20288/23491 (86%)]\tLoss: 0.021557\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:05 | INFO | Rank 0 | Train Epoch: 7 [20320/23491 (87%)]\tLoss: 0.145765\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:05 | INFO | Rank 0 | Train Epoch: 7 [20352/23491 (87%)]\tLoss: 0.006430\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:06 | INFO | Rank 0 | Train Epoch: 7 [20384/23491 (87%)]\tLoss: 0.115429\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:06 | INFO | Rank 0 | Train Epoch: 7 [20416/23491 (87%)]\tLoss: 0.210465\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:06 | INFO | Rank 0 | Train Epoch: 7 [20448/23491 (87%)]\tLoss: 0.022895\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:06 | INFO | Rank 0 | Train Epoch: 7 [20480/23491 (87%)]\tLoss: 0.085580\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:07 | INFO | Rank 0 | Train Epoch: 7 [20512/23491 (87%)]\tLoss: 0.054323\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:07 | INFO | Rank 0 | Train Epoch: 7 [20544/23491 (87%)]\tLoss: 0.082353\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:07 | INFO | Rank 0 | Train Epoch: 7 [20576/23491 (88%)]\tLoss: 0.142101\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:08 | INFO | Rank 0 | Train Epoch: 7 [20608/23491 (88%)]\tLoss: 0.042532\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:08 | INFO | Rank 0 | Train Epoch: 7 [20640/23491 (88%)]\tLoss: 0.338441\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:08 | INFO | Rank 0 | Train Epoch: 7 [20672/23491 (88%)]\tLoss: 0.081921\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:08 | INFO | Rank 0 | Train Epoch: 7 [20704/23491 (88%)]\tLoss: 0.214194\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:09 | INFO | Rank 0 | Train Epoch: 7 [20736/23491 (88%)]\tLoss: 0.280711\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:09 | INFO | Rank 0 | Train Epoch: 7 [20768/23491 (88%)]\tLoss: 0.139033\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:09 | INFO | Rank 0 | Train Epoch: 7 [20800/23491 (89%)]\tLoss: 0.059819\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:09 | INFO | Rank 0 | Train Epoch: 7 [20832/23491 (89%)]\tLoss: 0.086412\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:10 | INFO | Rank 0 | Train Epoch: 7 [20864/23491 (89%)]\tLoss: 0.037473\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:10 | INFO | Rank 0 | Train Epoch: 7 [20896/23491 (89%)]\tLoss: 0.039982\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:10 | INFO | Rank 0 | Train Epoch: 7 [20928/23491 (89%)]\tLoss: 0.047055\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:10 | INFO | Rank 0 | Train Epoch: 7 [20960/23491 (89%)]\tLoss: 0.080054\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:11 | INFO | Rank 0 | Train Epoch: 7 [20992/23491 (89%)]\tLoss: 0.048445\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:11 | INFO | Rank 0 | Train Epoch: 7 [21024/23491 (90%)]\tLoss: 0.038752\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:11 | INFO | Rank 0 | Train Epoch: 7 [21056/23491 (90%)]\tLoss: 0.059032\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:11 | INFO | Rank 0 | Train Epoch: 7 [21088/23491 (90%)]\tLoss: 0.104959\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:12 | INFO | Rank 0 | Train Epoch: 7 [21120/23491 (90%)]\tLoss: 0.128250\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:12 | INFO | Rank 0 | Train Epoch: 7 [21152/23491 (90%)]\tLoss: 0.089436\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:12 | INFO | Rank 0 | Train Epoch: 7 [21184/23491 (90%)]\tLoss: 0.139789\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:13 | INFO | Rank 0 | Train Epoch: 7 [21216/23491 (90%)]\tLoss: 0.095660\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:13 | INFO | Rank 0 | Train Epoch: 7 [21248/23491 (90%)]\tLoss: 0.155039\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:13 | INFO | Rank 0 | Train Epoch: 7 [21280/23491 (91%)]\tLoss: 0.108277\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:13 | INFO | Rank 0 | Train Epoch: 7 [21312/23491 (91%)]\tLoss: 0.097364\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:14 | INFO | Rank 0 | Train Epoch: 7 [21344/23491 (91%)]\tLoss: 0.033153\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:14 | INFO | Rank 0 | Train Epoch: 7 [21376/23491 (91%)]\tLoss: 0.152473\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:14 | INFO | Rank 0 | Train Epoch: 7 [21408/23491 (91%)]\tLoss: 0.022095\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:14 | INFO | Rank 0 | Train Epoch: 7 [21440/23491 (91%)]\tLoss: 0.025585\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000010\tlogit_scale 4.541\n",
      "2022-11-08,05:55:15 | INFO | Rank 0 | Train Epoch: 7 [21472/23491 (91%)]\tLoss: 0.093830\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:15 | INFO | Rank 0 | Train Epoch: 7 [21504/23491 (92%)]\tLoss: 0.082598\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:15 | INFO | Rank 0 | Train Epoch: 7 [21536/23491 (92%)]\tLoss: 0.009700\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:15 | INFO | Rank 0 | Train Epoch: 7 [21568/23491 (92%)]\tLoss: 0.173377\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:16 | INFO | Rank 0 | Train Epoch: 7 [21600/23491 (92%)]\tLoss: 0.017810\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:16 | INFO | Rank 0 | Train Epoch: 7 [21632/23491 (92%)]\tLoss: 0.226438\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:16 | INFO | Rank 0 | Train Epoch: 7 [21664/23491 (92%)]\tLoss: 0.074371\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:17 | INFO | Rank 0 | Train Epoch: 7 [21696/23491 (92%)]\tLoss: 0.187910\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:17 | INFO | Rank 0 | Train Epoch: 7 [21728/23491 (93%)]\tLoss: 0.025724\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:17 | INFO | Rank 0 | Train Epoch: 7 [21760/23491 (93%)]\tLoss: 0.098490\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:17 | INFO | Rank 0 | Train Epoch: 7 [21792/23491 (93%)]\tLoss: 0.110124\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:18 | INFO | Rank 0 | Train Epoch: 7 [21824/23491 (93%)]\tLoss: 0.065716\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:18 | INFO | Rank 0 | Train Epoch: 7 [21856/23491 (93%)]\tLoss: 0.091262\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:18 | INFO | Rank 0 | Train Epoch: 7 [21888/23491 (93%)]\tLoss: 0.079725\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:18 | INFO | Rank 0 | Train Epoch: 7 [21920/23491 (93%)]\tLoss: 0.095840\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:19 | INFO | Rank 0 | Train Epoch: 7 [21952/23491 (93%)]\tLoss: 0.166978\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:19 | INFO | Rank 0 | Train Epoch: 7 [21984/23491 (94%)]\tLoss: 0.120205\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:19 | INFO | Rank 0 | Train Epoch: 7 [22016/23491 (94%)]\tLoss: 0.109457\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:19 | INFO | Rank 0 | Train Epoch: 7 [22048/23491 (94%)]\tLoss: 0.028202\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:20 | INFO | Rank 0 | Train Epoch: 7 [22080/23491 (94%)]\tLoss: 0.049283\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:20 | INFO | Rank 0 | Train Epoch: 7 [22112/23491 (94%)]\tLoss: 0.132907\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:20 | INFO | Rank 0 | Train Epoch: 7 [22144/23491 (94%)]\tLoss: 0.048873\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:21 | INFO | Rank 0 | Train Epoch: 7 [22176/23491 (94%)]\tLoss: 0.062980\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:21 | INFO | Rank 0 | Train Epoch: 7 [22208/23491 (95%)]\tLoss: 0.039652\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:21 | INFO | Rank 0 | Train Epoch: 7 [22240/23491 (95%)]\tLoss: 0.199099\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:21 | INFO | Rank 0 | Train Epoch: 7 [22272/23491 (95%)]\tLoss: 0.123631\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:22 | INFO | Rank 0 | Train Epoch: 7 [22304/23491 (95%)]\tLoss: 0.033532\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:22 | INFO | Rank 0 | Train Epoch: 7 [22336/23491 (95%)]\tLoss: 0.089859\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:22 | INFO | Rank 0 | Train Epoch: 7 [22368/23491 (95%)]\tLoss: 0.058466\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:22 | INFO | Rank 0 | Train Epoch: 7 [22400/23491 (95%)]\tLoss: 0.009383\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:23 | INFO | Rank 0 | Train Epoch: 7 [22432/23491 (96%)]\tLoss: 0.070627\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:23 | INFO | Rank 0 | Train Epoch: 7 [22464/23491 (96%)]\tLoss: 0.090564\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:23 | INFO | Rank 0 | Train Epoch: 7 [22496/23491 (96%)]\tLoss: 0.114431\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:23 | INFO | Rank 0 | Train Epoch: 7 [22528/23491 (96%)]\tLoss: 0.050684\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:24 | INFO | Rank 0 | Train Epoch: 7 [22560/23491 (96%)]\tLoss: 0.013986\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:24 | INFO | Rank 0 | Train Epoch: 7 [22592/23491 (96%)]\tLoss: 0.131018\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:24 | INFO | Rank 0 | Train Epoch: 7 [22624/23491 (96%)]\tLoss: 0.174347\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:25 | INFO | Rank 0 | Train Epoch: 7 [22656/23491 (96%)]\tLoss: 0.026273\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:25 | INFO | Rank 0 | Train Epoch: 7 [22688/23491 (97%)]\tLoss: 0.082431\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:25 | INFO | Rank 0 | Train Epoch: 7 [22720/23491 (97%)]\tLoss: 0.028738\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:25 | INFO | Rank 0 | Train Epoch: 7 [22752/23491 (97%)]\tLoss: 0.098683\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:26 | INFO | Rank 0 | Train Epoch: 7 [22784/23491 (97%)]\tLoss: 0.056549\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:26 | INFO | Rank 0 | Train Epoch: 7 [22816/23491 (97%)]\tLoss: 0.046430\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:26 | INFO | Rank 0 | Train Epoch: 7 [22848/23491 (97%)]\tLoss: 0.038225\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:26 | INFO | Rank 0 | Train Epoch: 7 [22880/23491 (97%)]\tLoss: 0.100213\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:27 | INFO | Rank 0 | Train Epoch: 7 [22912/23491 (98%)]\tLoss: 0.090706\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:27 | INFO | Rank 0 | Train Epoch: 7 [22944/23491 (98%)]\tLoss: 0.084173\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:27 | INFO | Rank 0 | Train Epoch: 7 [22976/23491 (98%)]\tLoss: 0.156335\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:27 | INFO | Rank 0 | Train Epoch: 7 [23008/23491 (98%)]\tLoss: 0.090051\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:28 | INFO | Rank 0 | Train Epoch: 7 [23040/23491 (98%)]\tLoss: 0.029254\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:28 | INFO | Rank 0 | Train Epoch: 7 [23072/23491 (98%)]\tLoss: 0.193691\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:28 | INFO | Rank 0 | Train Epoch: 7 [23104/23491 (98%)]\tLoss: 0.184802\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:29 | INFO | Rank 0 | Train Epoch: 7 [23136/23491 (99%)]\tLoss: 0.038454\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:29 | INFO | Rank 0 | Train Epoch: 7 [23168/23491 (99%)]\tLoss: 0.110290\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:29 | INFO | Rank 0 | Train Epoch: 7 [23200/23491 (99%)]\tLoss: 0.007271\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:29 | INFO | Rank 0 | Train Epoch: 7 [23232/23491 (99%)]\tLoss: 0.023039\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:30 | INFO | Rank 0 | Train Epoch: 7 [23264/23491 (99%)]\tLoss: 0.096349\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:30 | INFO | Rank 0 | Train Epoch: 7 [23296/23491 (99%)]\tLoss: 0.017163\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:30 | INFO | Rank 0 | Train Epoch: 7 [23328/23491 (99%)]\tLoss: 0.090425\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:30 | INFO | Rank 0 | Train Epoch: 7 [23360/23491 (99%)]\tLoss: 0.013351\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:31 | INFO | Rank 0 | Train Epoch: 7 [23392/23491 (100%)]\tLoss: 0.113852\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:31 | INFO | Rank 0 | Train Epoch: 7 [23424/23491 (100%)]\tLoss: 0.069100\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:55:31 | INFO | Rank 0 | Train Epoch: 7 [23456/23491 (100%)]\tLoss: 0.127849\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "  0%|                                                   | 0/386 [00:00<?, ?it/s]2022-11-08,05:55:31 | INFO | Rank 0 | Begin to eval epoch: 8...\n",
      "100%|█████████████████████████████████████████| 386/386 [00:46<00:00,  8.36it/s]\n",
      "2022-11-08,05:56:17 | INFO | Rank 0 | Eval Epoch: 8 val_loss: 3.0736\tepoch: 8.0000\tnum_elements: 12328.0000\n",
      "2022-11-08,05:56:17 | INFO | Rank 0 | Start epoch 8\n",
      "2022-11-08,05:56:18 | INFO | Rank 0 | Train Epoch: 8 [0/23491 (0%)]\tLoss: 0.091892\tData (t) 0.035\tBatch (t) 0.249\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:18 | INFO | Rank 0 | Train Epoch: 8 [32/23491 (0%)]\tLoss: 0.067081\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:18 | INFO | Rank 0 | Train Epoch: 8 [64/23491 (0%)]\tLoss: 0.158696\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:18 | INFO | Rank 0 | Train Epoch: 8 [96/23491 (0%)]\tLoss: 0.014368\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:19 | INFO | Rank 0 | Train Epoch: 8 [128/23491 (1%)]\tLoss: 0.125785\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:19 | INFO | Rank 0 | Train Epoch: 8 [160/23491 (1%)]\tLoss: 0.080524\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:19 | INFO | Rank 0 | Train Epoch: 8 [192/23491 (1%)]\tLoss: 0.182863\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:20 | INFO | Rank 0 | Train Epoch: 8 [224/23491 (1%)]\tLoss: 0.082308\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:20 | INFO | Rank 0 | Train Epoch: 8 [256/23491 (1%)]\tLoss: 0.043265\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:20 | INFO | Rank 0 | Train Epoch: 8 [288/23491 (1%)]\tLoss: 0.073802\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:20 | INFO | Rank 0 | Train Epoch: 8 [320/23491 (1%)]\tLoss: 0.203312\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:21 | INFO | Rank 0 | Train Epoch: 8 [352/23491 (1%)]\tLoss: 0.122349\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:21 | INFO | Rank 0 | Train Epoch: 8 [384/23491 (2%)]\tLoss: 0.025920\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:21 | INFO | Rank 0 | Train Epoch: 8 [416/23491 (2%)]\tLoss: 0.010020\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:21 | INFO | Rank 0 | Train Epoch: 8 [448/23491 (2%)]\tLoss: 0.022043\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:22 | INFO | Rank 0 | Train Epoch: 8 [480/23491 (2%)]\tLoss: 0.025804\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:22 | INFO | Rank 0 | Train Epoch: 8 [512/23491 (2%)]\tLoss: 0.069364\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:22 | INFO | Rank 0 | Train Epoch: 8 [544/23491 (2%)]\tLoss: 0.052979\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:22 | INFO | Rank 0 | Train Epoch: 8 [576/23491 (2%)]\tLoss: 0.041329\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:23 | INFO | Rank 0 | Train Epoch: 8 [608/23491 (3%)]\tLoss: 0.044881\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:23 | INFO | Rank 0 | Train Epoch: 8 [640/23491 (3%)]\tLoss: 0.105298\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:23 | INFO | Rank 0 | Train Epoch: 8 [672/23491 (3%)]\tLoss: 0.082711\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:24 | INFO | Rank 0 | Train Epoch: 8 [704/23491 (3%)]\tLoss: 0.182487\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000009\tlogit_scale 4.541\n",
      "2022-11-08,05:56:24 | INFO | Rank 0 | Train Epoch: 8 [736/23491 (3%)]\tLoss: 0.143645\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:24 | INFO | Rank 0 | Train Epoch: 8 [768/23491 (3%)]\tLoss: 0.015195\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:24 | INFO | Rank 0 | Train Epoch: 8 [800/23491 (3%)]\tLoss: 0.085204\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:25 | INFO | Rank 0 | Train Epoch: 8 [832/23491 (4%)]\tLoss: 0.201782\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:25 | INFO | Rank 0 | Train Epoch: 8 [864/23491 (4%)]\tLoss: 0.020083\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:25 | INFO | Rank 0 | Train Epoch: 8 [896/23491 (4%)]\tLoss: 0.029420\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:25 | INFO | Rank 0 | Train Epoch: 8 [928/23491 (4%)]\tLoss: 0.109149\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:26 | INFO | Rank 0 | Train Epoch: 8 [960/23491 (4%)]\tLoss: 0.010034\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:26 | INFO | Rank 0 | Train Epoch: 8 [992/23491 (4%)]\tLoss: 0.051642\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:26 | INFO | Rank 0 | Train Epoch: 8 [1024/23491 (4%)]\tLoss: 0.013983\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:26 | INFO | Rank 0 | Train Epoch: 8 [1056/23491 (4%)]\tLoss: 0.011472\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:27 | INFO | Rank 0 | Train Epoch: 8 [1088/23491 (5%)]\tLoss: 0.072443\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:27 | INFO | Rank 0 | Train Epoch: 8 [1120/23491 (5%)]\tLoss: 0.051386\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:27 | INFO | Rank 0 | Train Epoch: 8 [1152/23491 (5%)]\tLoss: 0.069811\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:28 | INFO | Rank 0 | Train Epoch: 8 [1184/23491 (5%)]\tLoss: 0.070291\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:28 | INFO | Rank 0 | Train Epoch: 8 [1216/23491 (5%)]\tLoss: 0.174613\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:28 | INFO | Rank 0 | Train Epoch: 8 [1248/23491 (5%)]\tLoss: 0.040393\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:28 | INFO | Rank 0 | Train Epoch: 8 [1280/23491 (5%)]\tLoss: 0.007401\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:29 | INFO | Rank 0 | Train Epoch: 8 [1312/23491 (6%)]\tLoss: 0.011487\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:29 | INFO | Rank 0 | Train Epoch: 8 [1344/23491 (6%)]\tLoss: 0.116460\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:29 | INFO | Rank 0 | Train Epoch: 8 [1376/23491 (6%)]\tLoss: 0.017022\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:29 | INFO | Rank 0 | Train Epoch: 8 [1408/23491 (6%)]\tLoss: 0.163015\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:30 | INFO | Rank 0 | Train Epoch: 8 [1440/23491 (6%)]\tLoss: 0.038493\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:30 | INFO | Rank 0 | Train Epoch: 8 [1472/23491 (6%)]\tLoss: 0.069570\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:30 | INFO | Rank 0 | Train Epoch: 8 [1504/23491 (6%)]\tLoss: 0.062561\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:30 | INFO | Rank 0 | Train Epoch: 8 [1536/23491 (7%)]\tLoss: 0.142713\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:31 | INFO | Rank 0 | Train Epoch: 8 [1568/23491 (7%)]\tLoss: 0.062635\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:31 | INFO | Rank 0 | Train Epoch: 8 [1600/23491 (7%)]\tLoss: 0.007061\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:31 | INFO | Rank 0 | Train Epoch: 8 [1632/23491 (7%)]\tLoss: 0.023877\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:32 | INFO | Rank 0 | Train Epoch: 8 [1664/23491 (7%)]\tLoss: 0.074757\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:32 | INFO | Rank 0 | Train Epoch: 8 [1696/23491 (7%)]\tLoss: 0.200441\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:32 | INFO | Rank 0 | Train Epoch: 8 [1728/23491 (7%)]\tLoss: 0.136393\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:32 | INFO | Rank 0 | Train Epoch: 8 [1760/23491 (7%)]\tLoss: 0.097249\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:33 | INFO | Rank 0 | Train Epoch: 8 [1792/23491 (8%)]\tLoss: 0.013255\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:33 | INFO | Rank 0 | Train Epoch: 8 [1824/23491 (8%)]\tLoss: 0.054257\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:33 | INFO | Rank 0 | Train Epoch: 8 [1856/23491 (8%)]\tLoss: 0.078981\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:33 | INFO | Rank 0 | Train Epoch: 8 [1888/23491 (8%)]\tLoss: 0.042501\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:34 | INFO | Rank 0 | Train Epoch: 8 [1920/23491 (8%)]\tLoss: 0.032547\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:34 | INFO | Rank 0 | Train Epoch: 8 [1952/23491 (8%)]\tLoss: 0.065953\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:34 | INFO | Rank 0 | Train Epoch: 8 [1984/23491 (8%)]\tLoss: 0.075236\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:34 | INFO | Rank 0 | Train Epoch: 8 [2016/23491 (9%)]\tLoss: 0.083326\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:35 | INFO | Rank 0 | Train Epoch: 8 [2048/23491 (9%)]\tLoss: 0.065628\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:35 | INFO | Rank 0 | Train Epoch: 8 [2080/23491 (9%)]\tLoss: 0.092642\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:35 | INFO | Rank 0 | Train Epoch: 8 [2112/23491 (9%)]\tLoss: 0.040108\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:36 | INFO | Rank 0 | Train Epoch: 8 [2144/23491 (9%)]\tLoss: 0.017839\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:36 | INFO | Rank 0 | Train Epoch: 8 [2176/23491 (9%)]\tLoss: 0.098787\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:36 | INFO | Rank 0 | Train Epoch: 8 [2208/23491 (9%)]\tLoss: 0.018852\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:36 | INFO | Rank 0 | Train Epoch: 8 [2240/23491 (10%)]\tLoss: 0.031126\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:37 | INFO | Rank 0 | Train Epoch: 8 [2272/23491 (10%)]\tLoss: 0.082498\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:37 | INFO | Rank 0 | Train Epoch: 8 [2304/23491 (10%)]\tLoss: 0.002047\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:37 | INFO | Rank 0 | Train Epoch: 8 [2336/23491 (10%)]\tLoss: 0.076162\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:37 | INFO | Rank 0 | Train Epoch: 8 [2368/23491 (10%)]\tLoss: 0.058230\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:38 | INFO | Rank 0 | Train Epoch: 8 [2400/23491 (10%)]\tLoss: 0.031397\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:38 | INFO | Rank 0 | Train Epoch: 8 [2432/23491 (10%)]\tLoss: 0.045112\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:38 | INFO | Rank 0 | Train Epoch: 8 [2464/23491 (10%)]\tLoss: 0.066818\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:38 | INFO | Rank 0 | Train Epoch: 8 [2496/23491 (11%)]\tLoss: 0.015784\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:39 | INFO | Rank 0 | Train Epoch: 8 [2528/23491 (11%)]\tLoss: 0.097479\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:39 | INFO | Rank 0 | Train Epoch: 8 [2560/23491 (11%)]\tLoss: 0.044630\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:39 | INFO | Rank 0 | Train Epoch: 8 [2592/23491 (11%)]\tLoss: 0.095038\tData (t) 0.054\tBatch (t) 0.286\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:40 | INFO | Rank 0 | Train Epoch: 8 [2624/23491 (11%)]\tLoss: 0.031739\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:40 | INFO | Rank 0 | Train Epoch: 8 [2656/23491 (11%)]\tLoss: 0.035788\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:40 | INFO | Rank 0 | Train Epoch: 8 [2688/23491 (11%)]\tLoss: 0.008988\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:40 | INFO | Rank 0 | Train Epoch: 8 [2720/23491 (12%)]\tLoss: 0.061567\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:41 | INFO | Rank 0 | Train Epoch: 8 [2752/23491 (12%)]\tLoss: 0.148830\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:41 | INFO | Rank 0 | Train Epoch: 8 [2784/23491 (12%)]\tLoss: 0.069288\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:41 | INFO | Rank 0 | Train Epoch: 8 [2816/23491 (12%)]\tLoss: 0.020540\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:41 | INFO | Rank 0 | Train Epoch: 8 [2848/23491 (12%)]\tLoss: 0.051911\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:42 | INFO | Rank 0 | Train Epoch: 8 [2880/23491 (12%)]\tLoss: 0.047257\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:42 | INFO | Rank 0 | Train Epoch: 8 [2912/23491 (12%)]\tLoss: 0.060133\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:42 | INFO | Rank 0 | Train Epoch: 8 [2944/23491 (13%)]\tLoss: 0.116827\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:42 | INFO | Rank 0 | Train Epoch: 8 [2976/23491 (13%)]\tLoss: 0.029913\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:43 | INFO | Rank 0 | Train Epoch: 8 [3008/23491 (13%)]\tLoss: 0.140839\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:43 | INFO | Rank 0 | Train Epoch: 8 [3040/23491 (13%)]\tLoss: 0.047650\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:43 | INFO | Rank 0 | Train Epoch: 8 [3072/23491 (13%)]\tLoss: 0.025805\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:44 | INFO | Rank 0 | Train Epoch: 8 [3104/23491 (13%)]\tLoss: 0.114133\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:44 | INFO | Rank 0 | Train Epoch: 8 [3136/23491 (13%)]\tLoss: 0.075798\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:44 | INFO | Rank 0 | Train Epoch: 8 [3168/23491 (13%)]\tLoss: 0.063766\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:44 | INFO | Rank 0 | Train Epoch: 8 [3200/23491 (14%)]\tLoss: 0.005952\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:45 | INFO | Rank 0 | Train Epoch: 8 [3232/23491 (14%)]\tLoss: 0.014538\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:45 | INFO | Rank 0 | Train Epoch: 8 [3264/23491 (14%)]\tLoss: 0.083187\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:45 | INFO | Rank 0 | Train Epoch: 8 [3296/23491 (14%)]\tLoss: 0.106055\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:45 | INFO | Rank 0 | Train Epoch: 8 [3328/23491 (14%)]\tLoss: 0.156448\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:46 | INFO | Rank 0 | Train Epoch: 8 [3360/23491 (14%)]\tLoss: 0.015415\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:46 | INFO | Rank 0 | Train Epoch: 8 [3392/23491 (14%)]\tLoss: 0.107762\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:46 | INFO | Rank 0 | Train Epoch: 8 [3424/23491 (15%)]\tLoss: 0.035096\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:46 | INFO | Rank 0 | Train Epoch: 8 [3456/23491 (15%)]\tLoss: 0.102339\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:47 | INFO | Rank 0 | Train Epoch: 8 [3488/23491 (15%)]\tLoss: 0.118135\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:47 | INFO | Rank 0 | Train Epoch: 8 [3520/23491 (15%)]\tLoss: 0.028024\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:47 | INFO | Rank 0 | Train Epoch: 8 [3552/23491 (15%)]\tLoss: 0.052822\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:48 | INFO | Rank 0 | Train Epoch: 8 [3584/23491 (15%)]\tLoss: 0.027755\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000008\tlogit_scale 4.541\n",
      "2022-11-08,05:56:48 | INFO | Rank 0 | Train Epoch: 8 [3616/23491 (15%)]\tLoss: 0.016957\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:48 | INFO | Rank 0 | Train Epoch: 8 [3648/23491 (16%)]\tLoss: 0.036906\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:48 | INFO | Rank 0 | Train Epoch: 8 [3680/23491 (16%)]\tLoss: 0.083436\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:49 | INFO | Rank 0 | Train Epoch: 8 [3712/23491 (16%)]\tLoss: 0.102079\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:49 | INFO | Rank 0 | Train Epoch: 8 [3744/23491 (16%)]\tLoss: 0.090479\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:49 | INFO | Rank 0 | Train Epoch: 8 [3776/23491 (16%)]\tLoss: 0.072956\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:49 | INFO | Rank 0 | Train Epoch: 8 [3808/23491 (16%)]\tLoss: 0.059773\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:50 | INFO | Rank 0 | Train Epoch: 8 [3840/23491 (16%)]\tLoss: 0.057680\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:50 | INFO | Rank 0 | Train Epoch: 8 [3872/23491 (16%)]\tLoss: 0.021674\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:50 | INFO | Rank 0 | Train Epoch: 8 [3904/23491 (17%)]\tLoss: 0.029988\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:50 | INFO | Rank 0 | Train Epoch: 8 [3936/23491 (17%)]\tLoss: 0.161057\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:51 | INFO | Rank 0 | Train Epoch: 8 [3968/23491 (17%)]\tLoss: 0.000746\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:51 | INFO | Rank 0 | Train Epoch: 8 [4000/23491 (17%)]\tLoss: 0.067153\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:51 | INFO | Rank 0 | Train Epoch: 8 [4032/23491 (17%)]\tLoss: 0.094224\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:52 | INFO | Rank 0 | Train Epoch: 8 [4064/23491 (17%)]\tLoss: 0.084648\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:52 | INFO | Rank 0 | Train Epoch: 8 [4096/23491 (17%)]\tLoss: 0.009924\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:52 | INFO | Rank 0 | Train Epoch: 8 [4128/23491 (18%)]\tLoss: 0.011380\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:52 | INFO | Rank 0 | Train Epoch: 8 [4160/23491 (18%)]\tLoss: 0.017465\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:53 | INFO | Rank 0 | Train Epoch: 8 [4192/23491 (18%)]\tLoss: 0.018096\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:53 | INFO | Rank 0 | Train Epoch: 8 [4224/23491 (18%)]\tLoss: 0.013681\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:53 | INFO | Rank 0 | Train Epoch: 8 [4256/23491 (18%)]\tLoss: 0.054844\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:53 | INFO | Rank 0 | Train Epoch: 8 [4288/23491 (18%)]\tLoss: 0.089404\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:54 | INFO | Rank 0 | Train Epoch: 8 [4320/23491 (18%)]\tLoss: 0.112747\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:54 | INFO | Rank 0 | Train Epoch: 8 [4352/23491 (19%)]\tLoss: 0.125416\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:54 | INFO | Rank 0 | Train Epoch: 8 [4384/23491 (19%)]\tLoss: 0.026957\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:54 | INFO | Rank 0 | Train Epoch: 8 [4416/23491 (19%)]\tLoss: 0.065144\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:55 | INFO | Rank 0 | Train Epoch: 8 [4448/23491 (19%)]\tLoss: 0.120535\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:55 | INFO | Rank 0 | Train Epoch: 8 [4480/23491 (19%)]\tLoss: 0.068919\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:55 | INFO | Rank 0 | Train Epoch: 8 [4512/23491 (19%)]\tLoss: 0.131379\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:56 | INFO | Rank 0 | Train Epoch: 8 [4544/23491 (19%)]\tLoss: 0.041817\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:56 | INFO | Rank 0 | Train Epoch: 8 [4576/23491 (19%)]\tLoss: 0.016526\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:56 | INFO | Rank 0 | Train Epoch: 8 [4608/23491 (20%)]\tLoss: 0.019860\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:56 | INFO | Rank 0 | Train Epoch: 8 [4640/23491 (20%)]\tLoss: 0.017432\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:57 | INFO | Rank 0 | Train Epoch: 8 [4672/23491 (20%)]\tLoss: 0.094761\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:57 | INFO | Rank 0 | Train Epoch: 8 [4704/23491 (20%)]\tLoss: 0.004192\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:57 | INFO | Rank 0 | Train Epoch: 8 [4736/23491 (20%)]\tLoss: 0.103900\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:57 | INFO | Rank 0 | Train Epoch: 8 [4768/23491 (20%)]\tLoss: 0.099640\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:58 | INFO | Rank 0 | Train Epoch: 8 [4800/23491 (20%)]\tLoss: 0.086549\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:58 | INFO | Rank 0 | Train Epoch: 8 [4832/23491 (21%)]\tLoss: 0.076545\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:58 | INFO | Rank 0 | Train Epoch: 8 [4864/23491 (21%)]\tLoss: 0.017525\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:58 | INFO | Rank 0 | Train Epoch: 8 [4896/23491 (21%)]\tLoss: 0.150886\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:59 | INFO | Rank 0 | Train Epoch: 8 [4928/23491 (21%)]\tLoss: 0.044722\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:59 | INFO | Rank 0 | Train Epoch: 8 [4960/23491 (21%)]\tLoss: 0.015640\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:56:59 | INFO | Rank 0 | Train Epoch: 8 [4992/23491 (21%)]\tLoss: 0.083436\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:00 | INFO | Rank 0 | Train Epoch: 8 [5024/23491 (21%)]\tLoss: 0.080185\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:00 | INFO | Rank 0 | Train Epoch: 8 [5056/23491 (22%)]\tLoss: 0.106871\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:00 | INFO | Rank 0 | Train Epoch: 8 [5088/23491 (22%)]\tLoss: 0.025196\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:00 | INFO | Rank 0 | Train Epoch: 8 [5120/23491 (22%)]\tLoss: 0.018072\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:01 | INFO | Rank 0 | Train Epoch: 8 [5152/23491 (22%)]\tLoss: 0.018129\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:01 | INFO | Rank 0 | Train Epoch: 8 [5184/23491 (22%)]\tLoss: 0.239078\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:01 | INFO | Rank 0 | Train Epoch: 8 [5216/23491 (22%)]\tLoss: 0.052758\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:01 | INFO | Rank 0 | Train Epoch: 8 [5248/23491 (22%)]\tLoss: 0.164360\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:02 | INFO | Rank 0 | Train Epoch: 8 [5280/23491 (22%)]\tLoss: 0.131011\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:02 | INFO | Rank 0 | Train Epoch: 8 [5312/23491 (23%)]\tLoss: 0.065216\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:02 | INFO | Rank 0 | Train Epoch: 8 [5344/23491 (23%)]\tLoss: 0.026996\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:02 | INFO | Rank 0 | Train Epoch: 8 [5376/23491 (23%)]\tLoss: 0.048077\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:03 | INFO | Rank 0 | Train Epoch: 8 [5408/23491 (23%)]\tLoss: 0.180701\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:03 | INFO | Rank 0 | Train Epoch: 8 [5440/23491 (23%)]\tLoss: 0.033588\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:03 | INFO | Rank 0 | Train Epoch: 8 [5472/23491 (23%)]\tLoss: 0.139406\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:04 | INFO | Rank 0 | Train Epoch: 8 [5504/23491 (23%)]\tLoss: 0.011103\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:04 | INFO | Rank 0 | Train Epoch: 8 [5536/23491 (24%)]\tLoss: 0.055536\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:04 | INFO | Rank 0 | Train Epoch: 8 [5568/23491 (24%)]\tLoss: 0.100719\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:04 | INFO | Rank 0 | Train Epoch: 8 [5600/23491 (24%)]\tLoss: 0.024309\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:05 | INFO | Rank 0 | Train Epoch: 8 [5632/23491 (24%)]\tLoss: 0.069254\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:05 | INFO | Rank 0 | Train Epoch: 8 [5664/23491 (24%)]\tLoss: 0.064013\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:05 | INFO | Rank 0 | Train Epoch: 8 [5696/23491 (24%)]\tLoss: 0.002270\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:05 | INFO | Rank 0 | Train Epoch: 8 [5728/23491 (24%)]\tLoss: 0.060693\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:06 | INFO | Rank 0 | Train Epoch: 8 [5760/23491 (25%)]\tLoss: 0.043138\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:06 | INFO | Rank 0 | Train Epoch: 8 [5792/23491 (25%)]\tLoss: 0.065543\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:06 | INFO | Rank 0 | Train Epoch: 8 [5824/23491 (25%)]\tLoss: 0.034567\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:06 | INFO | Rank 0 | Train Epoch: 8 [5856/23491 (25%)]\tLoss: 0.128530\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:07 | INFO | Rank 0 | Train Epoch: 8 [5888/23491 (25%)]\tLoss: 0.153837\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:07 | INFO | Rank 0 | Train Epoch: 8 [5920/23491 (25%)]\tLoss: 0.032017\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:07 | INFO | Rank 0 | Train Epoch: 8 [5952/23491 (25%)]\tLoss: 0.048420\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:08 | INFO | Rank 0 | Train Epoch: 8 [5984/23491 (25%)]\tLoss: 0.073544\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:08 | INFO | Rank 0 | Train Epoch: 8 [6016/23491 (26%)]\tLoss: 0.021220\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:08 | INFO | Rank 0 | Train Epoch: 8 [6048/23491 (26%)]\tLoss: 0.108699\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:08 | INFO | Rank 0 | Train Epoch: 8 [6080/23491 (26%)]\tLoss: 0.102137\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:09 | INFO | Rank 0 | Train Epoch: 8 [6112/23491 (26%)]\tLoss: 0.056622\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:09 | INFO | Rank 0 | Train Epoch: 8 [6144/23491 (26%)]\tLoss: 0.023554\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:09 | INFO | Rank 0 | Train Epoch: 8 [6176/23491 (26%)]\tLoss: 0.145068\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:09 | INFO | Rank 0 | Train Epoch: 8 [6208/23491 (26%)]\tLoss: 0.102136\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:10 | INFO | Rank 0 | Train Epoch: 8 [6240/23491 (27%)]\tLoss: 0.040833\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:10 | INFO | Rank 0 | Train Epoch: 8 [6272/23491 (27%)]\tLoss: 0.032579\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:10 | INFO | Rank 0 | Train Epoch: 8 [6304/23491 (27%)]\tLoss: 0.084407\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:10 | INFO | Rank 0 | Train Epoch: 8 [6336/23491 (27%)]\tLoss: 0.004015\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:11 | INFO | Rank 0 | Train Epoch: 8 [6368/23491 (27%)]\tLoss: 0.014814\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:11 | INFO | Rank 0 | Train Epoch: 8 [6400/23491 (27%)]\tLoss: 0.062571\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:11 | INFO | Rank 0 | Train Epoch: 8 [6432/23491 (27%)]\tLoss: 0.034270\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:11 | INFO | Rank 0 | Train Epoch: 8 [6464/23491 (28%)]\tLoss: 0.073983\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:12 | INFO | Rank 0 | Train Epoch: 8 [6496/23491 (28%)]\tLoss: 0.034822\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:12 | INFO | Rank 0 | Train Epoch: 8 [6528/23491 (28%)]\tLoss: 0.080653\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:12 | INFO | Rank 0 | Train Epoch: 8 [6560/23491 (28%)]\tLoss: 0.033396\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:13 | INFO | Rank 0 | Train Epoch: 8 [6592/23491 (28%)]\tLoss: 0.069968\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:13 | INFO | Rank 0 | Train Epoch: 8 [6624/23491 (28%)]\tLoss: 0.052535\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:13 | INFO | Rank 0 | Train Epoch: 8 [6656/23491 (28%)]\tLoss: 0.035057\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:13 | INFO | Rank 0 | Train Epoch: 8 [6688/23491 (28%)]\tLoss: 0.045320\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000007\tlogit_scale 4.541\n",
      "2022-11-08,05:57:14 | INFO | Rank 0 | Train Epoch: 8 [6720/23491 (29%)]\tLoss: 0.038722\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:14 | INFO | Rank 0 | Train Epoch: 8 [6752/23491 (29%)]\tLoss: 0.052255\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:14 | INFO | Rank 0 | Train Epoch: 8 [6784/23491 (29%)]\tLoss: 0.022728\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:14 | INFO | Rank 0 | Train Epoch: 8 [6816/23491 (29%)]\tLoss: 0.115768\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:15 | INFO | Rank 0 | Train Epoch: 8 [6848/23491 (29%)]\tLoss: 0.099797\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:15 | INFO | Rank 0 | Train Epoch: 8 [6880/23491 (29%)]\tLoss: 0.010801\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:15 | INFO | Rank 0 | Train Epoch: 8 [6912/23491 (29%)]\tLoss: 0.053192\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:15 | INFO | Rank 0 | Train Epoch: 8 [6944/23491 (30%)]\tLoss: 0.075394\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:16 | INFO | Rank 0 | Train Epoch: 8 [6976/23491 (30%)]\tLoss: 0.015452\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:16 | INFO | Rank 0 | Train Epoch: 8 [7008/23491 (30%)]\tLoss: 0.018076\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:16 | INFO | Rank 0 | Train Epoch: 8 [7040/23491 (30%)]\tLoss: 0.158335\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:17 | INFO | Rank 0 | Train Epoch: 8 [7072/23491 (30%)]\tLoss: 0.016082\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:17 | INFO | Rank 0 | Train Epoch: 8 [7104/23491 (30%)]\tLoss: 0.009829\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:17 | INFO | Rank 0 | Train Epoch: 8 [7136/23491 (30%)]\tLoss: 0.035544\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:17 | INFO | Rank 0 | Train Epoch: 8 [7168/23491 (31%)]\tLoss: 0.001614\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:18 | INFO | Rank 0 | Train Epoch: 8 [7200/23491 (31%)]\tLoss: 0.047699\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:18 | INFO | Rank 0 | Train Epoch: 8 [7232/23491 (31%)]\tLoss: 0.038352\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:18 | INFO | Rank 0 | Train Epoch: 8 [7264/23491 (31%)]\tLoss: 0.018847\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:18 | INFO | Rank 0 | Train Epoch: 8 [7296/23491 (31%)]\tLoss: 0.157151\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:19 | INFO | Rank 0 | Train Epoch: 8 [7328/23491 (31%)]\tLoss: 0.123022\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:19 | INFO | Rank 0 | Train Epoch: 8 [7360/23491 (31%)]\tLoss: 0.034645\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:19 | INFO | Rank 0 | Train Epoch: 8 [7392/23491 (31%)]\tLoss: 0.047786\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:19 | INFO | Rank 0 | Train Epoch: 8 [7424/23491 (32%)]\tLoss: 0.077447\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:20 | INFO | Rank 0 | Train Epoch: 8 [7456/23491 (32%)]\tLoss: 0.060183\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:20 | INFO | Rank 0 | Train Epoch: 8 [7488/23491 (32%)]\tLoss: 0.055823\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:20 | INFO | Rank 0 | Train Epoch: 8 [7520/23491 (32%)]\tLoss: 0.022469\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:21 | INFO | Rank 0 | Train Epoch: 8 [7552/23491 (32%)]\tLoss: 0.022063\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.541\n",
      "2022-11-08,05:57:21 | INFO | Rank 0 | Train Epoch: 8 [7584/23491 (32%)]\tLoss: 0.118263\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:21 | INFO | Rank 0 | Train Epoch: 8 [7616/23491 (32%)]\tLoss: 0.006825\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:21 | INFO | Rank 0 | Train Epoch: 8 [7648/23491 (33%)]\tLoss: 0.055225\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:22 | INFO | Rank 0 | Train Epoch: 8 [7680/23491 (33%)]\tLoss: 0.063877\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:22 | INFO | Rank 0 | Train Epoch: 8 [7712/23491 (33%)]\tLoss: 0.001163\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:22 | INFO | Rank 0 | Train Epoch: 8 [7744/23491 (33%)]\tLoss: 0.040795\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:22 | INFO | Rank 0 | Train Epoch: 8 [7776/23491 (33%)]\tLoss: 0.109628\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:23 | INFO | Rank 0 | Train Epoch: 8 [7808/23491 (33%)]\tLoss: 0.120668\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:23 | INFO | Rank 0 | Train Epoch: 8 [7840/23491 (33%)]\tLoss: 0.003324\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:23 | INFO | Rank 0 | Train Epoch: 8 [7872/23491 (34%)]\tLoss: 0.084686\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:23 | INFO | Rank 0 | Train Epoch: 8 [7904/23491 (34%)]\tLoss: 0.052084\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:24 | INFO | Rank 0 | Train Epoch: 8 [7936/23491 (34%)]\tLoss: 0.011644\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:24 | INFO | Rank 0 | Train Epoch: 8 [7968/23491 (34%)]\tLoss: 0.055379\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:24 | INFO | Rank 0 | Train Epoch: 8 [8000/23491 (34%)]\tLoss: 0.092528\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:25 | INFO | Rank 0 | Train Epoch: 8 [8032/23491 (34%)]\tLoss: 0.061809\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:25 | INFO | Rank 0 | Train Epoch: 8 [8064/23491 (34%)]\tLoss: 0.055628\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:25 | INFO | Rank 0 | Train Epoch: 8 [8096/23491 (34%)]\tLoss: 0.091753\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:25 | INFO | Rank 0 | Train Epoch: 8 [8128/23491 (35%)]\tLoss: 0.136706\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:26 | INFO | Rank 0 | Train Epoch: 8 [8160/23491 (35%)]\tLoss: 0.034207\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:26 | INFO | Rank 0 | Train Epoch: 8 [8192/23491 (35%)]\tLoss: 0.156033\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:26 | INFO | Rank 0 | Train Epoch: 8 [8224/23491 (35%)]\tLoss: 0.080293\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:26 | INFO | Rank 0 | Train Epoch: 8 [8256/23491 (35%)]\tLoss: 0.182096\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:27 | INFO | Rank 0 | Train Epoch: 8 [8288/23491 (35%)]\tLoss: 0.138213\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:27 | INFO | Rank 0 | Train Epoch: 8 [8320/23491 (35%)]\tLoss: 0.068749\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:27 | INFO | Rank 0 | Train Epoch: 8 [8352/23491 (36%)]\tLoss: 0.018244\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:27 | INFO | Rank 0 | Train Epoch: 8 [8384/23491 (36%)]\tLoss: 0.064683\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:28 | INFO | Rank 0 | Train Epoch: 8 [8416/23491 (36%)]\tLoss: 0.128200\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:28 | INFO | Rank 0 | Train Epoch: 8 [8448/23491 (36%)]\tLoss: 0.128101\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:28 | INFO | Rank 0 | Train Epoch: 8 [8480/23491 (36%)]\tLoss: 0.072252\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:29 | INFO | Rank 0 | Train Epoch: 8 [8512/23491 (36%)]\tLoss: 0.028617\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:29 | INFO | Rank 0 | Train Epoch: 8 [8544/23491 (36%)]\tLoss: 0.025134\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:29 | INFO | Rank 0 | Train Epoch: 8 [8576/23491 (37%)]\tLoss: 0.004644\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:29 | INFO | Rank 0 | Train Epoch: 8 [8608/23491 (37%)]\tLoss: 0.005902\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:30 | INFO | Rank 0 | Train Epoch: 8 [8640/23491 (37%)]\tLoss: 0.078730\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:30 | INFO | Rank 0 | Train Epoch: 8 [8672/23491 (37%)]\tLoss: 0.134955\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:30 | INFO | Rank 0 | Train Epoch: 8 [8704/23491 (37%)]\tLoss: 0.154665\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:30 | INFO | Rank 0 | Train Epoch: 8 [8736/23491 (37%)]\tLoss: 0.049444\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:31 | INFO | Rank 0 | Train Epoch: 8 [8768/23491 (37%)]\tLoss: 0.040924\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:31 | INFO | Rank 0 | Train Epoch: 8 [8800/23491 (37%)]\tLoss: 0.074040\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:31 | INFO | Rank 0 | Train Epoch: 8 [8832/23491 (38%)]\tLoss: 0.026006\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:31 | INFO | Rank 0 | Train Epoch: 8 [8864/23491 (38%)]\tLoss: 0.029046\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:32 | INFO | Rank 0 | Train Epoch: 8 [8896/23491 (38%)]\tLoss: 0.030163\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:32 | INFO | Rank 0 | Train Epoch: 8 [8928/23491 (38%)]\tLoss: 0.021651\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:32 | INFO | Rank 0 | Train Epoch: 8 [8960/23491 (38%)]\tLoss: 0.084590\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:33 | INFO | Rank 0 | Train Epoch: 8 [8992/23491 (38%)]\tLoss: 0.088398\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:33 | INFO | Rank 0 | Train Epoch: 8 [9024/23491 (38%)]\tLoss: 0.036746\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:33 | INFO | Rank 0 | Train Epoch: 8 [9056/23491 (39%)]\tLoss: 0.101138\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:33 | INFO | Rank 0 | Train Epoch: 8 [9088/23491 (39%)]\tLoss: 0.015421\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:34 | INFO | Rank 0 | Train Epoch: 8 [9120/23491 (39%)]\tLoss: 0.101353\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:34 | INFO | Rank 0 | Train Epoch: 8 [9152/23491 (39%)]\tLoss: 0.023944\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:34 | INFO | Rank 0 | Train Epoch: 8 [9184/23491 (39%)]\tLoss: 0.026202\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:34 | INFO | Rank 0 | Train Epoch: 8 [9216/23491 (39%)]\tLoss: 0.012944\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:35 | INFO | Rank 0 | Train Epoch: 8 [9248/23491 (39%)]\tLoss: 0.029257\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:35 | INFO | Rank 0 | Train Epoch: 8 [9280/23491 (40%)]\tLoss: 0.045492\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:35 | INFO | Rank 0 | Train Epoch: 8 [9312/23491 (40%)]\tLoss: 0.061870\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:35 | INFO | Rank 0 | Train Epoch: 8 [9344/23491 (40%)]\tLoss: 0.098410\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:36 | INFO | Rank 0 | Train Epoch: 8 [9376/23491 (40%)]\tLoss: 0.007615\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:36 | INFO | Rank 0 | Train Epoch: 8 [9408/23491 (40%)]\tLoss: 0.114893\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:36 | INFO | Rank 0 | Train Epoch: 8 [9440/23491 (40%)]\tLoss: 0.028727\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:37 | INFO | Rank 0 | Train Epoch: 8 [9472/23491 (40%)]\tLoss: 0.064949\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:37 | INFO | Rank 0 | Train Epoch: 8 [9504/23491 (40%)]\tLoss: 0.089471\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:37 | INFO | Rank 0 | Train Epoch: 8 [9536/23491 (41%)]\tLoss: 0.076725\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:37 | INFO | Rank 0 | Train Epoch: 8 [9568/23491 (41%)]\tLoss: 0.117642\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:38 | INFO | Rank 0 | Train Epoch: 8 [9600/23491 (41%)]\tLoss: 0.019832\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:38 | INFO | Rank 0 | Train Epoch: 8 [9632/23491 (41%)]\tLoss: 0.036886\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:38 | INFO | Rank 0 | Train Epoch: 8 [9664/23491 (41%)]\tLoss: 0.041115\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:38 | INFO | Rank 0 | Train Epoch: 8 [9696/23491 (41%)]\tLoss: 0.034345\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:39 | INFO | Rank 0 | Train Epoch: 8 [9728/23491 (41%)]\tLoss: 0.030520\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:39 | INFO | Rank 0 | Train Epoch: 8 [9760/23491 (42%)]\tLoss: 0.072200\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:39 | INFO | Rank 0 | Train Epoch: 8 [9792/23491 (42%)]\tLoss: 0.020891\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:39 | INFO | Rank 0 | Train Epoch: 8 [9824/23491 (42%)]\tLoss: 0.208402\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:40 | INFO | Rank 0 | Train Epoch: 8 [9856/23491 (42%)]\tLoss: 0.012200\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:40 | INFO | Rank 0 | Train Epoch: 8 [9888/23491 (42%)]\tLoss: 0.003994\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:40 | INFO | Rank 0 | Train Epoch: 8 [9920/23491 (42%)]\tLoss: 0.045224\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:40 | INFO | Rank 0 | Train Epoch: 8 [9952/23491 (42%)]\tLoss: 0.059964\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:41 | INFO | Rank 0 | Train Epoch: 8 [9984/23491 (43%)]\tLoss: 0.027181\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000006\tlogit_scale 4.542\n",
      "2022-11-08,05:57:41 | INFO | Rank 0 | Train Epoch: 8 [10016/23491 (43%)]\tLoss: 0.104166\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:41 | INFO | Rank 0 | Train Epoch: 8 [10048/23491 (43%)]\tLoss: 0.065900\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:42 | INFO | Rank 0 | Train Epoch: 8 [10080/23491 (43%)]\tLoss: 0.039229\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:42 | INFO | Rank 0 | Train Epoch: 8 [10112/23491 (43%)]\tLoss: 0.026599\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:42 | INFO | Rank 0 | Train Epoch: 8 [10144/23491 (43%)]\tLoss: 0.059814\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:42 | INFO | Rank 0 | Train Epoch: 8 [10176/23491 (43%)]\tLoss: 0.058841\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:43 | INFO | Rank 0 | Train Epoch: 8 [10208/23491 (43%)]\tLoss: 0.048530\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:43 | INFO | Rank 0 | Train Epoch: 8 [10240/23491 (44%)]\tLoss: 0.000932\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:43 | INFO | Rank 0 | Train Epoch: 8 [10272/23491 (44%)]\tLoss: 0.175578\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:43 | INFO | Rank 0 | Train Epoch: 8 [10304/23491 (44%)]\tLoss: 0.026346\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:44 | INFO | Rank 0 | Train Epoch: 8 [10336/23491 (44%)]\tLoss: 0.039347\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:44 | INFO | Rank 0 | Train Epoch: 8 [10368/23491 (44%)]\tLoss: 0.115574\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:44 | INFO | Rank 0 | Train Epoch: 8 [10400/23491 (44%)]\tLoss: 0.029498\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:44 | INFO | Rank 0 | Train Epoch: 8 [10432/23491 (44%)]\tLoss: 0.110641\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:45 | INFO | Rank 0 | Train Epoch: 8 [10464/23491 (45%)]\tLoss: 0.089782\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:45 | INFO | Rank 0 | Train Epoch: 8 [10496/23491 (45%)]\tLoss: 0.006613\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:45 | INFO | Rank 0 | Train Epoch: 8 [10528/23491 (45%)]\tLoss: 0.104843\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:46 | INFO | Rank 0 | Train Epoch: 8 [10560/23491 (45%)]\tLoss: 0.050265\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:46 | INFO | Rank 0 | Train Epoch: 8 [10592/23491 (45%)]\tLoss: 0.010037\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:46 | INFO | Rank 0 | Train Epoch: 8 [10624/23491 (45%)]\tLoss: 0.027646\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:46 | INFO | Rank 0 | Train Epoch: 8 [10656/23491 (45%)]\tLoss: 0.070375\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:47 | INFO | Rank 0 | Train Epoch: 8 [10688/23491 (46%)]\tLoss: 0.064179\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:47 | INFO | Rank 0 | Train Epoch: 8 [10720/23491 (46%)]\tLoss: 0.094676\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:47 | INFO | Rank 0 | Train Epoch: 8 [10752/23491 (46%)]\tLoss: 0.156682\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:47 | INFO | Rank 0 | Train Epoch: 8 [10784/23491 (46%)]\tLoss: 0.082151\tData (t) 0.055\tBatch (t) 0.269\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:48 | INFO | Rank 0 | Train Epoch: 8 [10816/23491 (46%)]\tLoss: 0.015379\tData (t) 0.056\tBatch (t) 0.269\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:48 | INFO | Rank 0 | Train Epoch: 8 [10848/23491 (46%)]\tLoss: 0.042881\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:48 | INFO | Rank 0 | Train Epoch: 8 [10880/23491 (46%)]\tLoss: 0.015950\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:48 | INFO | Rank 0 | Train Epoch: 8 [10912/23491 (46%)]\tLoss: 0.039072\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:49 | INFO | Rank 0 | Train Epoch: 8 [10944/23491 (47%)]\tLoss: 0.048603\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:49 | INFO | Rank 0 | Train Epoch: 8 [10976/23491 (47%)]\tLoss: 0.007914\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:49 | INFO | Rank 0 | Train Epoch: 8 [11008/23491 (47%)]\tLoss: 0.079242\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:50 | INFO | Rank 0 | Train Epoch: 8 [11040/23491 (47%)]\tLoss: 0.206309\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:50 | INFO | Rank 0 | Train Epoch: 8 [11072/23491 (47%)]\tLoss: 0.172586\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:50 | INFO | Rank 0 | Train Epoch: 8 [11104/23491 (47%)]\tLoss: 0.080829\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:50 | INFO | Rank 0 | Train Epoch: 8 [11136/23491 (47%)]\tLoss: 0.038574\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:51 | INFO | Rank 0 | Train Epoch: 8 [11168/23491 (48%)]\tLoss: 0.074397\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:51 | INFO | Rank 0 | Train Epoch: 8 [11200/23491 (48%)]\tLoss: 0.200658\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:51 | INFO | Rank 0 | Train Epoch: 8 [11232/23491 (48%)]\tLoss: 0.003139\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:51 | INFO | Rank 0 | Train Epoch: 8 [11264/23491 (48%)]\tLoss: 0.074664\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:52 | INFO | Rank 0 | Train Epoch: 8 [11296/23491 (48%)]\tLoss: 0.032629\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:52 | INFO | Rank 0 | Train Epoch: 8 [11328/23491 (48%)]\tLoss: 0.129104\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:52 | INFO | Rank 0 | Train Epoch: 8 [11360/23491 (48%)]\tLoss: 0.080028\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:52 | INFO | Rank 0 | Train Epoch: 8 [11392/23491 (49%)]\tLoss: 0.247046\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:53 | INFO | Rank 0 | Train Epoch: 8 [11424/23491 (49%)]\tLoss: 0.175419\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:53 | INFO | Rank 0 | Train Epoch: 8 [11456/23491 (49%)]\tLoss: 0.023449\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:53 | INFO | Rank 0 | Train Epoch: 8 [11488/23491 (49%)]\tLoss: 0.085517\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:54 | INFO | Rank 0 | Train Epoch: 8 [11520/23491 (49%)]\tLoss: 0.032064\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:54 | INFO | Rank 0 | Train Epoch: 8 [11552/23491 (49%)]\tLoss: 0.054895\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:54 | INFO | Rank 0 | Train Epoch: 8 [11584/23491 (49%)]\tLoss: 0.013435\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:54 | INFO | Rank 0 | Train Epoch: 8 [11616/23491 (49%)]\tLoss: 0.018005\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:55 | INFO | Rank 0 | Train Epoch: 8 [11648/23491 (50%)]\tLoss: 0.129443\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:55 | INFO | Rank 0 | Train Epoch: 8 [11680/23491 (50%)]\tLoss: 0.012204\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:55 | INFO | Rank 0 | Train Epoch: 8 [11712/23491 (50%)]\tLoss: 0.033030\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:55 | INFO | Rank 0 | Train Epoch: 8 [11744/23491 (50%)]\tLoss: 0.067676\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:56 | INFO | Rank 0 | Train Epoch: 8 [11776/23491 (50%)]\tLoss: 0.008786\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:56 | INFO | Rank 0 | Train Epoch: 8 [11808/23491 (50%)]\tLoss: 0.090706\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:56 | INFO | Rank 0 | Train Epoch: 8 [11840/23491 (50%)]\tLoss: 0.061809\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:56 | INFO | Rank 0 | Train Epoch: 8 [11872/23491 (51%)]\tLoss: 0.045460\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:57 | INFO | Rank 0 | Train Epoch: 8 [11904/23491 (51%)]\tLoss: 0.018732\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:57 | INFO | Rank 0 | Train Epoch: 8 [11936/23491 (51%)]\tLoss: 0.023024\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:57 | INFO | Rank 0 | Train Epoch: 8 [11968/23491 (51%)]\tLoss: 0.164793\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:58 | INFO | Rank 0 | Train Epoch: 8 [12000/23491 (51%)]\tLoss: 0.029178\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:58 | INFO | Rank 0 | Train Epoch: 8 [12032/23491 (51%)]\tLoss: 0.006108\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:58 | INFO | Rank 0 | Train Epoch: 8 [12064/23491 (51%)]\tLoss: 0.210266\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:58 | INFO | Rank 0 | Train Epoch: 8 [12096/23491 (51%)]\tLoss: 0.103390\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:59 | INFO | Rank 0 | Train Epoch: 8 [12128/23491 (52%)]\tLoss: 0.091491\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:59 | INFO | Rank 0 | Train Epoch: 8 [12160/23491 (52%)]\tLoss: 0.188656\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:59 | INFO | Rank 0 | Train Epoch: 8 [12192/23491 (52%)]\tLoss: 0.047006\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:57:59 | INFO | Rank 0 | Train Epoch: 8 [12224/23491 (52%)]\tLoss: 0.062350\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:00 | INFO | Rank 0 | Train Epoch: 8 [12256/23491 (52%)]\tLoss: 0.129263\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:00 | INFO | Rank 0 | Train Epoch: 8 [12288/23491 (52%)]\tLoss: 0.088433\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:00 | INFO | Rank 0 | Train Epoch: 8 [12320/23491 (52%)]\tLoss: 0.007113\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:00 | INFO | Rank 0 | Train Epoch: 8 [12352/23491 (53%)]\tLoss: 0.005870\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:01 | INFO | Rank 0 | Train Epoch: 8 [12384/23491 (53%)]\tLoss: 0.015704\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:01 | INFO | Rank 0 | Train Epoch: 8 [12416/23491 (53%)]\tLoss: 0.002849\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:01 | INFO | Rank 0 | Train Epoch: 8 [12448/23491 (53%)]\tLoss: 0.042423\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:02 | INFO | Rank 0 | Train Epoch: 8 [12480/23491 (53%)]\tLoss: 0.030084\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:02 | INFO | Rank 0 | Train Epoch: 8 [12512/23491 (53%)]\tLoss: 0.005990\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:02 | INFO | Rank 0 | Train Epoch: 8 [12544/23491 (53%)]\tLoss: 0.087169\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:02 | INFO | Rank 0 | Train Epoch: 8 [12576/23491 (54%)]\tLoss: 0.089614\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:03 | INFO | Rank 0 | Train Epoch: 8 [12608/23491 (54%)]\tLoss: 0.043573\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:03 | INFO | Rank 0 | Train Epoch: 8 [12640/23491 (54%)]\tLoss: 0.101665\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:03 | INFO | Rank 0 | Train Epoch: 8 [12672/23491 (54%)]\tLoss: 0.027452\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:03 | INFO | Rank 0 | Train Epoch: 8 [12704/23491 (54%)]\tLoss: 0.017243\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:04 | INFO | Rank 0 | Train Epoch: 8 [12736/23491 (54%)]\tLoss: 0.065716\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:04 | INFO | Rank 0 | Train Epoch: 8 [12768/23491 (54%)]\tLoss: 0.253434\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:04 | INFO | Rank 0 | Train Epoch: 8 [12800/23491 (54%)]\tLoss: 0.061735\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:04 | INFO | Rank 0 | Train Epoch: 8 [12832/23491 (55%)]\tLoss: 0.058679\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:05 | INFO | Rank 0 | Train Epoch: 8 [12864/23491 (55%)]\tLoss: 0.016767\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:05 | INFO | Rank 0 | Train Epoch: 8 [12896/23491 (55%)]\tLoss: 0.102705\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:05 | INFO | Rank 0 | Train Epoch: 8 [12928/23491 (55%)]\tLoss: 0.133118\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:06 | INFO | Rank 0 | Train Epoch: 8 [12960/23491 (55%)]\tLoss: 0.127144\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:06 | INFO | Rank 0 | Train Epoch: 8 [12992/23491 (55%)]\tLoss: 0.090112\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:06 | INFO | Rank 0 | Train Epoch: 8 [13024/23491 (55%)]\tLoss: 0.039108\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:06 | INFO | Rank 0 | Train Epoch: 8 [13056/23491 (56%)]\tLoss: 0.240488\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:07 | INFO | Rank 0 | Train Epoch: 8 [13088/23491 (56%)]\tLoss: 0.004191\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:07 | INFO | Rank 0 | Train Epoch: 8 [13120/23491 (56%)]\tLoss: 0.087159\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:07 | INFO | Rank 0 | Train Epoch: 8 [13152/23491 (56%)]\tLoss: 0.021826\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:07 | INFO | Rank 0 | Train Epoch: 8 [13184/23491 (56%)]\tLoss: 0.021004\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:08 | INFO | Rank 0 | Train Epoch: 8 [13216/23491 (56%)]\tLoss: 0.027190\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:08 | INFO | Rank 0 | Train Epoch: 8 [13248/23491 (56%)]\tLoss: 0.119005\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:08 | INFO | Rank 0 | Train Epoch: 8 [13280/23491 (57%)]\tLoss: 0.034808\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:08 | INFO | Rank 0 | Train Epoch: 8 [13312/23491 (57%)]\tLoss: 0.023073\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:09 | INFO | Rank 0 | Train Epoch: 8 [13344/23491 (57%)]\tLoss: 0.007341\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:09 | INFO | Rank 0 | Train Epoch: 8 [13376/23491 (57%)]\tLoss: 0.064436\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:09 | INFO | Rank 0 | Train Epoch: 8 [13408/23491 (57%)]\tLoss: 0.032301\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:10 | INFO | Rank 0 | Train Epoch: 8 [13440/23491 (57%)]\tLoss: 0.051890\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:10 | INFO | Rank 0 | Train Epoch: 8 [13472/23491 (57%)]\tLoss: 0.030731\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:10 | INFO | Rank 0 | Train Epoch: 8 [13504/23491 (57%)]\tLoss: 0.094304\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:10 | INFO | Rank 0 | Train Epoch: 8 [13536/23491 (58%)]\tLoss: 0.037131\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:11 | INFO | Rank 0 | Train Epoch: 8 [13568/23491 (58%)]\tLoss: 0.095444\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:11 | INFO | Rank 0 | Train Epoch: 8 [13600/23491 (58%)]\tLoss: 0.029392\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000005\tlogit_scale 4.542\n",
      "2022-11-08,05:58:11 | INFO | Rank 0 | Train Epoch: 8 [13632/23491 (58%)]\tLoss: 0.163149\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:11 | INFO | Rank 0 | Train Epoch: 8 [13664/23491 (58%)]\tLoss: 0.088961\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:12 | INFO | Rank 0 | Train Epoch: 8 [13696/23491 (58%)]\tLoss: 0.017608\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:12 | INFO | Rank 0 | Train Epoch: 8 [13728/23491 (58%)]\tLoss: 0.095473\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:12 | INFO | Rank 0 | Train Epoch: 8 [13760/23491 (59%)]\tLoss: 0.028742\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:12 | INFO | Rank 0 | Train Epoch: 8 [13792/23491 (59%)]\tLoss: 0.012317\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:13 | INFO | Rank 0 | Train Epoch: 8 [13824/23491 (59%)]\tLoss: 0.013894\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:13 | INFO | Rank 0 | Train Epoch: 8 [13856/23491 (59%)]\tLoss: 0.053947\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:13 | INFO | Rank 0 | Train Epoch: 8 [13888/23491 (59%)]\tLoss: 0.078700\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:13 | INFO | Rank 0 | Train Epoch: 8 [13920/23491 (59%)]\tLoss: 0.055150\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:14 | INFO | Rank 0 | Train Epoch: 8 [13952/23491 (59%)]\tLoss: 0.034019\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:14 | INFO | Rank 0 | Train Epoch: 8 [13984/23491 (60%)]\tLoss: 0.026644\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:14 | INFO | Rank 0 | Train Epoch: 8 [14016/23491 (60%)]\tLoss: 0.001190\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:15 | INFO | Rank 0 | Train Epoch: 8 [14048/23491 (60%)]\tLoss: 0.154673\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:15 | INFO | Rank 0 | Train Epoch: 8 [14080/23491 (60%)]\tLoss: 0.025906\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:15 | INFO | Rank 0 | Train Epoch: 8 [14112/23491 (60%)]\tLoss: 0.016222\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:15 | INFO | Rank 0 | Train Epoch: 8 [14144/23491 (60%)]\tLoss: 0.010304\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:16 | INFO | Rank 0 | Train Epoch: 8 [14176/23491 (60%)]\tLoss: 0.121375\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:16 | INFO | Rank 0 | Train Epoch: 8 [14208/23491 (60%)]\tLoss: 0.013484\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:16 | INFO | Rank 0 | Train Epoch: 8 [14240/23491 (61%)]\tLoss: 0.038193\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:16 | INFO | Rank 0 | Train Epoch: 8 [14272/23491 (61%)]\tLoss: 0.009380\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:17 | INFO | Rank 0 | Train Epoch: 8 [14304/23491 (61%)]\tLoss: 0.055747\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:17 | INFO | Rank 0 | Train Epoch: 8 [14336/23491 (61%)]\tLoss: 0.011347\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:17 | INFO | Rank 0 | Train Epoch: 8 [14368/23491 (61%)]\tLoss: 0.097387\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:17 | INFO | Rank 0 | Train Epoch: 8 [14400/23491 (61%)]\tLoss: 0.046631\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:18 | INFO | Rank 0 | Train Epoch: 8 [14432/23491 (61%)]\tLoss: 0.111487\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:18 | INFO | Rank 0 | Train Epoch: 8 [14464/23491 (62%)]\tLoss: 0.077223\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:18 | INFO | Rank 0 | Train Epoch: 8 [14496/23491 (62%)]\tLoss: 0.154221\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:19 | INFO | Rank 0 | Train Epoch: 8 [14528/23491 (62%)]\tLoss: 0.023013\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:19 | INFO | Rank 0 | Train Epoch: 8 [14560/23491 (62%)]\tLoss: 0.072111\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:19 | INFO | Rank 0 | Train Epoch: 8 [14592/23491 (62%)]\tLoss: 0.101265\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:19 | INFO | Rank 0 | Train Epoch: 8 [14624/23491 (62%)]\tLoss: 0.050979\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:20 | INFO | Rank 0 | Train Epoch: 8 [14656/23491 (62%)]\tLoss: 0.035910\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:20 | INFO | Rank 0 | Train Epoch: 8 [14688/23491 (63%)]\tLoss: 0.036378\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:20 | INFO | Rank 0 | Train Epoch: 8 [14720/23491 (63%)]\tLoss: 0.020066\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:20 | INFO | Rank 0 | Train Epoch: 8 [14752/23491 (63%)]\tLoss: 0.050993\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:21 | INFO | Rank 0 | Train Epoch: 8 [14784/23491 (63%)]\tLoss: 0.206574\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:21 | INFO | Rank 0 | Train Epoch: 8 [14816/23491 (63%)]\tLoss: 0.022051\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:21 | INFO | Rank 0 | Train Epoch: 8 [14848/23491 (63%)]\tLoss: 0.175833\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:21 | INFO | Rank 0 | Train Epoch: 8 [14880/23491 (63%)]\tLoss: 0.003544\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:22 | INFO | Rank 0 | Train Epoch: 8 [14912/23491 (63%)]\tLoss: 0.068108\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:22 | INFO | Rank 0 | Train Epoch: 8 [14944/23491 (64%)]\tLoss: 0.023945\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:22 | INFO | Rank 0 | Train Epoch: 8 [14976/23491 (64%)]\tLoss: 0.072057\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:23 | INFO | Rank 0 | Train Epoch: 8 [15008/23491 (64%)]\tLoss: 0.043007\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:23 | INFO | Rank 0 | Train Epoch: 8 [15040/23491 (64%)]\tLoss: 0.031899\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:23 | INFO | Rank 0 | Train Epoch: 8 [15072/23491 (64%)]\tLoss: 0.107620\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:23 | INFO | Rank 0 | Train Epoch: 8 [15104/23491 (64%)]\tLoss: 0.045518\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:24 | INFO | Rank 0 | Train Epoch: 8 [15136/23491 (64%)]\tLoss: 0.031516\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:24 | INFO | Rank 0 | Train Epoch: 8 [15168/23491 (65%)]\tLoss: 0.005805\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:24 | INFO | Rank 0 | Train Epoch: 8 [15200/23491 (65%)]\tLoss: 0.025578\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:24 | INFO | Rank 0 | Train Epoch: 8 [15232/23491 (65%)]\tLoss: 0.031401\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:25 | INFO | Rank 0 | Train Epoch: 8 [15264/23491 (65%)]\tLoss: 0.041889\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:25 | INFO | Rank 0 | Train Epoch: 8 [15296/23491 (65%)]\tLoss: 0.161807\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:25 | INFO | Rank 0 | Train Epoch: 8 [15328/23491 (65%)]\tLoss: 0.075140\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:25 | INFO | Rank 0 | Train Epoch: 8 [15360/23491 (65%)]\tLoss: 0.002870\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:26 | INFO | Rank 0 | Train Epoch: 8 [15392/23491 (66%)]\tLoss: 0.109396\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:26 | INFO | Rank 0 | Train Epoch: 8 [15424/23491 (66%)]\tLoss: 0.111510\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:26 | INFO | Rank 0 | Train Epoch: 8 [15456/23491 (66%)]\tLoss: 0.144237\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:27 | INFO | Rank 0 | Train Epoch: 8 [15488/23491 (66%)]\tLoss: 0.074292\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:27 | INFO | Rank 0 | Train Epoch: 8 [15520/23491 (66%)]\tLoss: 0.029884\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:27 | INFO | Rank 0 | Train Epoch: 8 [15552/23491 (66%)]\tLoss: 0.069617\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:27 | INFO | Rank 0 | Train Epoch: 8 [15584/23491 (66%)]\tLoss: 0.016476\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:28 | INFO | Rank 0 | Train Epoch: 8 [15616/23491 (66%)]\tLoss: 0.033015\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:28 | INFO | Rank 0 | Train Epoch: 8 [15648/23491 (67%)]\tLoss: 0.070329\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:28 | INFO | Rank 0 | Train Epoch: 8 [15680/23491 (67%)]\tLoss: 0.017818\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:28 | INFO | Rank 0 | Train Epoch: 8 [15712/23491 (67%)]\tLoss: 0.036315\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:29 | INFO | Rank 0 | Train Epoch: 8 [15744/23491 (67%)]\tLoss: 0.010754\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:29 | INFO | Rank 0 | Train Epoch: 8 [15776/23491 (67%)]\tLoss: 0.075704\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:29 | INFO | Rank 0 | Train Epoch: 8 [15808/23491 (67%)]\tLoss: 0.066388\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:29 | INFO | Rank 0 | Train Epoch: 8 [15840/23491 (67%)]\tLoss: 0.013080\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:30 | INFO | Rank 0 | Train Epoch: 8 [15872/23491 (68%)]\tLoss: 0.074998\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:30 | INFO | Rank 0 | Train Epoch: 8 [15904/23491 (68%)]\tLoss: 0.066194\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:30 | INFO | Rank 0 | Train Epoch: 8 [15936/23491 (68%)]\tLoss: 0.080065\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:31 | INFO | Rank 0 | Train Epoch: 8 [15968/23491 (68%)]\tLoss: 0.105194\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:31 | INFO | Rank 0 | Train Epoch: 8 [16000/23491 (68%)]\tLoss: 0.006119\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:31 | INFO | Rank 0 | Train Epoch: 8 [16032/23491 (68%)]\tLoss: 0.020254\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:31 | INFO | Rank 0 | Train Epoch: 8 [16064/23491 (68%)]\tLoss: 0.090033\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:32 | INFO | Rank 0 | Train Epoch: 8 [16096/23491 (69%)]\tLoss: 0.048133\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:32 | INFO | Rank 0 | Train Epoch: 8 [16128/23491 (69%)]\tLoss: 0.011564\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:32 | INFO | Rank 0 | Train Epoch: 8 [16160/23491 (69%)]\tLoss: 0.061880\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:32 | INFO | Rank 0 | Train Epoch: 8 [16192/23491 (69%)]\tLoss: 0.117969\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:33 | INFO | Rank 0 | Train Epoch: 8 [16224/23491 (69%)]\tLoss: 0.119956\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:33 | INFO | Rank 0 | Train Epoch: 8 [16256/23491 (69%)]\tLoss: 0.106786\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:33 | INFO | Rank 0 | Train Epoch: 8 [16288/23491 (69%)]\tLoss: 0.045741\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:33 | INFO | Rank 0 | Train Epoch: 8 [16320/23491 (69%)]\tLoss: 0.028909\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:34 | INFO | Rank 0 | Train Epoch: 8 [16352/23491 (70%)]\tLoss: 0.006315\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:34 | INFO | Rank 0 | Train Epoch: 8 [16384/23491 (70%)]\tLoss: 0.197381\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:34 | INFO | Rank 0 | Train Epoch: 8 [16416/23491 (70%)]\tLoss: 0.140507\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:35 | INFO | Rank 0 | Train Epoch: 8 [16448/23491 (70%)]\tLoss: 0.026293\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:35 | INFO | Rank 0 | Train Epoch: 8 [16480/23491 (70%)]\tLoss: 0.051758\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:35 | INFO | Rank 0 | Train Epoch: 8 [16512/23491 (70%)]\tLoss: 0.007734\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:35 | INFO | Rank 0 | Train Epoch: 8 [16544/23491 (70%)]\tLoss: 0.010572\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:36 | INFO | Rank 0 | Train Epoch: 8 [16576/23491 (71%)]\tLoss: 0.007741\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:36 | INFO | Rank 0 | Train Epoch: 8 [16608/23491 (71%)]\tLoss: 0.045494\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:36 | INFO | Rank 0 | Train Epoch: 8 [16640/23491 (71%)]\tLoss: 0.133340\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:36 | INFO | Rank 0 | Train Epoch: 8 [16672/23491 (71%)]\tLoss: 0.116148\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:37 | INFO | Rank 0 | Train Epoch: 8 [16704/23491 (71%)]\tLoss: 0.166805\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:37 | INFO | Rank 0 | Train Epoch: 8 [16736/23491 (71%)]\tLoss: 0.002006\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:37 | INFO | Rank 0 | Train Epoch: 8 [16768/23491 (71%)]\tLoss: 0.014957\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:37 | INFO | Rank 0 | Train Epoch: 8 [16800/23491 (72%)]\tLoss: 0.008332\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:38 | INFO | Rank 0 | Train Epoch: 8 [16832/23491 (72%)]\tLoss: 0.001546\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:38 | INFO | Rank 0 | Train Epoch: 8 [16864/23491 (72%)]\tLoss: 0.091574\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:38 | INFO | Rank 0 | Train Epoch: 8 [16896/23491 (72%)]\tLoss: 0.079996\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:39 | INFO | Rank 0 | Train Epoch: 8 [16928/23491 (72%)]\tLoss: 0.105901\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:39 | INFO | Rank 0 | Train Epoch: 8 [16960/23491 (72%)]\tLoss: 0.021286\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:39 | INFO | Rank 0 | Train Epoch: 8 [16992/23491 (72%)]\tLoss: 0.026758\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:39 | INFO | Rank 0 | Train Epoch: 8 [17024/23491 (72%)]\tLoss: 0.218482\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:40 | INFO | Rank 0 | Train Epoch: 8 [17056/23491 (73%)]\tLoss: 0.046599\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:40 | INFO | Rank 0 | Train Epoch: 8 [17088/23491 (73%)]\tLoss: 0.130420\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:40 | INFO | Rank 0 | Train Epoch: 8 [17120/23491 (73%)]\tLoss: 0.027765\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:40 | INFO | Rank 0 | Train Epoch: 8 [17152/23491 (73%)]\tLoss: 0.005145\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:41 | INFO | Rank 0 | Train Epoch: 8 [17184/23491 (73%)]\tLoss: 0.076597\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:41 | INFO | Rank 0 | Train Epoch: 8 [17216/23491 (73%)]\tLoss: 0.012374\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:41 | INFO | Rank 0 | Train Epoch: 8 [17248/23491 (73%)]\tLoss: 0.043051\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:41 | INFO | Rank 0 | Train Epoch: 8 [17280/23491 (74%)]\tLoss: 0.058050\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:42 | INFO | Rank 0 | Train Epoch: 8 [17312/23491 (74%)]\tLoss: 0.003771\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:42 | INFO | Rank 0 | Train Epoch: 8 [17344/23491 (74%)]\tLoss: 0.158159\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:42 | INFO | Rank 0 | Train Epoch: 8 [17376/23491 (74%)]\tLoss: 0.081045\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:43 | INFO | Rank 0 | Train Epoch: 8 [17408/23491 (74%)]\tLoss: 0.190546\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:43 | INFO | Rank 0 | Train Epoch: 8 [17440/23491 (74%)]\tLoss: 0.055397\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:43 | INFO | Rank 0 | Train Epoch: 8 [17472/23491 (74%)]\tLoss: 0.014966\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:43 | INFO | Rank 0 | Train Epoch: 8 [17504/23491 (75%)]\tLoss: 0.023505\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:44 | INFO | Rank 0 | Train Epoch: 8 [17536/23491 (75%)]\tLoss: 0.004577\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:44 | INFO | Rank 0 | Train Epoch: 8 [17568/23491 (75%)]\tLoss: 0.133429\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:44 | INFO | Rank 0 | Train Epoch: 8 [17600/23491 (75%)]\tLoss: 0.008733\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000004\tlogit_scale 4.542\n",
      "2022-11-08,05:58:44 | INFO | Rank 0 | Train Epoch: 8 [17632/23491 (75%)]\tLoss: 0.087815\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:45 | INFO | Rank 0 | Train Epoch: 8 [17664/23491 (75%)]\tLoss: 0.039025\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:45 | INFO | Rank 0 | Train Epoch: 8 [17696/23491 (75%)]\tLoss: 0.004627\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:45 | INFO | Rank 0 | Train Epoch: 8 [17728/23491 (75%)]\tLoss: 0.157606\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:45 | INFO | Rank 0 | Train Epoch: 8 [17760/23491 (76%)]\tLoss: 0.017874\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:46 | INFO | Rank 0 | Train Epoch: 8 [17792/23491 (76%)]\tLoss: 0.054703\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:46 | INFO | Rank 0 | Train Epoch: 8 [17824/23491 (76%)]\tLoss: 0.021270\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:46 | INFO | Rank 0 | Train Epoch: 8 [17856/23491 (76%)]\tLoss: 0.088070\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:46 | INFO | Rank 0 | Train Epoch: 8 [17888/23491 (76%)]\tLoss: 0.044459\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:47 | INFO | Rank 0 | Train Epoch: 8 [17920/23491 (76%)]\tLoss: 0.094046\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:47 | INFO | Rank 0 | Train Epoch: 8 [17952/23491 (76%)]\tLoss: 0.090422\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:47 | INFO | Rank 0 | Train Epoch: 8 [17984/23491 (77%)]\tLoss: 0.090012\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:48 | INFO | Rank 0 | Train Epoch: 8 [18016/23491 (77%)]\tLoss: 0.081669\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:48 | INFO | Rank 0 | Train Epoch: 8 [18048/23491 (77%)]\tLoss: 0.037321\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:48 | INFO | Rank 0 | Train Epoch: 8 [18080/23491 (77%)]\tLoss: 0.072944\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:48 | INFO | Rank 0 | Train Epoch: 8 [18112/23491 (77%)]\tLoss: 0.085102\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:49 | INFO | Rank 0 | Train Epoch: 8 [18144/23491 (77%)]\tLoss: 0.091699\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:49 | INFO | Rank 0 | Train Epoch: 8 [18176/23491 (77%)]\tLoss: 0.009707\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:49 | INFO | Rank 0 | Train Epoch: 8 [18208/23491 (78%)]\tLoss: 0.077027\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:49 | INFO | Rank 0 | Train Epoch: 8 [18240/23491 (78%)]\tLoss: 0.048504\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:50 | INFO | Rank 0 | Train Epoch: 8 [18272/23491 (78%)]\tLoss: 0.071677\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:50 | INFO | Rank 0 | Train Epoch: 8 [18304/23491 (78%)]\tLoss: 0.109949\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:50 | INFO | Rank 0 | Train Epoch: 8 [18336/23491 (78%)]\tLoss: 0.074480\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:50 | INFO | Rank 0 | Train Epoch: 8 [18368/23491 (78%)]\tLoss: 0.109568\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:51 | INFO | Rank 0 | Train Epoch: 8 [18400/23491 (78%)]\tLoss: 0.058556\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:51 | INFO | Rank 0 | Train Epoch: 8 [18432/23491 (78%)]\tLoss: 0.070593\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:51 | INFO | Rank 0 | Train Epoch: 8 [18464/23491 (79%)]\tLoss: 0.054382\tData (t) 0.055\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:52 | INFO | Rank 0 | Train Epoch: 8 [18496/23491 (79%)]\tLoss: 0.098690\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:52 | INFO | Rank 0 | Train Epoch: 8 [18528/23491 (79%)]\tLoss: 0.035023\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:52 | INFO | Rank 0 | Train Epoch: 8 [18560/23491 (79%)]\tLoss: 0.045326\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:52 | INFO | Rank 0 | Train Epoch: 8 [18592/23491 (79%)]\tLoss: 0.162794\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:53 | INFO | Rank 0 | Train Epoch: 8 [18624/23491 (79%)]\tLoss: 0.034300\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:53 | INFO | Rank 0 | Train Epoch: 8 [18656/23491 (79%)]\tLoss: 0.119625\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:53 | INFO | Rank 0 | Train Epoch: 8 [18688/23491 (80%)]\tLoss: 0.128921\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:53 | INFO | Rank 0 | Train Epoch: 8 [18720/23491 (80%)]\tLoss: 0.070038\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:54 | INFO | Rank 0 | Train Epoch: 8 [18752/23491 (80%)]\tLoss: 0.044649\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:54 | INFO | Rank 0 | Train Epoch: 8 [18784/23491 (80%)]\tLoss: 0.113840\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:54 | INFO | Rank 0 | Train Epoch: 8 [18816/23491 (80%)]\tLoss: 0.104741\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:54 | INFO | Rank 0 | Train Epoch: 8 [18848/23491 (80%)]\tLoss: 0.042787\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:55 | INFO | Rank 0 | Train Epoch: 8 [18880/23491 (80%)]\tLoss: 0.015305\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:55 | INFO | Rank 0 | Train Epoch: 8 [18912/23491 (81%)]\tLoss: 0.021479\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:55 | INFO | Rank 0 | Train Epoch: 8 [18944/23491 (81%)]\tLoss: 0.039861\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:56 | INFO | Rank 0 | Train Epoch: 8 [18976/23491 (81%)]\tLoss: 0.117632\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:56 | INFO | Rank 0 | Train Epoch: 8 [19008/23491 (81%)]\tLoss: 0.070024\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:56 | INFO | Rank 0 | Train Epoch: 8 [19040/23491 (81%)]\tLoss: 0.030318\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:56 | INFO | Rank 0 | Train Epoch: 8 [19072/23491 (81%)]\tLoss: 0.047258\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:57 | INFO | Rank 0 | Train Epoch: 8 [19104/23491 (81%)]\tLoss: 0.005375\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:57 | INFO | Rank 0 | Train Epoch: 8 [19136/23491 (81%)]\tLoss: 0.052617\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:57 | INFO | Rank 0 | Train Epoch: 8 [19168/23491 (82%)]\tLoss: 0.062443\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:57 | INFO | Rank 0 | Train Epoch: 8 [19200/23491 (82%)]\tLoss: 0.002507\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:58 | INFO | Rank 0 | Train Epoch: 8 [19232/23491 (82%)]\tLoss: 0.014191\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:58 | INFO | Rank 0 | Train Epoch: 8 [19264/23491 (82%)]\tLoss: 0.149270\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:58 | INFO | Rank 0 | Train Epoch: 8 [19296/23491 (82%)]\tLoss: 0.011794\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:58 | INFO | Rank 0 | Train Epoch: 8 [19328/23491 (82%)]\tLoss: 0.028314\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:59 | INFO | Rank 0 | Train Epoch: 8 [19360/23491 (82%)]\tLoss: 0.045531\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:59 | INFO | Rank 0 | Train Epoch: 8 [19392/23491 (83%)]\tLoss: 0.056210\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:58:59 | INFO | Rank 0 | Train Epoch: 8 [19424/23491 (83%)]\tLoss: 0.109953\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:00 | INFO | Rank 0 | Train Epoch: 8 [19456/23491 (83%)]\tLoss: 0.061181\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:00 | INFO | Rank 0 | Train Epoch: 8 [19488/23491 (83%)]\tLoss: 0.018498\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:00 | INFO | Rank 0 | Train Epoch: 8 [19520/23491 (83%)]\tLoss: 0.032859\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:00 | INFO | Rank 0 | Train Epoch: 8 [19552/23491 (83%)]\tLoss: 0.020278\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:01 | INFO | Rank 0 | Train Epoch: 8 [19584/23491 (83%)]\tLoss: 0.005731\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:01 | INFO | Rank 0 | Train Epoch: 8 [19616/23491 (84%)]\tLoss: 0.058283\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:01 | INFO | Rank 0 | Train Epoch: 8 [19648/23491 (84%)]\tLoss: 0.016620\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:01 | INFO | Rank 0 | Train Epoch: 8 [19680/23491 (84%)]\tLoss: 0.083821\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:02 | INFO | Rank 0 | Train Epoch: 8 [19712/23491 (84%)]\tLoss: 0.031107\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:02 | INFO | Rank 0 | Train Epoch: 8 [19744/23491 (84%)]\tLoss: 0.027619\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:02 | INFO | Rank 0 | Train Epoch: 8 [19776/23491 (84%)]\tLoss: 0.052987\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:02 | INFO | Rank 0 | Train Epoch: 8 [19808/23491 (84%)]\tLoss: 0.083506\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:03 | INFO | Rank 0 | Train Epoch: 8 [19840/23491 (84%)]\tLoss: 0.100846\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:03 | INFO | Rank 0 | Train Epoch: 8 [19872/23491 (85%)]\tLoss: 0.024975\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:03 | INFO | Rank 0 | Train Epoch: 8 [19904/23491 (85%)]\tLoss: 0.010280\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:04 | INFO | Rank 0 | Train Epoch: 8 [19936/23491 (85%)]\tLoss: 0.029381\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:04 | INFO | Rank 0 | Train Epoch: 8 [19968/23491 (85%)]\tLoss: 0.034597\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:04 | INFO | Rank 0 | Train Epoch: 8 [20000/23491 (85%)]\tLoss: 0.084214\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:04 | INFO | Rank 0 | Train Epoch: 8 [20032/23491 (85%)]\tLoss: 0.067602\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:05 | INFO | Rank 0 | Train Epoch: 8 [20064/23491 (85%)]\tLoss: 0.059971\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:05 | INFO | Rank 0 | Train Epoch: 8 [20096/23491 (86%)]\tLoss: 0.171832\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:05 | INFO | Rank 0 | Train Epoch: 8 [20128/23491 (86%)]\tLoss: 0.004945\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:05 | INFO | Rank 0 | Train Epoch: 8 [20160/23491 (86%)]\tLoss: 0.157195\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:06 | INFO | Rank 0 | Train Epoch: 8 [20192/23491 (86%)]\tLoss: 0.058609\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:06 | INFO | Rank 0 | Train Epoch: 8 [20224/23491 (86%)]\tLoss: 0.088844\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:06 | INFO | Rank 0 | Train Epoch: 8 [20256/23491 (86%)]\tLoss: 0.126369\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:06 | INFO | Rank 0 | Train Epoch: 8 [20288/23491 (86%)]\tLoss: 0.068000\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:07 | INFO | Rank 0 | Train Epoch: 8 [20320/23491 (87%)]\tLoss: 0.049079\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:07 | INFO | Rank 0 | Train Epoch: 8 [20352/23491 (87%)]\tLoss: 0.005422\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:07 | INFO | Rank 0 | Train Epoch: 8 [20384/23491 (87%)]\tLoss: 0.081960\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:08 | INFO | Rank 0 | Train Epoch: 8 [20416/23491 (87%)]\tLoss: 0.056203\tData (t) 0.055\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:08 | INFO | Rank 0 | Train Epoch: 8 [20448/23491 (87%)]\tLoss: 0.033957\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:08 | INFO | Rank 0 | Train Epoch: 8 [20480/23491 (87%)]\tLoss: 0.051229\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:08 | INFO | Rank 0 | Train Epoch: 8 [20512/23491 (87%)]\tLoss: 0.004840\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:09 | INFO | Rank 0 | Train Epoch: 8 [20544/23491 (87%)]\tLoss: 0.102310\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:09 | INFO | Rank 0 | Train Epoch: 8 [20576/23491 (88%)]\tLoss: 0.049531\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:09 | INFO | Rank 0 | Train Epoch: 8 [20608/23491 (88%)]\tLoss: 0.029981\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:09 | INFO | Rank 0 | Train Epoch: 8 [20640/23491 (88%)]\tLoss: 0.082829\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:10 | INFO | Rank 0 | Train Epoch: 8 [20672/23491 (88%)]\tLoss: 0.047330\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:10 | INFO | Rank 0 | Train Epoch: 8 [20704/23491 (88%)]\tLoss: 0.046753\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:10 | INFO | Rank 0 | Train Epoch: 8 [20736/23491 (88%)]\tLoss: 0.022326\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:10 | INFO | Rank 0 | Train Epoch: 8 [20768/23491 (88%)]\tLoss: 0.042600\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:11 | INFO | Rank 0 | Train Epoch: 8 [20800/23491 (89%)]\tLoss: 0.015770\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:11 | INFO | Rank 0 | Train Epoch: 8 [20832/23491 (89%)]\tLoss: 0.094920\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:11 | INFO | Rank 0 | Train Epoch: 8 [20864/23491 (89%)]\tLoss: 0.050311\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:12 | INFO | Rank 0 | Train Epoch: 8 [20896/23491 (89%)]\tLoss: 0.019997\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:12 | INFO | Rank 0 | Train Epoch: 8 [20928/23491 (89%)]\tLoss: 0.012096\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:12 | INFO | Rank 0 | Train Epoch: 8 [20960/23491 (89%)]\tLoss: 0.071929\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:12 | INFO | Rank 0 | Train Epoch: 8 [20992/23491 (89%)]\tLoss: 0.075603\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:13 | INFO | Rank 0 | Train Epoch: 8 [21024/23491 (90%)]\tLoss: 0.034804\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:13 | INFO | Rank 0 | Train Epoch: 8 [21056/23491 (90%)]\tLoss: 0.045566\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:13 | INFO | Rank 0 | Train Epoch: 8 [21088/23491 (90%)]\tLoss: 0.095709\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:13 | INFO | Rank 0 | Train Epoch: 8 [21120/23491 (90%)]\tLoss: 0.006531\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:14 | INFO | Rank 0 | Train Epoch: 8 [21152/23491 (90%)]\tLoss: 0.039118\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:14 | INFO | Rank 0 | Train Epoch: 8 [21184/23491 (90%)]\tLoss: 0.011381\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:14 | INFO | Rank 0 | Train Epoch: 8 [21216/23491 (90%)]\tLoss: 0.008362\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:14 | INFO | Rank 0 | Train Epoch: 8 [21248/23491 (90%)]\tLoss: 0.046253\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:15 | INFO | Rank 0 | Train Epoch: 8 [21280/23491 (91%)]\tLoss: 0.043742\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:15 | INFO | Rank 0 | Train Epoch: 8 [21312/23491 (91%)]\tLoss: 0.111028\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:15 | INFO | Rank 0 | Train Epoch: 8 [21344/23491 (91%)]\tLoss: 0.026156\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:16 | INFO | Rank 0 | Train Epoch: 8 [21376/23491 (91%)]\tLoss: 0.008224\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:16 | INFO | Rank 0 | Train Epoch: 8 [21408/23491 (91%)]\tLoss: 0.068926\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:16 | INFO | Rank 0 | Train Epoch: 8 [21440/23491 (91%)]\tLoss: 0.046178\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:16 | INFO | Rank 0 | Train Epoch: 8 [21472/23491 (91%)]\tLoss: 0.085929\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:17 | INFO | Rank 0 | Train Epoch: 8 [21504/23491 (92%)]\tLoss: 0.045571\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:17 | INFO | Rank 0 | Train Epoch: 8 [21536/23491 (92%)]\tLoss: 0.010564\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:17 | INFO | Rank 0 | Train Epoch: 8 [21568/23491 (92%)]\tLoss: 0.185244\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:17 | INFO | Rank 0 | Train Epoch: 8 [21600/23491 (92%)]\tLoss: 0.032460\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:18 | INFO | Rank 0 | Train Epoch: 8 [21632/23491 (92%)]\tLoss: 0.048568\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:18 | INFO | Rank 0 | Train Epoch: 8 [21664/23491 (92%)]\tLoss: 0.049042\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:18 | INFO | Rank 0 | Train Epoch: 8 [21696/23491 (92%)]\tLoss: 0.080642\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:18 | INFO | Rank 0 | Train Epoch: 8 [21728/23491 (93%)]\tLoss: 0.068919\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:19 | INFO | Rank 0 | Train Epoch: 8 [21760/23491 (93%)]\tLoss: 0.057212\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:19 | INFO | Rank 0 | Train Epoch: 8 [21792/23491 (93%)]\tLoss: 0.044268\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:19 | INFO | Rank 0 | Train Epoch: 8 [21824/23491 (93%)]\tLoss: 0.047457\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:20 | INFO | Rank 0 | Train Epoch: 8 [21856/23491 (93%)]\tLoss: 0.098413\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:20 | INFO | Rank 0 | Train Epoch: 8 [21888/23491 (93%)]\tLoss: 0.008194\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:20 | INFO | Rank 0 | Train Epoch: 8 [21920/23491 (93%)]\tLoss: 0.105931\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:20 | INFO | Rank 0 | Train Epoch: 8 [21952/23491 (93%)]\tLoss: 0.041121\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:21 | INFO | Rank 0 | Train Epoch: 8 [21984/23491 (94%)]\tLoss: 0.109737\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:21 | INFO | Rank 0 | Train Epoch: 8 [22016/23491 (94%)]\tLoss: 0.003682\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:21 | INFO | Rank 0 | Train Epoch: 8 [22048/23491 (94%)]\tLoss: 0.049993\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:21 | INFO | Rank 0 | Train Epoch: 8 [22080/23491 (94%)]\tLoss: 0.002053\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:22 | INFO | Rank 0 | Train Epoch: 8 [22112/23491 (94%)]\tLoss: 0.035544\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:22 | INFO | Rank 0 | Train Epoch: 8 [22144/23491 (94%)]\tLoss: 0.027152\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:22 | INFO | Rank 0 | Train Epoch: 8 [22176/23491 (94%)]\tLoss: 0.045036\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:22 | INFO | Rank 0 | Train Epoch: 8 [22208/23491 (95%)]\tLoss: 0.003802\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000003\tlogit_scale 4.542\n",
      "2022-11-08,05:59:23 | INFO | Rank 0 | Train Epoch: 8 [22240/23491 (95%)]\tLoss: 0.149310\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:23 | INFO | Rank 0 | Train Epoch: 8 [22272/23491 (95%)]\tLoss: 0.045288\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:23 | INFO | Rank 0 | Train Epoch: 8 [22304/23491 (95%)]\tLoss: 0.139279\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:23 | INFO | Rank 0 | Train Epoch: 8 [22336/23491 (95%)]\tLoss: 0.092482\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:24 | INFO | Rank 0 | Train Epoch: 8 [22368/23491 (95%)]\tLoss: 0.002572\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:24 | INFO | Rank 0 | Train Epoch: 8 [22400/23491 (95%)]\tLoss: 0.030719\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:24 | INFO | Rank 0 | Train Epoch: 8 [22432/23491 (96%)]\tLoss: 0.003720\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:25 | INFO | Rank 0 | Train Epoch: 8 [22464/23491 (96%)]\tLoss: 0.034807\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:25 | INFO | Rank 0 | Train Epoch: 8 [22496/23491 (96%)]\tLoss: 0.030100\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:25 | INFO | Rank 0 | Train Epoch: 8 [22528/23491 (96%)]\tLoss: 0.067632\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:25 | INFO | Rank 0 | Train Epoch: 8 [22560/23491 (96%)]\tLoss: 0.096393\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:26 | INFO | Rank 0 | Train Epoch: 8 [22592/23491 (96%)]\tLoss: 0.141507\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:26 | INFO | Rank 0 | Train Epoch: 8 [22624/23491 (96%)]\tLoss: 0.040431\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:26 | INFO | Rank 0 | Train Epoch: 8 [22656/23491 (96%)]\tLoss: 0.012264\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:26 | INFO | Rank 0 | Train Epoch: 8 [22688/23491 (97%)]\tLoss: 0.048260\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:27 | INFO | Rank 0 | Train Epoch: 8 [22720/23491 (97%)]\tLoss: 0.044616\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:27 | INFO | Rank 0 | Train Epoch: 8 [22752/23491 (97%)]\tLoss: 0.007272\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:27 | INFO | Rank 0 | Train Epoch: 8 [22784/23491 (97%)]\tLoss: 0.009070\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:27 | INFO | Rank 0 | Train Epoch: 8 [22816/23491 (97%)]\tLoss: 0.098674\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:28 | INFO | Rank 0 | Train Epoch: 8 [22848/23491 (97%)]\tLoss: 0.204996\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:28 | INFO | Rank 0 | Train Epoch: 8 [22880/23491 (97%)]\tLoss: 0.034048\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:28 | INFO | Rank 0 | Train Epoch: 8 [22912/23491 (98%)]\tLoss: 0.004045\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:29 | INFO | Rank 0 | Train Epoch: 8 [22944/23491 (98%)]\tLoss: 0.242102\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:29 | INFO | Rank 0 | Train Epoch: 8 [22976/23491 (98%)]\tLoss: 0.028677\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:29 | INFO | Rank 0 | Train Epoch: 8 [23008/23491 (98%)]\tLoss: 0.056745\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:29 | INFO | Rank 0 | Train Epoch: 8 [23040/23491 (98%)]\tLoss: 0.058158\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:30 | INFO | Rank 0 | Train Epoch: 8 [23072/23491 (98%)]\tLoss: 0.078067\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:30 | INFO | Rank 0 | Train Epoch: 8 [23104/23491 (98%)]\tLoss: 0.120742\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:30 | INFO | Rank 0 | Train Epoch: 8 [23136/23491 (99%)]\tLoss: 0.129450\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:30 | INFO | Rank 0 | Train Epoch: 8 [23168/23491 (99%)]\tLoss: 0.063614\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:31 | INFO | Rank 0 | Train Epoch: 8 [23200/23491 (99%)]\tLoss: 0.006606\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:31 | INFO | Rank 0 | Train Epoch: 8 [23232/23491 (99%)]\tLoss: 0.065528\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:31 | INFO | Rank 0 | Train Epoch: 8 [23264/23491 (99%)]\tLoss: 0.125854\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:31 | INFO | Rank 0 | Train Epoch: 8 [23296/23491 (99%)]\tLoss: 0.070828\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:32 | INFO | Rank 0 | Train Epoch: 8 [23328/23491 (99%)]\tLoss: 0.076987\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:32 | INFO | Rank 0 | Train Epoch: 8 [23360/23491 (99%)]\tLoss: 0.058144\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:32 | INFO | Rank 0 | Train Epoch: 8 [23392/23491 (100%)]\tLoss: 0.110719\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:33 | INFO | Rank 0 | Train Epoch: 8 [23424/23491 (100%)]\tLoss: 0.005732\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,05:59:33 | INFO | Rank 0 | Train Epoch: 8 [23456/23491 (100%)]\tLoss: 0.011876\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "  0%|                                                   | 0/386 [00:00<?, ?it/s]2022-11-08,05:59:33 | INFO | Rank 0 | Begin to eval epoch: 9...\n",
      "100%|█████████████████████████████████████████| 386/386 [00:46<00:00,  8.36it/s]\n",
      "2022-11-08,06:00:19 | INFO | Rank 0 | Eval Epoch: 9 val_loss: 3.2305\tepoch: 9.0000\tnum_elements: 12328.0000\n",
      "2022-11-08,06:00:19 | INFO | Rank 0 | Start epoch 9\n",
      "2022-11-08,06:00:19 | INFO | Rank 0 | Train Epoch: 9 [0/23491 (0%)]\tLoss: 0.007234\tData (t) 0.035\tBatch (t) 0.248\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:20 | INFO | Rank 0 | Train Epoch: 9 [32/23491 (0%)]\tLoss: 0.027687\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:20 | INFO | Rank 0 | Train Epoch: 9 [64/23491 (0%)]\tLoss: 0.037670\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:20 | INFO | Rank 0 | Train Epoch: 9 [96/23491 (0%)]\tLoss: 0.000656\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:20 | INFO | Rank 0 | Train Epoch: 9 [128/23491 (1%)]\tLoss: 0.005411\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:21 | INFO | Rank 0 | Train Epoch: 9 [160/23491 (1%)]\tLoss: 0.039011\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:21 | INFO | Rank 0 | Train Epoch: 9 [192/23491 (1%)]\tLoss: 0.051102\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:21 | INFO | Rank 0 | Train Epoch: 9 [224/23491 (1%)]\tLoss: 0.059824\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:21 | INFO | Rank 0 | Train Epoch: 9 [256/23491 (1%)]\tLoss: 0.130526\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:22 | INFO | Rank 0 | Train Epoch: 9 [288/23491 (1%)]\tLoss: 0.016560\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:22 | INFO | Rank 0 | Train Epoch: 9 [320/23491 (1%)]\tLoss: 0.096689\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:22 | INFO | Rank 0 | Train Epoch: 9 [352/23491 (1%)]\tLoss: 0.114500\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:22 | INFO | Rank 0 | Train Epoch: 9 [384/23491 (2%)]\tLoss: 0.007390\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:23 | INFO | Rank 0 | Train Epoch: 9 [416/23491 (2%)]\tLoss: 0.077857\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:23 | INFO | Rank 0 | Train Epoch: 9 [448/23491 (2%)]\tLoss: 0.049486\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:23 | INFO | Rank 0 | Train Epoch: 9 [480/23491 (2%)]\tLoss: 0.025631\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:24 | INFO | Rank 0 | Train Epoch: 9 [512/23491 (2%)]\tLoss: 0.012853\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:24 | INFO | Rank 0 | Train Epoch: 9 [544/23491 (2%)]\tLoss: 0.039941\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:24 | INFO | Rank 0 | Train Epoch: 9 [576/23491 (2%)]\tLoss: 0.014762\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:24 | INFO | Rank 0 | Train Epoch: 9 [608/23491 (3%)]\tLoss: 0.103439\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:25 | INFO | Rank 0 | Train Epoch: 9 [640/23491 (3%)]\tLoss: 0.136406\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:25 | INFO | Rank 0 | Train Epoch: 9 [672/23491 (3%)]\tLoss: 0.008823\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:25 | INFO | Rank 0 | Train Epoch: 9 [704/23491 (3%)]\tLoss: 0.013537\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:25 | INFO | Rank 0 | Train Epoch: 9 [736/23491 (3%)]\tLoss: 0.007545\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:26 | INFO | Rank 0 | Train Epoch: 9 [768/23491 (3%)]\tLoss: 0.034224\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:26 | INFO | Rank 0 | Train Epoch: 9 [800/23491 (3%)]\tLoss: 0.020966\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:26 | INFO | Rank 0 | Train Epoch: 9 [832/23491 (4%)]\tLoss: 0.052413\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:26 | INFO | Rank 0 | Train Epoch: 9 [864/23491 (4%)]\tLoss: 0.028906\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:27 | INFO | Rank 0 | Train Epoch: 9 [896/23491 (4%)]\tLoss: 0.044444\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:27 | INFO | Rank 0 | Train Epoch: 9 [928/23491 (4%)]\tLoss: 0.102613\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:27 | INFO | Rank 0 | Train Epoch: 9 [960/23491 (4%)]\tLoss: 0.005658\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:28 | INFO | Rank 0 | Train Epoch: 9 [992/23491 (4%)]\tLoss: 0.004697\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:28 | INFO | Rank 0 | Train Epoch: 9 [1024/23491 (4%)]\tLoss: 0.121206\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:28 | INFO | Rank 0 | Train Epoch: 9 [1056/23491 (4%)]\tLoss: 0.031927\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:28 | INFO | Rank 0 | Train Epoch: 9 [1088/23491 (5%)]\tLoss: 0.004200\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:29 | INFO | Rank 0 | Train Epoch: 9 [1120/23491 (5%)]\tLoss: 0.008433\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:29 | INFO | Rank 0 | Train Epoch: 9 [1152/23491 (5%)]\tLoss: 0.067023\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:29 | INFO | Rank 0 | Train Epoch: 9 [1184/23491 (5%)]\tLoss: 0.022647\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:29 | INFO | Rank 0 | Train Epoch: 9 [1216/23491 (5%)]\tLoss: 0.028751\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:30 | INFO | Rank 0 | Train Epoch: 9 [1248/23491 (5%)]\tLoss: 0.211419\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:30 | INFO | Rank 0 | Train Epoch: 9 [1280/23491 (5%)]\tLoss: 0.005288\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:30 | INFO | Rank 0 | Train Epoch: 9 [1312/23491 (6%)]\tLoss: 0.057817\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:30 | INFO | Rank 0 | Train Epoch: 9 [1344/23491 (6%)]\tLoss: 0.051516\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:31 | INFO | Rank 0 | Train Epoch: 9 [1376/23491 (6%)]\tLoss: 0.005901\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:31 | INFO | Rank 0 | Train Epoch: 9 [1408/23491 (6%)]\tLoss: 0.008604\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:31 | INFO | Rank 0 | Train Epoch: 9 [1440/23491 (6%)]\tLoss: 0.020716\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:32 | INFO | Rank 0 | Train Epoch: 9 [1472/23491 (6%)]\tLoss: 0.063699\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:32 | INFO | Rank 0 | Train Epoch: 9 [1504/23491 (6%)]\tLoss: 0.156751\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:32 | INFO | Rank 0 | Train Epoch: 9 [1536/23491 (7%)]\tLoss: 0.079055\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:32 | INFO | Rank 0 | Train Epoch: 9 [1568/23491 (7%)]\tLoss: 0.064252\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:33 | INFO | Rank 0 | Train Epoch: 9 [1600/23491 (7%)]\tLoss: 0.025748\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:33 | INFO | Rank 0 | Train Epoch: 9 [1632/23491 (7%)]\tLoss: 0.083564\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:33 | INFO | Rank 0 | Train Epoch: 9 [1664/23491 (7%)]\tLoss: 0.005270\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:33 | INFO | Rank 0 | Train Epoch: 9 [1696/23491 (7%)]\tLoss: 0.147144\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:34 | INFO | Rank 0 | Train Epoch: 9 [1728/23491 (7%)]\tLoss: 0.013199\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:34 | INFO | Rank 0 | Train Epoch: 9 [1760/23491 (7%)]\tLoss: 0.008784\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:34 | INFO | Rank 0 | Train Epoch: 9 [1792/23491 (8%)]\tLoss: 0.087811\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:34 | INFO | Rank 0 | Train Epoch: 9 [1824/23491 (8%)]\tLoss: 0.026724\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:35 | INFO | Rank 0 | Train Epoch: 9 [1856/23491 (8%)]\tLoss: 0.156410\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:35 | INFO | Rank 0 | Train Epoch: 9 [1888/23491 (8%)]\tLoss: 0.009340\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:35 | INFO | Rank 0 | Train Epoch: 9 [1920/23491 (8%)]\tLoss: 0.015049\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:36 | INFO | Rank 0 | Train Epoch: 9 [1952/23491 (8%)]\tLoss: 0.054037\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:36 | INFO | Rank 0 | Train Epoch: 9 [1984/23491 (8%)]\tLoss: 0.017751\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:36 | INFO | Rank 0 | Train Epoch: 9 [2016/23491 (9%)]\tLoss: 0.006433\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:36 | INFO | Rank 0 | Train Epoch: 9 [2048/23491 (9%)]\tLoss: 0.006903\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:37 | INFO | Rank 0 | Train Epoch: 9 [2080/23491 (9%)]\tLoss: 0.029453\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:37 | INFO | Rank 0 | Train Epoch: 9 [2112/23491 (9%)]\tLoss: 0.070613\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:37 | INFO | Rank 0 | Train Epoch: 9 [2144/23491 (9%)]\tLoss: 0.008261\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:37 | INFO | Rank 0 | Train Epoch: 9 [2176/23491 (9%)]\tLoss: 0.023398\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:38 | INFO | Rank 0 | Train Epoch: 9 [2208/23491 (9%)]\tLoss: 0.002313\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:38 | INFO | Rank 0 | Train Epoch: 9 [2240/23491 (10%)]\tLoss: 0.005901\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:38 | INFO | Rank 0 | Train Epoch: 9 [2272/23491 (10%)]\tLoss: 0.069230\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:38 | INFO | Rank 0 | Train Epoch: 9 [2304/23491 (10%)]\tLoss: 0.070182\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:39 | INFO | Rank 0 | Train Epoch: 9 [2336/23491 (10%)]\tLoss: 0.021109\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:39 | INFO | Rank 0 | Train Epoch: 9 [2368/23491 (10%)]\tLoss: 0.025121\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:39 | INFO | Rank 0 | Train Epoch: 9 [2400/23491 (10%)]\tLoss: 0.002840\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:40 | INFO | Rank 0 | Train Epoch: 9 [2432/23491 (10%)]\tLoss: 0.082642\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:40 | INFO | Rank 0 | Train Epoch: 9 [2464/23491 (10%)]\tLoss: 0.028412\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:40 | INFO | Rank 0 | Train Epoch: 9 [2496/23491 (11%)]\tLoss: 0.050038\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:40 | INFO | Rank 0 | Train Epoch: 9 [2528/23491 (11%)]\tLoss: 0.029720\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:41 | INFO | Rank 0 | Train Epoch: 9 [2560/23491 (11%)]\tLoss: 0.075192\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:41 | INFO | Rank 0 | Train Epoch: 9 [2592/23491 (11%)]\tLoss: 0.014536\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:41 | INFO | Rank 0 | Train Epoch: 9 [2624/23491 (11%)]\tLoss: 0.038413\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:41 | INFO | Rank 0 | Train Epoch: 9 [2656/23491 (11%)]\tLoss: 0.030263\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:42 | INFO | Rank 0 | Train Epoch: 9 [2688/23491 (11%)]\tLoss: 0.050688\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:42 | INFO | Rank 0 | Train Epoch: 9 [2720/23491 (12%)]\tLoss: 0.141039\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:42 | INFO | Rank 0 | Train Epoch: 9 [2752/23491 (12%)]\tLoss: 0.037836\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:42 | INFO | Rank 0 | Train Epoch: 9 [2784/23491 (12%)]\tLoss: 0.051221\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:43 | INFO | Rank 0 | Train Epoch: 9 [2816/23491 (12%)]\tLoss: 0.010327\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:43 | INFO | Rank 0 | Train Epoch: 9 [2848/23491 (12%)]\tLoss: 0.167043\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:43 | INFO | Rank 0 | Train Epoch: 9 [2880/23491 (12%)]\tLoss: 0.001744\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:44 | INFO | Rank 0 | Train Epoch: 9 [2912/23491 (12%)]\tLoss: 0.018910\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:44 | INFO | Rank 0 | Train Epoch: 9 [2944/23491 (13%)]\tLoss: 0.001343\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:44 | INFO | Rank 0 | Train Epoch: 9 [2976/23491 (13%)]\tLoss: 0.124203\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:44 | INFO | Rank 0 | Train Epoch: 9 [3008/23491 (13%)]\tLoss: 0.003444\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:45 | INFO | Rank 0 | Train Epoch: 9 [3040/23491 (13%)]\tLoss: 0.012888\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:45 | INFO | Rank 0 | Train Epoch: 9 [3072/23491 (13%)]\tLoss: 0.005648\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:45 | INFO | Rank 0 | Train Epoch: 9 [3104/23491 (13%)]\tLoss: 0.021557\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:45 | INFO | Rank 0 | Train Epoch: 9 [3136/23491 (13%)]\tLoss: 0.122006\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:46 | INFO | Rank 0 | Train Epoch: 9 [3168/23491 (13%)]\tLoss: 0.093779\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:46 | INFO | Rank 0 | Train Epoch: 9 [3200/23491 (14%)]\tLoss: 0.019488\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:46 | INFO | Rank 0 | Train Epoch: 9 [3232/23491 (14%)]\tLoss: 0.039042\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:46 | INFO | Rank 0 | Train Epoch: 9 [3264/23491 (14%)]\tLoss: 0.019564\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:47 | INFO | Rank 0 | Train Epoch: 9 [3296/23491 (14%)]\tLoss: 0.027199\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:47 | INFO | Rank 0 | Train Epoch: 9 [3328/23491 (14%)]\tLoss: 0.044137\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:47 | INFO | Rank 0 | Train Epoch: 9 [3360/23491 (14%)]\tLoss: 0.112368\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:47 | INFO | Rank 0 | Train Epoch: 9 [3392/23491 (14%)]\tLoss: 0.080401\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:48 | INFO | Rank 0 | Train Epoch: 9 [3424/23491 (15%)]\tLoss: 0.008362\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:48 | INFO | Rank 0 | Train Epoch: 9 [3456/23491 (15%)]\tLoss: 0.026220\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:48 | INFO | Rank 0 | Train Epoch: 9 [3488/23491 (15%)]\tLoss: 0.049176\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:49 | INFO | Rank 0 | Train Epoch: 9 [3520/23491 (15%)]\tLoss: 0.032844\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:49 | INFO | Rank 0 | Train Epoch: 9 [3552/23491 (15%)]\tLoss: 0.048500\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:49 | INFO | Rank 0 | Train Epoch: 9 [3584/23491 (15%)]\tLoss: 0.061447\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:49 | INFO | Rank 0 | Train Epoch: 9 [3616/23491 (15%)]\tLoss: 0.044458\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:50 | INFO | Rank 0 | Train Epoch: 9 [3648/23491 (16%)]\tLoss: 0.035449\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:50 | INFO | Rank 0 | Train Epoch: 9 [3680/23491 (16%)]\tLoss: 0.169232\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:50 | INFO | Rank 0 | Train Epoch: 9 [3712/23491 (16%)]\tLoss: 0.063585\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:50 | INFO | Rank 0 | Train Epoch: 9 [3744/23491 (16%)]\tLoss: 0.108472\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:51 | INFO | Rank 0 | Train Epoch: 9 [3776/23491 (16%)]\tLoss: 0.120889\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:51 | INFO | Rank 0 | Train Epoch: 9 [3808/23491 (16%)]\tLoss: 0.165340\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:51 | INFO | Rank 0 | Train Epoch: 9 [3840/23491 (16%)]\tLoss: 0.033906\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:51 | INFO | Rank 0 | Train Epoch: 9 [3872/23491 (16%)]\tLoss: 0.041482\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:52 | INFO | Rank 0 | Train Epoch: 9 [3904/23491 (17%)]\tLoss: 0.046421\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:52 | INFO | Rank 0 | Train Epoch: 9 [3936/23491 (17%)]\tLoss: 0.027203\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:52 | INFO | Rank 0 | Train Epoch: 9 [3968/23491 (17%)]\tLoss: 0.039580\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:53 | INFO | Rank 0 | Train Epoch: 9 [4000/23491 (17%)]\tLoss: 0.047843\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:53 | INFO | Rank 0 | Train Epoch: 9 [4032/23491 (17%)]\tLoss: 0.049185\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:53 | INFO | Rank 0 | Train Epoch: 9 [4064/23491 (17%)]\tLoss: 0.029168\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:53 | INFO | Rank 0 | Train Epoch: 9 [4096/23491 (17%)]\tLoss: 0.162470\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:54 | INFO | Rank 0 | Train Epoch: 9 [4128/23491 (18%)]\tLoss: 0.032997\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:54 | INFO | Rank 0 | Train Epoch: 9 [4160/23491 (18%)]\tLoss: 0.199072\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:54 | INFO | Rank 0 | Train Epoch: 9 [4192/23491 (18%)]\tLoss: 0.033362\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:54 | INFO | Rank 0 | Train Epoch: 9 [4224/23491 (18%)]\tLoss: 0.024875\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:55 | INFO | Rank 0 | Train Epoch: 9 [4256/23491 (18%)]\tLoss: 0.072238\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:55 | INFO | Rank 0 | Train Epoch: 9 [4288/23491 (18%)]\tLoss: 0.054127\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:55 | INFO | Rank 0 | Train Epoch: 9 [4320/23491 (18%)]\tLoss: 0.056307\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000002\tlogit_scale 4.542\n",
      "2022-11-08,06:00:55 | INFO | Rank 0 | Train Epoch: 9 [4352/23491 (19%)]\tLoss: 0.031981\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:00:56 | INFO | Rank 0 | Train Epoch: 9 [4384/23491 (19%)]\tLoss: 0.002072\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:00:56 | INFO | Rank 0 | Train Epoch: 9 [4416/23491 (19%)]\tLoss: 0.024640\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:00:56 | INFO | Rank 0 | Train Epoch: 9 [4448/23491 (19%)]\tLoss: 0.036957\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:00:57 | INFO | Rank 0 | Train Epoch: 9 [4480/23491 (19%)]\tLoss: 0.229074\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:00:57 | INFO | Rank 0 | Train Epoch: 9 [4512/23491 (19%)]\tLoss: 0.104451\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:00:57 | INFO | Rank 0 | Train Epoch: 9 [4544/23491 (19%)]\tLoss: 0.003792\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:00:57 | INFO | Rank 0 | Train Epoch: 9 [4576/23491 (19%)]\tLoss: 0.024738\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:00:58 | INFO | Rank 0 | Train Epoch: 9 [4608/23491 (20%)]\tLoss: 0.034435\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:00:58 | INFO | Rank 0 | Train Epoch: 9 [4640/23491 (20%)]\tLoss: 0.043436\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:00:58 | INFO | Rank 0 | Train Epoch: 9 [4672/23491 (20%)]\tLoss: 0.057010\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:00:58 | INFO | Rank 0 | Train Epoch: 9 [4704/23491 (20%)]\tLoss: 0.024061\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:00:59 | INFO | Rank 0 | Train Epoch: 9 [4736/23491 (20%)]\tLoss: 0.003694\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:00:59 | INFO | Rank 0 | Train Epoch: 9 [4768/23491 (20%)]\tLoss: 0.105240\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:00:59 | INFO | Rank 0 | Train Epoch: 9 [4800/23491 (20%)]\tLoss: 0.041752\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:00:59 | INFO | Rank 0 | Train Epoch: 9 [4832/23491 (21%)]\tLoss: 0.062443\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:00 | INFO | Rank 0 | Train Epoch: 9 [4864/23491 (21%)]\tLoss: 0.045005\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:00 | INFO | Rank 0 | Train Epoch: 9 [4896/23491 (21%)]\tLoss: 0.027864\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:00 | INFO | Rank 0 | Train Epoch: 9 [4928/23491 (21%)]\tLoss: 0.034150\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:01 | INFO | Rank 0 | Train Epoch: 9 [4960/23491 (21%)]\tLoss: 0.012183\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:01 | INFO | Rank 0 | Train Epoch: 9 [4992/23491 (21%)]\tLoss: 0.060510\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:01 | INFO | Rank 0 | Train Epoch: 9 [5024/23491 (21%)]\tLoss: 0.041817\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:01 | INFO | Rank 0 | Train Epoch: 9 [5056/23491 (22%)]\tLoss: 0.032779\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:02 | INFO | Rank 0 | Train Epoch: 9 [5088/23491 (22%)]\tLoss: 0.063605\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:02 | INFO | Rank 0 | Train Epoch: 9 [5120/23491 (22%)]\tLoss: 0.000325\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:02 | INFO | Rank 0 | Train Epoch: 9 [5152/23491 (22%)]\tLoss: 0.051857\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:02 | INFO | Rank 0 | Train Epoch: 9 [5184/23491 (22%)]\tLoss: 0.071632\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:03 | INFO | Rank 0 | Train Epoch: 9 [5216/23491 (22%)]\tLoss: 0.017660\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:03 | INFO | Rank 0 | Train Epoch: 9 [5248/23491 (22%)]\tLoss: 0.012884\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:03 | INFO | Rank 0 | Train Epoch: 9 [5280/23491 (22%)]\tLoss: 0.005418\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:03 | INFO | Rank 0 | Train Epoch: 9 [5312/23491 (23%)]\tLoss: 0.027159\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:04 | INFO | Rank 0 | Train Epoch: 9 [5344/23491 (23%)]\tLoss: 0.070462\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:04 | INFO | Rank 0 | Train Epoch: 9 [5376/23491 (23%)]\tLoss: 0.117232\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:04 | INFO | Rank 0 | Train Epoch: 9 [5408/23491 (23%)]\tLoss: 0.043681\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:04 | INFO | Rank 0 | Train Epoch: 9 [5440/23491 (23%)]\tLoss: 0.087472\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:05 | INFO | Rank 0 | Train Epoch: 9 [5472/23491 (23%)]\tLoss: 0.014709\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:05 | INFO | Rank 0 | Train Epoch: 9 [5504/23491 (23%)]\tLoss: 0.042316\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:05 | INFO | Rank 0 | Train Epoch: 9 [5536/23491 (24%)]\tLoss: 0.083795\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:06 | INFO | Rank 0 | Train Epoch: 9 [5568/23491 (24%)]\tLoss: 0.004874\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:06 | INFO | Rank 0 | Train Epoch: 9 [5600/23491 (24%)]\tLoss: 0.013167\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:06 | INFO | Rank 0 | Train Epoch: 9 [5632/23491 (24%)]\tLoss: 0.063405\tData (t) 0.056\tBatch (t) 0.268\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:06 | INFO | Rank 0 | Train Epoch: 9 [5664/23491 (24%)]\tLoss: 0.159099\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:07 | INFO | Rank 0 | Train Epoch: 9 [5696/23491 (24%)]\tLoss: 0.006835\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:07 | INFO | Rank 0 | Train Epoch: 9 [5728/23491 (24%)]\tLoss: 0.092716\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:07 | INFO | Rank 0 | Train Epoch: 9 [5760/23491 (25%)]\tLoss: 0.144533\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:07 | INFO | Rank 0 | Train Epoch: 9 [5792/23491 (25%)]\tLoss: 0.055152\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:08 | INFO | Rank 0 | Train Epoch: 9 [5824/23491 (25%)]\tLoss: 0.004667\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:08 | INFO | Rank 0 | Train Epoch: 9 [5856/23491 (25%)]\tLoss: 0.030492\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:08 | INFO | Rank 0 | Train Epoch: 9 [5888/23491 (25%)]\tLoss: 0.092566\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:08 | INFO | Rank 0 | Train Epoch: 9 [5920/23491 (25%)]\tLoss: 0.007142\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:09 | INFO | Rank 0 | Train Epoch: 9 [5952/23491 (25%)]\tLoss: 0.089788\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:09 | INFO | Rank 0 | Train Epoch: 9 [5984/23491 (25%)]\tLoss: 0.023809\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:09 | INFO | Rank 0 | Train Epoch: 9 [6016/23491 (26%)]\tLoss: 0.046988\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:10 | INFO | Rank 0 | Train Epoch: 9 [6048/23491 (26%)]\tLoss: 0.078041\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:10 | INFO | Rank 0 | Train Epoch: 9 [6080/23491 (26%)]\tLoss: 0.023486\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:10 | INFO | Rank 0 | Train Epoch: 9 [6112/23491 (26%)]\tLoss: 0.013923\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:10 | INFO | Rank 0 | Train Epoch: 9 [6144/23491 (26%)]\tLoss: 0.061635\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:11 | INFO | Rank 0 | Train Epoch: 9 [6176/23491 (26%)]\tLoss: 0.050710\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:11 | INFO | Rank 0 | Train Epoch: 9 [6208/23491 (26%)]\tLoss: 0.097506\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:11 | INFO | Rank 0 | Train Epoch: 9 [6240/23491 (27%)]\tLoss: 0.026597\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:11 | INFO | Rank 0 | Train Epoch: 9 [6272/23491 (27%)]\tLoss: 0.002384\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:12 | INFO | Rank 0 | Train Epoch: 9 [6304/23491 (27%)]\tLoss: 0.015346\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:12 | INFO | Rank 0 | Train Epoch: 9 [6336/23491 (27%)]\tLoss: 0.013866\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:12 | INFO | Rank 0 | Train Epoch: 9 [6368/23491 (27%)]\tLoss: 0.081743\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:12 | INFO | Rank 0 | Train Epoch: 9 [6400/23491 (27%)]\tLoss: 0.116165\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:13 | INFO | Rank 0 | Train Epoch: 9 [6432/23491 (27%)]\tLoss: 0.170669\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:13 | INFO | Rank 0 | Train Epoch: 9 [6464/23491 (28%)]\tLoss: 0.080412\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:13 | INFO | Rank 0 | Train Epoch: 9 [6496/23491 (28%)]\tLoss: 0.043218\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:14 | INFO | Rank 0 | Train Epoch: 9 [6528/23491 (28%)]\tLoss: 0.021525\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:14 | INFO | Rank 0 | Train Epoch: 9 [6560/23491 (28%)]\tLoss: 0.039142\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:14 | INFO | Rank 0 | Train Epoch: 9 [6592/23491 (28%)]\tLoss: 0.025074\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:14 | INFO | Rank 0 | Train Epoch: 9 [6624/23491 (28%)]\tLoss: 0.048081\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:15 | INFO | Rank 0 | Train Epoch: 9 [6656/23491 (28%)]\tLoss: 0.041880\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:15 | INFO | Rank 0 | Train Epoch: 9 [6688/23491 (28%)]\tLoss: 0.042020\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:15 | INFO | Rank 0 | Train Epoch: 9 [6720/23491 (29%)]\tLoss: 0.001210\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:15 | INFO | Rank 0 | Train Epoch: 9 [6752/23491 (29%)]\tLoss: 0.076606\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:16 | INFO | Rank 0 | Train Epoch: 9 [6784/23491 (29%)]\tLoss: 0.026838\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:16 | INFO | Rank 0 | Train Epoch: 9 [6816/23491 (29%)]\tLoss: 0.002599\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:16 | INFO | Rank 0 | Train Epoch: 9 [6848/23491 (29%)]\tLoss: 0.091137\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:16 | INFO | Rank 0 | Train Epoch: 9 [6880/23491 (29%)]\tLoss: 0.011954\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:17 | INFO | Rank 0 | Train Epoch: 9 [6912/23491 (29%)]\tLoss: 0.013203\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:17 | INFO | Rank 0 | Train Epoch: 9 [6944/23491 (30%)]\tLoss: 0.003342\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:17 | INFO | Rank 0 | Train Epoch: 9 [6976/23491 (30%)]\tLoss: 0.075367\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:18 | INFO | Rank 0 | Train Epoch: 9 [7008/23491 (30%)]\tLoss: 0.012814\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:18 | INFO | Rank 0 | Train Epoch: 9 [7040/23491 (30%)]\tLoss: 0.078202\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:18 | INFO | Rank 0 | Train Epoch: 9 [7072/23491 (30%)]\tLoss: 0.036519\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:18 | INFO | Rank 0 | Train Epoch: 9 [7104/23491 (30%)]\tLoss: 0.012804\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:19 | INFO | Rank 0 | Train Epoch: 9 [7136/23491 (30%)]\tLoss: 0.091025\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:19 | INFO | Rank 0 | Train Epoch: 9 [7168/23491 (31%)]\tLoss: 0.109523\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:19 | INFO | Rank 0 | Train Epoch: 9 [7200/23491 (31%)]\tLoss: 0.056538\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:19 | INFO | Rank 0 | Train Epoch: 9 [7232/23491 (31%)]\tLoss: 0.000577\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:20 | INFO | Rank 0 | Train Epoch: 9 [7264/23491 (31%)]\tLoss: 0.012144\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:20 | INFO | Rank 0 | Train Epoch: 9 [7296/23491 (31%)]\tLoss: 0.047271\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:20 | INFO | Rank 0 | Train Epoch: 9 [7328/23491 (31%)]\tLoss: 0.126324\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:20 | INFO | Rank 0 | Train Epoch: 9 [7360/23491 (31%)]\tLoss: 0.021653\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:21 | INFO | Rank 0 | Train Epoch: 9 [7392/23491 (31%)]\tLoss: 0.002571\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:21 | INFO | Rank 0 | Train Epoch: 9 [7424/23491 (32%)]\tLoss: 0.032744\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:21 | INFO | Rank 0 | Train Epoch: 9 [7456/23491 (32%)]\tLoss: 0.009652\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:22 | INFO | Rank 0 | Train Epoch: 9 [7488/23491 (32%)]\tLoss: 0.008420\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:22 | INFO | Rank 0 | Train Epoch: 9 [7520/23491 (32%)]\tLoss: 0.003515\tData (t) 0.055\tBatch (t) 0.270\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:22 | INFO | Rank 0 | Train Epoch: 9 [7552/23491 (32%)]\tLoss: 0.011924\tData (t) 0.055\tBatch (t) 0.269\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:22 | INFO | Rank 0 | Train Epoch: 9 [7584/23491 (32%)]\tLoss: 0.041834\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:23 | INFO | Rank 0 | Train Epoch: 9 [7616/23491 (32%)]\tLoss: 0.132053\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:23 | INFO | Rank 0 | Train Epoch: 9 [7648/23491 (33%)]\tLoss: 0.060582\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:23 | INFO | Rank 0 | Train Epoch: 9 [7680/23491 (33%)]\tLoss: 0.002704\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:23 | INFO | Rank 0 | Train Epoch: 9 [7712/23491 (33%)]\tLoss: 0.054827\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:24 | INFO | Rank 0 | Train Epoch: 9 [7744/23491 (33%)]\tLoss: 0.013172\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:24 | INFO | Rank 0 | Train Epoch: 9 [7776/23491 (33%)]\tLoss: 0.062079\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:24 | INFO | Rank 0 | Train Epoch: 9 [7808/23491 (33%)]\tLoss: 0.060846\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:24 | INFO | Rank 0 | Train Epoch: 9 [7840/23491 (33%)]\tLoss: 0.014295\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:25 | INFO | Rank 0 | Train Epoch: 9 [7872/23491 (34%)]\tLoss: 0.002490\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:25 | INFO | Rank 0 | Train Epoch: 9 [7904/23491 (34%)]\tLoss: 0.030523\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:25 | INFO | Rank 0 | Train Epoch: 9 [7936/23491 (34%)]\tLoss: 0.018683\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:26 | INFO | Rank 0 | Train Epoch: 9 [7968/23491 (34%)]\tLoss: 0.045211\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:26 | INFO | Rank 0 | Train Epoch: 9 [8000/23491 (34%)]\tLoss: 0.003887\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:26 | INFO | Rank 0 | Train Epoch: 9 [8032/23491 (34%)]\tLoss: 0.023658\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:26 | INFO | Rank 0 | Train Epoch: 9 [8064/23491 (34%)]\tLoss: 0.088007\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:27 | INFO | Rank 0 | Train Epoch: 9 [8096/23491 (34%)]\tLoss: 0.063903\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:27 | INFO | Rank 0 | Train Epoch: 9 [8128/23491 (35%)]\tLoss: 0.138022\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:27 | INFO | Rank 0 | Train Epoch: 9 [8160/23491 (35%)]\tLoss: 0.052334\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:27 | INFO | Rank 0 | Train Epoch: 9 [8192/23491 (35%)]\tLoss: 0.002006\tData (t) 0.055\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:28 | INFO | Rank 0 | Train Epoch: 9 [8224/23491 (35%)]\tLoss: 0.013812\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:28 | INFO | Rank 0 | Train Epoch: 9 [8256/23491 (35%)]\tLoss: 0.069531\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:28 | INFO | Rank 0 | Train Epoch: 9 [8288/23491 (35%)]\tLoss: 0.134367\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:28 | INFO | Rank 0 | Train Epoch: 9 [8320/23491 (35%)]\tLoss: 0.097189\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:29 | INFO | Rank 0 | Train Epoch: 9 [8352/23491 (36%)]\tLoss: 0.130870\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:29 | INFO | Rank 0 | Train Epoch: 9 [8384/23491 (36%)]\tLoss: 0.026493\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:29 | INFO | Rank 0 | Train Epoch: 9 [8416/23491 (36%)]\tLoss: 0.050307\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:30 | INFO | Rank 0 | Train Epoch: 9 [8448/23491 (36%)]\tLoss: 0.023990\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:30 | INFO | Rank 0 | Train Epoch: 9 [8480/23491 (36%)]\tLoss: 0.009525\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:30 | INFO | Rank 0 | Train Epoch: 9 [8512/23491 (36%)]\tLoss: 0.018941\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:30 | INFO | Rank 0 | Train Epoch: 9 [8544/23491 (36%)]\tLoss: 0.022833\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:31 | INFO | Rank 0 | Train Epoch: 9 [8576/23491 (37%)]\tLoss: 0.024958\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:31 | INFO | Rank 0 | Train Epoch: 9 [8608/23491 (37%)]\tLoss: 0.031922\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:31 | INFO | Rank 0 | Train Epoch: 9 [8640/23491 (37%)]\tLoss: 0.030097\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:31 | INFO | Rank 0 | Train Epoch: 9 [8672/23491 (37%)]\tLoss: 0.144409\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:32 | INFO | Rank 0 | Train Epoch: 9 [8704/23491 (37%)]\tLoss: 0.051052\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:32 | INFO | Rank 0 | Train Epoch: 9 [8736/23491 (37%)]\tLoss: 0.008951\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:32 | INFO | Rank 0 | Train Epoch: 9 [8768/23491 (37%)]\tLoss: 0.058813\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:32 | INFO | Rank 0 | Train Epoch: 9 [8800/23491 (37%)]\tLoss: 0.019747\tData (t) 0.054\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:33 | INFO | Rank 0 | Train Epoch: 9 [8832/23491 (38%)]\tLoss: 0.120349\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:33 | INFO | Rank 0 | Train Epoch: 9 [8864/23491 (38%)]\tLoss: 0.110887\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:33 | INFO | Rank 0 | Train Epoch: 9 [8896/23491 (38%)]\tLoss: 0.022052\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:34 | INFO | Rank 0 | Train Epoch: 9 [8928/23491 (38%)]\tLoss: 0.061220\tData (t) 0.054\tBatch (t) 0.268\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:34 | INFO | Rank 0 | Train Epoch: 9 [8960/23491 (38%)]\tLoss: 0.027286\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:34 | INFO | Rank 0 | Train Epoch: 9 [8992/23491 (38%)]\tLoss: 0.043367\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:34 | INFO | Rank 0 | Train Epoch: 9 [9024/23491 (38%)]\tLoss: 0.070911\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:35 | INFO | Rank 0 | Train Epoch: 9 [9056/23491 (39%)]\tLoss: 0.014035\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:35 | INFO | Rank 0 | Train Epoch: 9 [9088/23491 (39%)]\tLoss: 0.039738\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:35 | INFO | Rank 0 | Train Epoch: 9 [9120/23491 (39%)]\tLoss: 0.099227\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:35 | INFO | Rank 0 | Train Epoch: 9 [9152/23491 (39%)]\tLoss: 0.058388\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:36 | INFO | Rank 0 | Train Epoch: 9 [9184/23491 (39%)]\tLoss: 0.075360\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:36 | INFO | Rank 0 | Train Epoch: 9 [9216/23491 (39%)]\tLoss: 0.031862\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:36 | INFO | Rank 0 | Train Epoch: 9 [9248/23491 (39%)]\tLoss: 0.048385\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:36 | INFO | Rank 0 | Train Epoch: 9 [9280/23491 (40%)]\tLoss: 0.034269\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:37 | INFO | Rank 0 | Train Epoch: 9 [9312/23491 (40%)]\tLoss: 0.072211\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:37 | INFO | Rank 0 | Train Epoch: 9 [9344/23491 (40%)]\tLoss: 0.007443\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:37 | INFO | Rank 0 | Train Epoch: 9 [9376/23491 (40%)]\tLoss: 0.005812\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:38 | INFO | Rank 0 | Train Epoch: 9 [9408/23491 (40%)]\tLoss: 0.046271\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:38 | INFO | Rank 0 | Train Epoch: 9 [9440/23491 (40%)]\tLoss: 0.120429\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:38 | INFO | Rank 0 | Train Epoch: 9 [9472/23491 (40%)]\tLoss: 0.023314\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:38 | INFO | Rank 0 | Train Epoch: 9 [9504/23491 (40%)]\tLoss: 0.027548\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:39 | INFO | Rank 0 | Train Epoch: 9 [9536/23491 (41%)]\tLoss: 0.000810\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:39 | INFO | Rank 0 | Train Epoch: 9 [9568/23491 (41%)]\tLoss: 0.133277\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:39 | INFO | Rank 0 | Train Epoch: 9 [9600/23491 (41%)]\tLoss: 0.080055\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:39 | INFO | Rank 0 | Train Epoch: 9 [9632/23491 (41%)]\tLoss: 0.008585\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:40 | INFO | Rank 0 | Train Epoch: 9 [9664/23491 (41%)]\tLoss: 0.082425\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:40 | INFO | Rank 0 | Train Epoch: 9 [9696/23491 (41%)]\tLoss: 0.027852\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:40 | INFO | Rank 0 | Train Epoch: 9 [9728/23491 (41%)]\tLoss: 0.090063\tData (t) 0.053\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:40 | INFO | Rank 0 | Train Epoch: 9 [9760/23491 (42%)]\tLoss: 0.013784\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:41 | INFO | Rank 0 | Train Epoch: 9 [9792/23491 (42%)]\tLoss: 0.014223\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:41 | INFO | Rank 0 | Train Epoch: 9 [9824/23491 (42%)]\tLoss: 0.014725\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:41 | INFO | Rank 0 | Train Epoch: 9 [9856/23491 (42%)]\tLoss: 0.124037\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:42 | INFO | Rank 0 | Train Epoch: 9 [9888/23491 (42%)]\tLoss: 0.014276\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:42 | INFO | Rank 0 | Train Epoch: 9 [9920/23491 (42%)]\tLoss: 0.052970\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:42 | INFO | Rank 0 | Train Epoch: 9 [9952/23491 (42%)]\tLoss: 0.061280\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:42 | INFO | Rank 0 | Train Epoch: 9 [9984/23491 (43%)]\tLoss: 0.051581\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:43 | INFO | Rank 0 | Train Epoch: 9 [10016/23491 (43%)]\tLoss: 0.028417\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:43 | INFO | Rank 0 | Train Epoch: 9 [10048/23491 (43%)]\tLoss: 0.057407\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:43 | INFO | Rank 0 | Train Epoch: 9 [10080/23491 (43%)]\tLoss: 0.013210\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:43 | INFO | Rank 0 | Train Epoch: 9 [10112/23491 (43%)]\tLoss: 0.057362\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:44 | INFO | Rank 0 | Train Epoch: 9 [10144/23491 (43%)]\tLoss: 0.021926\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:44 | INFO | Rank 0 | Train Epoch: 9 [10176/23491 (43%)]\tLoss: 0.013853\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:44 | INFO | Rank 0 | Train Epoch: 9 [10208/23491 (43%)]\tLoss: 0.069876\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:44 | INFO | Rank 0 | Train Epoch: 9 [10240/23491 (44%)]\tLoss: 0.001257\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:45 | INFO | Rank 0 | Train Epoch: 9 [10272/23491 (44%)]\tLoss: 0.033378\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:45 | INFO | Rank 0 | Train Epoch: 9 [10304/23491 (44%)]\tLoss: 0.036450\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:45 | INFO | Rank 0 | Train Epoch: 9 [10336/23491 (44%)]\tLoss: 0.011137\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:46 | INFO | Rank 0 | Train Epoch: 9 [10368/23491 (44%)]\tLoss: 0.041299\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:46 | INFO | Rank 0 | Train Epoch: 9 [10400/23491 (44%)]\tLoss: 0.024240\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:46 | INFO | Rank 0 | Train Epoch: 9 [10432/23491 (44%)]\tLoss: 0.063173\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:46 | INFO | Rank 0 | Train Epoch: 9 [10464/23491 (45%)]\tLoss: 0.009580\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:47 | INFO | Rank 0 | Train Epoch: 9 [10496/23491 (45%)]\tLoss: 0.065021\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:47 | INFO | Rank 0 | Train Epoch: 9 [10528/23491 (45%)]\tLoss: 0.005963\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:47 | INFO | Rank 0 | Train Epoch: 9 [10560/23491 (45%)]\tLoss: 0.027932\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:47 | INFO | Rank 0 | Train Epoch: 9 [10592/23491 (45%)]\tLoss: 0.045528\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:48 | INFO | Rank 0 | Train Epoch: 9 [10624/23491 (45%)]\tLoss: 0.022401\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:48 | INFO | Rank 0 | Train Epoch: 9 [10656/23491 (45%)]\tLoss: 0.101511\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:48 | INFO | Rank 0 | Train Epoch: 9 [10688/23491 (46%)]\tLoss: 0.004178\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:48 | INFO | Rank 0 | Train Epoch: 9 [10720/23491 (46%)]\tLoss: 0.015979\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:49 | INFO | Rank 0 | Train Epoch: 9 [10752/23491 (46%)]\tLoss: 0.026051\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:49 | INFO | Rank 0 | Train Epoch: 9 [10784/23491 (46%)]\tLoss: 0.075604\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:49 | INFO | Rank 0 | Train Epoch: 9 [10816/23491 (46%)]\tLoss: 0.046243\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:50 | INFO | Rank 0 | Train Epoch: 9 [10848/23491 (46%)]\tLoss: 0.143273\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:50 | INFO | Rank 0 | Train Epoch: 9 [10880/23491 (46%)]\tLoss: 0.095983\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:50 | INFO | Rank 0 | Train Epoch: 9 [10912/23491 (46%)]\tLoss: 0.059414\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:50 | INFO | Rank 0 | Train Epoch: 9 [10944/23491 (47%)]\tLoss: 0.039636\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:51 | INFO | Rank 0 | Train Epoch: 9 [10976/23491 (47%)]\tLoss: 0.011765\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:51 | INFO | Rank 0 | Train Epoch: 9 [11008/23491 (47%)]\tLoss: 0.011001\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:51 | INFO | Rank 0 | Train Epoch: 9 [11040/23491 (47%)]\tLoss: 0.023896\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:51 | INFO | Rank 0 | Train Epoch: 9 [11072/23491 (47%)]\tLoss: 0.016813\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:52 | INFO | Rank 0 | Train Epoch: 9 [11104/23491 (47%)]\tLoss: 0.018796\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:52 | INFO | Rank 0 | Train Epoch: 9 [11136/23491 (47%)]\tLoss: 0.013981\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:52 | INFO | Rank 0 | Train Epoch: 9 [11168/23491 (48%)]\tLoss: 0.022996\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:52 | INFO | Rank 0 | Train Epoch: 9 [11200/23491 (48%)]\tLoss: 0.140209\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:53 | INFO | Rank 0 | Train Epoch: 9 [11232/23491 (48%)]\tLoss: 0.031040\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:53 | INFO | Rank 0 | Train Epoch: 9 [11264/23491 (48%)]\tLoss: 0.017185\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:53 | INFO | Rank 0 | Train Epoch: 9 [11296/23491 (48%)]\tLoss: 0.004706\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:54 | INFO | Rank 0 | Train Epoch: 9 [11328/23491 (48%)]\tLoss: 0.003469\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:54 | INFO | Rank 0 | Train Epoch: 9 [11360/23491 (48%)]\tLoss: 0.089798\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:54 | INFO | Rank 0 | Train Epoch: 9 [11392/23491 (49%)]\tLoss: 0.049933\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:54 | INFO | Rank 0 | Train Epoch: 9 [11424/23491 (49%)]\tLoss: 0.005038\tData (t) 0.055\tBatch (t) 0.268\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:55 | INFO | Rank 0 | Train Epoch: 9 [11456/23491 (49%)]\tLoss: 0.062638\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:55 | INFO | Rank 0 | Train Epoch: 9 [11488/23491 (49%)]\tLoss: 0.004594\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:55 | INFO | Rank 0 | Train Epoch: 9 [11520/23491 (49%)]\tLoss: 0.036679\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:55 | INFO | Rank 0 | Train Epoch: 9 [11552/23491 (49%)]\tLoss: 0.007053\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:56 | INFO | Rank 0 | Train Epoch: 9 [11584/23491 (49%)]\tLoss: 0.102745\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:56 | INFO | Rank 0 | Train Epoch: 9 [11616/23491 (49%)]\tLoss: 0.058198\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:56 | INFO | Rank 0 | Train Epoch: 9 [11648/23491 (50%)]\tLoss: 0.043439\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:56 | INFO | Rank 0 | Train Epoch: 9 [11680/23491 (50%)]\tLoss: 0.061872\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:57 | INFO | Rank 0 | Train Epoch: 9 [11712/23491 (50%)]\tLoss: 0.105403\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:57 | INFO | Rank 0 | Train Epoch: 9 [11744/23491 (50%)]\tLoss: 0.096825\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:57 | INFO | Rank 0 | Train Epoch: 9 [11776/23491 (50%)]\tLoss: 0.015428\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:58 | INFO | Rank 0 | Train Epoch: 9 [11808/23491 (50%)]\tLoss: 0.002701\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:58 | INFO | Rank 0 | Train Epoch: 9 [11840/23491 (50%)]\tLoss: 0.046747\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:58 | INFO | Rank 0 | Train Epoch: 9 [11872/23491 (51%)]\tLoss: 0.204086\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:58 | INFO | Rank 0 | Train Epoch: 9 [11904/23491 (51%)]\tLoss: 0.006449\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:59 | INFO | Rank 0 | Train Epoch: 9 [11936/23491 (51%)]\tLoss: 0.017716\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:59 | INFO | Rank 0 | Train Epoch: 9 [11968/23491 (51%)]\tLoss: 0.073577\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:59 | INFO | Rank 0 | Train Epoch: 9 [12000/23491 (51%)]\tLoss: 0.081536\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:01:59 | INFO | Rank 0 | Train Epoch: 9 [12032/23491 (51%)]\tLoss: 0.014538\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:02:00 | INFO | Rank 0 | Train Epoch: 9 [12064/23491 (51%)]\tLoss: 0.068515\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:02:00 | INFO | Rank 0 | Train Epoch: 9 [12096/23491 (51%)]\tLoss: 0.093758\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:02:00 | INFO | Rank 0 | Train Epoch: 9 [12128/23491 (52%)]\tLoss: 0.034862\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:02:00 | INFO | Rank 0 | Train Epoch: 9 [12160/23491 (52%)]\tLoss: 0.173781\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:02:01 | INFO | Rank 0 | Train Epoch: 9 [12192/23491 (52%)]\tLoss: 0.065563\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:02:01 | INFO | Rank 0 | Train Epoch: 9 [12224/23491 (52%)]\tLoss: 0.001707\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:02:01 | INFO | Rank 0 | Train Epoch: 9 [12256/23491 (52%)]\tLoss: 0.058829\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:02:01 | INFO | Rank 0 | Train Epoch: 9 [12288/23491 (52%)]\tLoss: 0.076332\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:02:02 | INFO | Rank 0 | Train Epoch: 9 [12320/23491 (52%)]\tLoss: 0.017991\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:02:02 | INFO | Rank 0 | Train Epoch: 9 [12352/23491 (53%)]\tLoss: 0.025299\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:02:02 | INFO | Rank 0 | Train Epoch: 9 [12384/23491 (53%)]\tLoss: 0.041315\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:02:03 | INFO | Rank 0 | Train Epoch: 9 [12416/23491 (53%)]\tLoss: 0.021143\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:02:03 | INFO | Rank 0 | Train Epoch: 9 [12448/23491 (53%)]\tLoss: 0.049313\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000001\tlogit_scale 4.542\n",
      "2022-11-08,06:02:03 | INFO | Rank 0 | Train Epoch: 9 [12480/23491 (53%)]\tLoss: 0.019670\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:03 | INFO | Rank 0 | Train Epoch: 9 [12512/23491 (53%)]\tLoss: 0.084618\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:04 | INFO | Rank 0 | Train Epoch: 9 [12544/23491 (53%)]\tLoss: 0.072168\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:04 | INFO | Rank 0 | Train Epoch: 9 [12576/23491 (54%)]\tLoss: 0.006613\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:04 | INFO | Rank 0 | Train Epoch: 9 [12608/23491 (54%)]\tLoss: 0.012309\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:04 | INFO | Rank 0 | Train Epoch: 9 [12640/23491 (54%)]\tLoss: 0.024927\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:05 | INFO | Rank 0 | Train Epoch: 9 [12672/23491 (54%)]\tLoss: 0.036412\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:05 | INFO | Rank 0 | Train Epoch: 9 [12704/23491 (54%)]\tLoss: 0.053393\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:05 | INFO | Rank 0 | Train Epoch: 9 [12736/23491 (54%)]\tLoss: 0.022479\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:05 | INFO | Rank 0 | Train Epoch: 9 [12768/23491 (54%)]\tLoss: 0.091210\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:06 | INFO | Rank 0 | Train Epoch: 9 [12800/23491 (54%)]\tLoss: 0.088133\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:06 | INFO | Rank 0 | Train Epoch: 9 [12832/23491 (55%)]\tLoss: 0.054151\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:06 | INFO | Rank 0 | Train Epoch: 9 [12864/23491 (55%)]\tLoss: 0.018703\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:07 | INFO | Rank 0 | Train Epoch: 9 [12896/23491 (55%)]\tLoss: 0.025646\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:07 | INFO | Rank 0 | Train Epoch: 9 [12928/23491 (55%)]\tLoss: 0.009288\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:07 | INFO | Rank 0 | Train Epoch: 9 [12960/23491 (55%)]\tLoss: 0.025881\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:07 | INFO | Rank 0 | Train Epoch: 9 [12992/23491 (55%)]\tLoss: 0.086346\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:08 | INFO | Rank 0 | Train Epoch: 9 [13024/23491 (55%)]\tLoss: 0.058458\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:08 | INFO | Rank 0 | Train Epoch: 9 [13056/23491 (56%)]\tLoss: 0.123840\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:08 | INFO | Rank 0 | Train Epoch: 9 [13088/23491 (56%)]\tLoss: 0.145636\tData (t) 0.053\tBatch (t) 0.265\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:08 | INFO | Rank 0 | Train Epoch: 9 [13120/23491 (56%)]\tLoss: 0.186528\tData (t) 0.053\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:09 | INFO | Rank 0 | Train Epoch: 9 [13152/23491 (56%)]\tLoss: 0.019998\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:09 | INFO | Rank 0 | Train Epoch: 9 [13184/23491 (56%)]\tLoss: 0.075035\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:09 | INFO | Rank 0 | Train Epoch: 9 [13216/23491 (56%)]\tLoss: 0.001919\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:09 | INFO | Rank 0 | Train Epoch: 9 [13248/23491 (56%)]\tLoss: 0.003146\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:10 | INFO | Rank 0 | Train Epoch: 9 [13280/23491 (57%)]\tLoss: 0.067566\tData (t) 0.054\tBatch (t) 0.267\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:10 | INFO | Rank 0 | Train Epoch: 9 [13312/23491 (57%)]\tLoss: 0.002288\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:10 | INFO | Rank 0 | Train Epoch: 9 [13344/23491 (57%)]\tLoss: 0.028604\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n",
      "2022-11-08,06:02:11 | INFO | Rank 0 | Train Epoch: 9 [13376/23491 (57%)]\tLoss: 0.030009\tData (t) 0.054\tBatch (t) 0.266\tLR: 0.000000\tlogit_scale 4.542\n"
     ]
    }
   ],
   "source": [
    "!python3 -u src/training/main.py \\\n",
    "    --save-frequency 5 \\\n",
    "    --train-data=\"./data/Multimodal_Retrieval/MR_train_queries_tiny.jsonl\"  \\\n",
    "    --train-img=\"./data/Multimodal_Retrieval/MR_train_imgs.224.npz\"  \\\n",
    "    --val-data=\"./data/Multimodal_Retrieval/MR_valid_queries_tiny.jsonl\"  \\\n",
    "    --val-img=\"./data/Multimodal_Retrieval/MR_valid_imgs.224.npz\"  \\\n",
    "    --clip-weight-path=\"./weights/ViT-B-16.state_dict.pt\" \\\n",
    "    --bert-weight-path=\"./weights/pytorch_model.bin\" \\\n",
    "    --warmup 500 \\\n",
    "    --batch-size=32 \\\n",
    "    --lr=8e-5 \\\n",
    "    --wd=0.001 \\\n",
    "    --epochs=10 \\\n",
    "    --model ViT-B-16 \\\n",
    "    --gpu 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
